{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-17T13:10:49.753578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                  AIVI DATA INTEGRATION - BLOCO 1 v4.1                        ║\n",
    "║              CONFIGURAÇÃO COMPLETA DO AMBIENTE + UX/UI + LOGS                ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║  Versão: 4.1 - Consolidado, Modular, Inteligente                            ║\n",
    "║  Data: 2025-01-15                                                            ║\n",
    "║  Prompt Base: AIVI v4.1 (com UX/UI, Schema Logging, Exploração)             ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║  CONTEÚDO DESTE BLOCO:                                                       ║\n",
    "║    1. Imports e Constantes AIVI 2025                                         ║\n",
    "║    2. Sistema UX/UI com Timer (PARTE 0.10)                                   ║\n",
    "║    3. Log de Campos + Exploração (PARTE 12.3 + 14)                           ║\n",
    "║    4. Regex Patterns para Detecção de Conteúdo                               ║\n",
    "║    5. Validações Não-Destrutivas                                             ║\n",
    "║    6. FileManager Expandido                                                  ║\n",
    "║    7. Inicialização e Teste                                                  ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║  PROTOCOLO BLOCO-A-BLOCO:                                                    ║\n",
    "║    ✅ Execute este bloco                                                     ║\n",
    "║    ✅ Valide todos os outputs                                                ║\n",
    "║    ✅ Teste a GUI (janela de seleção de pasta)                               ║\n",
    "║    ✅ Confirme: \"BLOCO 1 OK\" ou reporte problemas                            ║\n",
    "║    ⏭️  Só então prosseguiremos para BLOCO 2                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 1: IMPORTS E CONFIGURAÇÕES BÁSICAS\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" 🚀 BLOCO 1: CONFIGURAÇÃO COMPLETA DO AMBIENTE\".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# Imports padrão\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Imports para análise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports para GUI\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "# Configurações\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.4f}')\n",
    "\n",
    "print(\"📦 SEÇÃO 1.1: Imports\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   ✅ Bibliotecas padrão: sys, os, json, logging, datetime\")\n",
    "print(\"   ✅ Análise de dados: pandas, numpy\")\n",
    "print(\"   ✅ GUI: tkinter\")\n",
    "print(\"   ✅ Configurações aplicadas\")\n",
    "print()\n",
    "\n",
    "# Verificar versões\n",
    "modulos_carregados = {\n",
    "    'Python': sys.version.split()[0],\n",
    "    'Pandas': pd.__version__,\n",
    "    'NumPy': np.__version__\n",
    "}\n",
    "\n",
    "print(\"📋 Versões:\")\n",
    "for modulo, versao in modulos_carregados.items():\n",
    "    print(f\"   • {modulo}: {versao}\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 2: CONSTANTES AIVI 2025\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"📊 SEÇÃO 1.2: Constantes AIVI 2025\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Constantes principais\n",
    "CONSTANTES_AIVI = {\n",
    "    'ANO_VIGENCIA': 2025,\n",
    "    'VERSAO_SISTEMA': '4.1',\n",
    "    'DATA_ATUALIZACAO': '2025-01-15',\n",
    "\n",
    "    # Parâmetros estatísticos\n",
    "    'PERCENTIL_INFERIOR': 10,\n",
    "    'PERCENTIL_SUPERIOR': 90,\n",
    "    'DESVIOS_PADRAO_BATENTE': 2.5,\n",
    "\n",
    "    # Pesos AIVI\n",
    "    'PESO_CONFORMIDADE': 0.50,\n",
    "    'PESO_SEVERIDADE': 0.30,\n",
    "    'PESO_FREQUENCIA': 0.20,\n",
    "\n",
    "    # Limites de alerta\n",
    "    'LIMITE_CRITICO_PCT': 30.0,\n",
    "    'LIMITE_ALERTA_PCT': 10.0,\n",
    "\n",
    "    # Configurações de análise\n",
    "    'MESES_MINIMO_HISTORICO': 6,\n",
    "    'MESES_IDEAL_HISTORICO': 12,\n",
    "    'CONFIANCA_MINIMA_MAPEAMENTO': 0.80\n",
    "}\n",
    "\n",
    "print(f\"   ✅ Ano de vigência: {CONSTANTES_AIVI['ANO_VIGENCIA']}\")\n",
    "print(f\"   ✅ Versão do sistema: {CONSTANTES_AIVI['VERSAO_SISTEMA']}\")\n",
    "print(f\"   ✅ {len(CONSTANTES_AIVI)} constantes definidas\")\n",
    "print()\n",
    "\n",
    "# Schema AIVI - Campos obrigatórios\n",
    "SCHEMA_AIVI_CAMPOS_OBRIGATORIOS = [\n",
    "    'Período',\n",
    "    'Centro',\n",
    "    'Sigla',\n",
    "    'Cód Grupo de produto',\n",
    "    'Expedição c/ Veículo',\n",
    "    'Variação Interna',\n",
    "    '% VI',\n",
    "    'LI Atual (%)',\n",
    "    'LS Atual (%)'\n",
    "]\n",
    "\n",
    "print(f\"   ✅ Schema AIVI: {len(SCHEMA_AIVI_CAMPOS_OBRIGATORIOS)} campos obrigatórios\")\n",
    "print()\n",
    "\n",
    "# Dicionário de sinônimos expandido\n",
    "DICIONARIO_SINONIMOS = {\n",
    "    'Centro': [\n",
    "        'Centro', 'Código de Centro', 'Cod Centro', 'CódigoCentro',\n",
    "        'Centro Operacional', 'ID Centro', 'Centro_ID', 'CENTRO',\n",
    "        'Cod_Centro', 'Centro_Operacional', 'Plant', 'Planta'\n",
    "    ],\n",
    "\n",
    "    'Sigla': [\n",
    "        'Sigla', 'Sigla de Centro', 'Sigla Centro', 'Sigla Base',\n",
    "        'Base', 'Sigla_Centro', 'SIGLA', 'SiglaBase', 'Sigla_Base',\n",
    "        'Sigla do Centro', 'Nome Base', 'Base Operacional'\n",
    "    ],\n",
    "\n",
    "    'Cód Grupo de produto': [\n",
    "        'Cód Grupo de produto', 'Código Produto', 'Cod Produto',\n",
    "        'Grupo Produto', 'CodGrupoProduto', 'Cód_Grupo_produto',\n",
    "        'PRODUTO', 'Produto_Cod', 'CodGrupo', 'Material Group',\n",
    "        'Grupo de Material', 'Product Group'\n",
    "    ],\n",
    "\n",
    "    'Expedição c/ Veículo': [\n",
    "        'Expedição c/ Veículo', 'Expedição', 'Expedicao',\n",
    "        'Volume Expedido', 'Exped_Veiculo', 'EXPEDICAO', 'Exped',\n",
    "        'Expedicao_Veiculo', 'Volume_Expedido', 'Dispatch Volume',\n",
    "        'Volume Carregado', 'Carregamento'\n",
    "    ],\n",
    "\n",
    "    'Variação Interna': [\n",
    "        'Variação Interna', 'Variacao Interna', 'VI', 'Var Interna',\n",
    "        'VarInt', 'VARIACAO', 'Var_Interna', 'VariacaoInterna',\n",
    "        'Internal Variation', 'Variation'\n",
    "    ],\n",
    "\n",
    "    '% VI': [\n",
    "        '% VI', 'Percentual VI', 'VI %', 'Percentual Variacao Interna',\n",
    "        'Perc VI', 'VI_Percent', 'Variation %'\n",
    "    ],\n",
    "\n",
    "    'LI Atual (%)': [\n",
    "        'LI Atual (%)', 'Limite Inferior', 'LI', 'Lim Inferior',\n",
    "        'Limite_Inferior', 'LIMITE_INF', 'LimInf', 'Lim_Inferior',\n",
    "        'Lower Limit', 'LL'\n",
    "    ],\n",
    "\n",
    "    'LS Atual (%)': [\n",
    "        'LS Atual (%)', 'Limite Superior', 'LS', 'Lim Superior',\n",
    "        'Limite_Superior', 'LIMITE_SUP', 'LimSup', 'Lim_Superior',\n",
    "        'Upper Limit', 'UL'\n",
    "    ],\n",
    "\n",
    "    'Período': [\n",
    "        'Período', 'Periodo', 'Data', 'Data Referencia',\n",
    "        'Mês/Ano', 'Mes Ano', 'Competencia', 'Period', 'Date'\n",
    "    ],\n",
    "\n",
    "    'Mês do exercício': [\n",
    "        'Mês do exercício', 'Mês', 'Mes', 'Mês Exercício',\n",
    "        'MesExercicio', 'MES', 'Mes_Exercicio', 'Mes_Ref', 'Month'\n",
    "    ],\n",
    "\n",
    "    'Ano do documento do material': [\n",
    "        'Ano do documento do material', 'Ano', 'Ano Documento',\n",
    "        'AnoDoc', 'ANO', 'Ano_Documento', 'Ano_Ref', 'Year'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"   ✅ Dicionário de sinônimos: {len(DICIONARIO_SINONIMOS)} campos principais\")\n",
    "print(f\"   ✅ Total de variações mapeadas: {sum(len(v) for v in DICIONARIO_SINONIMOS.values())}\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 3: REGEX PATTERNS PARA DETECÇÃO DE CONTEÚDO\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🔍 SEÇÃO 1.3: Regex Patterns para Detecção de Conteúdo\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "PATTERNS_CONTEUDO = {\n",
    "    # CENTRO: 4 dígitos numéricos como string\n",
    "    'centro': {\n",
    "        'pattern': r'^\\d{4}$',\n",
    "        'description': 'Centro: 4 dígitos',\n",
    "        'exemplo': '1001'\n",
    "    },\n",
    "\n",
    "    # CÓDIGO DE MATERIAL/PRODUTO: formatos xx.xxx.xxx, x.xxx.xxx, xxxxxxxx, xxxxxxx\n",
    "    'codigo_material': {\n",
    "        'pattern': r'^(\\d{1,2}\\.\\d{3}\\.\\d{3}|\\d{7,8})$',\n",
    "        'description': 'Código Material: xx.xxx.xxx ou 7-8 dígitos',\n",
    "        'exemplo': '10.123.456'\n",
    "    },\n",
    "\n",
    "    # CÓDIGO DE GRUPO: pode ter texto com underscore ou números\n",
    "    'codigo_grupo': {\n",
    "        'pattern': r'^([A-Z0-9_]+|\\d{1,2}\\.\\d{3}\\.\\d{3}|\\d{7,8})$',\n",
    "        'description': 'Código Grupo: TEXTO_TEXTO ou numérico',\n",
    "        'exemplo': 'DIESEL_S10'\n",
    "    },\n",
    "\n",
    "    # TRANSPORTE/DOCUMENTO: 10 dígitos\n",
    "    'documento_transporte': {\n",
    "        'pattern': r'^\\d{10}$',\n",
    "        'description': 'Documento Transporte: 10 dígitos',\n",
    "        'exemplo': '1234567890'\n",
    "    },\n",
    "\n",
    "    # PERÍODO/DATA: diversos formatos\n",
    "    'data': {\n",
    "        'pattern': r'^\\d{2}/\\d{2}/\\d{4}$|^\\d{4}-\\d{2}-\\d{2}$|^\\d{1,2}\\.\\d{4}$|^\\d{2}\\.\\d{4}$',\n",
    "        'description': 'Data: dd/mm/yyyy, yyyy-mm-dd ou mm.yyyy',\n",
    "        'exemplo': '01/01/2025'\n",
    "    },\n",
    "\n",
    "    # VALORES NUMÉRICOS: com separadores regionais\n",
    "    'valor_numerico': {\n",
    "        'pattern': r'^-?\\d{1,3}(\\.\\d{3})*(,\\d+)?$|^-?\\d+(,\\d{3})*(\\.\\d+)?$|^-?\\d+(\\.\\d+)?$',\n",
    "        'description': 'Valor: 1.234,56 ou 1,234.56 ou 1234.56',\n",
    "        'exemplo': '1.234,56'\n",
    "    },\n",
    "\n",
    "    # PERCENTUAL\n",
    "    'percentual': {\n",
    "        'pattern': r'^-?\\d+([.,]\\d+)?%?$',\n",
    "        'description': 'Percentual: 12,34% ou 12.34',\n",
    "        'exemplo': '12,34%'\n",
    "    },\n",
    "\n",
    "    # SIGLA BASE: 2-4 letras maiúsculas\n",
    "    'sigla_base': {\n",
    "        'pattern': r'^[A-Z]{2,4}$',\n",
    "        'description': 'Sigla: 2-4 letras maiúsculas',\n",
    "        'exemplo': 'RLAM'\n",
    "    },\n",
    "\n",
    "    # TEXTO GERAL\n",
    "    'texto': {\n",
    "        'pattern': r'^[A-Za-zÀ-ÿ\\s\\-_/]+$',\n",
    "        'description': 'Texto: letras, espaços, hífen',\n",
    "        'exemplo': 'Gasolina Comum'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"   ✅ {len(PATTERNS_CONTEUDO)} patterns definidos\")\n",
    "for tipo, config in list(PATTERNS_CONTEUDO.items())[:3]:\n",
    "    print(f\"      • {tipo}: {config['description']}\")\n",
    "print(f\"      • ... e mais {len(PATTERNS_CONTEUDO) - 3} patterns\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 4: FUNÇÕES AUXILIARES - DETECÇÃO E VALIDAÇÃO\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"⚙️  SEÇÃO 1.4: Funções Auxiliares\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def normalizar_string(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza string para comparação (remove acentos, lowercase, apenas alfanuméricos).\n",
    "\n",
    "    Args:\n",
    "        s: String a normalizar\n",
    "\n",
    "    Returns:\n",
    "        String normalizada\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize('NFKD', str(s))\n",
    "    s = s.encode('ASCII', 'ignore').decode('ASCII')\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z0-9]', '', s)\n",
    "    return s\n",
    "\n",
    "def calcular_similaridade(s1: str, s2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcula similaridade entre duas strings (0.0 a 1.0).\n",
    "\n",
    "    Args:\n",
    "        s1: Primeira string\n",
    "        s2: Segunda string\n",
    "\n",
    "    Returns:\n",
    "        Score de similaridade\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    s1_norm = normalizar_string(s1)\n",
    "    s2_norm = normalizar_string(s2)\n",
    "    return SequenceMatcher(None, s1_norm, s2_norm).ratio()\n",
    "\n",
    "def detectar_tipo_conteudo(valor: str, verbose: bool = False) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detecta tipo de conteúdo usando regex patterns.\n",
    "\n",
    "    Args:\n",
    "        valor: String a analisar\n",
    "        verbose: Se True, mostra detalhes\n",
    "\n",
    "    Returns:\n",
    "        Dict com tipo detectado e confiança\n",
    "    \"\"\"\n",
    "    if pd.isna(valor) or str(valor).strip() == '':\n",
    "        return {'tipo': 'VAZIO', 'confianca': 1.0, 'pattern': None}\n",
    "\n",
    "    valor_str = str(valor).strip()\n",
    "    matches = []\n",
    "\n",
    "    # Testar todos os patterns\n",
    "    for tipo, config in PATTERNS_CONTEUDO.items():\n",
    "        if re.match(config['pattern'], valor_str):\n",
    "            matches.append(tipo)\n",
    "            if verbose:\n",
    "                print(f\"   ✅ Match: {tipo} - {config['description']}\")\n",
    "\n",
    "    if not matches:\n",
    "        return {'tipo': 'DESCONHECIDO', 'confianca': 0.0, 'pattern': None}\n",
    "\n",
    "    # Priorizar mais específico\n",
    "    prioridade = ['centro', 'codigo_material', 'documento_transporte', 'data',\n",
    "                  'percentual', 'valor_numerico', 'sigla_base', 'codigo_grupo', 'texto']\n",
    "\n",
    "    for tipo_prior in prioridade:\n",
    "        if tipo_prior in matches:\n",
    "            return {\n",
    "                'tipo': tipo_prior.upper(),\n",
    "                'confianca': 1.0 if len(matches) == 1 else 0.8,\n",
    "                'pattern': PATTERNS_CONTEUDO[tipo_prior]['pattern'],\n",
    "                'alternativas': [m for m in matches if m != tipo_prior]\n",
    "            }\n",
    "\n",
    "    return {'tipo': matches[0].upper(), 'confianca': 0.7, 'pattern': PATTERNS_CONTEUDO[matches[0]]['pattern']}\n",
    "\n",
    "def analisar_coluna_completa(serie: pd.Series, amostra: int = 100) -> Dict:\n",
    "    \"\"\"\n",
    "    Analisa coluna completa para determinar tipo predominante.\n",
    "\n",
    "    Args:\n",
    "        serie: Série pandas\n",
    "        amostra: Número de valores a analisar\n",
    "\n",
    "    Returns:\n",
    "        Dict com análise completa\n",
    "    \"\"\"\n",
    "    valores_nao_nulos = serie.dropna().astype(str).head(amostra)\n",
    "\n",
    "    if len(valores_nao_nulos) == 0:\n",
    "        return {\n",
    "            'tipo_predominante': 'VAZIO',\n",
    "            'confianca': 0.0,\n",
    "            'tipos_encontrados': {},\n",
    "            'exemplos': []\n",
    "        }\n",
    "\n",
    "    tipos_contagem = {}\n",
    "    exemplos_por_tipo = {}\n",
    "\n",
    "    for valor in valores_nao_nulos:\n",
    "        deteccao = detectar_tipo_conteudo(valor)\n",
    "        tipo = deteccao['tipo']\n",
    "\n",
    "        tipos_contagem[tipo] = tipos_contagem.get(tipo, 0) + 1\n",
    "\n",
    "        if tipo not in exemplos_por_tipo:\n",
    "            exemplos_por_tipo[tipo] = []\n",
    "        if len(exemplos_por_tipo[tipo]) < 3:\n",
    "            exemplos_por_tipo[tipo].append(valor)\n",
    "\n",
    "    tipo_predominante = max(tipos_contagem, key=tipos_contagem.get)\n",
    "    total = len(valores_nao_nulos)\n",
    "    confianca = tipos_contagem[tipo_predominante] / total\n",
    "\n",
    "    return {\n",
    "        'tipo_predominante': tipo_predominante,\n",
    "        'confianca': confianca,\n",
    "        'tipos_encontrados': tipos_contagem,\n",
    "        'exemplos': exemplos_por_tipo.get(tipo_predominante, [])[:3],\n",
    "        'total_analisado': total\n",
    "    }\n",
    "\n",
    "def identificar_linha_cabecalho(df: pd.DataFrame, dicionario_termos: List[str]) -> int:\n",
    "    \"\"\"\n",
    "    Identifica linha de cabeçalho usando dicionário de termos conhecidos.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame bruto\n",
    "        dicionario_termos: Lista de termos que aparecem em cabeçalhos\n",
    "\n",
    "    Returns:\n",
    "        Índice da linha de cabeçalho (ou -1 se não encontrado)\n",
    "    \"\"\"\n",
    "    termos_norm = [normalizar_string(t) for t in dicionario_termos]\n",
    "\n",
    "    for idx in range(min(20, len(df))):\n",
    "        row = df.iloc[idx]\n",
    "        valores_norm = [normalizar_string(str(v)) for v in row if pd.notna(v)]\n",
    "\n",
    "        matches = sum(1 for termo in termos_norm if any(termo in v for v in valores_norm))\n",
    "        pct_match = matches / len(termos_norm) if termos_norm else 0\n",
    "\n",
    "        if pct_match >= 0.5:\n",
    "            return idx\n",
    "\n",
    "    return -1\n",
    "\n",
    "def validar_transformacao(df_antes: pd.DataFrame, df_depois: pd.DataFrame,\n",
    "                         nome_transformacao: str, permitir_reducao: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Valida transformação comparando estados antes/depois.\n",
    "\n",
    "    Args:\n",
    "        df_antes: DataFrame original\n",
    "        df_depois: DataFrame transformado\n",
    "        nome_transformacao: Nome da operação\n",
    "        permitir_reducao: Se True, permite redução de linhas/colunas\n",
    "\n",
    "    Returns:\n",
    "        Dict com resultado da validação\n",
    "    \"\"\"\n",
    "    resultado = {\n",
    "        'nome': nome_transformacao,\n",
    "        'passou': True,\n",
    "        'alertas': [],\n",
    "        'metricas': {}\n",
    "    }\n",
    "\n",
    "    # Linhas\n",
    "    linhas_antes = len(df_antes)\n",
    "    linhas_depois = len(df_depois)\n",
    "    diff_linhas = linhas_depois - linhas_antes\n",
    "\n",
    "    resultado['metricas']['linhas'] = {\n",
    "        'antes': linhas_antes,\n",
    "        'depois': linhas_depois,\n",
    "        'diferenca': diff_linhas\n",
    "    }\n",
    "\n",
    "    if diff_linhas < 0 and not permitir_reducao:\n",
    "        resultado['passou'] = False\n",
    "        resultado['alertas'].append(f\"❌ PERDA DE LINHAS: {abs(diff_linhas):,}\")\n",
    "\n",
    "    # Colunas\n",
    "    colunas_antes = len(df_antes.columns)\n",
    "    colunas_depois = len(df_depois.columns)\n",
    "\n",
    "    resultado['metricas']['colunas'] = {\n",
    "        'antes': colunas_antes,\n",
    "        'depois': colunas_depois,\n",
    "        'diferenca': colunas_depois - colunas_antes\n",
    "    }\n",
    "\n",
    "    # NULLs\n",
    "    nulls_antes = df_antes.isnull().sum().sum()\n",
    "    nulls_depois = df_depois.isnull().sum().sum()\n",
    "\n",
    "    resultado['metricas']['nulls'] = {\n",
    "        'antes': int(nulls_antes),\n",
    "        'depois': int(nulls_depois),\n",
    "        'diferenca': int(nulls_depois - nulls_antes)\n",
    "    }\n",
    "\n",
    "    return resultado\n",
    "\n",
    "def formatar_tabela_resumo(dados: Dict[str, Any], titulo: str = \"RESUMO\") -> None:\n",
    "    \"\"\"\n",
    "    Formata dicionário como tabela imprimível.\n",
    "\n",
    "    Args:\n",
    "        dados: Dicionário com dados\n",
    "        titulo: Título da tabela\n",
    "    \"\"\"\n",
    "    print(f\"\\n╔{'═' * 78}╗\")\n",
    "    print(f\"║ {titulo.center(76)} ║\")\n",
    "    print(f\"╠{'═' * 78}╣\")\n",
    "\n",
    "    for chave, valor in dados.items():\n",
    "        chave_fmt = chave.replace('_', ' ').title().ljust(35)\n",
    "\n",
    "        if isinstance(valor, (int, np.integer)):\n",
    "            valor_fmt = f\"{valor:,}\".rjust(40)\n",
    "        elif isinstance(valor, (float, np.floating)):\n",
    "            valor_fmt = f\"{valor:,.2f}\".rjust(40)\n",
    "        elif isinstance(valor, bool):\n",
    "            valor_fmt = (\"✅ SIM\" if valor else \"❌ NÃO\").rjust(40)\n",
    "        else:\n",
    "            valor_str = str(valor)\n",
    "            if len(valor_str) > 40:\n",
    "                valor_fmt = (valor_str[:37] + \"...\").rjust(40)\n",
    "            else:\n",
    "                valor_fmt = valor_str.rjust(40)\n",
    "\n",
    "        print(f\"║ {chave_fmt} : {valor_fmt} ║\")\n",
    "\n",
    "    print(f\"╚{'═' * 78}╝\")\n",
    "\n",
    "print(\"   ✅ normalizar_string()\")\n",
    "print(\"   ✅ calcular_similaridade()\")\n",
    "print(\"   ✅ detectar_tipo_conteudo()\")\n",
    "print(\"   ✅ analisar_coluna_completa()\")\n",
    "print(\"   ✅ identificar_linha_cabecalho()\")\n",
    "print(\"   ✅ validar_transformacao()\")\n",
    "print(\"   ✅ formatar_tabela_resumo()\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 5: SISTEMA UX/UI COM TIMER (PARTE 0.10)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🎨 SEÇÃO 1.5: Sistema UX/UI com Timer e Memória\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "class DialogoPadraoAIVI:\n",
    "    \"\"\"\n",
    "    Classe base para diálogos interativos com:\n",
    "    - Memória de última escolha\n",
    "    - Timer de 10s com countdown visual\n",
    "    - Botões padronizados\n",
    "    - Logging transparente\n",
    "    \"\"\"\n",
    "\n",
    "    CONFIG_DIR = Path.home() / '.aivi_config'\n",
    "    TIMER_PADRAO = 10\n",
    "\n",
    "    def __init__(self, tipo: str, titulo: str, mensagem: str):\n",
    "        self.tipo = tipo\n",
    "        self.titulo = titulo\n",
    "        self.mensagem = mensagem\n",
    "        self.CONFIG_DIR.mkdir(exist_ok=True)\n",
    "        self.config_file = self.CONFIG_DIR / f'aivi_{tipo}_last.json'\n",
    "\n",
    "    def carregar_ultima_escolha(self) -> Optional[str]:\n",
    "        \"\"\"Carrega última escolha salva.\"\"\"\n",
    "        if self.config_file.exists():\n",
    "            try:\n",
    "                with open(self.config_file, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultima = config.get('last_choice')\n",
    "\n",
    "                # Validar se é caminho e se existe\n",
    "                if self.tipo in ['diretorio', 'arquivo']:\n",
    "                    if ultima and Path(ultima).exists():\n",
    "                        return ultima\n",
    "                    return None\n",
    "                return ultima\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, escolha: str) -> None:\n",
    "        \"\"\"Salva escolha atual.\"\"\"\n",
    "        config = {\n",
    "            'last_choice': str(escolha),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'tipo': self.tipo\n",
    "        }\n",
    "        with open(self.config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def selecionar_diretorio_trabalho() -> Path:\n",
    "    \"\"\"\n",
    "    Seleciona diretório de trabalho com UX/UI padrão:\n",
    "    - Memória de última pasta\n",
    "    - Timer de 10s\n",
    "    - Botões padronizados\n",
    "\n",
    "    Returns:\n",
    "        Path do diretório selecionado\n",
    "    \"\"\"\n",
    "    dialogo = DialogoPadraoAIVI(\n",
    "        'diretorio_trabalho',\n",
    "        'Diretório de Trabalho AIVI',\n",
    "        'Selecione a pasta onde os dados e outputs serão salvos'\n",
    "    )\n",
    "\n",
    "    ultimo_dir = dialogo.carregar_ultima_escolha()\n",
    "\n",
    "    # Criar janela\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Ocultar janela principal\n",
    "\n",
    "    # Se tem última pasta, criar janela com timer\n",
    "    if ultimo_dir:\n",
    "        root.deiconify()\n",
    "        root.title(\"AIVI - Diretório de Trabalho\")\n",
    "        root.geometry(\"600x300\")\n",
    "\n",
    "        # Centralizar\n",
    "        x = (root.winfo_screenwidth() // 2) - 300\n",
    "        y = (root.winfo_screenheight() // 2) - 150\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        resultado = {'path': None, 'cancelado': False, 'timeout': False}\n",
    "        contador = [10]\n",
    "\n",
    "        # Frame\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Título\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Diretório de Trabalho AIVI\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=f\"📂 Última pasta usada:\\n{ultimo_dir}\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E8F5E9',\n",
    "            fg='#2E7D32',\n",
    "            padx=10,\n",
    "            pady=10,\n",
    "            wraplength=550\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        # Timer\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"{contador[0]}s\",\n",
    "            font=('Arial', 20, 'bold'),\n",
    "            fg='#FF4444',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 20))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not resultado['cancelado']:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"{contador[0]}s\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0 and not resultado['cancelado']:\n",
    "                resultado['timeout'] = True\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        # Botões\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=20)\n",
    "\n",
    "        def escolher_nova():\n",
    "            resultado['cancelado'] = True\n",
    "            root.withdraw()\n",
    "            diretorio = filedialog.askdirectory(\n",
    "                title=\"Diretório de Trabalho AIVI\",\n",
    "                initialdir=ultimo_dir\n",
    "            )\n",
    "            resultado['path'] = diretorio if diretorio else ultimo_dir\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['path'] = ultimo_dir\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Escolher Nova Pasta\",\n",
    "            command=escolher_nova,\n",
    "            width=22,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Usar Última Pasta\",\n",
    "            command=usar_ultima,\n",
    "            width=22,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#2196F3',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        # Iniciar timer\n",
    "        root.after(1000, countdown)\n",
    "        root.mainloop()\n",
    "\n",
    "        # Processar resultado\n",
    "        if resultado.get('timeout'):\n",
    "            print(f\"   ⏱️  Timeout (10s) - usando última pasta\")\n",
    "            resultado['path'] = ultimo_dir\n",
    "\n",
    "        if resultado['path']:\n",
    "            dialogo.salvar_escolha(resultado['path'])\n",
    "            return Path(resultado['path'])\n",
    "\n",
    "    # Sem última pasta ou escolher nova\n",
    "    root.withdraw()\n",
    "    diretorio = filedialog.askdirectory(title=\"Diretório de Trabalho AIVI\")\n",
    "\n",
    "    if diretorio:\n",
    "        dialogo.salvar_escolha(diretorio)\n",
    "        print(f\"   ✅ Diretório selecionado: {diretorio}\")\n",
    "        return Path(diretorio)\n",
    "    else:\n",
    "        raise ValueError(\"❌ Nenhum diretório selecionado\")\n",
    "\n",
    "print(\"   ✅ DialogoPadraoAIVI (classe base)\")\n",
    "print(\"   ✅ selecionar_diretorio_trabalho() (com timer + memória)\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 6: FILEMANAGER EXPANDIDO COM LOGS DE CAMPOS\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"📁 SEÇÃO 1.6: FileManager Expandido\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "class FileManagerAIVI:\n",
    "    \"\"\"\n",
    "    Gerenciador de arquivos e logs AIVI v4.1.\n",
    "\n",
    "    Funcionalidades:\n",
    "    - Estrutura de pastas completa\n",
    "    - Log de execução (geral + específico)\n",
    "    - Log de campos separado (PARTE 12.3)\n",
    "    - Pasta de exploração (PARTE 14)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, diretorio_base: Optional[Path] = None):\n",
    "        \"\"\"Inicializa FileManager.\"\"\"\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        print(f\"   🕐 Timestamp: {self.timestamp}\")\n",
    "\n",
    "        # Selecionar diretório base\n",
    "        if diretorio_base is None:\n",
    "            self.diretorio_base = selecionar_diretorio_trabalho()\n",
    "        else:\n",
    "            self.diretorio_base = Path(diretorio_base)\n",
    "\n",
    "        print(f\"   📂 Diretório base: {self.diretorio_base}\")\n",
    "\n",
    "        # Criar estrutura\n",
    "        self.diretorio_execucao = self.diretorio_base / f\"AIVI_DataIntegration_{self.timestamp}\"\n",
    "        self._criar_estrutura()\n",
    "        self._configurar_logging()\n",
    "\n",
    "        # Log inicial\n",
    "        self.logger.info(\"═\" * 80)\n",
    "        self.logger.info(\"NOVA EXECUÇÃO - AIVI DATA INTEGRATION v4.1\")\n",
    "        self.logger.info(\"═\" * 80)\n",
    "        self.logger.info(f\"Timestamp: {self.timestamp}\")\n",
    "        self.logger.info(f\"Diretório: {self.diretorio_execucao}\")\n",
    "        self.logger.info(f\"Python: {sys.version.split()[0]}\")\n",
    "        self.logger.info(f\"Pandas: {pd.__version__}\")\n",
    "\n",
    "        print()\n",
    "        print(f\"   ✅ FileManager inicializado\")\n",
    "        print(f\"   ✅ Sistema de logs ativo\")\n",
    "        print()\n",
    "\n",
    "    def _criar_estrutura(self):\n",
    "        \"\"\"Cria estrutura de pastas.\"\"\"\n",
    "\n",
    "        # Estrutura expandida v4.1\n",
    "        self.diretorios = {\n",
    "            'logs': self.diretorio_execucao / '01_Logs',\n",
    "            'logs_campos': self.diretorio_execucao / '01_Logs' / 'logs_campos',  # NOVO\n",
    "            'logs_execucao': self.diretorio_execucao / '01_Logs' / 'logs_execucao',  # NOVO\n",
    "            'dados_entrada': self.diretorio_execucao / '02_Dados_Entrada',\n",
    "            'dados_processados': self.diretorio_execucao / '03_Dados_Processados',\n",
    "            'dados_integrados': self.diretorio_execucao / '04_Dados_Integrados',\n",
    "            'exploracao': self.diretorio_execucao / '05_Exploracao',  # NOVO (PARTE 14)\n",
    "            'relatorios': self.diretorio_execucao / '06_Relatorios',\n",
    "            'validacoes': self.diretorio_execucao / '07_Validacoes',\n",
    "            'exports': self.diretorio_execucao / '08_Exports'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for nome, caminho in self.diretorios.items():\n",
    "            caminho.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _configurar_logging(self):\n",
    "        \"\"\"Configura sistema de logging.\"\"\"\n",
    "\n",
    "        log_file = self.diretorios['logs_execucao'] / f'aivi_analise_{self.timestamp}.log'\n",
    "\n",
    "        # Configurar logger\n",
    "        self.logger = logging.getLogger(f'AIVI_{self.timestamp}')\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Handler para arquivo\n",
    "        fh = logging.FileHandler(log_file, encoding='utf-8')\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Handler para console\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)\n",
    "\n",
    "        # Formato\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s | %(levelname)-8s | %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "        fh.setFormatter(formatter)\n",
    "        ch.setFormatter(formatter)\n",
    "\n",
    "        self.logger.addHandler(fh)\n",
    "        self.logger.addHandler(ch)\n",
    "\n",
    "    def salvar_metadata(self, metadata_adicional: Dict = None) -> Path:\n",
    "        \"\"\"Salva metadata da execução.\"\"\"\n",
    "\n",
    "        metadata = {\n",
    "            'timestamp': self.timestamp,\n",
    "            'versao': CONSTANTES_AIVI['VERSAO_SISTEMA'],\n",
    "            'data_atualizacao': CONSTANTES_AIVI['DATA_ATUALIZACAO'],\n",
    "            'diretorio_base': str(self.diretorio_base),\n",
    "            'diretorio_execucao': str(self.diretorio_execucao),\n",
    "            'estrutura_pastas': {k: str(v) for k, v in self.diretorios.items()},\n",
    "            'python_version': sys.version,\n",
    "            'pandas_version': pd.__version__\n",
    "        }\n",
    "\n",
    "        if metadata_adicional:\n",
    "            metadata.update(metadata_adicional)\n",
    "\n",
    "        metadata_file = self.diretorios['logs'] / 'metadata.json'\n",
    "        with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return metadata_file\n",
    "\n",
    "    def registrar_schema_campos(self, df: pd.DataFrame, fonte: str, arquivo_origem: str) -> Path:\n",
    "        \"\"\"\n",
    "        Registra schema completo de campos em log separado (PARTE 12.3).\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame a registrar\n",
    "            fonte: Nome da fonte (ex: 'SAP_YSMM_VI_ACOMP')\n",
    "            arquivo_origem: Nome do arquivo original\n",
    "\n",
    "        Returns:\n",
    "            Path do arquivo de log de campos\n",
    "        \"\"\"\n",
    "        schema_info = {\n",
    "            'fonte': fonte,\n",
    "            'arquivo_origem': arquivo_origem,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_registros': len(df),\n",
    "            'total_colunas': len(df.columns),\n",
    "            'campos': {}\n",
    "        }\n",
    "\n",
    "        # Analisar cada campo\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            serie = df[col]\n",
    "\n",
    "            campo_info = {\n",
    "                'posicao': i,\n",
    "                'nome_original': col,\n",
    "                'tipo_pandas': str(serie.dtype),\n",
    "                'count_total': len(serie),\n",
    "                'count_nulos': int(serie.isnull().sum()),\n",
    "                'pct_nulos': float(serie.isnull().sum() / len(serie) * 100) if len(serie) > 0 else 0,\n",
    "                'count_unicos': int(serie.nunique()),\n",
    "                'pct_cardinalidade': float(serie.nunique() / len(serie) * 100) if len(serie) > 0 else 0\n",
    "            }\n",
    "\n",
    "            # Análise de conteúdo\n",
    "            analise = analisar_coluna_completa(serie, amostra=50)\n",
    "            campo_info['tipo_conteudo_detectado'] = analise['tipo_predominante']\n",
    "            campo_info['confianca_deteccao'] = analise['confianca']\n",
    "            campo_info['exemplos'] = analise['exemplos']\n",
    "\n",
    "            schema_info['campos'][col] = campo_info\n",
    "\n",
    "        # Salvar\n",
    "        log_campos_file = self.diretorios['logs_campos'] / f'{fonte}_{self.timestamp}_schema.json'\n",
    "        with open(log_campos_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(schema_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Schema de campos registrado: {log_campos_file.name}\")\n",
    "\n",
    "        return log_campos_file\n",
    "\n",
    "print(\"   ✅ FileManagerAIVI (classe expandida)\")\n",
    "print(\"   ✅ Suporte a logs de campos (PARTE 12.3)\")\n",
    "print(\"   ✅ Pasta de exploração (PARTE 14)\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 7: INICIALIZAÇÃO E TESTE\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🚀 SEÇÃO 1.7: Inicializando FileManager\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Inicializar (vai abrir GUI)\n",
    "try:\n",
    "    fm = FileManagerAIVI()\n",
    "\n",
    "    # Criar aliases para compatibilidade\n",
    "    gerenciador = fm\n",
    "    gp = fm\n",
    "\n",
    "    # Aliases de diretórios\n",
    "    DIR_LOGS = fm.diretorios['logs']\n",
    "    DIR_LOGS_CAMPOS = fm.diretorios['logs_campos']\n",
    "    DIR_LOGS_EXECUCAO = fm.diretorios['logs_execucao']\n",
    "    DIR_DADOS_ENTRADA = fm.diretorios['dados_entrada']\n",
    "    DIR_DADOS_PROCESSADOS = fm.diretorios['dados_processados']\n",
    "    DIR_DADOS_INTEGRADOS = fm.diretorios['dados_integrados']\n",
    "    DIR_EXPLORACAO = fm.diretorios['exploracao']\n",
    "    DIR_RELATORIOS = fm.diretorios['relatorios']\n",
    "    DIR_VALIDACOES = fm.diretorios['validacoes']\n",
    "    DIR_EXPORTS = fm.diretorios['exports']\n",
    "\n",
    "    # Salvar metadata inicial\n",
    "    metadata_file = fm.salvar_metadata({\n",
    "        'bloco': 1,\n",
    "        'fase': 'configuracao_completa',\n",
    "        'modulos_carregados': modulos_carregados,\n",
    "        'constantes': CONSTANTES_AIVI,\n",
    "        'patterns_definidos': len(PATTERNS_CONTEUDO),\n",
    "        'sinonimos_mapeados': sum(len(v) for v in DICIONARIO_SINONIMOS.values())\n",
    "    })\n",
    "\n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ❌ ERRO NA INICIALIZAÇÃO \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "    print(f\"Erro: {str(e)}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n",
    "    raise\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL DO BLOCO 1\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" ✅ BLOCO 1 CONCLUÍDO COM SUCESSO \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# Resumo em tabela formatada\n",
    "formatar_tabela_resumo({\n",
    "    'timestamp': fm.timestamp,\n",
    "    'versao_sistema': CONSTANTES_AIVI['VERSAO_SISTEMA'],\n",
    "    'diretorio_execucao': fm.diretorio_execucao.name,\n",
    "    'total_pastas_criadas': len(fm.diretorios),\n",
    "    'constantes_aivi': len(CONSTANTES_AIVI),\n",
    "    'campos_obrigatorios': len(SCHEMA_AIVI_CAMPOS_OBRIGATORIOS),\n",
    "    'patterns_regex': len(PATTERNS_CONTEUDO),\n",
    "    'sinonimos_mapeados': sum(len(v) for v in DICIONARIO_SINONIMOS.values()),\n",
    "    'funcoes_auxiliares': 7,\n",
    "    'sistema_ux_ui': 'ATIVO (timer + memória)',\n",
    "    'log_campos': 'ATIVO (PARTE 12.3)',\n",
    "    'exploracao': 'ATIVO (PARTE 14)'\n",
    "}, \"RESUMO DO BLOCO 1\")\n",
    "\n",
    "print()\n",
    "print(\"📂 ESTRUTURA DE PASTAS CRIADA:\")\n",
    "print(\"-\" * 80)\n",
    "for nome, caminho in fm.diretorios.items():\n",
    "    print(f\"   {nome.ljust(20)} → {caminho.name}\")\n",
    "\n",
    "print()\n",
    "print(\"🔗 VARIÁVEIS GLOBAIS DISPONÍVEIS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   • fm / gerenciador / gp (FileManager)\")\n",
    "print(\"   • DIR_LOGS, DIR_LOGS_CAMPOS, DIR_DADOS_ENTRADA, etc\")\n",
    "print(\"   • CONSTANTES_AIVI (dict)\")\n",
    "print(\"   • SCHEMA_AIVI_CAMPOS_OBRIGATORIOS (list)\")\n",
    "print(\"   • DICIONARIO_SINONIMOS (dict)\")\n",
    "print(\"   • PATTERNS_CONTEUDO (dict)\")\n",
    "print(\"   • Funções: normalizar_string(), detectar_tipo_conteudo(), etc\")\n",
    "\n",
    "print()\n",
    "print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   1. ✅ Verifique se o diretório foi criado corretamente\")\n",
    "print(\"   2. ✅ Confirme que todas as pastas existem (9 pastas)\")\n",
    "print(\"   3. ✅ Abra o arquivo de log em 01_Logs/logs_execucao/\")\n",
    "print(\"   4. 📤 Envie: 'BLOCO 1 OK' para prosseguir\")\n",
    "print(\"   5. ⏭️  BLOCO 2 será o próximo (Carregador de Arquivos)\")\n",
    "\n",
    "print()\n",
    "print(\"🔗 CAMINHO COMPLETO:\")\n",
    "print(f\"   {fm.diretorio_execucao}\")\n",
    "print()\n",
    "print(\"═\" * 80)"
   ],
   "id": "195b3fbf337a7cfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                 🚀 BLOCO 1: CONFIGURAÇÃO COMPLETA DO AMBIENTE                 ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📦 SEÇÃO 1.1: Imports\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ Bibliotecas padrão: sys, os, json, logging, datetime\n",
      "   ✅ Análise de dados: pandas, numpy\n",
      "   ✅ GUI: tkinter\n",
      "   ✅ Configurações aplicadas\n",
      "\n",
      "📋 Versões:\n",
      "   • Python: 3.11.9\n",
      "   • Pandas: 2.3.3\n",
      "   • NumPy: 2.3.3\n",
      "\n",
      "📊 SEÇÃO 1.2: Constantes AIVI 2025\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ Ano de vigência: 2025\n",
      "   ✅ Versão do sistema: 4.1\n",
      "   ✅ 14 constantes definidas\n",
      "\n",
      "   ✅ Schema AIVI: 9 campos obrigatórios\n",
      "\n",
      "   ✅ Dicionário de sinônimos: 11 campos principais\n",
      "   ✅ Total de variações mapeadas: 111\n",
      "\n",
      "🔍 SEÇÃO 1.3: Regex Patterns para Detecção de Conteúdo\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ 9 patterns definidos\n",
      "      • centro: Centro: 4 dígitos\n",
      "      • codigo_material: Código Material: xx.xxx.xxx ou 7-8 dígitos\n",
      "      • codigo_grupo: Código Grupo: TEXTO_TEXTO ou numérico\n",
      "      • ... e mais 6 patterns\n",
      "\n",
      "⚙️  SEÇÃO 1.4: Funções Auxiliares\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ normalizar_string()\n",
      "   ✅ calcular_similaridade()\n",
      "   ✅ detectar_tipo_conteudo()\n",
      "   ✅ analisar_coluna_completa()\n",
      "   ✅ identificar_linha_cabecalho()\n",
      "   ✅ validar_transformacao()\n",
      "   ✅ formatar_tabela_resumo()\n",
      "\n",
      "🎨 SEÇÃO 1.5: Sistema UX/UI com Timer e Memória\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ DialogoPadraoAIVI (classe base)\n",
      "   ✅ selecionar_diretorio_trabalho() (com timer + memória)\n",
      "\n",
      "📁 SEÇÃO 1.6: FileManager Expandido\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ FileManagerAIVI (classe expandida)\n",
      "   ✅ Suporte a logs de campos (PARTE 12.3)\n",
      "   ✅ Pasta de exploração (PARTE 14)\n",
      "\n",
      "🚀 SEÇÃO 1.7: Inicializando FileManager\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   🕐 Timestamp: 20251017_101052\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "363528e05a5f0590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:01:48.822186Z",
     "start_time": "2025-10-15T14:01:20.772843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "AIVI DATA INTEGRATION - BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "Versão: 3.0 - Modular (um arquivo por vez)\n",
    "Arquivo: YSMM_VI_ACOMP (SAP - Base de Dados Históricos)\n",
    "\n",
    "FUNCIONALIDADES:\n",
    "  ✅ Seleção via GUI\n",
    "  ✅ Suporte robusto a .XLS e .XLSX\n",
    "  ✅ Limpeza SAP automática (remove col A, linhas 1,2,3,5)\n",
    "  ✅ Detecção automática de schema (Parte 16)\n",
    "  ✅ Listagem COMPLETA de todas as colunas\n",
    "  ✅ Validação de campos obrigatórios\n",
    "  ✅ Backup automático\n",
    "  ✅ Logging completo\n",
    "\n",
    "APÓS ESTE BLOCO:\n",
    "  • df_sap disponível globalmente\n",
    "  • Aguarda feedback do usuário\n",
    "  • Próximo: BLOCO 3 (Arquivo 2)\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1/N \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# FUNÇÃO AUXILIAR: Similaridade de Strings\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def calcular_similaridade(s1, s2):\n",
    "    \"\"\"\n",
    "    Calcula similaridade entre duas strings usando SequenceMatcher.\n",
    "\n",
    "    Args:\n",
    "        s1: String 1\n",
    "        s2: String 2\n",
    "\n",
    "    Returns:\n",
    "        float: Similaridade entre 0.0 e 1.0 (0% a 100%)\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, s1.lower(), s2.lower()).ratio()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# CLASSE: CarregadorArquivo (MODULAR - reutilizável)\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CarregadorArquivo:\n",
    "    \"\"\"\n",
    "    Carregador modular de arquivos Excel com detecção automática de schema.\n",
    "\n",
    "    Design Pattern: Template Method\n",
    "    - Métodos genéricos para qualquer arquivo\n",
    "    - Métodos específicos por tipo de arquivo (SAP, ESO, etc)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gerenciador):\n",
    "        self.gerenciador = gerenciador\n",
    "        self.logger = gerenciador.logger\n",
    "        self.df = None\n",
    "        self.arquivo_original = None\n",
    "        self.tipo_arquivo = None\n",
    "        self.mapeamento_colunas = {}\n",
    "        self.log_deteccao = []\n",
    "\n",
    "    def selecionar_arquivo_gui(self, titulo, mensagem):\n",
    "        \"\"\"Abre GUI para seleção de arquivo.\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "        root.attributes('-alpha', 0.0)\n",
    "        root.update()\n",
    "\n",
    "        messagebox.showinfo(titulo, mensagem.strip())\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=titulo,\n",
    "            filetypes=[\n",
    "                (\"Excel files\", \"*.xlsx *.xls\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(f\"❌ Nenhum arquivo selecionado\")\n",
    "\n",
    "        return Path(arquivo)\n",
    "\n",
    "    def carregar_excel_robusto(self, caminho):\n",
    "        \"\"\"\n",
    "        Carrega Excel com múltiplos engines (tolerante a falhas).\n",
    "\n",
    "        Ordem de tentativa:\n",
    "          1. Engine específico da extensão (openpyxl ou xlrd)\n",
    "          2. Engine automático (pandas decide)\n",
    "        \"\"\"\n",
    "        extensao = caminho.suffix.lower()\n",
    "\n",
    "        print(f\"📖 Carregando arquivo Excel ({extensao})...\")\n",
    "\n",
    "        # Definir engines\n",
    "        if extensao == '.xlsx':\n",
    "            engines = ['openpyxl', None]\n",
    "        elif extensao == '.xls':\n",
    "            engines = ['xlrd', None]\n",
    "        else:\n",
    "            engines = [None, 'openpyxl', 'xlrd']\n",
    "\n",
    "        # Tentar cada engine\n",
    "        ultimo_erro = None\n",
    "\n",
    "        for i, engine in enumerate(engines, 1):\n",
    "            try:\n",
    "                if engine:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine='{engine}'\")\n",
    "                    df = pd.read_excel(caminho, header=None, engine=engine)\n",
    "                else:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine automático\")\n",
    "                    df = pd.read_excel(caminho, header=None)\n",
    "\n",
    "                print(f\"   ✅ Sucesso! {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "                self.logger.info(f\"Carregado: {caminho.name} ({df.shape[0]} × {df.shape[1]})\")\n",
    "                return df\n",
    "\n",
    "            except Exception as e:\n",
    "                ultimo_erro = e\n",
    "                print(f\"   ❌ Falhou: {str(e)[:60]}...\")\n",
    "                continue\n",
    "\n",
    "        # Nenhum engine funcionou\n",
    "        print()\n",
    "        print(\"❌ ERRO: Não foi possível ler o arquivo\")\n",
    "\n",
    "        if extensao == '.xls':\n",
    "            print()\n",
    "            print(\"💡 SOLUÇÃO para .XLS:\")\n",
    "            print(\"   1. Instale xlrd: pip install xlrd\")\n",
    "            print(\"   2. OU converta para .XLSX no Excel\")\n",
    "\n",
    "        raise Exception(f\"Falha ao ler: {ultimo_erro}\")\n",
    "\n",
    "    def limpar_sap_bruto(self, df_bruto):\n",
    "        \"\"\"\n",
    "        Limpeza específica para arquivos SAP YSMM_VI_ACOMP.\n",
    "\n",
    "        Transformações:\n",
    "          1. Remove coluna A (índice 0) - coluna vazia do SAP\n",
    "          2. Remove linhas 1, 2, 3, 5 - cabeçalhos e vazias\n",
    "          3. Linha 4 vira cabeçalho\n",
    "        \"\"\"\n",
    "        print()\n",
    "        print(\"🧹 Aplicando limpeza SAP (YSMM_VI_ACOMP)...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        print(f\"   📊 Original: {df_bruto.shape[0]:,} linhas × {df_bruto.shape[1]} colunas\")\n",
    "\n",
    "        df = df_bruto.copy()\n",
    "\n",
    "        # PASSO 1: Remover primeira coluna\n",
    "        if df.shape[1] > 0:\n",
    "            df = df.iloc[:, 1:]\n",
    "            print(f\"   ✅ Removida coluna A (índice 0)\")\n",
    "\n",
    "        # PASSO 2: Processar cabeçalho\n",
    "        if len(df) > 4:\n",
    "            # Linha 4 (índice 3) vira cabeçalho\n",
    "            novo_cabecalho = df.iloc[3].values\n",
    "\n",
    "            # Remover linhas 0,1,2,4 e pegar de 5 em diante\n",
    "            df = df.iloc[5:].reset_index(drop=True)\n",
    "            df.columns = novo_cabecalho\n",
    "\n",
    "            print(f\"   ✅ Removidas linhas 1, 2, 3, 5\")\n",
    "            print(f\"   ✅ Cabeçalho definido (linha 4 original)\")\n",
    "\n",
    "        print(f\"   📊 Limpo: {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "        print()\n",
    "\n",
    "        self.logger.info(f\"Limpeza SAP aplicada: {df.shape[0]} × {df.shape[1]}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def detectar_colunas_automatico(self, df, campos_esperados):\n",
    "        \"\"\"\n",
    "        Detecção automática de colunas usando similaridade de strings.\n",
    "\n",
    "        Implementa Parte 16 do prompt: Inteligência de Dados.\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame com colunas a mapear\n",
    "            campos_esperados: dict {campo_padrao: [sinonimos]}\n",
    "\n",
    "        Returns:\n",
    "            (df_mapeado, mapeamento, log_deteccao, sucesso)\n",
    "        \"\"\"\n",
    "        print(\"🔍 DETECÇÃO AUTOMÁTICA DE COLUNAS\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        mapeamento = {}\n",
    "        log_deteccao = []\n",
    "        campos_nao_encontrados = []\n",
    "\n",
    "        # Para cada campo esperado\n",
    "        for campo_padrao, sinonimos in campos_esperados.items():\n",
    "            melhor_score = 0.0\n",
    "            melhor_match = None\n",
    "            melhor_coluna_df = None\n",
    "\n",
    "            # Procurar nas colunas do DataFrame\n",
    "            for col_df in df.columns:\n",
    "                col_df_str = str(col_df).strip()\n",
    "\n",
    "                # Calcular similaridade com cada sinônimo\n",
    "                for sinonimo in sinonimos:\n",
    "                    # Exata?\n",
    "                    if col_df_str == sinonimo:\n",
    "                        score = 1.0\n",
    "                    else:\n",
    "                        # Fuzzy match\n",
    "                        score = calcular_similaridade(col_df_str, sinonimo)\n",
    "\n",
    "                    if score > melhor_score:\n",
    "                        melhor_score = score\n",
    "                        melhor_match = sinonimo\n",
    "                        melhor_coluna_df = col_df\n",
    "\n",
    "            # Threshold: 70%\n",
    "            if melhor_score >= 0.70:\n",
    "                # Mapear se nome diferente\n",
    "                if melhor_coluna_df != campo_padrao:\n",
    "                    mapeamento[melhor_coluna_df] = campo_padrao\n",
    "\n",
    "                # Status visual\n",
    "                if melhor_score >= 0.95:\n",
    "                    status = \"✅ AUTO\"\n",
    "                    auto = True\n",
    "                elif melhor_score >= 0.80:\n",
    "                    status = \"⚠️  REVISAR\"\n",
    "                    auto = False\n",
    "                else:\n",
    "                    status = \"⚠️  BAIXA\"\n",
    "                    auto = False\n",
    "\n",
    "                print(f\"   {status} '{melhor_coluna_df}' → '{campo_padrao}'\")\n",
    "                print(f\"           Confiança: {melhor_score:.1%} (match: '{melhor_match}')\")\n",
    "\n",
    "                log_deteccao.append({\n",
    "                    'coluna_original': melhor_coluna_df,\n",
    "                    'campo_padrao': campo_padrao,\n",
    "                    'confianca': melhor_score,\n",
    "                    'match_com': melhor_match,\n",
    "                    'automatico': auto\n",
    "                })\n",
    "            else:\n",
    "                print(f\"   ❌ '{campo_padrao}' - Não encontrado (melhor: {melhor_score:.1%})\")\n",
    "                campos_nao_encontrados.append(campo_padrao)\n",
    "\n",
    "                log_deteccao.append({\n",
    "                    'coluna_original': None,\n",
    "                    'campo_padrao': campo_padrao,\n",
    "                    'confianca': melhor_score,\n",
    "                    'automatico': False,\n",
    "                    'status': 'NAO_ENCONTRADO'\n",
    "                })\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Aplicar mapeamento\n",
    "        if mapeamento:\n",
    "            df = df.rename(columns=mapeamento)\n",
    "            print(f\"   🔄 {len(mapeamento)} colunas renomeadas\")\n",
    "            self.logger.info(f\"Mapeamento: {len(mapeamento)} colunas\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Resultado\n",
    "        sucesso = len(campos_nao_encontrados) == 0\n",
    "\n",
    "        if campos_nao_encontrados:\n",
    "            print(f\"⚠️  {len(campos_nao_encontrados)} campos não encontrados:\")\n",
    "            for campo in campos_nao_encontrados:\n",
    "                print(f\"      • {campo}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"✅ Todos os campos obrigatórios mapeados!\")\n",
    "            print()\n",
    "\n",
    "        return df, mapeamento, log_deteccao, sucesso\n",
    "\n",
    "    def listar_todas_colunas(self, df):\n",
    "        \"\"\"\n",
    "        Lista TODAS as colunas com informações detalhadas.\n",
    "\n",
    "        Para cada coluna mostra:\n",
    "          - Tipo de dados\n",
    "          - Quantidade de nulos\n",
    "          - Quantidade de valores únicos\n",
    "        \"\"\"\n",
    "        print()\n",
    "        print(\"📑 LISTAGEM COMPLETA DE COLUNAS\")\n",
    "        print(\"═\" * 80)\n",
    "        print(f\"📏 Total: {len(df.columns)} colunas\")\n",
    "        print()\n",
    "\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            tipo = df[col].dtype\n",
    "            nulos = df[col].isna().sum()\n",
    "            pct_nulos = (nulos / len(df) * 100) if len(df) > 0 else 0\n",
    "            unicos = df[col].nunique()\n",
    "\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       ├─ Tipo: {tipo}\")\n",
    "            print(f\"       ├─ Nulos: {nulos:,} ({pct_nulos:.1f}%)\")\n",
    "            print(f\"       └─ Únicos: {unicos:,}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    def mostrar_preview_dados(self, df, n_linhas=3):\n",
    "        \"\"\"Mostra preview das primeiras linhas.\"\"\"\n",
    "        print(\"📊 PREVIEW DOS DADOS (primeiras 5 colunas)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        colunas_preview = list(df.columns[:5])\n",
    "        print(df[colunas_preview].head(n_linhas).to_string(index=False))\n",
    "        print()\n",
    "\n",
    "    def salvar_backup(self, df, nome_base):\n",
    "        \"\"\"Salva backup na pasta de entrada.\"\"\"\n",
    "        timestamp = self.gerenciador.timestamp\n",
    "\n",
    "        arquivo_destino = self.gerenciador.diretorios['dados_entrada'] / \\\n",
    "                         f\"{nome_base}_{timestamp}.xlsx\"\n",
    "\n",
    "        try:\n",
    "            df.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "            self.logger.info(f\"Backup: {arquivo_destino.name}\")\n",
    "            print(f\"   ✅ Backup: {arquivo_destino.name}\")\n",
    "            return arquivo_destino\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao salvar backup: {str(e)}\")\n",
    "            self.logger.error(f\"Erro backup: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def salvar_log_deteccao(self, nome_arquivo=\"deteccao_schema\"):\n",
    "        \"\"\"Salva log de detecção em JSON.\"\"\"\n",
    "        if not self.log_deteccao:\n",
    "            return None\n",
    "\n",
    "        timestamp = self.gerenciador.timestamp\n",
    "        log_file = self.gerenciador.diretorios['logs'] / \\\n",
    "                  f\"{nome_arquivo}_{timestamp}.json\"\n",
    "\n",
    "        import json\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.log_deteccao, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Log detecção: {log_file.name}\")\n",
    "        return log_file\n",
    "\n",
    "    def carregar_ysmm_vi_acomp(self):\n",
    "        \"\"\"\n",
    "        Pipeline completo para carregar YSMM_VI_ACOMP (SAP).\n",
    "\n",
    "        Etapas:\n",
    "          1. Seleção via GUI\n",
    "          2. Carregamento robusto\n",
    "          3. Limpeza SAP\n",
    "          4. Detecção automática de schema\n",
    "          5. Listagem de todas as colunas\n",
    "          6. Preview dos dados\n",
    "          7. Backup\n",
    "        \"\"\"\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ARQUIVO 1: YSMM_VI_ACOMP (SAP - BASE HISTÓRICA) \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "\n",
    "        mensagem = \"\"\"\n",
    "╔═══════════════════════════════════════════════════╗\n",
    "║  📂 ARQUIVO SAP - YSMM_VI_ACOMP                   ║\n",
    "╠═══════════════════════════════════════════════════╣\n",
    "║                                                   ║\n",
    "║  Transação: YSMM_VI_ACOMP                         ║\n",
    "║  Conteúdo: Dados históricos de variações internas║\n",
    "║  Período: Recomendado 12+ meses                   ║\n",
    "║                                                   ║\n",
    "║  ⚠️  IMPORTANTE:                                  ║\n",
    "║                                                   ║\n",
    "║  • Selecione arquivo ORIGINAL (BRUTO) do SAP      ║\n",
    "║  • NÃO faça limpeza manual                        ║\n",
    "║  • Aceita .XLS ou .XLSX                           ║\n",
    "║  • Nome típico: 2025-2024-YSMM_VI_ACOMP.xlsx      ║\n",
    "║                                                   ║\n",
    "╚═══════════════════════════════════════════════════╝\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 1: Seleção\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.arquivo_original = self.selecionar_arquivo_gui(\n",
    "                titulo=\"[1/N] YSMM_VI_ACOMP (SAP - BRUTO)\",\n",
    "                mensagem=mensagem\n",
    "            )\n",
    "\n",
    "            self.tipo_arquivo = \"SAP_YSMM_VI_ACOMP\"\n",
    "\n",
    "            print(f\"✅ Arquivo selecionado:\")\n",
    "            print(f\"   📁 Nome: {self.arquivo_original.name}\")\n",
    "            print(f\"   📊 Tamanho: {self.arquivo_original.stat().st_size:,} bytes\")\n",
    "            print(f\"   🔧 Tipo: {self.arquivo_original.suffix}\")\n",
    "            print()\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 2: Carregamento\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            df_bruto = self.carregar_excel_robusto(self.arquivo_original)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 3: Limpeza SAP\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            df_limpo = self.limpar_sap_bruto(df_bruto)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 4: Detecção automática de schema\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            # Campos obrigatórios SAP\n",
    "            campos_sap = {\n",
    "                'Centro': ['Centro', 'Código de Centro', 'Cod Centro'],\n",
    "                'Cód Grupo de produto': ['Cód Grupo de produto', 'Cod Grupo de produto'],\n",
    "                'Expedição': ['Expedição c/ Veí', 'Expedição c/ Veículo', 'Expedição'],\n",
    "                'Variação Interna': ['Variação Interna', 'Variacao Interna', 'VI'],\n",
    "                'Mês': ['Mês do exercício', 'Mes do exercicio', 'Mês'],\n",
    "                'Ano': ['Ano do documento do material', 'Ano do documento', 'Ano']\n",
    "            }\n",
    "\n",
    "            df_mapeado, mapeamento, log, sucesso = \\\n",
    "                self.detectar_colunas_automatico(df_limpo, campos_sap)\n",
    "\n",
    "            self.df = df_mapeado\n",
    "            self.mapeamento_colunas = mapeamento\n",
    "            self.log_deteccao = log\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 5: Listar TODAS as colunas\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.listar_todas_colunas(self.df)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 6: Preview\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.mostrar_preview_dados(self.df)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 7: Backup\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            print(\"💾 Salvando backup...\")\n",
    "            backup = self.salvar_backup(self.df, \"SAP_YSMM_Limpo\")\n",
    "\n",
    "            log_file = self.salvar_log_deteccao(\"deteccao_sap\")\n",
    "            if log_file:\n",
    "                print(f\"   ✅ Log detecção: {log_file.name}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # RESULTADO FINAL\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "            print(\"║\" + \" ✅ ARQUIVO SAP CARREGADO COM SUCESSO \".center(78) + \"║\")\n",
    "            print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "            print()\n",
    "\n",
    "            print(\"📊 RESUMO DO CARREGAMENTO:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"   • Arquivo: {self.arquivo_original.name}\")\n",
    "            print(f\"   • Registros: {len(self.df):,}\")\n",
    "            print(f\"   • Colunas totais: {len(self.df.columns)}\")\n",
    "            print(f\"   • Colunas mapeadas: {len(self.mapeamento_colunas)}\")\n",
    "            print(f\"   • Detecção automática: {'✅ 100%' if sucesso else '⚠️  Parcial'}\")\n",
    "            print(f\"   • Backup salvo: ✅\")\n",
    "            print()\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "            print(\"║\" + \" ❌ ERRO AO CARREGAR ARQUIVO SAP \".center(78) + \"║\")\n",
    "            print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "            print()\n",
    "            print(f\"❌ Erro: {str(e)}\")\n",
    "            print()\n",
    "\n",
    "            import traceback\n",
    "            print(\"🔍 Detalhes técnicos:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "            self.logger.error(f\"Erro SAP: {str(e)}\")\n",
    "\n",
    "            return False\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# EXECUÇÃO: CARREGAR ARQUIVO 1 (YSMM_VI_ACOMP)\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print()\n",
    "print(\"⚠️  INSTRUÇÕES:\")\n",
    "print(\"   • Uma janela vai abrir para seleção do arquivo\")\n",
    "print(\"   • Selecione o arquivo YSMM_VI_ACOMP ORIGINAL (bruto) do SAP\")\n",
    "print(\"   • NÃO faça limpeza manual no arquivo\")\n",
    "print(\"   • Aceita .XLS ou .XLSX\")\n",
    "print()\n",
    "\n",
    "input(\"👉 Pressione ENTER para iniciar...\")\n",
    "\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Inicializar carregador\n",
    "    carregador_sap = CarregadorArquivo(fm)\n",
    "\n",
    "    # Carregar YSMM_VI_ACOMP\n",
    "    sucesso = carregador_sap.carregar_ysmm_vi_acomp()\n",
    "\n",
    "    if sucesso:\n",
    "        # Salvar referência global\n",
    "        df_sap = carregador_sap.df\n",
    "\n",
    "        arquivo_sap_info = {\n",
    "            'df': df_sap,\n",
    "            'arquivo': carregador_sap.arquivo_original,\n",
    "            'mapeamento': carregador_sap.mapeamento_colunas,\n",
    "            'log_deteccao': carregador_sap.log_deteccao\n",
    "        }\n",
    "\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"✅ BLOCO 2 - ARQUIVO 1 CONCLUÍDO\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   1. ✅ Revise a lista de colunas acima\")\n",
    "        print(\"   2. ✅ Verifique se os dados fazem sentido\")\n",
    "        print(\"   3. ✅ Confira a pasta 02_Dados_Entrada no Explorer\")\n",
    "        print(\"   4. 📤 Envie feedback:\")\n",
    "        print(\"       • 'ARQUIVO 1 OK' - para prosseguir\")\n",
    "        print(\"       • Descreva problemas - se houver erros\")\n",
    "        print(\"   5. ⏳ Aguarde BLOCO 3 (próximo arquivo)\")\n",
    "        print()\n",
    "        print(\"🔗 VARIÁVEIS DISPONÍVEIS:\")\n",
    "        print(\"   • df_sap - DataFrame com dados SAP\")\n",
    "        print(\"   • arquivo_sap_info - Metadados completos\")\n",
    "        print(\"   • carregador_sap - Instância do carregador\")\n",
    "        print()\n",
    "\n",
    "        fm.logger.info(\"BLOCO 2 - Arquivo 1 (SAP) concluído\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print(\"⚠️  Operação cancelada pelo usuário\")\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ERRO FATAL - BLOCO 2 \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "    print(f\"❌ Erro: {str(e)}\")\n",
    "    print()\n",
    "    import traceback\n",
    "    print(\"🔍 Detalhes técnicos:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print()\n",
    "print(\"═\" * 80)"
   ],
   "id": "e6ebf0abda5c4eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                  BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1/N                   ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "⚠️  INSTRUÇÕES:\n",
      "   • Uma janela vai abrir para seleção do arquivo\n",
      "   • Selecione o arquivo YSMM_VI_ACOMP ORIGINAL (bruto) do SAP\n",
      "   • NÃO faça limpeza manual no arquivo\n",
      "   • Aceita .XLS ou .XLSX\n",
      "\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║               ARQUIVO 1: YSMM_VI_ACOMP (SAP - BASE HISTÓRICA)                ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "✅ Arquivo selecionado:\n",
      "   📁 Nome: 2025-2024-YSMM_VI_ACOMP.xlsx\n",
      "   📊 Tamanho: 3,827,778 bytes\n",
      "   🔧 Tipo: .xlsx\n",
      "\n",
      "📖 Carregando arquivo Excel (.xlsx)...\n",
      "   Tentativa 1/2: engine='openpyxl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:01:41 | INFO     | Carregado: 2025-2024-YSMM_VI_ACOMP.xlsx (27660 × 30)\n",
      "2025-10-15 11:01:41 | INFO     | Limpeza SAP aplicada: 27655 × 29\n",
      "2025-10-15 11:01:41 | INFO     | Mapeamento: 3 colunas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Sucesso! 27,660 linhas × 30 colunas\n",
      "\n",
      "🧹 Aplicando limpeza SAP (YSMM_VI_ACOMP)...\n",
      "--------------------------------------------------------------------------------\n",
      "   📊 Original: 27,660 linhas × 30 colunas\n",
      "   ✅ Removida coluna A (índice 0)\n",
      "   ✅ Removidas linhas 1, 2, 3, 5\n",
      "   ✅ Cabeçalho definido (linha 4 original)\n",
      "   📊 Limpo: 27,655 linhas × 29 colunas\n",
      "\n",
      "🔍 DETECÇÃO AUTOMÁTICA DE COLUNAS\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ AUTO 'Centro' → 'Centro'\n",
      "           Confiança: 100.0% (match: 'Centro')\n",
      "   ✅ AUTO 'Cód Grupo de produto' → 'Cód Grupo de produto'\n",
      "           Confiança: 100.0% (match: 'Cód Grupo de produto')\n",
      "   ✅ AUTO 'Expedição c/ Veí' → 'Expedição'\n",
      "           Confiança: 100.0% (match: 'Expedição c/ Veí')\n",
      "   ✅ AUTO 'Variação Interna' → 'Variação Interna'\n",
      "           Confiança: 100.0% (match: 'Variação Interna')\n",
      "   ✅ AUTO 'Mês do exercício' → 'Mês'\n",
      "           Confiança: 100.0% (match: 'Mês do exercício')\n",
      "   ✅ AUTO 'Ano do documento do material' → 'Ano'\n",
      "           Confiança: 100.0% (match: 'Ano do documento do material')\n",
      "\n",
      "   🔄 3 colunas renomeadas\n",
      "\n",
      "✅ Todos os campos obrigatórios mapeados!\n",
      "\n",
      "\n",
      "📑 LISTAGEM COMPLETA DE COLUNAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📏 Total: 29 colunas\n",
      "\n",
      "    1. Nome do set\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 1,492 (5.4%)\n",
      "       └─ Únicos: 4\n",
      "    2. Mês\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 12\n",
      "    3. Ano\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "    4. Centro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 181\n",
      "    5. Cód Grupo de produto\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 419\n",
      "    6. Desc. Grupo de Produto\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 417\n",
      "    7. Nome\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 182\n",
      "    8. Expedição\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 22,828\n",
      "    9. Variação Interna\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 7,898\n",
      "   10. Variação Manual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2,681\n",
      "   11. VarInt + VarMan\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,485\n",
      "   12. Percentual de V\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 466\n",
      "   13. Limite Inferior\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 47\n",
      "   14. Limite Su\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 37\n",
      "   15. Histórico\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 246\n",
      "   16. Percentual Excedente\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 447\n",
      "   17. Quant. Exceden\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 4,800\n",
      "   18. Custo Unitário\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 10,739\n",
      "   19. Valor Excede\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,332\n",
      "   20. Imposto (R$)\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2,067\n",
      "   21. Valor Exced. da\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,797\n",
      "   22. Valor da VI (R$)\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 14,244\n",
      "   23. Valor da VI +\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 14,264\n",
      "   24. Perda ou So\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   25. Competência\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 6\n",
      "   26. Status de Homologação\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 3\n",
      "   27. Desc  Status\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 11\n",
      "   28. Icone\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 3\n",
      "   29. Status\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 25,807 (93.3%)\n",
      "       └─ Únicos: 10\n",
      "\n",
      "📊 PREVIEW DOS DADOS (primeiras 5 colunas)\n",
      "--------------------------------------------------------------------------------\n",
      "Nome do set Mês  Ano Centro Cód Grupo de produto\n",
      "        NaN  10 2025   5174     ETANOL_ADITIVADO\n",
      "        NaN  10 2025   5174   GASOLINA_ADITIVADA\n",
      "        NaN  10 2025   5174    GASOLINA_COMPOSTO\n",
      "\n",
      "💾 Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:01:48 | INFO     | Backup: SAP_YSMM_Limpo_20251015_110105.xlsx\n",
      "2025-10-15 11:01:48 | INFO     | Log detecção: deteccao_sap_20251015_110105.json\n",
      "2025-10-15 11:01:48 | INFO     | BLOCO 2 - Arquivo 1 (SAP) concluído\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Backup: SAP_YSMM_Limpo_20251015_110105.xlsx\n",
      "   ✅ Log detecção: deteccao_sap_20251015_110105.json\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                     ✅ ARQUIVO SAP CARREGADO COM SUCESSO                      ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 RESUMO DO CARREGAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   • Arquivo: 2025-2024-YSMM_VI_ACOMP.xlsx\n",
      "   • Registros: 27,655\n",
      "   • Colunas totais: 29\n",
      "   • Colunas mapeadas: 3\n",
      "   • Detecção automática: ✅ 100%\n",
      "   • Backup salvo: ✅\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "✅ BLOCO 2 - ARQUIVO 1 CONCLUÍDO\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📋 PRÓXIMOS PASSOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ✅ Revise a lista de colunas acima\n",
      "   2. ✅ Verifique se os dados fazem sentido\n",
      "   3. ✅ Confira a pasta 02_Dados_Entrada no Explorer\n",
      "   4. 📤 Envie feedback:\n",
      "       • 'ARQUIVO 1 OK' - para prosseguir\n",
      "       • Descreva problemas - se houver erros\n",
      "   5. ⏳ Aguarde BLOCO 3 (próximo arquivo)\n",
      "\n",
      "🔗 VARIÁVEIS DISPONÍVEIS:\n",
      "   • df_sap - DataFrame com dados SAP\n",
      "   • arquivo_sap_info - Metadados completos\n",
      "   • carregador_sap - Instância do carregador\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:02:04.249853Z",
     "start_time": "2025-10-15T14:01:59.241727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "AIVI DATA INTEGRATION - BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "Arquivo: ysmm_centros_br.xlsx\n",
    "Tipo: Tabela de Centros/Bases (Dados Complementares)\n",
    "\n",
    "LIMPEZA:\n",
    "  ✅ Primeira linha é o cabeçalho (usar header=0)\n",
    "  ✅ Sem colunas iniciais a expurgar\n",
    "\n",
    "FUNCIONALIDADES:\n",
    "  ✅ Carregamento robusto (.XLS/.XLSX)\n",
    "  ✅ Listagem completa de colunas\n",
    "  ✅ Preview dos dados\n",
    "  ✅ Backup automático\n",
    "  ✅ Logging\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2/N \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# FUNÇÃO: Carregar ysmm_centros_br.xlsx\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def carregar_ysmm_centros():\n",
    "    \"\"\"\n",
    "    Carrega arquivo ysmm_centros_br.xlsx (tabela de centros/bases).\n",
    "\n",
    "    Características:\n",
    "      - Primeira linha = cabeçalho\n",
    "      - Sem limpeza de colunas necessária\n",
    "      - Dados complementares para enriquecer base SAP\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ARQUIVO 2: ysmm_centros_br.xlsx (TABELA DE CENTROS) \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    # ETAPA 1: Seleção do arquivo\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "    mensagem = \"\"\"\n",
    "╔═══════════════════════════════════════════════════╗\n",
    "║  📂 ARQUIVO: ysmm_centros_br.xlsx                 ║\n",
    "╠═══════════════════════════════════════════════════╣\n",
    "║                                                   ║\n",
    "║  Conteúdo: Cadastro de Centros/Bases              ║\n",
    "║  Uso: Enriquecimento dos dados SAP                ║\n",
    "║                                                   ║\n",
    "║  Campos esperados:                                ║\n",
    "║  • Centro (código)                                ║\n",
    "║  • Sigla                                          ║\n",
    "║  • Nome/Região                                    ║\n",
    "║  • Outros atributos da base                       ║\n",
    "║                                                   ║\n",
    "║  ⚠️  Primeira linha é o cabeçalho                 ║\n",
    "║                                                   ║\n",
    "╚═══════════════════════════════════════════════════╝\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Seleção GUI\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "        root.attributes('-alpha', 0.0)\n",
    "        root.update()\n",
    "\n",
    "        messagebox.showinfo(\n",
    "            \"[2/N] ysmm_centros_br.xlsx\",\n",
    "            mensagem.strip()\n",
    "        )\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"[2/N] Selecione ysmm_centros_br.xlsx\",\n",
    "            filetypes=[\n",
    "                (\"Excel files\", \"*.xlsx *.xls\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"❌ Nenhum arquivo selecionado\")\n",
    "\n",
    "        arquivo_path = Path(arquivo)\n",
    "\n",
    "        print(f\"✅ Arquivo selecionado:\")\n",
    "        print(f\"   📁 Nome: {arquivo_path.name}\")\n",
    "        print(f\"   📊 Tamanho: {arquivo_path.stat().st_size:,} bytes\")\n",
    "        print(f\"   🔧 Tipo: {arquivo_path.suffix}\")\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 2: Carregamento\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        extensao = arquivo_path.suffix.lower()\n",
    "\n",
    "        print(f\"📖 Carregando arquivo Excel ({extensao})...\")\n",
    "\n",
    "        # Tentar engines\n",
    "        if extensao == '.xlsx':\n",
    "            engines = ['openpyxl', None]\n",
    "        elif extensao == '.xls':\n",
    "            engines = ['xlrd', None]\n",
    "        else:\n",
    "            engines = [None, 'openpyxl', 'xlrd']\n",
    "\n",
    "        df = None\n",
    "        for i, engine in enumerate(engines, 1):\n",
    "            try:\n",
    "                if engine:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine='{engine}'\")\n",
    "                    df = pd.read_excel(arquivo_path, header=0, engine=engine)\n",
    "                else:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine automático\")\n",
    "                    df = pd.read_excel(arquivo_path, header=0)\n",
    "\n",
    "                print(f\"   ✅ Sucesso! {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "                fm.logger.info(f\"Carregado: {arquivo_path.name} ({df.shape[0]} × {df.shape[1]})\")\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Falhou: {str(e)[:60]}...\")\n",
    "                if i == len(engines):\n",
    "                    if extensao == '.xls':\n",
    "                        print()\n",
    "                        print(\"💡 SOLUÇÃO para .XLS:\")\n",
    "                        print(\"   pip install xlrd\")\n",
    "                    raise Exception(f\"Falha ao ler: {e}\")\n",
    "\n",
    "        if df is None:\n",
    "            raise Exception(\"Nenhum engine funcionou\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 3: Limpeza (não necessária para este arquivo)\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"🧹 Limpeza de dados...\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   ✅ Nenhuma limpeza necessária (primeira linha = cabeçalho)\")\n",
    "        print(f\"   📊 Dados prontos: {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 4: Listar todas as colunas\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"📑 LISTAGEM COMPLETA DE COLUNAS\")\n",
    "        print(\"═\" * 80)\n",
    "        print(f\"📏 Total: {len(df.columns)} colunas\")\n",
    "        print()\n",
    "\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            tipo = df[col].dtype\n",
    "            nulos = df[col].isna().sum()\n",
    "            pct_nulos = (nulos / len(df) * 100) if len(df) > 0 else 0\n",
    "            unicos = df[col].nunique()\n",
    "\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       ├─ Tipo: {tipo}\")\n",
    "            print(f\"       ├─ Nulos: {nulos:,} ({pct_nulos:.1f}%)\")\n",
    "            print(f\"       └─ Únicos: {unicos:,}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 5: Preview dos dados\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"📊 PREVIEW DOS DADOS (primeiras 5 colunas)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        colunas_preview = list(df.columns[:5])\n",
    "        print(df[colunas_preview].head(5).to_string(index=False))\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 6: Backup\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"💾 Salvando backup...\")\n",
    "\n",
    "        timestamp = fm.timestamp\n",
    "        arquivo_destino = fm.diretorios['dados_entrada'] / \\\n",
    "                         f\"Centros_BR_{timestamp}.xlsx\"\n",
    "\n",
    "        try:\n",
    "            df.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "            fm.logger.info(f\"Backup: {arquivo_destino.name}\")\n",
    "            print(f\"   ✅ Backup salvo: {arquivo_destino.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao salvar backup: {str(e)}\")\n",
    "            fm.logger.error(f\"Erro backup: {str(e)}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # RESULTADO FINAL\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ✅ ARQUIVO CENTROS CARREGADO COM SUCESSO \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "\n",
    "        print(\"📊 RESUMO DO CARREGAMENTO:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"   • Arquivo: {arquivo_path.name}\")\n",
    "        print(f\"   • Registros: {len(df):,}\")\n",
    "        print(f\"   • Colunas: {len(df.columns)}\")\n",
    "        print(f\"   • Backup: ✅\")\n",
    "        print()\n",
    "\n",
    "        return df, arquivo_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ❌ ERRO AO CARREGAR ARQUIVO \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "        print(f\"❌ Erro: {str(e)}\")\n",
    "        print()\n",
    "\n",
    "        import traceback\n",
    "        print(\"🔍 Detalhes técnicos:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "        fm.logger.error(f\"Erro centros: {str(e)}\")\n",
    "\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# EXECUÇÃO: CARREGAR ARQUIVO 2\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print()\n",
    "print(\"⚠️  INSTRUÇÕES:\")\n",
    "print(\"   • Janela de seleção vai abrir\")\n",
    "print(\"   • Selecione o arquivo ysmm_centros_br.xlsx\")\n",
    "print(\"   • Primeira linha deve ser o cabeçalho\")\n",
    "print()\n",
    "\n",
    "input(\"👉 Pressione ENTER para iniciar...\")\n",
    "\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Carregar arquivo\n",
    "    df_centros, arquivo_centros = carregar_ysmm_centros()\n",
    "\n",
    "    if df_centros is not None:\n",
    "        # Salvar referência global\n",
    "        arquivo_centros_info = {\n",
    "            'df': df_centros,\n",
    "            'arquivo': arquivo_centros\n",
    "        }\n",
    "\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"✅ BLOCO 3 - ARQUIVO 2 CONCLUÍDO\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   1. ✅ Revise a lista de colunas acima\")\n",
    "        print(\"   2. ✅ Verifique se os dados fazem sentido\")\n",
    "        print(\"   3. 📤 Envie feedback:\")\n",
    "        print(\"       • 'ARQUIVO 2 OK' - para prosseguir\")\n",
    "        print(\"       • Descreva problemas - se houver erros\")\n",
    "        print(\"   4. ⏳ Aguarde próximo arquivo\")\n",
    "        print()\n",
    "        print(\"🔗 VARIÁVEIS DISPONÍVEIS:\")\n",
    "        print(\"   • df_centros - DataFrame com cadastro de centros\")\n",
    "        print(\"   • arquivo_centros_info - Metadados completos\")\n",
    "        print()\n",
    "\n",
    "        fm.logger.info(\"BLOCO 3 - Arquivo 2 (Centros) concluído\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print(\"⚠️  Operação cancelada pelo usuário\")\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ERRO FATAL - BLOCO 3 \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "    print(f\"❌ Erro: {str(e)}\")\n",
    "    print()\n",
    "    import traceback\n",
    "    print(\"🔍 Detalhes técnicos:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print()\n",
    "print(\"═\" * 80)"
   ],
   "id": "232087a72dbd916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                  BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2/N                   ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "⚠️  INSTRUÇÕES:\n",
      "   • Janela de seleção vai abrir\n",
      "   • Selecione o arquivo ysmm_centros_br.xlsx\n",
      "   • Primeira linha deve ser o cabeçalho\n",
      "\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║             ARQUIVO 2: ysmm_centros_br.xlsx (TABELA DE CENTROS)              ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:02:04 | INFO     | Carregado: ysmm_centros_br.xlsx (555 × 30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo selecionado:\n",
      "   📁 Nome: ysmm_centros_br.xlsx\n",
      "   📊 Tamanho: 117,411 bytes\n",
      "   🔧 Tipo: .xlsx\n",
      "\n",
      "📖 Carregando arquivo Excel (.xlsx)...\n",
      "   Tentativa 1/2: engine='openpyxl'\n",
      "   ✅ Sucesso! 555 linhas × 30 colunas\n",
      "\n",
      "🧹 Limpeza de dados...\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ Nenhuma limpeza necessária (primeira linha = cabeçalho)\n",
      "   📊 Dados prontos: 555 linhas × 30 colunas\n",
      "\n",
      "📑 LISTAGEM COMPLETA DE COLUNAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📏 Total: 30 colunas\n",
      "\n",
      "    1. Centro\n",
      "       ├─ Tipo: int64\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 555\n",
      "    2. Sigla\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 499\n",
      "    3. Regional/Região\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 463 (83.4%)\n",
      "       └─ Únicos: 5\n",
      "    4. Nome 1\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 550\n",
      "    5. Rua\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 485\n",
      "    6. Número\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 5 (0.9%)\n",
      "       └─ Únicos: 201\n",
      "    7. Compl\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 484 (87.2%)\n",
      "       └─ Únicos: 61\n",
      "    8. Bairro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 41 (7.4%)\n",
      "       └─ Únicos: 318\n",
      "    9. Local.Resd.Difer.\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 507 (91.4%)\n",
      "       └─ Únicos: 39\n",
      "   10. Código Postal\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 432\n",
      "   11. Cidade\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 210\n",
      "   12. Estado\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 27\n",
      "   13. Filial\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 247 (44.5%)\n",
      "       └─ Únicos: 259\n",
      "   14. CNPJ\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 143 (25.8%)\n",
      "       └─ Únicos: 354\n",
      "   15. Inscrição Estadual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 183 (33.0%)\n",
      "       └─ Únicos: 316\n",
      "   16. Inscrição Municipal\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 224 (40.4%)\n",
      "       └─ Únicos: 287\n",
      "   17. NIRE\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 333 (60.0%)\n",
      "       └─ Únicos: 219\n",
      "   18. ICAO\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 238 (42.9%)\n",
      "       └─ Únicos: 216\n",
      "   19. IATA\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 315 (56.8%)\n",
      "       └─ Únicos: 150\n",
      "   20. Centro Virtual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 247 (44.5%)\n",
      "       └─ Únicos: 2\n",
      "   21. Centro Inativo\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   22. Centro Fornecedor\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   23. Longitude\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 379 (68.3%)\n",
      "       └─ Únicos: 163\n",
      "   24. Latitude\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 379 (68.3%)\n",
      "       └─ Únicos: 163\n",
      "   25. Centro de Custo\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 30 (5.4%)\n",
      "       └─ Únicos: 345\n",
      "   26. Centro de Lucro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 30 (5.4%)\n",
      "       └─ Únicos: 341\n",
      "   27. Cliente Centro\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 290 (52.3%)\n",
      "       └─ Únicos: 265\n",
      "   28. Fornecedor Centro\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 264 (47.6%)\n",
      "       └─ Únicos: 291\n",
      "   29. Endereço\n",
      "       ├─ Tipo: int64\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 555\n",
      "   30. Agrpmto.estrut.reg.\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 48 (8.6%)\n",
      "       └─ Únicos: 10\n",
      "\n",
      "📊 PREVIEW DOS DADOS (primeiras 5 colunas)\n",
      "--------------------------------------------------------------------------------\n",
      " Centro         Sigla Regional/Região                       Nome 1                       Rua\n",
      "      1        Centro             NaN                  Centro 0001       RUA CORREIA VASQUES\n",
      "      2        Centro             NaN      Centro 0002 - padrão PS                       NaN\n",
      "   5001 Administração             NaN Administração Central  VIBRA       RUA CORREIA VASQUES\n",
      "   5002      exDISGUA             NaN  exDISGUA Antiga Regional RJ Pça Vinte e Dois de Abril\n",
      "   5003         UNISP             NaN      UNISP - UNIDADE ADM. SP                 R Funchal\n",
      "\n",
      "💾 Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:02:04 | INFO     | Backup: Centros_BR_20251015_110105.xlsx\n",
      "2025-10-15 11:02:04 | INFO     | BLOCO 3 - Arquivo 2 (Centros) concluído\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Backup salvo: Centros_BR_20251015_110105.xlsx\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                   ✅ ARQUIVO CENTROS CARREGADO COM SUCESSO                    ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 RESUMO DO CARREGAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   • Arquivo: ysmm_centros_br.xlsx\n",
      "   • Registros: 555\n",
      "   • Colunas: 30\n",
      "   • Backup: ✅\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "✅ BLOCO 3 - ARQUIVO 2 CONCLUÍDO\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📋 PRÓXIMOS PASSOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ✅ Revise a lista de colunas acima\n",
      "   2. ✅ Verifique se os dados fazem sentido\n",
      "   3. 📤 Envie feedback:\n",
      "       • 'ARQUIVO 2 OK' - para prosseguir\n",
      "       • Descreva problemas - se houver erros\n",
      "   4. ⏳ Aguarde próximo arquivo\n",
      "\n",
      "🔗 VARIÁVEIS DISPONÍVEIS:\n",
      "   • df_centros - DataFrame com cadastro de centros\n",
      "   • arquivo_centros_info - Metadados completos\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:02:15.585108Z",
     "start_time": "2025-10-15T18:02:14.712700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "BLOCO 4: CARREGADOR AIVI OPAV BW - CORRIGIDO v3\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "Sheet correto: \"Valor da Variação Total\"\n",
    "Cabeçalho: L34-AM34 (APENAS, colunas AW-BH descartadas)\n",
    "Resultado: 28 colunas (7 dimensões + 21 movimentações)\n",
    "Tratamento dinâmico de duplicadas: sufixo _dup1, _dup2, etc\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"BLOCO 4: CARREGADOR AIVI OPAV BW - ARQUIVO 3/N\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1: Seleção do arquivo\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'fm' in dir():\n",
    "    padrao_bw = '*xSAPtemp*.xls*'\n",
    "    arquivos_encontrados = list(fm.diretorios['dados_entrada'].glob(padrao_bw))\n",
    "\n",
    "    if arquivos_encontrados:\n",
    "        arquivo_path = arquivos_encontrados[0]\n",
    "        print(f\"Arquivo encontrado: {arquivo_path.name}\")\n",
    "    else:\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"Selecione arquivo BW (xSAPtemp...)\",\n",
    "            filetypes=[(\"Excel\", \"*.xls *.xlsx\"), (\"All\", \"*.*\")]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"Nenhum arquivo selecionado\")\n",
    "\n",
    "        arquivo_path = Path(arquivo)\n",
    "else:\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.attributes('-topmost', True)\n",
    "\n",
    "    arquivo = filedialog.askopenfilename(\n",
    "        title=\"Selecione arquivo BW (xSAPtemp...)\",\n",
    "        filetypes=[(\"Excel\", \"*.xls *.xlsx\"), (\"All\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    root.destroy()\n",
    "\n",
    "    if not arquivo:\n",
    "        raise ValueError(\"Nenhum arquivo selecionado\")\n",
    "\n",
    "    arquivo_path = Path(arquivo)\n",
    "\n",
    "print(f\"Arquivo selecionado: {arquivo_path.name}\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 2: Carregar SHEET CORRETO\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 2: Carregando sheet correto...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Nome do sheet correto\n",
    "SHEET_NAME = \"Valor da Variação Total\"\n",
    "\n",
    "try:\n",
    "    # Método 1: xlrd (mais confiável para .xls)\n",
    "    print(f\"Tentando xlrd (sheet: '{SHEET_NAME}')...\")\n",
    "\n",
    "    workbook = xlrd.open_workbook(str(arquivo_path))\n",
    "\n",
    "    # Listar sheets\n",
    "    print(f\"   Sheets disponiveis: {workbook.sheet_names()}\")\n",
    "\n",
    "    # Verificar se sheet existe\n",
    "    if SHEET_NAME not in workbook.sheet_names():\n",
    "        raise ValueError(f\"Sheet '{SHEET_NAME}' nao encontrado!\")\n",
    "\n",
    "    # Pegar sheet correto\n",
    "    sheet = workbook.sheet_by_name(SHEET_NAME)\n",
    "\n",
    "    print(f\"   Sheet: '{SHEET_NAME}'\")\n",
    "    print(f\"   Linhas: {sheet.nrows:,}\")\n",
    "    print(f\"   Colunas: {sheet.ncols}\")\n",
    "\n",
    "    # Converter para lista de listas\n",
    "    data = []\n",
    "    for row_idx in range(sheet.nrows):\n",
    "        data.append(sheet.row_values(row_idx))\n",
    "\n",
    "    # Criar DataFrame\n",
    "    df_bruto = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"   DataFrame criado: {df_bruto.shape[0]:,} x {df_bruto.shape[1]}\")\n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   Erro com xlrd: {str(e)}\")\n",
    "    print()\n",
    "\n",
    "    # Método 2: pandas como fallback\n",
    "    print(f\"Tentando pandas (sheet: '{SHEET_NAME}')...\")\n",
    "\n",
    "    df_bruto = pd.read_excel(\n",
    "        arquivo_path,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "    print(f\"   DataFrame criado: {df_bruto.shape[0]:,} x {df_bruto.shape[1]}\")\n",
    "    print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 3: VERIFICAR LINHA 34 (índice 33)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 3: Verificando linha 34 (cabecalho)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Linha 34 Excel = índice 33 pandas\n",
    "linha_34 = df_bruto.iloc[33]\n",
    "\n",
    "# Verificar colunas L-BH (índices 11-59)\n",
    "cols_lbh = linha_34.iloc[11:60]\n",
    "\n",
    "# Contar não-nulas\n",
    "non_null = cols_lbh.notna().sum()\n",
    "print(f\"   Celulas nao-nulas em L34-BH34: {non_null}/49\")\n",
    "\n",
    "# Mostrar primeiras não-nulas\n",
    "print(f\"   Primeiros valores nao-nulos:\")\n",
    "count = 0\n",
    "for i, val in enumerate(cols_lbh):\n",
    "    if pd.notna(val) and count < 10:\n",
    "        col_idx = 11 + i\n",
    "        # Nome da coluna (L=11, M=12, etc)\n",
    "        if col_idx < 26:\n",
    "            col_name = chr(65 + col_idx)\n",
    "        else:\n",
    "            col_name = chr(65 + (col_idx // 26) - 1) + chr(65 + (col_idx % 26))\n",
    "\n",
    "        val_str = str(val)[:30]\n",
    "        print(f\"      {col_name}34 (idx={col_idx}): '{val_str}'\")\n",
    "        count += 1\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 4: EXTRAIR CABEÇALHO CORRETO\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 4: Extraindo cabecalho das colunas especificas...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Linha 34 Excel = índice 33\n",
    "linha_cabecalho = df_bruto.iloc[33]\n",
    "\n",
    "# APENAS PARTE 1: Colunas L-AM (índices 11-38)\n",
    "# L=11, M=12, ..., AM=38 (28 colunas)\n",
    "cabecalho_bruto = linha_cabecalho.iloc[11:39].tolist()\n",
    "\n",
    "print(f\"   COLUNAS EXTRAIDAS (L34-AM34): {len(cabecalho_bruto)} colunas\")\n",
    "print()\n",
    "\n",
    "# Limpar nomes\n",
    "cabecalho_temp = []\n",
    "for i, nome in enumerate(cabecalho_bruto):\n",
    "    if pd.isna(nome) or str(nome).strip() == '':\n",
    "        nome_limpo = f'Col_{i}'\n",
    "    else:\n",
    "        # Remover apóstrofo inicial se existir\n",
    "        nome_str = str(nome).strip()\n",
    "        if nome_str.startswith(\"'\"):\n",
    "            nome_str = nome_str[1:]\n",
    "        # Remover quebras de linha\n",
    "        nome_str = nome_str.replace('\\n', ' ')\n",
    "        nome_limpo = nome_str\n",
    "    cabecalho_temp.append(nome_limpo)\n",
    "\n",
    "# Tratar duplicadas (adicionar sufixo _dup1, _dup2, etc)\n",
    "from collections import Counter\n",
    "\n",
    "contagem = Counter(cabecalho_temp)\n",
    "duplicadas = {nome: count for nome, count in contagem.items() if count > 1}\n",
    "\n",
    "if duplicadas:\n",
    "    print(f\"   AVISO: {len(duplicadas)} nomes duplicados encontrados\")\n",
    "    for nome, count in list(duplicadas.items())[:5]:\n",
    "        print(f\"      '{nome}': {count} ocorrencias\")\n",
    "    print()\n",
    "\n",
    "# Renomear duplicadas\n",
    "cabecalho_limpo = []\n",
    "contador = {}\n",
    "\n",
    "for nome in cabecalho_temp:\n",
    "    if nome in contador:\n",
    "        contador[nome] += 1\n",
    "        novo_nome = f\"{nome}_dup{contador[nome]}\"\n",
    "        cabecalho_limpo.append(novo_nome)\n",
    "    else:\n",
    "        contador[nome] = 0\n",
    "        cabecalho_limpo.append(nome)\n",
    "\n",
    "# Mostrar cabeçalho final\n",
    "print(\"   Cabecalho final:\")\n",
    "for i, nome in enumerate(cabecalho_limpo[:10], 1):\n",
    "    print(f\"      A{i if i <= 9 else str(i)}: {nome}\")\n",
    "if len(cabecalho_limpo) > 10:\n",
    "    print(f\"      ... (mais {len(cabecalho_limpo) - 10} colunas)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 5: EXTRAIR DADOS (linhas após linha 34)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 5: Extraindo dados...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Dados começam na linha 35 (índice 34)\n",
    "linha_inicio_dados = 34\n",
    "\n",
    "# Extrair APENAS colunas L-AM (índices 11-38)\n",
    "df_final = df_bruto.iloc[linha_inicio_dados:, 11:39].copy()\n",
    "\n",
    "# Aplicar cabeçalho\n",
    "df_final.columns = cabecalho_limpo\n",
    "\n",
    "# Reset index\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "print(f\"   Registros: {len(df_final):,}\")\n",
    "print(f\"   Colunas: {len(df_final.columns)}\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 6: CONVERTER DIMENSÕES PARA STRING\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 6: Convertendo dimensoes para STRING...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Primeiras 7 colunas = dimensões\n",
    "dimensoes_cols = df_final.columns[:7].tolist()\n",
    "\n",
    "for col in dimensoes_cols:\n",
    "    if col in df_final.columns:\n",
    "        df_final[col] = df_final[col].astype(str)\n",
    "        print(f\"   '{col}' -> STRING\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 7: PREVIEW DOS DADOS\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 7: PREVIEW DOS DADOS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Primeiras 7 colunas (DIMENSOES):\")\n",
    "print(df_final.iloc[:, :7].head(5).to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Primeiras 5 linhas completas:\")\n",
    "print(df_final.head(5).to_string(index=False, max_colwidth=20))\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 8: ESTATÍSTICAS DAS COLUNAS\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 8: ESTATISTICAS DAS COLUNAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, col in enumerate(df_final.columns, 1):\n",
    "    # Tratar caso de coluna duplicada (retorna DataFrame)\n",
    "    try:\n",
    "        col_serie = df_final[col]\n",
    "\n",
    "        # Se retornar DataFrame (duplicada), pegar primeira coluna\n",
    "        if isinstance(col_serie, pd.DataFrame):\n",
    "            col_serie = col_serie.iloc[:, 0]\n",
    "\n",
    "        tipo = col_serie.dtype\n",
    "        nulos = col_serie.isna().sum()\n",
    "        pct_nulos = (nulos / len(df_final) * 100) if len(df_final) > 0 else 0\n",
    "        unicos = col_serie.nunique()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback se der erro\n",
    "        tipo = \"unknown\"\n",
    "        nulos = 0\n",
    "        pct_nulos = 0.0\n",
    "        unicos = 0\n",
    "        print(f\"   AVISO: Erro ao analisar coluna '{col}': {str(e)[:50]}\")\n",
    "\n",
    "    # Identificar bloco\n",
    "    if i <= 7:\n",
    "        bloco = \"DIMENSAO\"\n",
    "    elif i <= 28:\n",
    "        bloco = \"MOVIM_BLK1\"\n",
    "    else:\n",
    "        bloco = \"MOVIM_BLK2\"\n",
    "\n",
    "    print(f\"   {i:2d}. {col[:30]}\")\n",
    "    print(f\"       Bloco: {bloco} | Tipo: {tipo} | Nulos: {pct_nulos:.1f}% | Unicos: {unicos:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 9: SALVAR BACKUP\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 9: Salvando backup...\")\n",
    "\n",
    "if 'fm' in dir():\n",
    "    timestamp = fm.timestamp\n",
    "    arquivo_destino = fm.diretorios['dados_entrada'] / f\"AIVI_OPAV_BW_{timestamp}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        df_final.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "        fm.logger.info(f\"Backup BW: {arquivo_destino.name}\")\n",
    "        print(f\"   Backup: {arquivo_destino.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Erro ao salvar: {str(e)}\")\n",
    "        fm.logger.error(f\"Erro backup BW: {str(e)}\")\n",
    "else:\n",
    "    print(\"   FileManager nao disponivel - backup ignorado\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ARQUIVO BW CARREGADO E PROCESSADO COM SUCESSO\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"RESUMO DO PROCESSAMENTO:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   Arquivo: {arquivo_path.name}\")\n",
    "print(f\"   Sheet: {SHEET_NAME}\")\n",
    "print(f\"   Registros: {len(df_final):,}\")\n",
    "print(f\"   Colunas totais: {len(df_final.columns)}\")\n",
    "print(f\"   Dimensoes (1-7): 7\")\n",
    "print(f\"   Movimentacoes (8-{len(df_final.columns)}): {len(df_final.columns) - 7}\")\n",
    "print()\n",
    "\n",
    "# Salvar na variável global\n",
    "df_opav = df_final\n",
    "arquivo_opav = arquivo_path\n",
    "\n",
    "print(\"VARIAVEIS DISPONIVEIS:\")\n",
    "print(\"   df_opav - DataFrame BW processado\")\n",
    "print(\"   arquivo_opav - Path do arquivo\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FIM BLOCO 4\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "fc881bbc1ead00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOCO 4: CARREGADOR AIVI OPAV BW - ARQUIVO 3/N\n",
      "================================================================================\n",
      "\n",
      "Arquivo encontrado: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "Arquivo selecionado: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "\n",
      "ETAPA 2: Carregando sheet correto...\n",
      "--------------------------------------------------------------------------------\n",
      "Tentando xlrd (sheet: 'Valor da Variação Total')...\n",
      "   Sheets disponiveis: ['SAPBEXqueriesDefunct', 'SAPBEXfiltersDefunct', 'Valor da Variação Total', 'Valor da Variação Total Grupo', 'Limite Técnico', 'Justificar', 'Limite Técnico Grupo', 'BExRepositorySheet', 'Justificar Grupo', 'Custo do Produto', 'Imposto']\n",
      "   Sheet: 'Valor da Variação Total'\n",
      "   Linhas: 1,001\n",
      "   Colunas: 60\n",
      "   DataFrame criado: 1,001 x 60\n",
      "\n",
      "ETAPA 3: Verificando linha 34 (cabecalho)...\n",
      "--------------------------------------------------------------------------------\n",
      "   Celulas nao-nulas em L34-BH34: 49/49\n",
      "   Primeiros valores nao-nulos:\n",
      "      L34 (idx=11): 'Centro de lucro'\n",
      "      M34 (idx=12): 'Ano civil/mês'\n",
      "      N34 (idx=13): 'Centro'\n",
      "      O34 (idx=14): ''\n",
      "      P34 (idx=15): 'HierarqPrd'\n",
      "      Q34 (idx=16): 'Produto'\n",
      "      R34 (idx=17): ''\n",
      "      S34 (idx=18): 'Estoque\n",
      "Inicial'\n",
      "      T34 (idx=19): 'Entrada'\n",
      "      U34 (idx=20): 'Variação\n",
      "Externa'\n",
      "\n",
      "ETAPA 4: Extraindo cabecalho das colunas especificas...\n",
      "--------------------------------------------------------------------------------\n",
      "   COLUNAS EXTRAIDAS (L34-AM34): 28 colunas\n",
      "\n",
      "   Cabecalho final:\n",
      "      A1: Centro de lucro\n",
      "      A2: Ano civil/mês\n",
      "      A3: Centro\n",
      "      A4: Col_3\n",
      "      A5: HierarqPrd\n",
      "      A6: Produto\n",
      "      A7: Col_6\n",
      "      A8: Estoque Inicial\n",
      "      A9: Entrada\n",
      "      A10: Variação Externa\n",
      "      ... (mais 18 colunas)\n",
      "\n",
      "ETAPA 5: Extraindo dados...\n",
      "--------------------------------------------------------------------------------\n",
      "   Registros: 967\n",
      "   Colunas: 28\n",
      "\n",
      "ETAPA 6: Convertendo dimensoes para STRING...\n",
      "--------------------------------------------------------------------------------\n",
      "   'Centro de lucro' -> STRING\n",
      "   'Ano civil/mês' -> STRING\n",
      "   'Centro' -> STRING\n",
      "   'Col_3' -> STRING\n",
      "   'HierarqPrd' -> STRING\n",
      "   'Produto' -> STRING\n",
      "   'Col_6' -> STRING\n",
      "\n",
      "ETAPA 7: PREVIEW DOS DADOS\n",
      "--------------------------------------------------------------------------------\n",
      "Primeiras 7 colunas (DIMENSOES):\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                      Col_6\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422    JET A NAO TABELADO - LI\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACIONAL I - LI\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078           GASOLINA COMUM C\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "\n",
      "Primeiras 5 linhas completas:\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                Col_6 Estoque Inicial    Entrada Variação Externa Variação Externa % Variação Interna Variação Interna % Variação Total Variação Total % Custo Unitário do Produto  Imposto Valor da Variação Interna Col_18 Quantidade Excedente da Variação Externa Valor Excedente da Variação Externa (R$) Quantidade Excedente da Variação Interna Valor Excedente da Variação Interna (R$) Quantidade Excedente da Variação Total Valor Excedente da Variação Total (R$) Valor Excedente da Variação Total + Imposto (R$) Competência para Absorção da Variação Total Excedente (R$) Competência para Absorção da Variação Total Excedente (R$) com LM e N4\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674    ÓLEO DIESEL B S10         16924.0                                                            18.0           0.106358           18.0         0.106358             5.300122           0.0            95.402202                              0.0                                      0.0                                    10.19                                54.008246                                    10.19                                  54.01                                  54.01                                               N3                                                         LM                                                  \n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422 JET A NAO TABELAD...        373850.0   939139.0            824.0            0.08774            -10.0          -0.000762          814.0         0.036144             3.890482      -2811.15           -38.904816                           366.22                              1424.772156                                      0.0                                      0.0                                      0.0                                    0.0                                2811.15                                                -                                                          -                                                  \n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACION...        598315.0  5188210.0           1494.0           0.028796                                             1494.0         0.013613             3.882566           0.0                  0.0                              0.0                                      0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                                -                                                          -                                                  \n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078     GASOLINA COMUM C         13076.0    14828.0              5.0            0.03372            234.0           0.838589          239.0           0.5593             5.133078           0.0          1201.140348                              0.0                                      0.0                                   220.33                              1130.971166                                   220.33                                1130.97                                1130.97                                               N3                                                         LM                                                  \n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674    ÓLEO DIESEL B S10        122306.0   178128.0            -17.0          -0.009544           -382.0          -0.127149         -399.0        -0.083375             5.331511           0.0         -2036.637033                              0.0                                      0.0                                  -240.63                             -1282.921386                                  -240.63                               -1282.92                               -1282.92                                               N3                                                         LM                                                  \n",
      "\n",
      "ETAPA 8: ESTATISTICAS DAS COLUNAS\n",
      "--------------------------------------------------------------------------------\n",
      "    1. Centro de lucro\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 2\n",
      "    2. Ano civil/mês\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 2\n",
      "    3. Centro\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 89\n",
      "    4. Col_3\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 89\n",
      "    5. HierarqPrd\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 5\n",
      "    6. Produto\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 15\n",
      "    7. Col_6\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 15\n",
      "    8. Estoque Inicial\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 183\n",
      "    9. Entrada\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 122\n",
      "   10. Variação Externa\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 104\n",
      "   11. Variação Externa %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 110\n",
      "   12. Variação Interna\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 98\n",
      "   13. Variação Interna %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 97\n",
      "   14. Variação Total\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 121\n",
      "   15. Variação Total %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 121\n",
      "   16. Custo Unitário do Produto\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 124\n",
      "   17. Imposto\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 29\n",
      "   18. Valor da Variação Interna\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 100\n",
      "   19. Col_18\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 1\n",
      "   20. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 43\n",
      "   21. Valor Excedente da Variação Ex\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 43\n",
      "   22. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   23. Valor Excedente da Variação In\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   24. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   25. Valor Excedente da Variação To\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   26. Valor Excedente da Variação To\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 49\n",
      "   27. Competência para Absorção da V\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 3\n",
      "   28. Competência para Absorção da V\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 4\n",
      "\n",
      "ETAPA 9: Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 15:02:15 | INFO     | Backup BW: AIVI_OPAV_BW_20251015_110105.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Backup: AIVI_OPAV_BW_20251015_110105.xlsx\n",
      "\n",
      "================================================================================\n",
      "ARQUIVO BW CARREGADO E PROCESSADO COM SUCESSO\n",
      "================================================================================\n",
      "\n",
      "RESUMO DO PROCESSAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   Arquivo: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   Sheet: Valor da Variação Total\n",
      "   Registros: 967\n",
      "   Colunas totais: 28\n",
      "   Dimensoes (1-7): 7\n",
      "   Movimentacoes (8-28): 21\n",
      "\n",
      "VARIAVEIS DISPONIVEIS:\n",
      "   df_opav - DataFrame BW processado\n",
      "   arquivo_opav - Path do arquivo\n",
      "\n",
      "================================================================================\n",
      "FIM BLOCO 4\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:33:04.046925Z",
     "start_time": "2025-10-15T14:33:00.270907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "Busca recursiva: *xSAPtemp*.xls* em pasta e subpastas\n",
    "Carrega cada arquivo com mesmo padrão do BLOCO 4\n",
    "Unifica tudo em um único DataFrame\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# CONFIGURAÇÕES\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "SHEET_NAME = \"Valor da Variação Total\"\n",
    "LINHA_CABECALHO = 33  # Linha 34 do Excel\n",
    "LINHA_INICIO_DADOS = 34\n",
    "\n",
    "# Colunas a extrair (APENAS L-AM, 28 colunas)\n",
    "COLS_EXTRAIR = (11, 39)  # L-AM (índices 11-38)\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# FUNÇÕES AUXILIARES (do BLOCO 4)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "def limpar_nome_coluna(nome):\n",
    "    \"\"\"\n",
    "    Limpa nome de coluna de caracteres especiais\n",
    "    \"\"\"\n",
    "    if pd.isna(nome) or str(nome).strip() == '':\n",
    "        return None\n",
    "\n",
    "    nome_str = str(nome).strip()\n",
    "    nome_str = nome_str.lstrip(\"'\")\n",
    "    nome_str = nome_str.replace('\\n', ' ')\n",
    "    nome_str = nome_str.replace('\\r', ' ')\n",
    "    nome_str = ' '.join(nome_str.split())\n",
    "\n",
    "    return nome_str\n",
    "\n",
    "def tratar_duplicadas(colunas):\n",
    "    \"\"\"\n",
    "    Adiciona sufixo _dup1, _dup2 às duplicadas\n",
    "    \"\"\"\n",
    "    contagem = Counter(colunas)\n",
    "    duplicadas = {n: c for n, c in contagem.items() if c > 1}\n",
    "\n",
    "    if duplicadas:\n",
    "        print(f\"   AVISO: {len(duplicadas)} nomes duplicados\")\n",
    "        for nome, count in list(duplicadas.items())[:3]:\n",
    "            print(f\"      '{nome}': {count} ocorrencias\")\n",
    "\n",
    "    colunas_novas = []\n",
    "    contador = {}\n",
    "\n",
    "    for nome in colunas:\n",
    "        if nome in contador:\n",
    "            contador[nome] += 1\n",
    "            colunas_novas.append(f\"{nome}_dup{contador[nome]}\")\n",
    "        else:\n",
    "            contador[nome] = 0\n",
    "            colunas_novas.append(nome)\n",
    "\n",
    "    return colunas_novas\n",
    "\n",
    "def carregar_arquivo_opav(arquivo_path):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo OPAV seguindo padrão do BLOCO 4\n",
    "\n",
    "    Retorna: DataFrame ou None se erro\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\n📄 Processando: {arquivo_path.name}\")\n",
    "        print(\"   \" + \"-\" * 76)\n",
    "\n",
    "        # Carregar com xlrd\n",
    "        workbook = xlrd.open_workbook(str(arquivo_path))\n",
    "\n",
    "        # Verificar sheet\n",
    "        if SHEET_NAME not in workbook.sheet_names():\n",
    "            print(f\"   ❌ Sheet '{SHEET_NAME}' nao encontrado\")\n",
    "            print(f\"   Sheets disponiveis: {workbook.sheet_names()}\")\n",
    "            return None\n",
    "\n",
    "        sheet = workbook.sheet_by_name(SHEET_NAME)\n",
    "        print(f\"   ✅ Sheet: '{SHEET_NAME}' ({sheet.nrows} linhas × {sheet.ncols} cols)\")\n",
    "\n",
    "        # Converter para DataFrame\n",
    "        data = [sheet.row_values(i) for i in range(sheet.nrows)]\n",
    "        df_bruto = pd.DataFrame(data)\n",
    "\n",
    "        # Extrair cabeçalho (APENAS L-AM)\n",
    "        linha_cab = df_bruto.iloc[LINHA_CABECALHO]\n",
    "        cab_bruto = linha_cab.iloc[COLS_EXTRAIR[0]:COLS_EXTRAIR[1]].tolist()\n",
    "\n",
    "        # Limpar cabeçalho\n",
    "        cab_temp = [limpar_nome_coluna(c) or f'Col_{i}'\n",
    "                    for i, c in enumerate(cab_bruto)]\n",
    "\n",
    "        # Tratar duplicadas\n",
    "        cab_final = tratar_duplicadas(cab_temp)\n",
    "\n",
    "        # Extrair dados (APENAS L-AM)\n",
    "        df_final = df_bruto.iloc[LINHA_INICIO_DADOS:, COLS_EXTRAIR[0]:COLS_EXTRAIR[1]].copy()\n",
    "\n",
    "        df_final.columns = cab_final\n",
    "        df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "        # Adicionar metadados\n",
    "        df_final['_arquivo_origem'] = arquivo_path.name\n",
    "        df_final['_arquivo_path'] = str(arquivo_path)\n",
    "        df_final['_data_carga'] = pd.Timestamp.now()\n",
    "\n",
    "        print(f\"   ✅ Carregado: {len(df_final):,} registros × {len(cab_final)} colunas\")\n",
    "\n",
    "        return df_final\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ ERRO: {str(e)[:100]}\")\n",
    "        import traceback\n",
    "        print(f\"   Detalhes: {traceback.format_exc()[:200]}\")\n",
    "        return None\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1: Determinar pasta base\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 1: Determinar pasta com arquivos OPAV\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "pasta_base = None\n",
    "\n",
    "# OPÇÃO 1: Usar pasta do arquivo já carregado (BLOCO 4)\n",
    "if 'arquivo_opav' in dir():\n",
    "    pasta_arquivo = arquivo_opav.parent\n",
    "    print(f\"📁 Arquivo OPAV ja carregado no BLOCO 4:\")\n",
    "    print(f\"   Arquivo: {arquivo_opav.name}\")\n",
    "    print(f\"   Pasta: {pasta_arquivo}\")\n",
    "    print()\n",
    "\n",
    "    # Verificar se há outros arquivos nessa pasta\n",
    "    outros_arquivos = list(pasta_arquivo.glob('*xSAPtemp*.xls*'))\n",
    "\n",
    "    if len(outros_arquivos) > 1:\n",
    "        print(f\"   ✅ Encontrados {len(outros_arquivos)} arquivos xSAPtemp nesta pasta\")\n",
    "        print(f\"   Usando esta pasta como base\")\n",
    "        pasta_base = pasta_arquivo\n",
    "    elif len(outros_arquivos) == 1:\n",
    "        print(f\"   ⚠️  Apenas 1 arquivo xSAPtemp nesta pasta\")\n",
    "        print(f\"   Vou perguntar se quer buscar em outra pasta\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Nenhum arquivo xSAPtemp nesta pasta\")\n",
    "        print(f\"   Vou perguntar outra pasta\")\n",
    "\n",
    "# OPÇÃO 2: Perguntar ao usuário\n",
    "if pasta_base is None:\n",
    "    print()\n",
    "    print(\"═\" * 80)\n",
    "    print(\"📂 SELEÇÃO DE PASTA\")\n",
    "    print(\"═\" * 80)\n",
    "    print()\n",
    "    print(\"Opcoes:\")\n",
    "    print(\"   1. Selecionar pasta manualmente\")\n",
    "    if 'arquivo_opav' in dir():\n",
    "        print(f\"   2. Usar pasta do arquivo atual ({arquivo_opav.parent.name})\")\n",
    "    if 'fm' in dir():\n",
    "        print(f\"   3. Usar pasta do FileManager ({fm.diretorios['dados_entrada'].name})\")\n",
    "    print()\n",
    "\n",
    "    escolha = input(\"Escolha (1/2/3): \").strip()\n",
    "\n",
    "    if escolha == '1':\n",
    "        # Janela de seleção\n",
    "        print(\"\\nAbrindo janela de selecao de pasta...\")\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        pasta = filedialog.askdirectory(\n",
    "            title=\"Selecione pasta com arquivos OPAV (xSAPtemp...)\"\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not pasta:\n",
    "            raise ValueError(\"Nenhuma pasta selecionada\")\n",
    "\n",
    "        pasta_base = Path(pasta)\n",
    "\n",
    "    elif escolha == '2' and 'arquivo_opav' in dir():\n",
    "        pasta_base = arquivo_opav.parent\n",
    "\n",
    "    elif escolha == '3' and 'fm' in dir():\n",
    "        pasta_base = fm.diretorios['dados_entrada']\n",
    "\n",
    "    else:\n",
    "        # Default: FileManager ou erro\n",
    "        if 'fm' in dir():\n",
    "            pasta_base = fm.diretorios['dados_entrada']\n",
    "        else:\n",
    "            raise ValueError(\"Opcao invalida\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1.5: Copiar arquivo para pasta FileManager (se necessário)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'arquivo_opav' in dir() and 'fm' in dir():\n",
    "    # Verificar se arquivo está fora da pasta do FileManager\n",
    "    arquivo_atual = arquivo_opav\n",
    "    pasta_fm = fm.diretorios['dados_entrada']\n",
    "\n",
    "    if arquivo_atual.parent != pasta_fm:\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"📋 ARQUIVO FORA DA PASTA DO FILEMANAGER\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(f\"Arquivo atual: {arquivo_atual}\")\n",
    "        print(f\"Pasta FileManager: {pasta_fm}\")\n",
    "        print()\n",
    "\n",
    "        # Verificar tamanho\n",
    "        tamanho_mb = arquivo_atual.stat().st_size / (1024 * 1024)\n",
    "        print(f\"Tamanho do arquivo: {tamanho_mb:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "        if tamanho_mb > 50:\n",
    "            print(\"⚠️  Arquivo grande (>50MB)\")\n",
    "            print()\n",
    "            print(\"Opcoes:\")\n",
    "            print(\"   1. Copiar para pasta FileManager (pode demorar)\")\n",
    "            print(\"   2. Buscar na pasta atual do arquivo\")\n",
    "            print(\"   3. Selecionar outra pasta\")\n",
    "            print()\n",
    "\n",
    "            escolha_copia = input(\"Escolha (1/2/3): \").strip()\n",
    "\n",
    "            if escolha_copia == '1':\n",
    "                print(\"\\n📋 Copiando arquivo...\")\n",
    "                import shutil\n",
    "\n",
    "                destino = pasta_fm / arquivo_atual.name\n",
    "\n",
    "                try:\n",
    "                    shutil.copy2(arquivo_atual, destino)\n",
    "                    print(f\"   ✅ Copiado para: {destino}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Erro ao copiar: {str(e)}\")\n",
    "                    print(f\"   Usando pasta original\")\n",
    "                    print()\n",
    "\n",
    "            elif escolha_copia == '2':\n",
    "                print(\"\\n✅ Usando pasta do arquivo atual\")\n",
    "                print()\n",
    "\n",
    "            elif escolha_copia == '3':\n",
    "                print(\"\\n📂 Abrindo janela de selecao...\")\n",
    "                root = tk.Tk()\n",
    "                root.withdraw()\n",
    "                root.lift()\n",
    "                root.attributes('-topmost', True)\n",
    "\n",
    "                pasta = filedialog.askdirectory(\n",
    "                    title=\"Selecione pasta com arquivos OPAV\"\n",
    "                )\n",
    "\n",
    "                root.destroy()\n",
    "\n",
    "                if pasta:\n",
    "                    pasta_base = Path(pasta)\n",
    "                    print(f\"   ✅ Pasta selecionada: {pasta_base}\")\n",
    "                print()\n",
    "        else:\n",
    "            # Arquivo pequeno (<50MB), copiar automaticamente\n",
    "            print(\"✅ Arquivo pequeno (<50MB)\")\n",
    "            print(\"   Copiando para pasta FileManager...\")\n",
    "\n",
    "            import shutil\n",
    "            destino = pasta_fm / arquivo_atual.name\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(arquivo_atual, destino)\n",
    "                print(f\"   ✅ Copiado para: {destino.name}\")\n",
    "                print()\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  Erro ao copiar: {str(e)}\")\n",
    "                print(f\"   Continuando com pasta original\")\n",
    "                print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"✅ PASTA BASE DEFINIDA: {pasta_base}\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 2: Buscar arquivos recursivamente\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 2: Buscando arquivos xSAPtemp recursivamente...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Buscar com glob recursivo\n",
    "padroes = ['*xSAPtemp*.xls', '*xSAPtemp*.xlsx']\n",
    "arquivos_encontrados = []\n",
    "\n",
    "for padrao in padroes:\n",
    "    arquivos_encontrados.extend(pasta_base.rglob(padrao))\n",
    "\n",
    "# Remover duplicatas (caso encontre mesmo arquivo com ambos padrões)\n",
    "arquivos_encontrados = list(set(arquivos_encontrados))\n",
    "\n",
    "# Ordenar por nome\n",
    "arquivos_encontrados.sort(key=lambda x: x.name)\n",
    "\n",
    "print(f\"✅ Encontrados: {len(arquivos_encontrados)} arquivos\")\n",
    "print()\n",
    "\n",
    "if len(arquivos_encontrados) == 0:\n",
    "    print(\"❌ NENHUM ARQUIVO ENCONTRADO!\")\n",
    "    print()\n",
    "    print(\"Padrões buscados:\")\n",
    "    for padrao in padroes:\n",
    "        print(f\"   • {padrao}\")\n",
    "    print()\n",
    "    print(f\"Pasta base: {pasta_base}\")\n",
    "    print()\n",
    "    raise ValueError(\"Nenhum arquivo xSAPtemp encontrado\")\n",
    "\n",
    "# Listar arquivos encontrados\n",
    "print(\"📋 ARQUIVOS ENCONTRADOS:\")\n",
    "print(\"-\" * 80)\n",
    "for i, arq in enumerate(arquivos_encontrados, 1):\n",
    "    # Caminho relativo à pasta base\n",
    "    rel_path = arq.relative_to(pasta_base)\n",
    "    tamanho_mb = arq.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   {i:2d}. {arq.name}\")\n",
    "    print(f\"       Pasta: {rel_path.parent}\")\n",
    "    print(f\"       Tamanho: {tamanho_mb:.2f} MB\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Confirmação do usuário\n",
    "print(\"═\" * 80)\n",
    "print(\"⚠️  CONFIRMAÇÃO NECESSÁRIA\")\n",
    "print(\"═\" * 80)\n",
    "print()\n",
    "print(f\"Foram encontrados {len(arquivos_encontrados)} arquivos.\")\n",
    "print(\"Todos serão processados e unificados em um único DataFrame.\")\n",
    "print()\n",
    "print(\"Deseja prosseguir?\")\n",
    "print(\"   [ENTER] = SIM, continuar\")\n",
    "print(\"   [Ctrl+C] = NÃO, cancelar\")\n",
    "print()\n",
    "\n",
    "input(\"Pressione ENTER para continuar...\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 3: Carregar todos os arquivos\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 3: Carregando todos os arquivos...\")\n",
    "print(\"═\" * 80)\n",
    "\n",
    "dataframes = []\n",
    "erros = []\n",
    "\n",
    "for i, arquivo in enumerate(arquivos_encontrados, 1):\n",
    "    print(f\"\\n[{i}/{len(arquivos_encontrados)}] Processando...\")\n",
    "\n",
    "    df = carregar_arquivo_opav(arquivo)\n",
    "\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "    else:\n",
    "        erros.append(arquivo.name)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"RESUMO DO CARREGAMENTO:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   ✅ Sucesso: {len(dataframes)} arquivos\")\n",
    "print(f\"   ❌ Erros: {len(erros)} arquivos\")\n",
    "\n",
    "if erros:\n",
    "    print(f\"\\n   Arquivos com erro:\")\n",
    "    for erro in erros:\n",
    "        print(f\"      • {erro}\")\n",
    "\n",
    "print()\n",
    "\n",
    "if len(dataframes) == 0:\n",
    "    raise ValueError(\"Nenhum arquivo foi carregado com sucesso!\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 4: Unificar DataFrames\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 4: Unificando DataFrames...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Concatenar verticalmente\n",
    "df_unificado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(f\"✅ DataFrame unificado criado\")\n",
    "print(f\"   Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   Colunas: {len(df_unificado.columns)}\")\n",
    "print()\n",
    "\n",
    "# Estatísticas por arquivo\n",
    "print(\"📊 REGISTROS POR ARQUIVO:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "contagem_por_arquivo = df_unificado['_arquivo_origem'].value_counts().sort_index()\n",
    "\n",
    "for arquivo, count in contagem_por_arquivo.items():\n",
    "    pct = (count / len(df_unificado)) * 100\n",
    "    print(f\"   {arquivo}: {count:,} registros ({pct:.1f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 5: Validações\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 5: Validações...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Verificar duplicatas\n",
    "print(\"🔍 Verificando duplicatas...\")\n",
    "\n",
    "# Colunas chave (sem metadados)\n",
    "colunas_chave = [c for c in df_unificado.columns\n",
    "                 if not c.startswith('_')][:7]\n",
    "\n",
    "print(f\"   Colunas chave: {colunas_chave[:5]}...\")\n",
    "\n",
    "duplicatas = df_unificado.duplicated(subset=colunas_chave)\n",
    "n_duplicatas = duplicatas.sum()\n",
    "\n",
    "if n_duplicatas > 0:\n",
    "    print(f\"   ⚠️  {n_duplicatas:,} linhas duplicadas encontradas\")\n",
    "    print(f\"   Mantendo primeira ocorrência...\")\n",
    "    df_unificado = df_unificado[~duplicatas].reset_index(drop=True)\n",
    "    print(f\"   ✅ Após remover: {len(df_unificado):,} registros\")\n",
    "else:\n",
    "    print(f\"   ✅ Nenhuma duplicata encontrada\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Valores nulos em colunas críticas\n",
    "print(\"🔍 Verificando nulos em colunas críticas...\")\n",
    "\n",
    "colunas_criticas = ['Centro', 'Produto', 'Ano civil/mês']\n",
    "\n",
    "for col in colunas_criticas:\n",
    "    if col in df_unificado.columns:\n",
    "        nulos = df_unificado[col].isna().sum()\n",
    "        if nulos > 0:\n",
    "            print(f\"   ⚠️  '{col}': {nulos:,} nulos\")\n",
    "        else:\n",
    "            print(f\"   ✅ '{col}': 0 nulos\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 6: Preview e Estatísticas\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 6: PREVIEW E ESTATISTICAS\")\n",
    "print(\"═\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"Primeiras 7 colunas (DIMENSOES):\")\n",
    "colunas_dim = [c for c in df_unificado.columns if not c.startswith('_')][:7]\n",
    "print(df_unificado[colunas_dim].head(5).to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Ultimas 3 colunas (METADADOS):\")\n",
    "print(df_unificado[['_arquivo_origem', '_arquivo_path', '_data_carga']].head(3).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Estatísticas resumidas\n",
    "print(\"📊 ESTATISTICAS GERAIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"   Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   Colunas totais: {len(df_unificado.columns)}\")\n",
    "print(f\"   Arquivos unificados: {len(dataframes)}\")\n",
    "print(f\"   Período de carga: {df_unificado['_data_carga'].min()} a {df_unificado['_data_carga'].max()}\")\n",
    "\n",
    "# Dimensões únicas\n",
    "if 'Centro' in df_unificado.columns:\n",
    "    print(f\"   Centros únicos: {df_unificado['Centro'].nunique()}\")\n",
    "\n",
    "if 'Produto' in df_unificado.columns:\n",
    "    print(f\"   Produtos únicos: {df_unificado['Produto'].nunique()}\")\n",
    "\n",
    "if 'Ano civil/mês' in df_unificado.columns:\n",
    "    print(f\"   Períodos únicos: {df_unificado['Ano civil/mês'].nunique()}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 7: Salvar Backup\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 7: Salvando backup...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "if 'fm' in dir():\n",
    "    timestamp = fm.timestamp\n",
    "    arquivo_destino = fm.diretorios['dados_processados'] / f\"AIVI_OPAV_UNIFICADO_{timestamp}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        df_unificado.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "        fm.logger.info(f\"OPAV unificado: {arquivo_destino.name} ({len(df_unificado)} registros)\")\n",
    "        print(f\"   ✅ Backup: {arquivo_destino.name}\")\n",
    "        print(f\"   📁 Local: {arquivo_destino.parent}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  Erro ao salvar: {str(e)}\")\n",
    "        fm.logger.error(f\"Erro backup OPAV unificado: {str(e)}\")\n",
    "else:\n",
    "    print(\"   ⚠️  FileManager não disponível - backup ignorado\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" ✅ UNIFICAÇÃO CONCLUÍDA COM SUCESSO \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "print(\"RESUMO FINAL:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   📄 Arquivos processados: {len(dataframes)}/{len(arquivos_encontrados)}\")\n",
    "print(f\"   📊 Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   📋 Colunas: {len(df_unificado.columns)}\")\n",
    "print(f\"   🗂️  Estrutura:\")\n",
    "print(f\"       • Dimensões: 7\")\n",
    "print(f\"       • Movimentações: {len(df_unificado.columns) - 10}\")\n",
    "print(f\"       • Metadados: 3\")\n",
    "print()\n",
    "\n",
    "# Salvar na variável global\n",
    "df_opav_unificado = df_unificado\n",
    "arquivos_opav_processados = [arq.name for arq in arquivos_encontrados if carregar_arquivo_opav(arq) is not None]\n",
    "\n",
    "print(\"VARIAVEIS DISPONIVEIS:\")\n",
    "print(\"   df_opav_unificado - DataFrame unificado\")\n",
    "print(\"   arquivos_opav_processados - Lista de arquivos\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FIM BLOCO 5\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "122aa20ef772bcdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                   BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW                    ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "ETAPA 1: Determinar pasta com arquivos OPAV\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📁 Arquivo OPAV ja carregado no BLOCO 4:\n",
      "   Arquivo: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   Pasta: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\n",
      "\n",
      "   ⚠️  Apenas 1 arquivo xSAPtemp nesta pasta\n",
      "   Vou perguntar se quer buscar em outra pasta\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📂 SELEÇÃO DE PASTA\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Opcoes:\n",
      "   1. Selecionar pasta manualmente\n",
      "   2. Usar pasta do arquivo atual (02_Dados_Entrada)\n",
      "   3. Usar pasta do FileManager (02_Dados_Entrada)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "✅ PASTA BASE DEFINIDA: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\n",
      "================================================================================\n",
      "\n",
      "ETAPA 2: Buscando arquivos xSAPtemp recursivamente...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ Encontrados: 1 arquivos\n",
      "\n",
      "📋 ARQUIVOS ENCONTRADOS:\n",
      "--------------------------------------------------------------------------------\n",
      "    1. Cópia de xSAPtemp4687_JAN_25.xls\n",
      "       Pasta: .\n",
      "       Tamanho: 15.88 MB\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⚠️  CONFIRMAÇÃO NECESSÁRIA\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Foram encontrados 1 arquivos.\n",
      "Todos serão processados e unificados em um único DataFrame.\n",
      "\n",
      "Deseja prosseguir?\n",
      "   [ENTER] = SIM, continuar\n",
      "   [Ctrl+C] = NÃO, cancelar\n",
      "\n",
      "\n",
      "ETAPA 3: Carregando todos os arquivos...\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "[1/1] Processando...\n",
      "\n",
      "📄 Processando: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   ----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:33:03 | INFO     | OPAV unificado: AIVI_OPAV_UNIFICADO_20251015_110105.xlsx (200 registros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Sheet: 'Valor da Variação Total' (1001 linhas × 60 cols)\n",
      "   ✅ Carregado: 967 registros × 28 colunas\n",
      "\n",
      "================================================================================\n",
      "RESUMO DO CARREGAMENTO:\n",
      "================================================================================\n",
      "   ✅ Sucesso: 1 arquivos\n",
      "   ❌ Erros: 0 arquivos\n",
      "\n",
      "ETAPA 4: Unificando DataFrames...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ DataFrame unificado criado\n",
      "   Registros totais: 967\n",
      "   Colunas: 31\n",
      "\n",
      "📊 REGISTROS POR ARQUIVO:\n",
      "--------------------------------------------------------------------------------\n",
      "   Cópia de xSAPtemp4687_JAN_25.xls: 967 registros (100.0%)\n",
      "\n",
      "ETAPA 5: Validações...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Verificando duplicatas...\n",
      "   Colunas chave: ['Centro de lucro', 'Ano civil/mês', 'Centro', 'Col_3', 'HierarqPrd']...\n",
      "   ⚠️  767 linhas duplicadas encontradas\n",
      "   Mantendo primeira ocorrência...\n",
      "   ✅ Após remover: 200 registros\n",
      "\n",
      "🔍 Verificando nulos em colunas críticas...\n",
      "   ✅ 'Centro': 0 nulos\n",
      "   ✅ 'Produto': 0 nulos\n",
      "   ✅ 'Ano civil/mês': 0 nulos\n",
      "\n",
      "ETAPA 6: PREVIEW E ESTATISTICAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Primeiras 7 colunas (DIMENSOES):\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                      Col_6\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422    JET A NAO TABELADO - LI\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACIONAL I - LI\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078           GASOLINA COMUM C\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "\n",
      "Ultimas 3 colunas (METADADOS):\n",
      "                 _arquivo_origem                                                                                                                                               _arquivo_path                _data_carga\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "\n",
      "📊 ESTATISTICAS GERAIS:\n",
      "--------------------------------------------------------------------------------\n",
      "   Registros totais: 200\n",
      "   Colunas totais: 31\n",
      "   Arquivos unificados: 1\n",
      "   Período de carga: 2025-10-15 11:33:03.714694 a 2025-10-15 11:33:03.714694\n",
      "   Centros únicos: 89\n",
      "   Produtos únicos: 15\n",
      "   Períodos únicos: 2\n",
      "\n",
      "ETAPA 7: Salvando backup...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   ✅ Backup: AIVI_OPAV_UNIFICADO_20251015_110105.xlsx\n",
      "   📁 Local: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\03_Dados_Processados\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                      ✅ UNIFICAÇÃO CONCLUÍDA COM SUCESSO                      ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "RESUMO FINAL:\n",
      "--------------------------------------------------------------------------------\n",
      "   📄 Arquivos processados: 1/1\n",
      "   📊 Registros totais: 200\n",
      "   📋 Colunas: 31\n",
      "   🗂️  Estrutura:\n",
      "       • Dimensões: 7\n",
      "       • Movimentações: 21\n",
      "       • Metadados: 3\n",
      "\n",
      "\n",
      "📄 Processando: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   ----------------------------------------------------------------------------\n",
      "   ✅ Sheet: 'Valor da Variação Total' (1001 linhas × 60 cols)\n",
      "   ✅ Carregado: 967 registros × 28 colunas\n",
      "VARIAVEIS DISPONIVEIS:\n",
      "   df_opav_unificado - DataFrame unificado\n",
      "   arquivos_opav_processados - Lista de arquivos\n",
      "\n",
      "================================================================================\n",
      "FIM BLOCO 5\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e7b9900a4c7e6c9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:05:58.248659Z",
     "start_time": "2025-10-15T18:05:56.955605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# BLOCO 0A: DETECTOR DE ARQUIVO DESCONHECIDO\n",
    "# Sistema inteligente para processar arquivos Excel de estrutura desconhecida\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class DetectorArquivoDesconhecido:\n",
    "    \"\"\"\n",
    "    Sistema para detectar automaticamente estrutura de arquivos Excel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, arquivo_path, fm=None):\n",
    "        self.arquivo_path = Path(arquivo_path)\n",
    "        self.fm = fm\n",
    "        self.nome_arquivo = self.arquivo_path.name\n",
    "        self.workbook = None\n",
    "        self.sheet_detectada = None\n",
    "        self.linha_cabecalho = None\n",
    "        self.linha_dados_inicio = None\n",
    "        self.df_bruto = None\n",
    "        self.df_limpo = None\n",
    "        self.log = []\n",
    "\n",
    "    def processar(self):\n",
    "        \"\"\"\n",
    "        Processamento completo do arquivo\n",
    "        \"\"\"\n",
    "        self._log(\"🔍 INICIANDO DETECÇÃO AUTOMÁTICA\", nivel=\"TITULO\")\n",
    "        self._log(f\"📁 Arquivo: {self.nome_arquivo}\")\n",
    "\n",
    "        # 1. Carregar workbook\n",
    "        self._carregar_workbook()\n",
    "\n",
    "        # 2. Detectar sheet correto\n",
    "        self._detectar_sheet()\n",
    "\n",
    "        # 3. Detectar linha de cabeçalho\n",
    "        self._detectar_cabecalho()\n",
    "\n",
    "        # 4. Extrair e limpar dados\n",
    "        self._extrair_dados()\n",
    "\n",
    "        # 5. Limpar estrutura\n",
    "        self._limpar_estrutura()\n",
    "\n",
    "        # 6. Relatório final\n",
    "        self._gerar_relatorio()\n",
    "\n",
    "        return self.df_limpo\n",
    "\n",
    "    def _carregar_workbook(self):\n",
    "        \"\"\"\n",
    "        Carrega workbook Excel\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📂 FASE 1: Carregamento do Arquivo\", nivel=\"SECAO\")\n",
    "\n",
    "        try:\n",
    "            # Tentar xlrd primeiro (mais robusto para .xls)\n",
    "            self.workbook = xlrd.open_workbook(str(self.arquivo_path))\n",
    "            self._log(f\"✅ Carregado com xlrd\")\n",
    "            self._log(f\"   Formato: XLS (Excel Antigo)\")\n",
    "        except Exception as e1:\n",
    "            # Fallback para pandas (xlsx, xlsm)\n",
    "            try:\n",
    "                self.workbook = pd.ExcelFile(str(self.arquivo_path))\n",
    "                self._log(f\"✅ Carregado com pandas\")\n",
    "                self._log(f\"   Formato: XLSX/XLSM (Excel Moderno)\")\n",
    "            except Exception as e2:\n",
    "                raise ValueError(f\"❌ Não foi possível carregar arquivo:\\n  xlrd: {e1}\\n  pandas: {e2}\")\n",
    "\n",
    "        # Listar sheets\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheets = self.workbook.sheet_names()\n",
    "        else:\n",
    "            sheets = self.workbook.sheet_names\n",
    "\n",
    "        self._log(f\"📊 Sheets encontradas: {len(sheets)}\")\n",
    "        for i, sheet in enumerate(sheets, 1):\n",
    "            self._log(f\"   {i}. {sheet}\")\n",
    "\n",
    "    def _detectar_sheet(self):\n",
    "        \"\"\"\n",
    "        Detecta sheet com dados relevantes\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📊 FASE 2: Detecção de Sheet\", nivel=\"SECAO\")\n",
    "\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheets = self.workbook.sheet_names()\n",
    "        else:\n",
    "            sheets = self.workbook.sheet_names\n",
    "\n",
    "        # REGRAS DE DETECÇÃO (ordem de prioridade)\n",
    "        regras = [\n",
    "            # BW específico\n",
    "            (r\"Valor da Variação Total\", \"BW - Variação Total\"),\n",
    "            (r\"Variação.*Total\", \"Variação Total (genérico)\"),\n",
    "            (r\"OPAV\", \"OPAV\"),\n",
    "            # Genéricas\n",
    "            (r\"(?i)dados\", \"Dados\"),\n",
    "            (r\"(?i)relat[oó]rio\", \"Relatório\"),\n",
    "            (r\"(?i)export\", \"Export\"),\n",
    "            (r\"(?i)result\", \"Result\"),\n",
    "        ]\n",
    "\n",
    "        candidatos = []\n",
    "\n",
    "        for sheet_name in sheets:\n",
    "            for padrao, descricao in regras:\n",
    "                if re.search(padrao, sheet_name):\n",
    "                    # Carregar amostra para validar\n",
    "                    validacao = self._validar_sheet(sheet_name)\n",
    "                    candidatos.append({\n",
    "                        'nome': sheet_name,\n",
    "                        'descricao': descricao,\n",
    "                        'score': validacao['score'],\n",
    "                        'linhas': validacao['linhas'],\n",
    "                        'colunas': validacao['colunas']\n",
    "                    })\n",
    "                    self._log(f\"   ✅ Candidato: '{sheet_name}' ({descricao})\")\n",
    "                    self._log(f\"      Score: {validacao['score']:.2f} | Linhas: {validacao['linhas']} | Colunas: {validacao['colunas']}\")\n",
    "                    break\n",
    "\n",
    "        if not candidatos:\n",
    "            # Se nenhum match, usar primeira sheet não vazia\n",
    "            self._log(\"   ⚠️  Nenhum match por padrão, analisando todas sheets...\")\n",
    "            for sheet_name in sheets:\n",
    "                validacao = self._validar_sheet(sheet_name)\n",
    "                if validacao['score'] > 0:\n",
    "                    candidatos.append({\n",
    "                        'nome': sheet_name,\n",
    "                        'descricao': 'Primeira não vazia',\n",
    "                        'score': validacao['score'],\n",
    "                        'linhas': validacao['linhas'],\n",
    "                        'colunas': validacao['colunas']\n",
    "                    })\n",
    "\n",
    "        if not candidatos:\n",
    "            raise ValueError(\"❌ Nenhuma sheet com dados foi encontrada\")\n",
    "\n",
    "        # Selecionar melhor candidato (maior score)\n",
    "        melhor = max(candidatos, key=lambda x: x['score'])\n",
    "        self.sheet_detectada = melhor['nome']\n",
    "\n",
    "        self._log(f\"\\n   🎯 SHEET SELECIONADA: '{self.sheet_detectada}'\")\n",
    "        self._log(f\"      {melhor['descricao']} | Score: {melhor['score']:.2f}\")\n",
    "\n",
    "    def _validar_sheet(self, sheet_name):\n",
    "        \"\"\"\n",
    "        Valida se sheet contém dados úteis\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(self.workbook, xlrd.Book):\n",
    "                sheet = self.workbook.sheet_by_name(sheet_name)\n",
    "                linhas = sheet.nrows\n",
    "                colunas = sheet.ncols\n",
    "                # Amostra: primeira linha não vazia\n",
    "                amostra = []\n",
    "                for i in range(min(50, linhas)):\n",
    "                    row = sheet.row_values(i)\n",
    "                    if any(str(c).strip() for c in row):\n",
    "                        amostra.append(row)\n",
    "                        if len(amostra) >= 10:\n",
    "                            break\n",
    "            else:\n",
    "                df_sample = pd.read_excel(self.workbook, sheet_name=sheet_name, nrows=50)\n",
    "                linhas = len(df_sample)\n",
    "                colunas = len(df_sample.columns)\n",
    "                amostra = df_sample.values.tolist()\n",
    "\n",
    "            # Calcular score\n",
    "            score = 0.0\n",
    "            if linhas > 10:\n",
    "                score += 1.0\n",
    "            if colunas > 5:\n",
    "                score += 1.0\n",
    "            if linhas > 100:\n",
    "                score += 0.5\n",
    "            if colunas > 15:\n",
    "                score += 0.5\n",
    "\n",
    "            # Penalizar sheets muito pequenas\n",
    "            if linhas < 5 or colunas < 3:\n",
    "                score = 0.0\n",
    "\n",
    "            return {\n",
    "                'score': score,\n",
    "                'linhas': linhas,\n",
    "                'colunas': colunas\n",
    "            }\n",
    "        except:\n",
    "            return {'score': 0.0, 'linhas': 0, 'colunas': 0}\n",
    "\n",
    "    def _detectar_cabecalho(self):\n",
    "        \"\"\"\n",
    "        Detecta linha de cabeçalho automaticamente\n",
    "        \"\"\"\n",
    "        self._log(\"\\n🔍 FASE 3: Detecção de Cabeçalho\", nivel=\"SECAO\")\n",
    "\n",
    "        # Carregar primeiras 100 linhas\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheet = self.workbook.sheet_by_name(self.sheet_detectada)\n",
    "            linhas_amostra = []\n",
    "            for i in range(min(100, sheet.nrows)):\n",
    "                linhas_amostra.append(sheet.row_values(i))\n",
    "        else:\n",
    "            df_amostra = pd.read_excel(\n",
    "                self.workbook,\n",
    "                sheet_name=self.sheet_detectada,\n",
    "                nrows=100,\n",
    "                header=None\n",
    "            )\n",
    "            linhas_amostra = df_amostra.values.tolist()\n",
    "\n",
    "        # Análise linha por linha\n",
    "        scores = []\n",
    "        for idx, linha in enumerate(linhas_amostra):\n",
    "            score = self._avaliar_linha_cabecalho(linha, idx)\n",
    "            scores.append({\n",
    "                'linha': idx,\n",
    "                'score': score,\n",
    "                'conteudo_sample': linha[:5]  # Primeiras 5 colunas\n",
    "            })\n",
    "\n",
    "        # Ordenar por score\n",
    "        scores_ordenados = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        # Mostrar top 5\n",
    "        self._log(\"   🏆 Top 5 candidatos a cabeçalho:\")\n",
    "        for i, item in enumerate(scores_ordenados[:5], 1):\n",
    "            self._log(f\"      {i}. Linha {item['linha']+1} (Excel) - Score: {item['score']:.2f}\")\n",
    "            self._log(f\"         Sample: {item['conteudo_sample']}\")\n",
    "\n",
    "        # Selecionar melhor\n",
    "        melhor = scores_ordenados[0]\n",
    "        self.linha_cabecalho = melhor['linha']\n",
    "        self.linha_dados_inicio = self.linha_cabecalho + 1\n",
    "\n",
    "        self._log(f\"\\n   🎯 CABEÇALHO DETECTADO: Linha {self.linha_cabecalho + 1} (Excel)\")\n",
    "        self._log(f\"      Início dos dados: Linha {self.linha_dados_inicio + 1} (Excel)\")\n",
    "\n",
    "    def _avaliar_linha_cabecalho(self, linha, idx):\n",
    "        \"\"\"\n",
    "        Avalia se uma linha é candidata a cabeçalho\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "\n",
    "        # Converter para strings\n",
    "        celulas = [str(c).strip() for c in linha if str(c).strip()]\n",
    "\n",
    "        if not celulas:\n",
    "            return 0.0\n",
    "\n",
    "        # CRITÉRIO 1: Quantidade de células não vazias (peso 2.0)\n",
    "        prop_nao_vazias = len(celulas) / len(linha)\n",
    "        score += prop_nao_vazias * 2.0\n",
    "\n",
    "        # CRITÉRIO 2: Células com texto (não só números) (peso 1.5)\n",
    "        tem_texto = sum(1 for c in celulas if re.search(r'[a-zA-Z]', c))\n",
    "        prop_texto = tem_texto / len(celulas) if celulas else 0\n",
    "        score += prop_texto * 1.5\n",
    "\n",
    "        # CRITÉRIO 3: Palavras-chave de cabeçalho (peso 3.0)\n",
    "        keywords = [\n",
    "            'centro', 'produto', 'material', 'código', 'cod', 'cód',\n",
    "            'data', 'período', 'ano', 'mês', 'mes',\n",
    "            'quantidade', 'valor', 'volume', 'expedição', 'variação',\n",
    "            'limite', 'batente', 'sigla', 'base', 'região', 'regiao',\n",
    "            'nome', 'descrição', 'descricao', 'tipo', 'status'\n",
    "        ]\n",
    "\n",
    "        texto_linha = ' '.join(celulas).lower()\n",
    "        keywords_encontradas = sum(1 for kw in keywords if kw in texto_linha)\n",
    "        score += (keywords_encontradas / len(keywords)) * 3.0\n",
    "\n",
    "        # CRITÉRIO 4: Tamanho médio das células (cabeçalhos tendem a ser curtos) (peso 1.0)\n",
    "        tamanho_medio = np.mean([len(c) for c in celulas])\n",
    "        if 5 <= tamanho_medio <= 50:\n",
    "            score += 1.0\n",
    "        elif tamanho_medio > 100:\n",
    "            score -= 0.5  # Penalizar linhas muito longas\n",
    "\n",
    "        # CRITÉRIO 5: Unicidade (cabeçalhos não devem ter repetições) (peso 1.5)\n",
    "        contador = Counter(celulas)\n",
    "        repeticoes = sum(1 for c, n in contador.items() if n > 1)\n",
    "        if repeticoes == 0:\n",
    "            score += 1.5\n",
    "        else:\n",
    "            score -= repeticoes * 0.3\n",
    "\n",
    "        # CRITÉRIO 6: Posição (linhas mais acima têm vantagem) (peso 0.5)\n",
    "        if idx < 50:\n",
    "            score += (50 - idx) / 100\n",
    "\n",
    "        # CRITÉRIO 7: Formato típico BW (linha ~30-40)\n",
    "        if 30 <= idx <= 40:\n",
    "            score += 0.5\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _extrair_dados(self):\n",
    "        \"\"\"\n",
    "        Extrai dados a partir da linha detectada\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📊 FASE 4: Extração de Dados\", nivel=\"SECAO\")\n",
    "\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheet = self.workbook.sheet_by_name(self.sheet_detectada)\n",
    "\n",
    "            # Extrair todas as linhas\n",
    "            data = []\n",
    "            for i in range(sheet.nrows):\n",
    "                data.append(sheet.row_values(i))\n",
    "\n",
    "            self.df_bruto = pd.DataFrame(data)\n",
    "\n",
    "            # Definir cabeçalho\n",
    "            cabecalho_bruto = self.df_bruto.iloc[self.linha_cabecalho].tolist()\n",
    "\n",
    "            # Extrair dados\n",
    "            self.df_bruto = self.df_bruto.iloc[self.linha_dados_inicio:].copy()\n",
    "            self.df_bruto.columns = cabecalho_bruto\n",
    "\n",
    "        else:\n",
    "            # pandas\n",
    "            self.df_bruto = pd.read_excel(\n",
    "                self.workbook,\n",
    "                sheet_name=self.sheet_detectada,\n",
    "                header=self.linha_cabecalho\n",
    "            )\n",
    "\n",
    "        self.df_bruto = self.df_bruto.reset_index(drop=True)\n",
    "\n",
    "        self._log(f\"✅ Dados extraídos\")\n",
    "        self._log(f\"   Registros: {len(self.df_bruto):,}\")\n",
    "        self._log(f\"   Colunas: {len(self.df_bruto.columns)}\")\n",
    "\n",
    "    def _limpar_estrutura(self):\n",
    "        \"\"\"\n",
    "        Limpa estrutura do DataFrame\n",
    "        \"\"\"\n",
    "        self._log(\"\\n🧹 FASE 5: Limpeza de Estrutura\", nivel=\"SECAO\")\n",
    "\n",
    "        df = self.df_bruto.copy()\n",
    "\n",
    "        # 1. Remover colunas completamente vazias\n",
    "        colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "        if colunas_vazias:\n",
    "            self._log(f\"   🗑️  Removendo {len(colunas_vazias)} colunas vazias\")\n",
    "            df = df.drop(columns=colunas_vazias)\n",
    "\n",
    "        # 2. Remover linhas completamente vazias\n",
    "        linhas_vazias = df.index[df.isna().all(axis=1)].tolist()\n",
    "        if linhas_vazias:\n",
    "            self._log(f\"   🗑️  Removendo {len(linhas_vazias)} linhas vazias\")\n",
    "            df = df.dropna(how='all')\n",
    "\n",
    "        # 3. Limpar nomes de colunas\n",
    "        self._log(\"   🧹 Limpando nomes de colunas...\")\n",
    "        colunas_limpas = []\n",
    "        for col in df.columns:\n",
    "            col_limpo = str(col).strip()\n",
    "            col_limpo = col_limpo.lstrip(\"'\")  # Excel adiciona '\n",
    "            col_limpo = col_limpo.replace('\\n', ' ')\n",
    "            col_limpo = col_limpo.replace('\\r', '')\n",
    "            col_limpo = ' '.join(col_limpo.split())  # Múltiplos espaços\n",
    "            colunas_limpas.append(col_limpo)\n",
    "\n",
    "        df.columns = colunas_limpas\n",
    "\n",
    "        # 4. Renomear colunas duplicadas\n",
    "        contagem = Counter(colunas_limpas)\n",
    "        duplicadas = {c: n for c, n in contagem.items() if n > 1}\n",
    "\n",
    "        if duplicadas:\n",
    "            self._log(f\"   ⚠️  Renomeando {len(duplicadas)} colunas duplicadas:\")\n",
    "            colunas_finais = []\n",
    "            contador = {}\n",
    "\n",
    "            for col in colunas_limpas:\n",
    "                if col in duplicadas:\n",
    "                    if col not in contador:\n",
    "                        contador[col] = 0\n",
    "                        colunas_finais.append(col)\n",
    "                    else:\n",
    "                        contador[col] += 1\n",
    "                        novo_nome = f\"{col}_dup{contador[col]}\"\n",
    "                        colunas_finais.append(novo_nome)\n",
    "                        self._log(f\"      '{col}' → '{novo_nome}'\")\n",
    "                else:\n",
    "                    colunas_finais.append(col)\n",
    "\n",
    "            df.columns = colunas_finais\n",
    "\n",
    "        # 5. Remover linhas de totais/resultados\n",
    "        padroes_remover = [\n",
    "            r'(?i)^total',\n",
    "            r'(?i)^resultado',\n",
    "            r'(?i)^soma',\n",
    "            r'(?i)^subtotal',\n",
    "            r'(?i)^grand total'\n",
    "        ]\n",
    "\n",
    "        linhas_remover = []\n",
    "        for idx, row in df.iterrows():\n",
    "            primeira_celula = str(row.iloc[0]).strip().lower()\n",
    "            for padrao in padroes_remover:\n",
    "                if re.search(padrao, primeira_celula):\n",
    "                    linhas_remover.append(idx)\n",
    "                    break\n",
    "\n",
    "        if linhas_remover:\n",
    "            self._log(f\"   🗑️  Removendo {len(linhas_remover)} linhas de totais/resultados\")\n",
    "            df = df.drop(index=linhas_remover)\n",
    "\n",
    "        # 6. Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        self.df_limpo = df\n",
    "\n",
    "        self._log(f\"\\n✅ Limpeza concluída\")\n",
    "        self._log(f\"   Registros finais: {len(self.df_limpo):,}\")\n",
    "        self._log(f\"   Colunas finais: {len(self.df_limpo.columns)}\")\n",
    "\n",
    "    def _gerar_relatorio(self):\n",
    "        \"\"\"\n",
    "        Gera relatório final de detecção\n",
    "        \"\"\"\n",
    "        self._log(\"\\n\" + \"=\"*80, nivel=\"TITULO\")\n",
    "        self._log(\"📋 RELATÓRIO FINAL DE DETECÇÃO\", nivel=\"TITULO\")\n",
    "        self._log(\"=\"*80, nivel=\"TITULO\")\n",
    "\n",
    "        self._log(f\"\\n📁 Arquivo: {self.nome_arquivo}\")\n",
    "        self._log(f\"📊 Sheet: {self.sheet_detectada}\")\n",
    "        self._log(f\"📍 Cabeçalho: Linha {self.linha_cabecalho + 1} (Excel)\")\n",
    "        self._log(f\"📍 Dados: Linha {self.linha_dados_inicio + 1} (Excel)\")\n",
    "\n",
    "        self._log(f\"\\n📊 Resultado Final:\")\n",
    "        self._log(f\"   Registros: {len(self.df_limpo):,}\")\n",
    "        self._log(f\"   Colunas: {len(self.df_limpo.columns)}\")\n",
    "\n",
    "        self._log(f\"\\n📋 Colunas detectadas:\")\n",
    "        for i, col in enumerate(self.df_limpo.columns, 1):\n",
    "            self._log(f\"   {i:2d}. {col}\")\n",
    "\n",
    "    def _log(self, mensagem, nivel=\"INFO\"):\n",
    "        \"\"\"\n",
    "        Sistema de log\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        if nivel == \"TITULO\":\n",
    "            print(mensagem)\n",
    "        elif nivel == \"SECAO\":\n",
    "            print(f\"\\n{mensagem}\")\n",
    "            print(\"─\" * 80)\n",
    "        else:\n",
    "            print(mensagem)\n",
    "\n",
    "        self.log.append({\n",
    "            'timestamp': timestamp,\n",
    "            'nivel': nivel,\n",
    "            'mensagem': mensagem\n",
    "        })\n",
    "\n",
    "    def exportar_log(self, pasta_destino):\n",
    "        \"\"\"\n",
    "        Exporta log para arquivo\n",
    "        \"\"\"\n",
    "        log_df = pd.DataFrame(self.log)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        arquivo_log = Path(pasta_destino) / f\"LOG_DeteccaoAutomatica_{timestamp}.xlsx\"\n",
    "\n",
    "        log_df.to_excel(arquivo_log, index=False)\n",
    "        print(f\"\\n💾 Log salvo: {arquivo_log}\")\n",
    "\n",
    "        return arquivo_log\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# EXEMPLO DE USO\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Usar FileManager se disponível\n",
    "    if 'fm' in dir():\n",
    "        pasta_entrada = fm.diretorios['dados_entrada']\n",
    "        pasta_logs = fm.diretorios['logs']\n",
    "    else:\n",
    "        pasta_entrada = Path('02_Dados_Entrada')\n",
    "        pasta_logs = Path('logs')\n",
    "\n",
    "    # Selecionar arquivo\n",
    "    arquivos_disponiveis = list(pasta_entrada.glob('*.xls*'))\n",
    "\n",
    "    print(\"📁 Arquivos disponíveis:\")\n",
    "    for i, arq in enumerate(arquivos_disponiveis, 1):\n",
    "        print(f\"   {i}. {arq.name}\")\n",
    "\n",
    "    escolha = int(input(\"\\nEscolha um arquivo (número): \")) - 1\n",
    "    arquivo_selecionado = arquivos_disponiveis[escolha]\n",
    "\n",
    "    # Processar\n",
    "    detector = DetectorArquivoDesconhecido(arquivo_selecionado)\n",
    "    df_resultado = detector.processar()\n",
    "\n",
    "    # Exportar log\n",
    "    detector.exportar_log(pasta_logs)\n",
    "\n",
    "    # Salvar resultado\n",
    "    arquivo_saida = pasta_entrada.parent / '03_Dados_Processados' / f\"Detectado_{arquivo_selecionado.stem}.xlsx\"\n",
    "    df_resultado.to_excel(arquivo_saida, index=False)\n",
    "    print(f\"💾 Resultado salvo: {arquivo_saida}\")"
   ],
   "id": "4a5f4951d942e0c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Arquivos disponíveis:\n",
      "   1. AIVI_OPAV_BW_20251015_110105.xlsx\n",
      "   2. Centros_BR_20251015_110105.xlsx\n",
      "   3. Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   4. SAP_YSMM_Limpo_20251015_110105.xlsx\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 506\u001B[39m\n\u001B[32m    503\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, arq \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(arquivos_disponiveis, \u001B[32m1\u001B[39m):\n\u001B[32m    504\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m   \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marq.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m506\u001B[39m escolha = \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43mEscolha um arquivo (número): \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m - \u001B[32m1\u001B[39m\n\u001B[32m    507\u001B[39m arquivo_selecionado = arquivos_disponiveis[escolha]\n\u001B[32m    509\u001B[39m \u001B[38;5;66;03m# Processar\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34b56a7611fbc6aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
