{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:01:08.459883Z",
     "start_time": "2025-10-15T14:01:05.309165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "AIVI DATA INTEGRATION - BLOCO 1: CONFIGURAÇÃO COMPLETA DO AMBIENTE\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "Versão: 3.1 - Consolidado, Modular, Inteligente (com última pasta + timer)\n",
    "Data: 2025-01-14\n",
    "\n",
    "CONTEÚDO DESTE BLOCO:\n",
    "  1. Imports e dependências\n",
    "  2. Constantes AIVI 2025\n",
    "  3. FileManager (gerenciamento de diretórios e logs)\n",
    "  4. Utilitários globais\n",
    "  5. Verificação de ambiente\n",
    "\n",
    "APÓS EXECUTAR:\n",
    "  - Ambiente completamente configurado\n",
    "  - FileManager inicializado\n",
    "  - Sistema de logs ativo\n",
    "  - Pronto para carregar dados\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 1: IMPORTS E DEPENDÊNCIAS\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 1: CONFIGURAÇÃO COMPLETA DO AMBIENTE \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import json\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Suprimir warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📦 SEÇÃO 1.1: Verificando bibliotecas essenciais\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Dicionário de bibliotecas necessárias\n",
    "BIBLIOTECAS = {\n",
    "    'pandas': ('Manipulação de dados', 'pd'),\n",
    "    'numpy': ('Cálculos numéricos', 'np'),\n",
    "    'scipy': ('Estatísticas avançadas', None),\n",
    "    'openpyxl': ('Excel (.xlsx)', None),\n",
    "    'xlrd': ('Excel (.xls) - OPCIONAL', None)\n",
    "}\n",
    "\n",
    "# Verificar e importar\n",
    "modulos_carregados = {}\n",
    "modulos_faltando = []\n",
    "\n",
    "for biblioteca, (descricao, alias) in BIBLIOTECAS.items():\n",
    "    try:\n",
    "        if alias:\n",
    "            exec(f\"import {biblioteca} as {alias}\")\n",
    "            modulo = eval(alias)\n",
    "        else:\n",
    "            exec(f\"import {biblioteca}\")\n",
    "            modulo = eval(biblioteca)\n",
    "\n",
    "        versao = getattr(modulo, '__version__', 'N/A')\n",
    "        print(f\"   ✅ {biblioteca.ljust(15)} v{versao} - {descricao}\")\n",
    "        modulos_carregados[biblioteca] = versao\n",
    "\n",
    "    except ImportError:\n",
    "        if biblioteca == 'xlrd':\n",
    "            print(f\"   ⚠️  {biblioteca.ljust(15)} OPCIONAL - {descricao}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {biblioteca.ljust(15)} FALTANDO - {descricao}\")\n",
    "            modulos_faltando.append(biblioteca)\n",
    "\n",
    "print()\n",
    "\n",
    "if modulos_faltando:\n",
    "    print(\"⚠️  ATENÇÃO: Instale as bibliotecas faltando:\")\n",
    "    for bib in modulos_faltando:\n",
    "        print(f\"   pip install {bib}\")\n",
    "    print()\n",
    "    raise ImportError(f\"Bibliotecas faltando: {', '.join(modulos_faltando)}\")\n",
    "\n",
    "# Configurar pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✅ Todas as bibliotecas essenciais carregadas\")\n",
    "print(\"   • pandas configurado (display otimizado)\")\n",
    "print(\"   • warnings suprimidos\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 2: CONSTANTES AIVI 2025\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"📊 SEÇÃO 1.2: Carregando constantes AIVI 2025\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Constantes numéricas\n",
    "CONSTANTES_AIVI = {\n",
    "    'BATENTE_MAX_INF': -1.00,\n",
    "    'BATENTE_MAX_SUP': 1.00,\n",
    "    'LI_MAX_CORPORATIVO': -0.05,\n",
    "    'LS_MIN_CORPORATIVO': 0.05,\n",
    "    'RANGE_MINIMO': 0.10,\n",
    "    'MULTIPLICADOR_IQR': 1.5,\n",
    "    'SIGMA_SHIFT_CEP': 1.5,\n",
    "    'LIMITE_MATERIALIDADE': 6500.00,\n",
    "    'MESES_MINIMOS': 6,\n",
    "    'P_VALUE_THRESHOLD': 0.05\n",
    "}\n",
    "\n",
    "# Schema padrão AIVI (campos essenciais)\n",
    "SCHEMA_AIVI_CAMPOS_OBRIGATORIOS = [\n",
    "    'Centro',\n",
    "    'Sigla',\n",
    "    'Cód Grupo de produto',\n",
    "    'Expedição c/ Veículo',\n",
    "    'Variação Interna',\n",
    "    '% VI',\n",
    "    'Limite Inferior',\n",
    "    'Limite Superior',\n",
    "    'Mês do exercício',\n",
    "    'Ano do documento do material'\n",
    "]\n",
    "\n",
    "# Dicionário de sinônimos (detecção automática)\n",
    "DICIONARIO_SINONIMOS = {\n",
    "    'Centro': ['Centro', 'Código de Centro', 'Cod Centro', 'CódigoCentro'],\n",
    "    'Sigla': ['Sigla', 'Sigla de Centro', 'Sigla Centro', 'Sigla Base'],\n",
    "    'Cód Grupo de produto': ['Cód Grupo de produto', 'Código Produto', 'Cod Produto'],\n",
    "    'Expedição c/ Veículo': ['Expedição c/ Veículo', 'Expedição', 'Expedicao'],\n",
    "    'Variação Interna': ['Variação Interna', 'Variacao Interna', 'VI'],\n",
    "    'Limite Inferior': ['Limite Inferior', 'LI', 'Lim Inferior'],\n",
    "    'Limite Superior': ['Limite Superior', 'LS', 'Lim Superior'],\n",
    "    'Mês do exercício': ['Mês do exercício', 'Mês', 'Mes'],\n",
    "    'Ano do documento do material': ['Ano do documento do material', 'Ano']\n",
    "}\n",
    "\n",
    "for chave, valor in CONSTANTES_AIVI.items():\n",
    "    print(f\"   {chave.ljust(25)} = {valor}\")\n",
    "\n",
    "print()\n",
    "print(f\"✅ {len(CONSTANTES_AIVI)} constantes carregadas\")\n",
    "print(f\"✅ Schema AIVI: {len(SCHEMA_AIVI_CAMPOS_OBRIGATORIOS)} campos obrigatórios\")\n",
    "print(f\"✅ Dicionário de sinônimos: {len(DICIONARIO_SINONIMOS)} campos mapeados\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 3: FILE MANAGER (GERENCIADOR DE DIRETÓRIOS E LOGS)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"📁 SEÇÃO 1.3: Inicializando FileManager\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "class FileManager:\n",
    "    \"\"\"\n",
    "    Gerenciador centralizado de arquivos, diretórios e logs para projeto AIVI.\n",
    "\n",
    "    Funcionalidades:\n",
    "      - Criação de estrutura de diretórios\n",
    "      - Sistema de logging (arquivo + console)\n",
    "      - Metadata tracking\n",
    "      - Operations log\n",
    "      - Paths dinâmicos\n",
    "      - Memória de última pasta usada (com timer de 10s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Arquivo de configuração para última pasta\n",
    "    CONFIG_FILE = Path.home() / '.aivi_last_dir.json'\n",
    "\n",
    "    def __init__(self, diretorio_base=None):\n",
    "        \"\"\"Inicializa FileManager com seleção GUI ou path fornecido.\"\"\"\n",
    "\n",
    "        self.operations_log = []\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        print(f\"   🕐 Timestamp: {self.timestamp}\")\n",
    "\n",
    "        # Selecionar diretório base\n",
    "        if diretorio_base is None:\n",
    "            self.diretorio_base = self._selecionar_diretorio_gui()\n",
    "        else:\n",
    "            self.diretorio_base = Path(diretorio_base)\n",
    "\n",
    "        print(f\"   📁 Diretório base: {self.diretorio_base}\")\n",
    "\n",
    "        # Salvar última pasta para próxima execução\n",
    "        self._salvar_ultima_pasta(self.diretorio_base)\n",
    "\n",
    "        # Criar estrutura\n",
    "        self.diretorio_execucao = self.diretorio_base / f\"AIVI_DataIntegration_{self.timestamp}\"\n",
    "        self._criar_estrutura()\n",
    "        self._configurar_logging()\n",
    "\n",
    "        # Log inicial\n",
    "        self.logger.info(\"═\" * 80)\n",
    "        self.logger.info(\"NOVA EXECUÇÃO - AIVI DATA INTEGRATION\")\n",
    "        self.logger.info(\"═\" * 80)\n",
    "        self.logger.info(f\"Timestamp: {self.timestamp}\")\n",
    "        self.logger.info(f\"Diretório: {self.diretorio_execucao}\")\n",
    "        self.logger.info(f\"Python: {sys.version.split()[0]}\")\n",
    "        self.logger.info(f\"Pandas: {pd.__version__}\")\n",
    "\n",
    "        print()\n",
    "        print(f\"   ✅ FileManager inicializado\")\n",
    "        print(f\"   ✅ Sistema de logs ativo\")\n",
    "        print()\n",
    "\n",
    "    def _carregar_ultima_pasta(self):\n",
    "        \"\"\"Carrega a última pasta usada do arquivo de configuração.\"\"\"\n",
    "        try:\n",
    "            if self.CONFIG_FILE.exists():\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                    ultima_pasta = Path(config.get('last_directory', ''))\n",
    "                    if ultima_pasta.exists():\n",
    "                        print(f\"   📂 Última pasta: {ultima_pasta}\")\n",
    "                        return ultima_pasta\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao carregar última pasta: {e}\")\n",
    "        return None\n",
    "\n",
    "    def _salvar_ultima_pasta(self, diretorio):\n",
    "        \"\"\"Salva a pasta selecionada para próxima execução.\"\"\"\n",
    "        try:\n",
    "            config = {\n",
    "                'last_directory': str(diretorio),\n",
    "                'last_used': datetime.now().isoformat()\n",
    "            }\n",
    "            with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "                json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"   💾 Última pasta salva: {self.CONFIG_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao salvar última pasta: {e}\")\n",
    "\n",
    "    def _selecionar_diretorio_gui(self):\n",
    "        \"\"\"Abre GUI para seleção de diretório com timer de 10s e fallback.\"\"\"\n",
    "        import tkinter as tk\n",
    "        from tkinter import filedialog\n",
    "\n",
    "        # Carregar última pasta\n",
    "        ultima_pasta = self._carregar_ultima_pasta()\n",
    "\n",
    "        print(\"   🖥️  Abrindo janela de seleção...\")\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"AIVI Data Integration - Diretório\")\n",
    "        root.geometry(\"600x400\")\n",
    "        root.resizable(False, False)\n",
    "\n",
    "        # Centralizar janela\n",
    "        root.update_idletasks()\n",
    "        x = (root.winfo_screenwidth() // 2) - (600 // 2)\n",
    "        y = (root.winfo_screenheight() // 2) - (400 // 2)\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        # Variáveis de controle\n",
    "        resultado = {'path': None, 'cancelado': False}\n",
    "        contador = [10]  # Lista para modificar em nested function\n",
    "\n",
    "        # Frame principal com scroll se necessário\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Título\n",
    "        tk.Label(frame, text=\"AIVI Data Integration\",\n",
    "                 font=('Arial', 14, 'bold'), bg='white').pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        msg = f\"Selecione onde salvar os dados processados.\\n\\n\"\n",
    "        msg += f\"Será criada a pasta:\\nAIVI_DataIntegration_{self.timestamp}\\n\\n\"\n",
    "\n",
    "        if ultima_pasta:\n",
    "            msg += f\"📂 Última pasta usada:\\n{ultima_pasta}\\n\\n\"\n",
    "            msg += f\"⏱️ Usando última pasta automaticamente em:\"\n",
    "        else:\n",
    "            msg += \"Nenhuma pasta anterior encontrada.\\nEscolha uma pasta para continuar.\"\n",
    "\n",
    "        tk.Label(frame, text=msg, justify=tk.LEFT,\n",
    "                 font=('Arial', 9), wraplength=550, bg='white').pack(pady=(0, 10))\n",
    "\n",
    "        # Label do timer (apenas se houver última pasta)\n",
    "        label_timer = None\n",
    "        if ultima_pasta:\n",
    "            label_timer = tk.Label(frame, text=\"10s\",\n",
    "                                  font=('Arial', 20, 'bold'),\n",
    "                                  fg='#FF4444', bg='white')\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "        # Função de countdown\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not resultado['cancelado']:\n",
    "                contador[0] -= 1\n",
    "                if label_timer:\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0 and not resultado['cancelado']:\n",
    "                # Timeout - usar última pasta\n",
    "                if ultima_pasta:\n",
    "                    print(\"   ⏱️  Timeout (10s) - usando última pasta\")\n",
    "                    resultado['path'] = str(ultima_pasta)\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        # Função para escolher nova pasta\n",
    "        def escolher_nova():\n",
    "            resultado['cancelado'] = True\n",
    "            root.withdraw()\n",
    "            diretorio = filedialog.askdirectory(\n",
    "                title=\"Selecione o diretório base\",\n",
    "                initialdir=ultima_pasta if ultima_pasta else None,\n",
    "                mustexist=True\n",
    "            )\n",
    "            if diretorio:\n",
    "                resultado['path'] = diretorio\n",
    "                print(\"   ✅ Nova pasta selecionada\")\n",
    "            elif ultima_pasta:\n",
    "                resultado['path'] = str(ultima_pasta)\n",
    "                print(\"   ⏱️  Seleção cancelada - usando última pasta\")\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        # Função para usar última pasta\n",
    "        def usar_ultima():\n",
    "            resultado['cancelado'] = True\n",
    "            if ultima_pasta:\n",
    "                resultado['path'] = str(ultima_pasta)\n",
    "                print(\"   ✅ Usando última pasta\")\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        # Separador visual\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(fill=tk.X, pady=10)\n",
    "\n",
    "        # Frame dos botões - FIXO NA PARTE INFERIOR\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=20)\n",
    "\n",
    "        btn_escolher = tk.Button(frame_btns, text=\"Escolher Nova Pasta\",\n",
    "                                 command=escolher_nova, width=22, height=2,\n",
    "                                 font=('Arial', 10, 'bold'),\n",
    "                                 bg='#4CAF50', fg='white',\n",
    "                                 cursor='hand2')\n",
    "        btn_escolher.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultima_pasta:\n",
    "            btn_usar = tk.Button(frame_btns, text=\"Usar Última Pasta\",\n",
    "                                command=usar_ultima, width=22, height=2,\n",
    "                                font=('Arial', 10),\n",
    "                                bg='#2196F3', fg='white',\n",
    "                                cursor='hand2')\n",
    "            btn_usar.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        # Iniciar countdown se houver última pasta\n",
    "        if ultima_pasta:\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        root.mainloop()\n",
    "\n",
    "        # Processar resultado\n",
    "        if not resultado['path']:\n",
    "            raise ValueError(\"❌ Nenhum diretório selecionado e sem histórico\")\n",
    "\n",
    "        return Path(resultado['path'])\n",
    "\n",
    "    def _criar_estrutura(self):\n",
    "        \"\"\"Cria árvore de diretórios.\"\"\"\n",
    "\n",
    "        self.diretorios = {\n",
    "            'raiz': self.diretorio_execucao,\n",
    "            'logs': self.diretorio_execucao / '01_Logs',\n",
    "            'dados_entrada': self.diretorio_execucao / '02_Dados_Entrada',\n",
    "            'dados_processados': self.diretorio_execucao / '03_Dados_Processados',\n",
    "            'dados_integrados': self.diretorio_execucao / '04_Dados_Integrados',\n",
    "            'relatorios': self.diretorio_execucao / '05_Relatorios',\n",
    "            'validacoes': self.diretorio_execucao / '06_Validacoes',\n",
    "            'exports': self.diretorio_execucao / '07_Exports'\n",
    "        }\n",
    "\n",
    "        print(\"   📂 Criando diretórios:\")\n",
    "        for nome, caminho in self.diretorios.items():\n",
    "            caminho.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"      ✅ {nome.ljust(20)} → {caminho.name}\")\n",
    "            self._log_operation('CREATE_DIR', f\"Diretório criado: {nome}\",\n",
    "                              {'path': str(caminho)})\n",
    "\n",
    "    def _configurar_logging(self):\n",
    "        \"\"\"Configura sistema de logging.\"\"\"\n",
    "\n",
    "        log_file = self.diretorios['logs'] / f'aivi_integration_{self.timestamp}.log'\n",
    "\n",
    "        self.logger = logging.getLogger('AIVI_Integration')\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.logger.handlers.clear()\n",
    "\n",
    "        # Handler arquivo\n",
    "        fh = logging.FileHandler(log_file, encoding='utf-8')\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "\n",
    "        # Handler console\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)\n",
    "\n",
    "        # Formato\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s | %(levelname)-8s | %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "        fh.setFormatter(formatter)\n",
    "        ch.setFormatter(formatter)\n",
    "\n",
    "        self.logger.addHandler(fh)\n",
    "        self.logger.addHandler(ch)\n",
    "\n",
    "        print(f\"   📝 Log: {log_file.name}\")\n",
    "\n",
    "    def _log_operation(self, operation_type, message, details=None):\n",
    "        \"\"\"Registra operação no log interno.\"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': operation_type,\n",
    "            'message': message,\n",
    "            'details': details or {}\n",
    "        }\n",
    "        self.operations_log.append(log_entry)\n",
    "\n",
    "    def get_path(self, path_type, filename=None):\n",
    "        \"\"\"\n",
    "        Retorna path dinâmico.\n",
    "\n",
    "        Args:\n",
    "            path_type: Tipo do diretório ('logs', 'dados_entrada', etc)\n",
    "            filename: Nome do arquivo (opcional)\n",
    "\n",
    "        Returns:\n",
    "            Path object\n",
    "        \"\"\"\n",
    "        if path_type not in self.diretorios:\n",
    "            raise ValueError(f\"Tipo inválido: {path_type}. \"\n",
    "                           f\"Válidos: {list(self.diretorios.keys())}\")\n",
    "\n",
    "        base_path = self.diretorios[path_type]\n",
    "\n",
    "        if filename:\n",
    "            full_path = base_path / filename\n",
    "            self._log_operation('GET_PATH', f\"Path: {path_type}/{filename}\",\n",
    "                              {'full_path': str(full_path)})\n",
    "            return full_path\n",
    "\n",
    "        return base_path\n",
    "\n",
    "    def file_exists(self, path_type, filename):\n",
    "        \"\"\"Verifica se arquivo existe.\"\"\"\n",
    "        file_path = self.get_path(path_type, filename)\n",
    "        exists = file_path.exists()\n",
    "        self._log_operation('CHECK_EXISTS', f\"Arquivo: {filename}\",\n",
    "                          {'exists': exists})\n",
    "        return exists\n",
    "\n",
    "    def salvar_metadata(self, dados_extras=None):\n",
    "        \"\"\"Salva metadata em JSON.\"\"\"\n",
    "        metadata = {\n",
    "            'timestamp': self.timestamp,\n",
    "            'data_execucao': datetime.now().isoformat(),\n",
    "            'diretorio_execucao': str(self.diretorio_execucao),\n",
    "            'python_version': sys.version.split()[0],\n",
    "            'pandas_version': pd.__version__,\n",
    "            'diretorios': {k: str(v) for k, v in self.diretorios.items()}\n",
    "        }\n",
    "\n",
    "        if dados_extras:\n",
    "            metadata.update(dados_extras)\n",
    "\n",
    "        metadata_path = self.diretorios['raiz'] / 'metadata.json'\n",
    "\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Metadata salvo: {metadata_path.name}\")\n",
    "        return metadata_path\n",
    "\n",
    "    def save_operations_log(self):\n",
    "        \"\"\"Salva log de operações.\"\"\"\n",
    "        log_filename = f\"operations_{self.timestamp}.json\"\n",
    "        log_path = self.diretorios['logs'] / log_filename\n",
    "\n",
    "        with open(log_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.operations_log, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Operations log salvo: {log_filename}\")\n",
    "        return log_path\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 4: UTILITÁRIOS GLOBAIS\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🔧 SEÇÃO 1.4: Definindo utilitários globais\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def normalizar_string(s):\n",
    "    \"\"\"Normaliza string para comparação (remove acentos, lowercase, etc).\"\"\"\n",
    "    s = unicodedata.normalize('NFKD', str(s))\n",
    "    s = s.encode('ASCII', 'ignore').decode('ASCII')\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z0-9]', '', s)\n",
    "    return s\n",
    "\n",
    "def calcular_similaridade(str1, str2):\n",
    "    \"\"\"Calcula similaridade entre duas strings (0.0 a 1.0).\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    s1 = normalizar_string(str1)\n",
    "    s2 = normalizar_string(str2)\n",
    "    return SequenceMatcher(None, s1, s2).ratio()\n",
    "\n",
    "def detectar_tipo_coluna(serie):\n",
    "    \"\"\"\n",
    "    Detecta tipo e características de uma coluna.\n",
    "    GARANTIA: Sempre retorna valores escalares (int, float, str, bool).\n",
    "\n",
    "    Returns:\n",
    "        dict com tipo, range, cardinalidade, etc\n",
    "    \"\"\"\n",
    "    serie = serie.dropna()\n",
    "\n",
    "    if len(serie) == 0:\n",
    "        return {'tipo': 'empty', 'count': 0, 'unique': 0, 'cardinalidade': 0.0}\n",
    "\n",
    "    # Detectar tipo\n",
    "    if pd.api.types.is_numeric_dtype(serie):\n",
    "        tipo = 'int' if pd.api.types.is_integer_dtype(serie) else 'float'\n",
    "    else:\n",
    "        tipo = 'string'\n",
    "\n",
    "    # ✅ CORREÇÃO: Garantir conversão para escalar usando .item() ou int()/float()\n",
    "    count_val = int(len(serie))  # len() já retorna int, mas garantindo\n",
    "    unique_val = int(serie.nunique())  # pandas retorna numpy.int64, converter para int\n",
    "    card_val = float(unique_val / count_val) if count_val > 0 else 0.0\n",
    "\n",
    "    info = {\n",
    "        'tipo': tipo,\n",
    "        'count': count_val,\n",
    "        'unique': unique_val,\n",
    "        'cardinalidade': card_val\n",
    "    }\n",
    "\n",
    "    if tipo in ['int', 'float']:\n",
    "        # ✅ CORREÇÃO: Usar .item() para garantir valor escalar do numpy/pandas\n",
    "        min_val = float(serie.min())\n",
    "        max_val = float(serie.max())\n",
    "        mean_val = float(serie.mean())\n",
    "\n",
    "        # ✅ CORREÇÃO: .any() e .all() retornam numpy.bool_, converter para bool\n",
    "        tem_neg = bool((serie < 0).any())\n",
    "        sempre_pos = bool((serie >= 0).all())\n",
    "\n",
    "        info.update({\n",
    "            'min': min_val,\n",
    "            'max': max_val,\n",
    "            'mean': mean_val,\n",
    "            'tem_negativos': tem_neg,\n",
    "            'sempre_positivo': sempre_pos\n",
    "        })\n",
    "\n",
    "    return info\n",
    "\n",
    "def mostrar_preview_coluna(df, coluna, n=5):\n",
    "    \"\"\"Mostra preview de uma coluna.\"\"\"\n",
    "    print(f\"\\n   📊 Coluna: {coluna}\")\n",
    "    print(f\"      Tipo: {df[coluna].dtype}\")\n",
    "    print(f\"      Não-nulos: {df[coluna].notna().sum():,} / {len(df):,}\")\n",
    "    print(f\"      Únicos: {df[coluna].nunique():,}\")\n",
    "    print(f\"      Amostra:\")\n",
    "    for i, val in enumerate(df[coluna].dropna().head(n), 1):\n",
    "        print(f\"         {i}. {val}\")\n",
    "\n",
    "print(\"   ✅ normalizar_string()\")\n",
    "print(\"   ✅ calcular_similaridade()\")\n",
    "print(\"   ✅ detectar_tipo_coluna()\")\n",
    "print(\"   ✅ mostrar_preview_coluna()\")\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# SEÇÃO 5: INICIALIZAR FILEMANAGER\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"🚀 SEÇÃO 1.5: Inicializando FileManager\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Inicializar (vai abrir GUI)\n",
    "fm = FileManager()\n",
    "\n",
    "# Salvar metadata inicial\n",
    "fm.salvar_metadata({\n",
    "    'bloco': 1,\n",
    "    'fase': 'configuracao_ambiente',\n",
    "    'modulos_carregados': modulos_carregados\n",
    "})\n",
    "\n",
    "# Criar aliases para compatibilidade\n",
    "gerenciador = fm\n",
    "gp = fm\n",
    "\n",
    "# Aliases de diretórios\n",
    "DIR_LOGS = fm.diretorios['logs']\n",
    "DIR_DADOS_ENTRADA = fm.diretorios['dados_entrada']\n",
    "DIR_DADOS_PROCESSADOS = fm.diretorios['dados_processados']\n",
    "DIR_DADOS_INTEGRADOS = fm.diretorios['dados_integrados']\n",
    "DIR_RELATORIOS = fm.diretorios['relatorios']\n",
    "DIR_VALIDACOES = fm.diretorios['validacoes']\n",
    "DIR_EXPORTS = fm.diretorios['exports']\n",
    "\n",
    "print()\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL DO BLOCO 1\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" ✅ BLOCO 1 CONCLUÍDO COM SUCESSO \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "print(\"📊 RESUMO DA CONFIGURAÇÃO:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   ✅ Bibliotecas carregadas: {len(modulos_carregados)}\")\n",
    "print(f\"   ✅ Constantes AIVI: {len(CONSTANTES_AIVI)}\")\n",
    "print(f\"   ✅ FileManager ativo: {fm.timestamp}\")\n",
    "print(f\"   ✅ Diretórios criados: {len(fm.diretorios)}\")\n",
    "print(f\"   ✅ Sistema de logs: OK\")\n",
    "print(f\"   ✅ Utilitários globais: 4 funções\")\n",
    "print(f\"   ✅ Sistema de última pasta: ATIVO (timer 10s)\")\n",
    "print()\n",
    "\n",
    "print(\"📂 ESTRUTURA DE DIRETÓRIOS:\")\n",
    "print(\"-\" * 80)\n",
    "for nome, caminho in fm.diretorios.items():\n",
    "    print(f\"   {nome.ljust(20)} → {caminho}\")\n",
    "print()\n",
    "\n",
    "print(\"🔗 VARIÁVEIS GLOBAIS DISPONÍVEIS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   • fm / gerenciador / gp (FileManager)\")\n",
    "print(\"   • DIR_LOGS, DIR_DADOS_ENTRADA, DIR_DADOS_PROCESSADOS, etc\")\n",
    "print(\"   • CONSTANTES_AIVI (dict)\")\n",
    "print(\"   • SCHEMA_AIVI_CAMPOS_OBRIGATORIOS (list)\")\n",
    "print(\"   • DICIONARIO_SINONIMOS (dict)\")\n",
    "print(\"   • Funções: normalizar_string(), calcular_similaridade(), etc\")\n",
    "print()\n",
    "\n",
    "print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   1. ✅ Verifique se o diretório foi criado corretamente\")\n",
    "print(\"   2. ✅ Confirme que o log foi iniciado\")\n",
    "print(\"   3. 📤 Envie: 'BLOCO 1 OK' para prosseguir\")\n",
    "print(\"   4. ⏳ BLOCO 2 carregará o arquivo YSMM_VI_ACOMP\")\n",
    "print()\n",
    "\n",
    "print(\"═\" * 80)"
   ],
   "id": "195b3fbf337a7cfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                  BLOCO 1: CONFIGURAÇÃO COMPLETA DO AMBIENTE                  ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📦 SEÇÃO 1.1: Verificando bibliotecas essenciais\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ pandas          v2.3.3 - Manipulação de dados\n",
      "   ✅ numpy           v2.3.3 - Cálculos numéricos\n",
      "   ✅ scipy           v1.16.2 - Estatísticas avançadas\n",
      "   ✅ openpyxl        v3.1.5 - Excel (.xlsx)\n",
      "   ✅ xlrd            v2.0.2 - Excel (.xls) - OPCIONAL\n",
      "\n",
      "✅ Todas as bibliotecas essenciais carregadas\n",
      "   • pandas configurado (display otimizado)\n",
      "   • warnings suprimidos\n",
      "\n",
      "📊 SEÇÃO 1.2: Carregando constantes AIVI 2025\n",
      "--------------------------------------------------------------------------------\n",
      "   BATENTE_MAX_INF           = -1.0\n",
      "   BATENTE_MAX_SUP           = 1.0\n",
      "   LI_MAX_CORPORATIVO        = -0.05\n",
      "   LS_MIN_CORPORATIVO        = 0.05\n",
      "   RANGE_MINIMO              = 0.1\n",
      "   MULTIPLICADOR_IQR         = 1.5\n",
      "   SIGMA_SHIFT_CEP           = 1.5\n",
      "   LIMITE_MATERIALIDADE      = 6500.0\n",
      "   MESES_MINIMOS             = 6\n",
      "   P_VALUE_THRESHOLD         = 0.05\n",
      "\n",
      "✅ 10 constantes carregadas\n",
      "✅ Schema AIVI: 10 campos obrigatórios\n",
      "✅ Dicionário de sinônimos: 9 campos mapeados\n",
      "\n",
      "📁 SEÇÃO 1.3: Inicializando FileManager\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔧 SEÇÃO 1.4: Definindo utilitários globais\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ normalizar_string()\n",
      "   ✅ calcular_similaridade()\n",
      "   ✅ detectar_tipo_coluna()\n",
      "   ✅ mostrar_preview_coluna()\n",
      "\n",
      "🚀 SEÇÃO 1.5: Inicializando FileManager\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   🕐 Timestamp: 20251015_110105\n",
      "   📂 Última pasta: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\n",
      "   🖥️  Abrindo janela de seleção...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:01:08 | INFO     | ════════════════════════════════════════════════════════════════════════════════\n",
      "2025-10-15 11:01:08 | INFO     | NOVA EXECUÇÃO - AIVI DATA INTEGRATION\n",
      "2025-10-15 11:01:08 | INFO     | ════════════════════════════════════════════════════════════════════════════════\n",
      "2025-10-15 11:01:08 | INFO     | Timestamp: 20251015_110105\n",
      "2025-10-15 11:01:08 | INFO     | Diretório: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\n",
      "2025-10-15 11:01:08 | INFO     | Python: 3.11.9\n",
      "2025-10-15 11:01:08 | INFO     | Pandas: 2.3.3\n",
      "2025-10-15 11:01:08 | INFO     | Metadata salvo: metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Usando última pasta\n",
      "   📁 Diretório base: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\n",
      "   💾 Última pasta salva: C:\\Users\\fpsou\\.aivi_last_dir.json\n",
      "   📂 Criando diretórios:\n",
      "      ✅ raiz                 → AIVI_DataIntegration_20251015_110105\n",
      "      ✅ logs                 → 01_Logs\n",
      "      ✅ dados_entrada        → 02_Dados_Entrada\n",
      "      ✅ dados_processados    → 03_Dados_Processados\n",
      "      ✅ dados_integrados     → 04_Dados_Integrados\n",
      "      ✅ relatorios           → 05_Relatorios\n",
      "      ✅ validacoes           → 06_Validacoes\n",
      "      ✅ exports              → 07_Exports\n",
      "   📝 Log: aivi_integration_20251015_110105.log\n",
      "\n",
      "   ✅ FileManager inicializado\n",
      "   ✅ Sistema de logs ativo\n",
      "\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                       ✅ BLOCO 1 CONCLUÍDO COM SUCESSO                        ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 RESUMO DA CONFIGURAÇÃO:\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ Bibliotecas carregadas: 5\n",
      "   ✅ Constantes AIVI: 10\n",
      "   ✅ FileManager ativo: 20251015_110105\n",
      "   ✅ Diretórios criados: 8\n",
      "   ✅ Sistema de logs: OK\n",
      "   ✅ Utilitários globais: 4 funções\n",
      "   ✅ Sistema de última pasta: ATIVO (timer 10s)\n",
      "\n",
      "📂 ESTRUTURA DE DIRETÓRIOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   raiz                 → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\n",
      "   logs                 → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\01_Logs\n",
      "   dados_entrada        → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\n",
      "   dados_processados    → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\03_Dados_Processados\n",
      "   dados_integrados     → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\04_Dados_Integrados\n",
      "   relatorios           → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\05_Relatorios\n",
      "   validacoes           → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\06_Validacoes\n",
      "   exports              → E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\07_Exports\n",
      "\n",
      "🔗 VARIÁVEIS GLOBAIS DISPONÍVEIS:\n",
      "--------------------------------------------------------------------------------\n",
      "   • fm / gerenciador / gp (FileManager)\n",
      "   • DIR_LOGS, DIR_DADOS_ENTRADA, DIR_DADOS_PROCESSADOS, etc\n",
      "   • CONSTANTES_AIVI (dict)\n",
      "   • SCHEMA_AIVI_CAMPOS_OBRIGATORIOS (list)\n",
      "   • DICIONARIO_SINONIMOS (dict)\n",
      "   • Funções: normalizar_string(), calcular_similaridade(), etc\n",
      "\n",
      "📋 PRÓXIMOS PASSOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ✅ Verifique se o diretório foi criado corretamente\n",
      "   2. ✅ Confirme que o log foi iniciado\n",
      "   3. 📤 Envie: 'BLOCO 1 OK' para prosseguir\n",
      "   4. ⏳ BLOCO 2 carregará o arquivo YSMM_VI_ACOMP\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:01:48.822186Z",
     "start_time": "2025-10-15T14:01:20.772843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "AIVI DATA INTEGRATION - BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "Versão: 3.0 - Modular (um arquivo por vez)\n",
    "Arquivo: YSMM_VI_ACOMP (SAP - Base de Dados Históricos)\n",
    "\n",
    "FUNCIONALIDADES:\n",
    "  ✅ Seleção via GUI\n",
    "  ✅ Suporte robusto a .XLS e .XLSX\n",
    "  ✅ Limpeza SAP automática (remove col A, linhas 1,2,3,5)\n",
    "  ✅ Detecção automática de schema (Parte 16)\n",
    "  ✅ Listagem COMPLETA de todas as colunas\n",
    "  ✅ Validação de campos obrigatórios\n",
    "  ✅ Backup automático\n",
    "  ✅ Logging completo\n",
    "\n",
    "APÓS ESTE BLOCO:\n",
    "  • df_sap disponível globalmente\n",
    "  • Aguarda feedback do usuário\n",
    "  • Próximo: BLOCO 3 (Arquivo 2)\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1/N \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# FUNÇÃO AUXILIAR: Similaridade de Strings\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def calcular_similaridade(s1, s2):\n",
    "    \"\"\"\n",
    "    Calcula similaridade entre duas strings usando SequenceMatcher.\n",
    "\n",
    "    Args:\n",
    "        s1: String 1\n",
    "        s2: String 2\n",
    "\n",
    "    Returns:\n",
    "        float: Similaridade entre 0.0 e 1.0 (0% a 100%)\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, s1.lower(), s2.lower()).ratio()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# CLASSE: CarregadorArquivo (MODULAR - reutilizável)\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class CarregadorArquivo:\n",
    "    \"\"\"\n",
    "    Carregador modular de arquivos Excel com detecção automática de schema.\n",
    "\n",
    "    Design Pattern: Template Method\n",
    "    - Métodos genéricos para qualquer arquivo\n",
    "    - Métodos específicos por tipo de arquivo (SAP, ESO, etc)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gerenciador):\n",
    "        self.gerenciador = gerenciador\n",
    "        self.logger = gerenciador.logger\n",
    "        self.df = None\n",
    "        self.arquivo_original = None\n",
    "        self.tipo_arquivo = None\n",
    "        self.mapeamento_colunas = {}\n",
    "        self.log_deteccao = []\n",
    "\n",
    "    def selecionar_arquivo_gui(self, titulo, mensagem):\n",
    "        \"\"\"Abre GUI para seleção de arquivo.\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "        root.attributes('-alpha', 0.0)\n",
    "        root.update()\n",
    "\n",
    "        messagebox.showinfo(titulo, mensagem.strip())\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=titulo,\n",
    "            filetypes=[\n",
    "                (\"Excel files\", \"*.xlsx *.xls\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(f\"❌ Nenhum arquivo selecionado\")\n",
    "\n",
    "        return Path(arquivo)\n",
    "\n",
    "    def carregar_excel_robusto(self, caminho):\n",
    "        \"\"\"\n",
    "        Carrega Excel com múltiplos engines (tolerante a falhas).\n",
    "\n",
    "        Ordem de tentativa:\n",
    "          1. Engine específico da extensão (openpyxl ou xlrd)\n",
    "          2. Engine automático (pandas decide)\n",
    "        \"\"\"\n",
    "        extensao = caminho.suffix.lower()\n",
    "\n",
    "        print(f\"📖 Carregando arquivo Excel ({extensao})...\")\n",
    "\n",
    "        # Definir engines\n",
    "        if extensao == '.xlsx':\n",
    "            engines = ['openpyxl', None]\n",
    "        elif extensao == '.xls':\n",
    "            engines = ['xlrd', None]\n",
    "        else:\n",
    "            engines = [None, 'openpyxl', 'xlrd']\n",
    "\n",
    "        # Tentar cada engine\n",
    "        ultimo_erro = None\n",
    "\n",
    "        for i, engine in enumerate(engines, 1):\n",
    "            try:\n",
    "                if engine:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine='{engine}'\")\n",
    "                    df = pd.read_excel(caminho, header=None, engine=engine)\n",
    "                else:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine automático\")\n",
    "                    df = pd.read_excel(caminho, header=None)\n",
    "\n",
    "                print(f\"   ✅ Sucesso! {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "                self.logger.info(f\"Carregado: {caminho.name} ({df.shape[0]} × {df.shape[1]})\")\n",
    "                return df\n",
    "\n",
    "            except Exception as e:\n",
    "                ultimo_erro = e\n",
    "                print(f\"   ❌ Falhou: {str(e)[:60]}...\")\n",
    "                continue\n",
    "\n",
    "        # Nenhum engine funcionou\n",
    "        print()\n",
    "        print(\"❌ ERRO: Não foi possível ler o arquivo\")\n",
    "\n",
    "        if extensao == '.xls':\n",
    "            print()\n",
    "            print(\"💡 SOLUÇÃO para .XLS:\")\n",
    "            print(\"   1. Instale xlrd: pip install xlrd\")\n",
    "            print(\"   2. OU converta para .XLSX no Excel\")\n",
    "\n",
    "        raise Exception(f\"Falha ao ler: {ultimo_erro}\")\n",
    "\n",
    "    def limpar_sap_bruto(self, df_bruto):\n",
    "        \"\"\"\n",
    "        Limpeza específica para arquivos SAP YSMM_VI_ACOMP.\n",
    "\n",
    "        Transformações:\n",
    "          1. Remove coluna A (índice 0) - coluna vazia do SAP\n",
    "          2. Remove linhas 1, 2, 3, 5 - cabeçalhos e vazias\n",
    "          3. Linha 4 vira cabeçalho\n",
    "        \"\"\"\n",
    "        print()\n",
    "        print(\"🧹 Aplicando limpeza SAP (YSMM_VI_ACOMP)...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        print(f\"   📊 Original: {df_bruto.shape[0]:,} linhas × {df_bruto.shape[1]} colunas\")\n",
    "\n",
    "        df = df_bruto.copy()\n",
    "\n",
    "        # PASSO 1: Remover primeira coluna\n",
    "        if df.shape[1] > 0:\n",
    "            df = df.iloc[:, 1:]\n",
    "            print(f\"   ✅ Removida coluna A (índice 0)\")\n",
    "\n",
    "        # PASSO 2: Processar cabeçalho\n",
    "        if len(df) > 4:\n",
    "            # Linha 4 (índice 3) vira cabeçalho\n",
    "            novo_cabecalho = df.iloc[3].values\n",
    "\n",
    "            # Remover linhas 0,1,2,4 e pegar de 5 em diante\n",
    "            df = df.iloc[5:].reset_index(drop=True)\n",
    "            df.columns = novo_cabecalho\n",
    "\n",
    "            print(f\"   ✅ Removidas linhas 1, 2, 3, 5\")\n",
    "            print(f\"   ✅ Cabeçalho definido (linha 4 original)\")\n",
    "\n",
    "        print(f\"   📊 Limpo: {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "        print()\n",
    "\n",
    "        self.logger.info(f\"Limpeza SAP aplicada: {df.shape[0]} × {df.shape[1]}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def detectar_colunas_automatico(self, df, campos_esperados):\n",
    "        \"\"\"\n",
    "        Detecção automática de colunas usando similaridade de strings.\n",
    "\n",
    "        Implementa Parte 16 do prompt: Inteligência de Dados.\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame com colunas a mapear\n",
    "            campos_esperados: dict {campo_padrao: [sinonimos]}\n",
    "\n",
    "        Returns:\n",
    "            (df_mapeado, mapeamento, log_deteccao, sucesso)\n",
    "        \"\"\"\n",
    "        print(\"🔍 DETECÇÃO AUTOMÁTICA DE COLUNAS\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        mapeamento = {}\n",
    "        log_deteccao = []\n",
    "        campos_nao_encontrados = []\n",
    "\n",
    "        # Para cada campo esperado\n",
    "        for campo_padrao, sinonimos in campos_esperados.items():\n",
    "            melhor_score = 0.0\n",
    "            melhor_match = None\n",
    "            melhor_coluna_df = None\n",
    "\n",
    "            # Procurar nas colunas do DataFrame\n",
    "            for col_df in df.columns:\n",
    "                col_df_str = str(col_df).strip()\n",
    "\n",
    "                # Calcular similaridade com cada sinônimo\n",
    "                for sinonimo in sinonimos:\n",
    "                    # Exata?\n",
    "                    if col_df_str == sinonimo:\n",
    "                        score = 1.0\n",
    "                    else:\n",
    "                        # Fuzzy match\n",
    "                        score = calcular_similaridade(col_df_str, sinonimo)\n",
    "\n",
    "                    if score > melhor_score:\n",
    "                        melhor_score = score\n",
    "                        melhor_match = sinonimo\n",
    "                        melhor_coluna_df = col_df\n",
    "\n",
    "            # Threshold: 70%\n",
    "            if melhor_score >= 0.70:\n",
    "                # Mapear se nome diferente\n",
    "                if melhor_coluna_df != campo_padrao:\n",
    "                    mapeamento[melhor_coluna_df] = campo_padrao\n",
    "\n",
    "                # Status visual\n",
    "                if melhor_score >= 0.95:\n",
    "                    status = \"✅ AUTO\"\n",
    "                    auto = True\n",
    "                elif melhor_score >= 0.80:\n",
    "                    status = \"⚠️  REVISAR\"\n",
    "                    auto = False\n",
    "                else:\n",
    "                    status = \"⚠️  BAIXA\"\n",
    "                    auto = False\n",
    "\n",
    "                print(f\"   {status} '{melhor_coluna_df}' → '{campo_padrao}'\")\n",
    "                print(f\"           Confiança: {melhor_score:.1%} (match: '{melhor_match}')\")\n",
    "\n",
    "                log_deteccao.append({\n",
    "                    'coluna_original': melhor_coluna_df,\n",
    "                    'campo_padrao': campo_padrao,\n",
    "                    'confianca': melhor_score,\n",
    "                    'match_com': melhor_match,\n",
    "                    'automatico': auto\n",
    "                })\n",
    "            else:\n",
    "                print(f\"   ❌ '{campo_padrao}' - Não encontrado (melhor: {melhor_score:.1%})\")\n",
    "                campos_nao_encontrados.append(campo_padrao)\n",
    "\n",
    "                log_deteccao.append({\n",
    "                    'coluna_original': None,\n",
    "                    'campo_padrao': campo_padrao,\n",
    "                    'confianca': melhor_score,\n",
    "                    'automatico': False,\n",
    "                    'status': 'NAO_ENCONTRADO'\n",
    "                })\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Aplicar mapeamento\n",
    "        if mapeamento:\n",
    "            df = df.rename(columns=mapeamento)\n",
    "            print(f\"   🔄 {len(mapeamento)} colunas renomeadas\")\n",
    "            self.logger.info(f\"Mapeamento: {len(mapeamento)} colunas\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Resultado\n",
    "        sucesso = len(campos_nao_encontrados) == 0\n",
    "\n",
    "        if campos_nao_encontrados:\n",
    "            print(f\"⚠️  {len(campos_nao_encontrados)} campos não encontrados:\")\n",
    "            for campo in campos_nao_encontrados:\n",
    "                print(f\"      • {campo}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"✅ Todos os campos obrigatórios mapeados!\")\n",
    "            print()\n",
    "\n",
    "        return df, mapeamento, log_deteccao, sucesso\n",
    "\n",
    "    def listar_todas_colunas(self, df):\n",
    "        \"\"\"\n",
    "        Lista TODAS as colunas com informações detalhadas.\n",
    "\n",
    "        Para cada coluna mostra:\n",
    "          - Tipo de dados\n",
    "          - Quantidade de nulos\n",
    "          - Quantidade de valores únicos\n",
    "        \"\"\"\n",
    "        print()\n",
    "        print(\"📑 LISTAGEM COMPLETA DE COLUNAS\")\n",
    "        print(\"═\" * 80)\n",
    "        print(f\"📏 Total: {len(df.columns)} colunas\")\n",
    "        print()\n",
    "\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            tipo = df[col].dtype\n",
    "            nulos = df[col].isna().sum()\n",
    "            pct_nulos = (nulos / len(df) * 100) if len(df) > 0 else 0\n",
    "            unicos = df[col].nunique()\n",
    "\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       ├─ Tipo: {tipo}\")\n",
    "            print(f\"       ├─ Nulos: {nulos:,} ({pct_nulos:.1f}%)\")\n",
    "            print(f\"       └─ Únicos: {unicos:,}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    def mostrar_preview_dados(self, df, n_linhas=3):\n",
    "        \"\"\"Mostra preview das primeiras linhas.\"\"\"\n",
    "        print(\"📊 PREVIEW DOS DADOS (primeiras 5 colunas)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        colunas_preview = list(df.columns[:5])\n",
    "        print(df[colunas_preview].head(n_linhas).to_string(index=False))\n",
    "        print()\n",
    "\n",
    "    def salvar_backup(self, df, nome_base):\n",
    "        \"\"\"Salva backup na pasta de entrada.\"\"\"\n",
    "        timestamp = self.gerenciador.timestamp\n",
    "\n",
    "        arquivo_destino = self.gerenciador.diretorios['dados_entrada'] / \\\n",
    "                         f\"{nome_base}_{timestamp}.xlsx\"\n",
    "\n",
    "        try:\n",
    "            df.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "            self.logger.info(f\"Backup: {arquivo_destino.name}\")\n",
    "            print(f\"   ✅ Backup: {arquivo_destino.name}\")\n",
    "            return arquivo_destino\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao salvar backup: {str(e)}\")\n",
    "            self.logger.error(f\"Erro backup: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def salvar_log_deteccao(self, nome_arquivo=\"deteccao_schema\"):\n",
    "        \"\"\"Salva log de detecção em JSON.\"\"\"\n",
    "        if not self.log_deteccao:\n",
    "            return None\n",
    "\n",
    "        timestamp = self.gerenciador.timestamp\n",
    "        log_file = self.gerenciador.diretorios['logs'] / \\\n",
    "                  f\"{nome_arquivo}_{timestamp}.json\"\n",
    "\n",
    "        import json\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.log_deteccao, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Log detecção: {log_file.name}\")\n",
    "        return log_file\n",
    "\n",
    "    def carregar_ysmm_vi_acomp(self):\n",
    "        \"\"\"\n",
    "        Pipeline completo para carregar YSMM_VI_ACOMP (SAP).\n",
    "\n",
    "        Etapas:\n",
    "          1. Seleção via GUI\n",
    "          2. Carregamento robusto\n",
    "          3. Limpeza SAP\n",
    "          4. Detecção automática de schema\n",
    "          5. Listagem de todas as colunas\n",
    "          6. Preview dos dados\n",
    "          7. Backup\n",
    "        \"\"\"\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ARQUIVO 1: YSMM_VI_ACOMP (SAP - BASE HISTÓRICA) \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "\n",
    "        mensagem = \"\"\"\n",
    "╔═══════════════════════════════════════════════════╗\n",
    "║  📂 ARQUIVO SAP - YSMM_VI_ACOMP                   ║\n",
    "╠═══════════════════════════════════════════════════╣\n",
    "║                                                   ║\n",
    "║  Transação: YSMM_VI_ACOMP                         ║\n",
    "║  Conteúdo: Dados históricos de variações internas║\n",
    "║  Período: Recomendado 12+ meses                   ║\n",
    "║                                                   ║\n",
    "║  ⚠️  IMPORTANTE:                                  ║\n",
    "║                                                   ║\n",
    "║  • Selecione arquivo ORIGINAL (BRUTO) do SAP      ║\n",
    "║  • NÃO faça limpeza manual                        ║\n",
    "║  • Aceita .XLS ou .XLSX                           ║\n",
    "║  • Nome típico: 2025-2024-YSMM_VI_ACOMP.xlsx      ║\n",
    "║                                                   ║\n",
    "╚═══════════════════════════════════════════════════╝\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 1: Seleção\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.arquivo_original = self.selecionar_arquivo_gui(\n",
    "                titulo=\"[1/N] YSMM_VI_ACOMP (SAP - BRUTO)\",\n",
    "                mensagem=mensagem\n",
    "            )\n",
    "\n",
    "            self.tipo_arquivo = \"SAP_YSMM_VI_ACOMP\"\n",
    "\n",
    "            print(f\"✅ Arquivo selecionado:\")\n",
    "            print(f\"   📁 Nome: {self.arquivo_original.name}\")\n",
    "            print(f\"   📊 Tamanho: {self.arquivo_original.stat().st_size:,} bytes\")\n",
    "            print(f\"   🔧 Tipo: {self.arquivo_original.suffix}\")\n",
    "            print()\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 2: Carregamento\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            df_bruto = self.carregar_excel_robusto(self.arquivo_original)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 3: Limpeza SAP\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            df_limpo = self.limpar_sap_bruto(df_bruto)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 4: Detecção automática de schema\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            # Campos obrigatórios SAP\n",
    "            campos_sap = {\n",
    "                'Centro': ['Centro', 'Código de Centro', 'Cod Centro'],\n",
    "                'Cód Grupo de produto': ['Cód Grupo de produto', 'Cod Grupo de produto'],\n",
    "                'Expedição': ['Expedição c/ Veí', 'Expedição c/ Veículo', 'Expedição'],\n",
    "                'Variação Interna': ['Variação Interna', 'Variacao Interna', 'VI'],\n",
    "                'Mês': ['Mês do exercício', 'Mes do exercicio', 'Mês'],\n",
    "                'Ano': ['Ano do documento do material', 'Ano do documento', 'Ano']\n",
    "            }\n",
    "\n",
    "            df_mapeado, mapeamento, log, sucesso = \\\n",
    "                self.detectar_colunas_automatico(df_limpo, campos_sap)\n",
    "\n",
    "            self.df = df_mapeado\n",
    "            self.mapeamento_colunas = mapeamento\n",
    "            self.log_deteccao = log\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 5: Listar TODAS as colunas\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.listar_todas_colunas(self.df)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 6: Preview\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            self.mostrar_preview_dados(self.df)\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # ETAPA 7: Backup\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            print(\"💾 Salvando backup...\")\n",
    "            backup = self.salvar_backup(self.df, \"SAP_YSMM_Limpo\")\n",
    "\n",
    "            log_file = self.salvar_log_deteccao(\"deteccao_sap\")\n",
    "            if log_file:\n",
    "                print(f\"   ✅ Log detecção: {log_file.name}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "            # RESULTADO FINAL\n",
    "            # ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "            print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "            print(\"║\" + \" ✅ ARQUIVO SAP CARREGADO COM SUCESSO \".center(78) + \"║\")\n",
    "            print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "            print()\n",
    "\n",
    "            print(\"📊 RESUMO DO CARREGAMENTO:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"   • Arquivo: {self.arquivo_original.name}\")\n",
    "            print(f\"   • Registros: {len(self.df):,}\")\n",
    "            print(f\"   • Colunas totais: {len(self.df.columns)}\")\n",
    "            print(f\"   • Colunas mapeadas: {len(self.mapeamento_colunas)}\")\n",
    "            print(f\"   • Detecção automática: {'✅ 100%' if sucesso else '⚠️  Parcial'}\")\n",
    "            print(f\"   • Backup salvo: ✅\")\n",
    "            print()\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "            print(\"║\" + \" ❌ ERRO AO CARREGAR ARQUIVO SAP \".center(78) + \"║\")\n",
    "            print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "            print()\n",
    "            print(f\"❌ Erro: {str(e)}\")\n",
    "            print()\n",
    "\n",
    "            import traceback\n",
    "            print(\"🔍 Detalhes técnicos:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "            self.logger.error(f\"Erro SAP: {str(e)}\")\n",
    "\n",
    "            return False\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# EXECUÇÃO: CARREGAR ARQUIVO 1 (YSMM_VI_ACOMP)\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print()\n",
    "print(\"⚠️  INSTRUÇÕES:\")\n",
    "print(\"   • Uma janela vai abrir para seleção do arquivo\")\n",
    "print(\"   • Selecione o arquivo YSMM_VI_ACOMP ORIGINAL (bruto) do SAP\")\n",
    "print(\"   • NÃO faça limpeza manual no arquivo\")\n",
    "print(\"   • Aceita .XLS ou .XLSX\")\n",
    "print()\n",
    "\n",
    "input(\"👉 Pressione ENTER para iniciar...\")\n",
    "\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Inicializar carregador\n",
    "    carregador_sap = CarregadorArquivo(fm)\n",
    "\n",
    "    # Carregar YSMM_VI_ACOMP\n",
    "    sucesso = carregador_sap.carregar_ysmm_vi_acomp()\n",
    "\n",
    "    if sucesso:\n",
    "        # Salvar referência global\n",
    "        df_sap = carregador_sap.df\n",
    "\n",
    "        arquivo_sap_info = {\n",
    "            'df': df_sap,\n",
    "            'arquivo': carregador_sap.arquivo_original,\n",
    "            'mapeamento': carregador_sap.mapeamento_colunas,\n",
    "            'log_deteccao': carregador_sap.log_deteccao\n",
    "        }\n",
    "\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"✅ BLOCO 2 - ARQUIVO 1 CONCLUÍDO\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   1. ✅ Revise a lista de colunas acima\")\n",
    "        print(\"   2. ✅ Verifique se os dados fazem sentido\")\n",
    "        print(\"   3. ✅ Confira a pasta 02_Dados_Entrada no Explorer\")\n",
    "        print(\"   4. 📤 Envie feedback:\")\n",
    "        print(\"       • 'ARQUIVO 1 OK' - para prosseguir\")\n",
    "        print(\"       • Descreva problemas - se houver erros\")\n",
    "        print(\"   5. ⏳ Aguarde BLOCO 3 (próximo arquivo)\")\n",
    "        print()\n",
    "        print(\"🔗 VARIÁVEIS DISPONÍVEIS:\")\n",
    "        print(\"   • df_sap - DataFrame com dados SAP\")\n",
    "        print(\"   • arquivo_sap_info - Metadados completos\")\n",
    "        print(\"   • carregador_sap - Instância do carregador\")\n",
    "        print()\n",
    "\n",
    "        fm.logger.info(\"BLOCO 2 - Arquivo 1 (SAP) concluído\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print(\"⚠️  Operação cancelada pelo usuário\")\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ERRO FATAL - BLOCO 2 \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "    print(f\"❌ Erro: {str(e)}\")\n",
    "    print()\n",
    "    import traceback\n",
    "    print(\"🔍 Detalhes técnicos:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print()\n",
    "print(\"═\" * 80)"
   ],
   "id": "e6ebf0abda5c4eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                  BLOCO 2: CARREGADOR MODULAR - ARQUIVO 1/N                   ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "⚠️  INSTRUÇÕES:\n",
      "   • Uma janela vai abrir para seleção do arquivo\n",
      "   • Selecione o arquivo YSMM_VI_ACOMP ORIGINAL (bruto) do SAP\n",
      "   • NÃO faça limpeza manual no arquivo\n",
      "   • Aceita .XLS ou .XLSX\n",
      "\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║               ARQUIVO 1: YSMM_VI_ACOMP (SAP - BASE HISTÓRICA)                ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "✅ Arquivo selecionado:\n",
      "   📁 Nome: 2025-2024-YSMM_VI_ACOMP.xlsx\n",
      "   📊 Tamanho: 3,827,778 bytes\n",
      "   🔧 Tipo: .xlsx\n",
      "\n",
      "📖 Carregando arquivo Excel (.xlsx)...\n",
      "   Tentativa 1/2: engine='openpyxl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:01:41 | INFO     | Carregado: 2025-2024-YSMM_VI_ACOMP.xlsx (27660 × 30)\n",
      "2025-10-15 11:01:41 | INFO     | Limpeza SAP aplicada: 27655 × 29\n",
      "2025-10-15 11:01:41 | INFO     | Mapeamento: 3 colunas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Sucesso! 27,660 linhas × 30 colunas\n",
      "\n",
      "🧹 Aplicando limpeza SAP (YSMM_VI_ACOMP)...\n",
      "--------------------------------------------------------------------------------\n",
      "   📊 Original: 27,660 linhas × 30 colunas\n",
      "   ✅ Removida coluna A (índice 0)\n",
      "   ✅ Removidas linhas 1, 2, 3, 5\n",
      "   ✅ Cabeçalho definido (linha 4 original)\n",
      "   📊 Limpo: 27,655 linhas × 29 colunas\n",
      "\n",
      "🔍 DETECÇÃO AUTOMÁTICA DE COLUNAS\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ AUTO 'Centro' → 'Centro'\n",
      "           Confiança: 100.0% (match: 'Centro')\n",
      "   ✅ AUTO 'Cód Grupo de produto' → 'Cód Grupo de produto'\n",
      "           Confiança: 100.0% (match: 'Cód Grupo de produto')\n",
      "   ✅ AUTO 'Expedição c/ Veí' → 'Expedição'\n",
      "           Confiança: 100.0% (match: 'Expedição c/ Veí')\n",
      "   ✅ AUTO 'Variação Interna' → 'Variação Interna'\n",
      "           Confiança: 100.0% (match: 'Variação Interna')\n",
      "   ✅ AUTO 'Mês do exercício' → 'Mês'\n",
      "           Confiança: 100.0% (match: 'Mês do exercício')\n",
      "   ✅ AUTO 'Ano do documento do material' → 'Ano'\n",
      "           Confiança: 100.0% (match: 'Ano do documento do material')\n",
      "\n",
      "   🔄 3 colunas renomeadas\n",
      "\n",
      "✅ Todos os campos obrigatórios mapeados!\n",
      "\n",
      "\n",
      "📑 LISTAGEM COMPLETA DE COLUNAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📏 Total: 29 colunas\n",
      "\n",
      "    1. Nome do set\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 1,492 (5.4%)\n",
      "       └─ Únicos: 4\n",
      "    2. Mês\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 12\n",
      "    3. Ano\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "    4. Centro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 181\n",
      "    5. Cód Grupo de produto\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 419\n",
      "    6. Desc. Grupo de Produto\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 417\n",
      "    7. Nome\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 182\n",
      "    8. Expedição\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 22,828\n",
      "    9. Variação Interna\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 7,898\n",
      "   10. Variação Manual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2,681\n",
      "   11. VarInt + VarMan\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,485\n",
      "   12. Percentual de V\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 466\n",
      "   13. Limite Inferior\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 47\n",
      "   14. Limite Su\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 37\n",
      "   15. Histórico\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 246\n",
      "   16. Percentual Excedente\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 447\n",
      "   17. Quant. Exceden\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 4,800\n",
      "   18. Custo Unitário\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 10,739\n",
      "   19. Valor Excede\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,332\n",
      "   20. Imposto (R$)\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2,067\n",
      "   21. Valor Exced. da\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 8,797\n",
      "   22. Valor da VI (R$)\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 14,244\n",
      "   23. Valor da VI +\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 14,264\n",
      "   24. Perda ou So\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   25. Competência\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 6\n",
      "   26. Status de Homologação\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 3\n",
      "   27. Desc  Status\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 11\n",
      "   28. Icone\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 3\n",
      "   29. Status\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 25,807 (93.3%)\n",
      "       └─ Únicos: 10\n",
      "\n",
      "📊 PREVIEW DOS DADOS (primeiras 5 colunas)\n",
      "--------------------------------------------------------------------------------\n",
      "Nome do set Mês  Ano Centro Cód Grupo de produto\n",
      "        NaN  10 2025   5174     ETANOL_ADITIVADO\n",
      "        NaN  10 2025   5174   GASOLINA_ADITIVADA\n",
      "        NaN  10 2025   5174    GASOLINA_COMPOSTO\n",
      "\n",
      "💾 Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:01:48 | INFO     | Backup: SAP_YSMM_Limpo_20251015_110105.xlsx\n",
      "2025-10-15 11:01:48 | INFO     | Log detecção: deteccao_sap_20251015_110105.json\n",
      "2025-10-15 11:01:48 | INFO     | BLOCO 2 - Arquivo 1 (SAP) concluído\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Backup: SAP_YSMM_Limpo_20251015_110105.xlsx\n",
      "   ✅ Log detecção: deteccao_sap_20251015_110105.json\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                     ✅ ARQUIVO SAP CARREGADO COM SUCESSO                      ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 RESUMO DO CARREGAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   • Arquivo: 2025-2024-YSMM_VI_ACOMP.xlsx\n",
      "   • Registros: 27,655\n",
      "   • Colunas totais: 29\n",
      "   • Colunas mapeadas: 3\n",
      "   • Detecção automática: ✅ 100%\n",
      "   • Backup salvo: ✅\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "✅ BLOCO 2 - ARQUIVO 1 CONCLUÍDO\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📋 PRÓXIMOS PASSOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ✅ Revise a lista de colunas acima\n",
      "   2. ✅ Verifique se os dados fazem sentido\n",
      "   3. ✅ Confira a pasta 02_Dados_Entrada no Explorer\n",
      "   4. 📤 Envie feedback:\n",
      "       • 'ARQUIVO 1 OK' - para prosseguir\n",
      "       • Descreva problemas - se houver erros\n",
      "   5. ⏳ Aguarde BLOCO 3 (próximo arquivo)\n",
      "\n",
      "🔗 VARIÁVEIS DISPONÍVEIS:\n",
      "   • df_sap - DataFrame com dados SAP\n",
      "   • arquivo_sap_info - Metadados completos\n",
      "   • carregador_sap - Instância do carregador\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:02:04.249853Z",
     "start_time": "2025-10-15T14:01:59.241727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "AIVI DATA INTEGRATION - BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "Arquivo: ysmm_centros_br.xlsx\n",
    "Tipo: Tabela de Centros/Bases (Dados Complementares)\n",
    "\n",
    "LIMPEZA:\n",
    "  ✅ Primeira linha é o cabeçalho (usar header=0)\n",
    "  ✅ Sem colunas iniciais a expurgar\n",
    "\n",
    "FUNCIONALIDADES:\n",
    "  ✅ Carregamento robusto (.XLS/.XLSX)\n",
    "  ✅ Listagem completa de colunas\n",
    "  ✅ Preview dos dados\n",
    "  ✅ Backup automático\n",
    "  ✅ Logging\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2/N \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# FUNÇÃO: Carregar ysmm_centros_br.xlsx\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def carregar_ysmm_centros():\n",
    "    \"\"\"\n",
    "    Carrega arquivo ysmm_centros_br.xlsx (tabela de centros/bases).\n",
    "\n",
    "    Características:\n",
    "      - Primeira linha = cabeçalho\n",
    "      - Sem limpeza de colunas necessária\n",
    "      - Dados complementares para enriquecer base SAP\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ARQUIVO 2: ysmm_centros_br.xlsx (TABELA DE CENTROS) \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "    # ETAPA 1: Seleção do arquivo\n",
    "    # ══════════════════════════════════════════════════════════════════════\n",
    "\n",
    "    mensagem = \"\"\"\n",
    "╔═══════════════════════════════════════════════════╗\n",
    "║  📂 ARQUIVO: ysmm_centros_br.xlsx                 ║\n",
    "╠═══════════════════════════════════════════════════╣\n",
    "║                                                   ║\n",
    "║  Conteúdo: Cadastro de Centros/Bases              ║\n",
    "║  Uso: Enriquecimento dos dados SAP                ║\n",
    "║                                                   ║\n",
    "║  Campos esperados:                                ║\n",
    "║  • Centro (código)                                ║\n",
    "║  • Sigla                                          ║\n",
    "║  • Nome/Região                                    ║\n",
    "║  • Outros atributos da base                       ║\n",
    "║                                                   ║\n",
    "║  ⚠️  Primeira linha é o cabeçalho                 ║\n",
    "║                                                   ║\n",
    "╚═══════════════════════════════════════════════════╝\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Seleção GUI\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "        root.attributes('-alpha', 0.0)\n",
    "        root.update()\n",
    "\n",
    "        messagebox.showinfo(\n",
    "            \"[2/N] ysmm_centros_br.xlsx\",\n",
    "            mensagem.strip()\n",
    "        )\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"[2/N] Selecione ysmm_centros_br.xlsx\",\n",
    "            filetypes=[\n",
    "                (\"Excel files\", \"*.xlsx *.xls\"),\n",
    "                (\"All files\", \"*.*\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"❌ Nenhum arquivo selecionado\")\n",
    "\n",
    "        arquivo_path = Path(arquivo)\n",
    "\n",
    "        print(f\"✅ Arquivo selecionado:\")\n",
    "        print(f\"   📁 Nome: {arquivo_path.name}\")\n",
    "        print(f\"   📊 Tamanho: {arquivo_path.stat().st_size:,} bytes\")\n",
    "        print(f\"   🔧 Tipo: {arquivo_path.suffix}\")\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 2: Carregamento\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        extensao = arquivo_path.suffix.lower()\n",
    "\n",
    "        print(f\"📖 Carregando arquivo Excel ({extensao})...\")\n",
    "\n",
    "        # Tentar engines\n",
    "        if extensao == '.xlsx':\n",
    "            engines = ['openpyxl', None]\n",
    "        elif extensao == '.xls':\n",
    "            engines = ['xlrd', None]\n",
    "        else:\n",
    "            engines = [None, 'openpyxl', 'xlrd']\n",
    "\n",
    "        df = None\n",
    "        for i, engine in enumerate(engines, 1):\n",
    "            try:\n",
    "                if engine:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine='{engine}'\")\n",
    "                    df = pd.read_excel(arquivo_path, header=0, engine=engine)\n",
    "                else:\n",
    "                    print(f\"   Tentativa {i}/{len(engines)}: engine automático\")\n",
    "                    df = pd.read_excel(arquivo_path, header=0)\n",
    "\n",
    "                print(f\"   ✅ Sucesso! {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "                fm.logger.info(f\"Carregado: {arquivo_path.name} ({df.shape[0]} × {df.shape[1]})\")\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Falhou: {str(e)[:60]}...\")\n",
    "                if i == len(engines):\n",
    "                    if extensao == '.xls':\n",
    "                        print()\n",
    "                        print(\"💡 SOLUÇÃO para .XLS:\")\n",
    "                        print(\"   pip install xlrd\")\n",
    "                    raise Exception(f\"Falha ao ler: {e}\")\n",
    "\n",
    "        if df is None:\n",
    "            raise Exception(\"Nenhum engine funcionou\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 3: Limpeza (não necessária para este arquivo)\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"🧹 Limpeza de dados...\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   ✅ Nenhuma limpeza necessária (primeira linha = cabeçalho)\")\n",
    "        print(f\"   📊 Dados prontos: {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 4: Listar todas as colunas\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"📑 LISTAGEM COMPLETA DE COLUNAS\")\n",
    "        print(\"═\" * 80)\n",
    "        print(f\"📏 Total: {len(df.columns)} colunas\")\n",
    "        print()\n",
    "\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            tipo = df[col].dtype\n",
    "            nulos = df[col].isna().sum()\n",
    "            pct_nulos = (nulos / len(df) * 100) if len(df) > 0 else 0\n",
    "            unicos = df[col].nunique()\n",
    "\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       ├─ Tipo: {tipo}\")\n",
    "            print(f\"       ├─ Nulos: {nulos:,} ({pct_nulos:.1f}%)\")\n",
    "            print(f\"       └─ Únicos: {unicos:,}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 5: Preview dos dados\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"📊 PREVIEW DOS DADOS (primeiras 5 colunas)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        colunas_preview = list(df.columns[:5])\n",
    "        print(df[colunas_preview].head(5).to_string(index=False))\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # ETAPA 6: Backup\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"💾 Salvando backup...\")\n",
    "\n",
    "        timestamp = fm.timestamp\n",
    "        arquivo_destino = fm.diretorios['dados_entrada'] / \\\n",
    "                         f\"Centros_BR_{timestamp}.xlsx\"\n",
    "\n",
    "        try:\n",
    "            df.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "            fm.logger.info(f\"Backup: {arquivo_destino.name}\")\n",
    "            print(f\"   ✅ Backup salvo: {arquivo_destino.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Erro ao salvar backup: {str(e)}\")\n",
    "            fm.logger.error(f\"Erro backup: {str(e)}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "        # RESULTADO FINAL\n",
    "        # ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ✅ ARQUIVO CENTROS CARREGADO COM SUCESSO \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "\n",
    "        print(\"📊 RESUMO DO CARREGAMENTO:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"   • Arquivo: {arquivo_path.name}\")\n",
    "        print(f\"   • Registros: {len(df):,}\")\n",
    "        print(f\"   • Colunas: {len(df.columns)}\")\n",
    "        print(f\"   • Backup: ✅\")\n",
    "        print()\n",
    "\n",
    "        return df, arquivo_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "        print(\"║\" + \" ❌ ERRO AO CARREGAR ARQUIVO \".center(78) + \"║\")\n",
    "        print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "        print()\n",
    "        print(f\"❌ Erro: {str(e)}\")\n",
    "        print()\n",
    "\n",
    "        import traceback\n",
    "        print(\"🔍 Detalhes técnicos:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "        fm.logger.error(f\"Erro centros: {str(e)}\")\n",
    "\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "# EXECUÇÃO: CARREGAR ARQUIVO 2\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print()\n",
    "print(\"⚠️  INSTRUÇÕES:\")\n",
    "print(\"   • Janela de seleção vai abrir\")\n",
    "print(\"   • Selecione o arquivo ysmm_centros_br.xlsx\")\n",
    "print(\"   • Primeira linha deve ser o cabeçalho\")\n",
    "print()\n",
    "\n",
    "input(\"👉 Pressione ENTER para iniciar...\")\n",
    "\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Carregar arquivo\n",
    "    df_centros, arquivo_centros = carregar_ysmm_centros()\n",
    "\n",
    "    if df_centros is not None:\n",
    "        # Salvar referência global\n",
    "        arquivo_centros_info = {\n",
    "            'df': df_centros,\n",
    "            'arquivo': arquivo_centros\n",
    "        }\n",
    "\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"✅ BLOCO 3 - ARQUIVO 2 CONCLUÍDO\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(\"📋 PRÓXIMOS PASSOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"   1. ✅ Revise a lista de colunas acima\")\n",
    "        print(\"   2. ✅ Verifique se os dados fazem sentido\")\n",
    "        print(\"   3. 📤 Envie feedback:\")\n",
    "        print(\"       • 'ARQUIVO 2 OK' - para prosseguir\")\n",
    "        print(\"       • Descreva problemas - se houver erros\")\n",
    "        print(\"   4. ⏳ Aguarde próximo arquivo\")\n",
    "        print()\n",
    "        print(\"🔗 VARIÁVEIS DISPONÍVEIS:\")\n",
    "        print(\"   • df_centros - DataFrame com cadastro de centros\")\n",
    "        print(\"   • arquivo_centros_info - Metadados completos\")\n",
    "        print()\n",
    "\n",
    "        fm.logger.info(\"BLOCO 3 - Arquivo 2 (Centros) concluído\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print(\"⚠️  Operação cancelada pelo usuário\")\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    print(\"║\" + \" ERRO FATAL - BLOCO 3 \".center(78) + \"║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    print()\n",
    "    print(f\"❌ Erro: {str(e)}\")\n",
    "    print()\n",
    "    import traceback\n",
    "    print(\"🔍 Detalhes técnicos:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print()\n",
    "print(\"═\" * 80)"
   ],
   "id": "232087a72dbd916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                  BLOCO 3: CARREGADOR MODULAR - ARQUIVO 2/N                   ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "⚠️  INSTRUÇÕES:\n",
      "   • Janela de seleção vai abrir\n",
      "   • Selecione o arquivo ysmm_centros_br.xlsx\n",
      "   • Primeira linha deve ser o cabeçalho\n",
      "\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║             ARQUIVO 2: ysmm_centros_br.xlsx (TABELA DE CENTROS)              ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:02:04 | INFO     | Carregado: ysmm_centros_br.xlsx (555 × 30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo selecionado:\n",
      "   📁 Nome: ysmm_centros_br.xlsx\n",
      "   📊 Tamanho: 117,411 bytes\n",
      "   🔧 Tipo: .xlsx\n",
      "\n",
      "📖 Carregando arquivo Excel (.xlsx)...\n",
      "   Tentativa 1/2: engine='openpyxl'\n",
      "   ✅ Sucesso! 555 linhas × 30 colunas\n",
      "\n",
      "🧹 Limpeza de dados...\n",
      "--------------------------------------------------------------------------------\n",
      "   ✅ Nenhuma limpeza necessária (primeira linha = cabeçalho)\n",
      "   📊 Dados prontos: 555 linhas × 30 colunas\n",
      "\n",
      "📑 LISTAGEM COMPLETA DE COLUNAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📏 Total: 30 colunas\n",
      "\n",
      "    1. Centro\n",
      "       ├─ Tipo: int64\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 555\n",
      "    2. Sigla\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 499\n",
      "    3. Regional/Região\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 463 (83.4%)\n",
      "       └─ Únicos: 5\n",
      "    4. Nome 1\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 550\n",
      "    5. Rua\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 485\n",
      "    6. Número\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 5 (0.9%)\n",
      "       └─ Únicos: 201\n",
      "    7. Compl\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 484 (87.2%)\n",
      "       └─ Únicos: 61\n",
      "    8. Bairro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 41 (7.4%)\n",
      "       └─ Únicos: 318\n",
      "    9. Local.Resd.Difer.\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 507 (91.4%)\n",
      "       └─ Únicos: 39\n",
      "   10. Código Postal\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 432\n",
      "   11. Cidade\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 2 (0.4%)\n",
      "       └─ Únicos: 210\n",
      "   12. Estado\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 27\n",
      "   13. Filial\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 247 (44.5%)\n",
      "       └─ Únicos: 259\n",
      "   14. CNPJ\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 143 (25.8%)\n",
      "       └─ Únicos: 354\n",
      "   15. Inscrição Estadual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 183 (33.0%)\n",
      "       └─ Únicos: 316\n",
      "   16. Inscrição Municipal\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 224 (40.4%)\n",
      "       └─ Únicos: 287\n",
      "   17. NIRE\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 333 (60.0%)\n",
      "       └─ Únicos: 219\n",
      "   18. ICAO\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 238 (42.9%)\n",
      "       └─ Únicos: 216\n",
      "   19. IATA\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 315 (56.8%)\n",
      "       └─ Únicos: 150\n",
      "   20. Centro Virtual\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 247 (44.5%)\n",
      "       └─ Únicos: 2\n",
      "   21. Centro Inativo\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   22. Centro Fornecedor\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 2\n",
      "   23. Longitude\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 379 (68.3%)\n",
      "       └─ Únicos: 163\n",
      "   24. Latitude\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 379 (68.3%)\n",
      "       └─ Únicos: 163\n",
      "   25. Centro de Custo\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 30 (5.4%)\n",
      "       └─ Únicos: 345\n",
      "   26. Centro de Lucro\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 30 (5.4%)\n",
      "       └─ Únicos: 341\n",
      "   27. Cliente Centro\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 290 (52.3%)\n",
      "       └─ Únicos: 265\n",
      "   28. Fornecedor Centro\n",
      "       ├─ Tipo: float64\n",
      "       ├─ Nulos: 264 (47.6%)\n",
      "       └─ Únicos: 291\n",
      "   29. Endereço\n",
      "       ├─ Tipo: int64\n",
      "       ├─ Nulos: 0 (0.0%)\n",
      "       └─ Únicos: 555\n",
      "   30. Agrpmto.estrut.reg.\n",
      "       ├─ Tipo: object\n",
      "       ├─ Nulos: 48 (8.6%)\n",
      "       └─ Únicos: 10\n",
      "\n",
      "📊 PREVIEW DOS DADOS (primeiras 5 colunas)\n",
      "--------------------------------------------------------------------------------\n",
      " Centro         Sigla Regional/Região                       Nome 1                       Rua\n",
      "      1        Centro             NaN                  Centro 0001       RUA CORREIA VASQUES\n",
      "      2        Centro             NaN      Centro 0002 - padrão PS                       NaN\n",
      "   5001 Administração             NaN Administração Central  VIBRA       RUA CORREIA VASQUES\n",
      "   5002      exDISGUA             NaN  exDISGUA Antiga Regional RJ Pça Vinte e Dois de Abril\n",
      "   5003         UNISP             NaN      UNISP - UNIDADE ADM. SP                 R Funchal\n",
      "\n",
      "💾 Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:02:04 | INFO     | Backup: Centros_BR_20251015_110105.xlsx\n",
      "2025-10-15 11:02:04 | INFO     | BLOCO 3 - Arquivo 2 (Centros) concluído\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Backup salvo: Centros_BR_20251015_110105.xlsx\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                   ✅ ARQUIVO CENTROS CARREGADO COM SUCESSO                    ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 RESUMO DO CARREGAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   • Arquivo: ysmm_centros_br.xlsx\n",
      "   • Registros: 555\n",
      "   • Colunas: 30\n",
      "   • Backup: ✅\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "✅ BLOCO 3 - ARQUIVO 2 CONCLUÍDO\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "📋 PRÓXIMOS PASSOS:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ✅ Revise a lista de colunas acima\n",
      "   2. ✅ Verifique se os dados fazem sentido\n",
      "   3. 📤 Envie feedback:\n",
      "       • 'ARQUIVO 2 OK' - para prosseguir\n",
      "       • Descreva problemas - se houver erros\n",
      "   4. ⏳ Aguarde próximo arquivo\n",
      "\n",
      "🔗 VARIÁVEIS DISPONÍVEIS:\n",
      "   • df_centros - DataFrame com cadastro de centros\n",
      "   • arquivo_centros_info - Metadados completos\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:02:15.585108Z",
     "start_time": "2025-10-15T18:02:14.712700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "BLOCO 4: CARREGADOR AIVI OPAV BW - CORRIGIDO v3\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "Sheet correto: \"Valor da Variação Total\"\n",
    "Cabeçalho: L34-AM34 (APENAS, colunas AW-BH descartadas)\n",
    "Resultado: 28 colunas (7 dimensões + 21 movimentações)\n",
    "Tratamento dinâmico de duplicadas: sufixo _dup1, _dup2, etc\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"BLOCO 4: CARREGADOR AIVI OPAV BW - ARQUIVO 3/N\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1: Seleção do arquivo\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'fm' in dir():\n",
    "    padrao_bw = '*xSAPtemp*.xls*'\n",
    "    arquivos_encontrados = list(fm.diretorios['dados_entrada'].glob(padrao_bw))\n",
    "\n",
    "    if arquivos_encontrados:\n",
    "        arquivo_path = arquivos_encontrados[0]\n",
    "        print(f\"Arquivo encontrado: {arquivo_path.name}\")\n",
    "    else:\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"Selecione arquivo BW (xSAPtemp...)\",\n",
    "            filetypes=[(\"Excel\", \"*.xls *.xlsx\"), (\"All\", \"*.*\")]\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"Nenhum arquivo selecionado\")\n",
    "\n",
    "        arquivo_path = Path(arquivo)\n",
    "else:\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.lift()\n",
    "    root.attributes('-topmost', True)\n",
    "\n",
    "    arquivo = filedialog.askopenfilename(\n",
    "        title=\"Selecione arquivo BW (xSAPtemp...)\",\n",
    "        filetypes=[(\"Excel\", \"*.xls *.xlsx\"), (\"All\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    root.destroy()\n",
    "\n",
    "    if not arquivo:\n",
    "        raise ValueError(\"Nenhum arquivo selecionado\")\n",
    "\n",
    "    arquivo_path = Path(arquivo)\n",
    "\n",
    "print(f\"Arquivo selecionado: {arquivo_path.name}\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 2: Carregar SHEET CORRETO\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 2: Carregando sheet correto...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Nome do sheet correto\n",
    "SHEET_NAME = \"Valor da Variação Total\"\n",
    "\n",
    "try:\n",
    "    # Método 1: xlrd (mais confiável para .xls)\n",
    "    print(f\"Tentando xlrd (sheet: '{SHEET_NAME}')...\")\n",
    "\n",
    "    workbook = xlrd.open_workbook(str(arquivo_path))\n",
    "\n",
    "    # Listar sheets\n",
    "    print(f\"   Sheets disponiveis: {workbook.sheet_names()}\")\n",
    "\n",
    "    # Verificar se sheet existe\n",
    "    if SHEET_NAME not in workbook.sheet_names():\n",
    "        raise ValueError(f\"Sheet '{SHEET_NAME}' nao encontrado!\")\n",
    "\n",
    "    # Pegar sheet correto\n",
    "    sheet = workbook.sheet_by_name(SHEET_NAME)\n",
    "\n",
    "    print(f\"   Sheet: '{SHEET_NAME}'\")\n",
    "    print(f\"   Linhas: {sheet.nrows:,}\")\n",
    "    print(f\"   Colunas: {sheet.ncols}\")\n",
    "\n",
    "    # Converter para lista de listas\n",
    "    data = []\n",
    "    for row_idx in range(sheet.nrows):\n",
    "        data.append(sheet.row_values(row_idx))\n",
    "\n",
    "    # Criar DataFrame\n",
    "    df_bruto = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"   DataFrame criado: {df_bruto.shape[0]:,} x {df_bruto.shape[1]}\")\n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   Erro com xlrd: {str(e)}\")\n",
    "    print()\n",
    "\n",
    "    # Método 2: pandas como fallback\n",
    "    print(f\"Tentando pandas (sheet: '{SHEET_NAME}')...\")\n",
    "\n",
    "    df_bruto = pd.read_excel(\n",
    "        arquivo_path,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "    print(f\"   DataFrame criado: {df_bruto.shape[0]:,} x {df_bruto.shape[1]}\")\n",
    "    print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 3: VERIFICAR LINHA 34 (índice 33)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 3: Verificando linha 34 (cabecalho)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Linha 34 Excel = índice 33 pandas\n",
    "linha_34 = df_bruto.iloc[33]\n",
    "\n",
    "# Verificar colunas L-BH (índices 11-59)\n",
    "cols_lbh = linha_34.iloc[11:60]\n",
    "\n",
    "# Contar não-nulas\n",
    "non_null = cols_lbh.notna().sum()\n",
    "print(f\"   Celulas nao-nulas em L34-BH34: {non_null}/49\")\n",
    "\n",
    "# Mostrar primeiras não-nulas\n",
    "print(f\"   Primeiros valores nao-nulos:\")\n",
    "count = 0\n",
    "for i, val in enumerate(cols_lbh):\n",
    "    if pd.notna(val) and count < 10:\n",
    "        col_idx = 11 + i\n",
    "        # Nome da coluna (L=11, M=12, etc)\n",
    "        if col_idx < 26:\n",
    "            col_name = chr(65 + col_idx)\n",
    "        else:\n",
    "            col_name = chr(65 + (col_idx // 26) - 1) + chr(65 + (col_idx % 26))\n",
    "\n",
    "        val_str = str(val)[:30]\n",
    "        print(f\"      {col_name}34 (idx={col_idx}): '{val_str}'\")\n",
    "        count += 1\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 4: EXTRAIR CABEÇALHO CORRETO\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 4: Extraindo cabecalho das colunas especificas...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Linha 34 Excel = índice 33\n",
    "linha_cabecalho = df_bruto.iloc[33]\n",
    "\n",
    "# APENAS PARTE 1: Colunas L-AM (índices 11-38)\n",
    "# L=11, M=12, ..., AM=38 (28 colunas)\n",
    "cabecalho_bruto = linha_cabecalho.iloc[11:39].tolist()\n",
    "\n",
    "print(f\"   COLUNAS EXTRAIDAS (L34-AM34): {len(cabecalho_bruto)} colunas\")\n",
    "print()\n",
    "\n",
    "# Limpar nomes\n",
    "cabecalho_temp = []\n",
    "for i, nome in enumerate(cabecalho_bruto):\n",
    "    if pd.isna(nome) or str(nome).strip() == '':\n",
    "        nome_limpo = f'Col_{i}'\n",
    "    else:\n",
    "        # Remover apóstrofo inicial se existir\n",
    "        nome_str = str(nome).strip()\n",
    "        if nome_str.startswith(\"'\"):\n",
    "            nome_str = nome_str[1:]\n",
    "        # Remover quebras de linha\n",
    "        nome_str = nome_str.replace('\\n', ' ')\n",
    "        nome_limpo = nome_str\n",
    "    cabecalho_temp.append(nome_limpo)\n",
    "\n",
    "# Tratar duplicadas (adicionar sufixo _dup1, _dup2, etc)\n",
    "from collections import Counter\n",
    "\n",
    "contagem = Counter(cabecalho_temp)\n",
    "duplicadas = {nome: count for nome, count in contagem.items() if count > 1}\n",
    "\n",
    "if duplicadas:\n",
    "    print(f\"   AVISO: {len(duplicadas)} nomes duplicados encontrados\")\n",
    "    for nome, count in list(duplicadas.items())[:5]:\n",
    "        print(f\"      '{nome}': {count} ocorrencias\")\n",
    "    print()\n",
    "\n",
    "# Renomear duplicadas\n",
    "cabecalho_limpo = []\n",
    "contador = {}\n",
    "\n",
    "for nome in cabecalho_temp:\n",
    "    if nome in contador:\n",
    "        contador[nome] += 1\n",
    "        novo_nome = f\"{nome}_dup{contador[nome]}\"\n",
    "        cabecalho_limpo.append(novo_nome)\n",
    "    else:\n",
    "        contador[nome] = 0\n",
    "        cabecalho_limpo.append(nome)\n",
    "\n",
    "# Mostrar cabeçalho final\n",
    "print(\"   Cabecalho final:\")\n",
    "for i, nome in enumerate(cabecalho_limpo[:10], 1):\n",
    "    print(f\"      A{i if i <= 9 else str(i)}: {nome}\")\n",
    "if len(cabecalho_limpo) > 10:\n",
    "    print(f\"      ... (mais {len(cabecalho_limpo) - 10} colunas)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 5: EXTRAIR DADOS (linhas após linha 34)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 5: Extraindo dados...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Dados começam na linha 35 (índice 34)\n",
    "linha_inicio_dados = 34\n",
    "\n",
    "# Extrair APENAS colunas L-AM (índices 11-38)\n",
    "df_final = df_bruto.iloc[linha_inicio_dados:, 11:39].copy()\n",
    "\n",
    "# Aplicar cabeçalho\n",
    "df_final.columns = cabecalho_limpo\n",
    "\n",
    "# Reset index\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "print(f\"   Registros: {len(df_final):,}\")\n",
    "print(f\"   Colunas: {len(df_final.columns)}\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 6: CONVERTER DIMENSÕES PARA STRING\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 6: Convertendo dimensoes para STRING...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Primeiras 7 colunas = dimensões\n",
    "dimensoes_cols = df_final.columns[:7].tolist()\n",
    "\n",
    "for col in dimensoes_cols:\n",
    "    if col in df_final.columns:\n",
    "        df_final[col] = df_final[col].astype(str)\n",
    "        print(f\"   '{col}' -> STRING\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 7: PREVIEW DOS DADOS\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 7: PREVIEW DOS DADOS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Primeiras 7 colunas (DIMENSOES):\")\n",
    "print(df_final.iloc[:, :7].head(5).to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Primeiras 5 linhas completas:\")\n",
    "print(df_final.head(5).to_string(index=False, max_colwidth=20))\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 8: ESTATÍSTICAS DAS COLUNAS\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 8: ESTATISTICAS DAS COLUNAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, col in enumerate(df_final.columns, 1):\n",
    "    # Tratar caso de coluna duplicada (retorna DataFrame)\n",
    "    try:\n",
    "        col_serie = df_final[col]\n",
    "\n",
    "        # Se retornar DataFrame (duplicada), pegar primeira coluna\n",
    "        if isinstance(col_serie, pd.DataFrame):\n",
    "            col_serie = col_serie.iloc[:, 0]\n",
    "\n",
    "        tipo = col_serie.dtype\n",
    "        nulos = col_serie.isna().sum()\n",
    "        pct_nulos = (nulos / len(df_final) * 100) if len(df_final) > 0 else 0\n",
    "        unicos = col_serie.nunique()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback se der erro\n",
    "        tipo = \"unknown\"\n",
    "        nulos = 0\n",
    "        pct_nulos = 0.0\n",
    "        unicos = 0\n",
    "        print(f\"   AVISO: Erro ao analisar coluna '{col}': {str(e)[:50]}\")\n",
    "\n",
    "    # Identificar bloco\n",
    "    if i <= 7:\n",
    "        bloco = \"DIMENSAO\"\n",
    "    elif i <= 28:\n",
    "        bloco = \"MOVIM_BLK1\"\n",
    "    else:\n",
    "        bloco = \"MOVIM_BLK2\"\n",
    "\n",
    "    print(f\"   {i:2d}. {col[:30]}\")\n",
    "    print(f\"       Bloco: {bloco} | Tipo: {tipo} | Nulos: {pct_nulos:.1f}% | Unicos: {unicos:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 9: SALVAR BACKUP\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 9: Salvando backup...\")\n",
    "\n",
    "if 'fm' in dir():\n",
    "    timestamp = fm.timestamp\n",
    "    arquivo_destino = fm.diretorios['dados_entrada'] / f\"AIVI_OPAV_BW_{timestamp}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        df_final.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "        fm.logger.info(f\"Backup BW: {arquivo_destino.name}\")\n",
    "        print(f\"   Backup: {arquivo_destino.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Erro ao salvar: {str(e)}\")\n",
    "        fm.logger.error(f\"Erro backup BW: {str(e)}\")\n",
    "else:\n",
    "    print(\"   FileManager nao disponivel - backup ignorado\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ARQUIVO BW CARREGADO E PROCESSADO COM SUCESSO\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"RESUMO DO PROCESSAMENTO:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   Arquivo: {arquivo_path.name}\")\n",
    "print(f\"   Sheet: {SHEET_NAME}\")\n",
    "print(f\"   Registros: {len(df_final):,}\")\n",
    "print(f\"   Colunas totais: {len(df_final.columns)}\")\n",
    "print(f\"   Dimensoes (1-7): 7\")\n",
    "print(f\"   Movimentacoes (8-{len(df_final.columns)}): {len(df_final.columns) - 7}\")\n",
    "print()\n",
    "\n",
    "# Salvar na variável global\n",
    "df_opav = df_final\n",
    "arquivo_opav = arquivo_path\n",
    "\n",
    "print(\"VARIAVEIS DISPONIVEIS:\")\n",
    "print(\"   df_opav - DataFrame BW processado\")\n",
    "print(\"   arquivo_opav - Path do arquivo\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FIM BLOCO 4\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "fc881bbc1ead00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOCO 4: CARREGADOR AIVI OPAV BW - ARQUIVO 3/N\n",
      "================================================================================\n",
      "\n",
      "Arquivo encontrado: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "Arquivo selecionado: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "\n",
      "ETAPA 2: Carregando sheet correto...\n",
      "--------------------------------------------------------------------------------\n",
      "Tentando xlrd (sheet: 'Valor da Variação Total')...\n",
      "   Sheets disponiveis: ['SAPBEXqueriesDefunct', 'SAPBEXfiltersDefunct', 'Valor da Variação Total', 'Valor da Variação Total Grupo', 'Limite Técnico', 'Justificar', 'Limite Técnico Grupo', 'BExRepositorySheet', 'Justificar Grupo', 'Custo do Produto', 'Imposto']\n",
      "   Sheet: 'Valor da Variação Total'\n",
      "   Linhas: 1,001\n",
      "   Colunas: 60\n",
      "   DataFrame criado: 1,001 x 60\n",
      "\n",
      "ETAPA 3: Verificando linha 34 (cabecalho)...\n",
      "--------------------------------------------------------------------------------\n",
      "   Celulas nao-nulas em L34-BH34: 49/49\n",
      "   Primeiros valores nao-nulos:\n",
      "      L34 (idx=11): 'Centro de lucro'\n",
      "      M34 (idx=12): 'Ano civil/mês'\n",
      "      N34 (idx=13): 'Centro'\n",
      "      O34 (idx=14): ''\n",
      "      P34 (idx=15): 'HierarqPrd'\n",
      "      Q34 (idx=16): 'Produto'\n",
      "      R34 (idx=17): ''\n",
      "      S34 (idx=18): 'Estoque\n",
      "Inicial'\n",
      "      T34 (idx=19): 'Entrada'\n",
      "      U34 (idx=20): 'Variação\n",
      "Externa'\n",
      "\n",
      "ETAPA 4: Extraindo cabecalho das colunas especificas...\n",
      "--------------------------------------------------------------------------------\n",
      "   COLUNAS EXTRAIDAS (L34-AM34): 28 colunas\n",
      "\n",
      "   Cabecalho final:\n",
      "      A1: Centro de lucro\n",
      "      A2: Ano civil/mês\n",
      "      A3: Centro\n",
      "      A4: Col_3\n",
      "      A5: HierarqPrd\n",
      "      A6: Produto\n",
      "      A7: Col_6\n",
      "      A8: Estoque Inicial\n",
      "      A9: Entrada\n",
      "      A10: Variação Externa\n",
      "      ... (mais 18 colunas)\n",
      "\n",
      "ETAPA 5: Extraindo dados...\n",
      "--------------------------------------------------------------------------------\n",
      "   Registros: 967\n",
      "   Colunas: 28\n",
      "\n",
      "ETAPA 6: Convertendo dimensoes para STRING...\n",
      "--------------------------------------------------------------------------------\n",
      "   'Centro de lucro' -> STRING\n",
      "   'Ano civil/mês' -> STRING\n",
      "   'Centro' -> STRING\n",
      "   'Col_3' -> STRING\n",
      "   'HierarqPrd' -> STRING\n",
      "   'Produto' -> STRING\n",
      "   'Col_6' -> STRING\n",
      "\n",
      "ETAPA 7: PREVIEW DOS DADOS\n",
      "--------------------------------------------------------------------------------\n",
      "Primeiras 7 colunas (DIMENSOES):\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                      Col_6\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422    JET A NAO TABELADO - LI\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACIONAL I - LI\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078           GASOLINA COMUM C\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "\n",
      "Primeiras 5 linhas completas:\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                Col_6 Estoque Inicial    Entrada Variação Externa Variação Externa % Variação Interna Variação Interna % Variação Total Variação Total % Custo Unitário do Produto  Imposto Valor da Variação Interna Col_18 Quantidade Excedente da Variação Externa Valor Excedente da Variação Externa (R$) Quantidade Excedente da Variação Interna Valor Excedente da Variação Interna (R$) Quantidade Excedente da Variação Total Valor Excedente da Variação Total (R$) Valor Excedente da Variação Total + Imposto (R$) Competência para Absorção da Variação Total Excedente (R$) Competência para Absorção da Variação Total Excedente (R$) com LM e N4\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674    ÓLEO DIESEL B S10         16924.0                                                            18.0           0.106358           18.0         0.106358             5.300122           0.0            95.402202                              0.0                                      0.0                                    10.19                                54.008246                                    10.19                                  54.01                                  54.01                                               N3                                                         LM                                                  \n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422 JET A NAO TABELAD...        373850.0   939139.0            824.0            0.08774            -10.0          -0.000762          814.0         0.036144             3.890482      -2811.15           -38.904816                           366.22                              1424.772156                                      0.0                                      0.0                                      0.0                                    0.0                                2811.15                                                -                                                          -                                                  \n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACION...        598315.0  5188210.0           1494.0           0.028796                                             1494.0         0.013613             3.882566           0.0                  0.0                              0.0                                      0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                                -                                                          -                                                  \n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078     GASOLINA COMUM C         13076.0    14828.0              5.0            0.03372            234.0           0.838589          239.0           0.5593             5.133078           0.0          1201.140348                              0.0                                      0.0                                   220.33                              1130.971166                                   220.33                                1130.97                                1130.97                                               N3                                                         LM                                                  \n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674    ÓLEO DIESEL B S10        122306.0   178128.0            -17.0          -0.009544           -382.0          -0.127149         -399.0        -0.083375             5.331511           0.0         -2036.637033                              0.0                                      0.0                                  -240.63                             -1282.921386                                  -240.63                               -1282.92                               -1282.92                                               N3                                                         LM                                                  \n",
      "\n",
      "ETAPA 8: ESTATISTICAS DAS COLUNAS\n",
      "--------------------------------------------------------------------------------\n",
      "    1. Centro de lucro\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 2\n",
      "    2. Ano civil/mês\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 2\n",
      "    3. Centro\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 89\n",
      "    4. Col_3\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 89\n",
      "    5. HierarqPrd\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 5\n",
      "    6. Produto\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 15\n",
      "    7. Col_6\n",
      "       Bloco: DIMENSAO | Tipo: object | Nulos: 0.0% | Unicos: 15\n",
      "    8. Estoque Inicial\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 183\n",
      "    9. Entrada\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 122\n",
      "   10. Variação Externa\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 104\n",
      "   11. Variação Externa %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 110\n",
      "   12. Variação Interna\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 98\n",
      "   13. Variação Interna %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 97\n",
      "   14. Variação Total\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 121\n",
      "   15. Variação Total %\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 121\n",
      "   16. Custo Unitário do Produto\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 124\n",
      "   17. Imposto\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 29\n",
      "   18. Valor da Variação Interna\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 100\n",
      "   19. Col_18\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 1\n",
      "   20. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 43\n",
      "   21. Valor Excedente da Variação Ex\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 43\n",
      "   22. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   23. Valor Excedente da Variação In\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   24. Quantidade Excedente da Variaç\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   25. Valor Excedente da Variação To\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 23\n",
      "   26. Valor Excedente da Variação To\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 49\n",
      "   27. Competência para Absorção da V\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 3\n",
      "   28. Competência para Absorção da V\n",
      "       Bloco: MOVIM_BLK1 | Tipo: object | Nulos: 0.0% | Unicos: 4\n",
      "\n",
      "ETAPA 9: Salvando backup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 15:02:15 | INFO     | Backup BW: AIVI_OPAV_BW_20251015_110105.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Backup: AIVI_OPAV_BW_20251015_110105.xlsx\n",
      "\n",
      "================================================================================\n",
      "ARQUIVO BW CARREGADO E PROCESSADO COM SUCESSO\n",
      "================================================================================\n",
      "\n",
      "RESUMO DO PROCESSAMENTO:\n",
      "--------------------------------------------------------------------------------\n",
      "   Arquivo: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   Sheet: Valor da Variação Total\n",
      "   Registros: 967\n",
      "   Colunas totais: 28\n",
      "   Dimensoes (1-7): 7\n",
      "   Movimentacoes (8-28): 21\n",
      "\n",
      "VARIAVEIS DISPONIVEIS:\n",
      "   df_opav - DataFrame BW processado\n",
      "   arquivo_opav - Path do arquivo\n",
      "\n",
      "================================================================================\n",
      "FIM BLOCO 4\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:33:04.046925Z",
     "start_time": "2025-10-15T14:33:00.270907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW\n",
    "═══════════════════════════════════════════════════════════════════\n",
    "Busca recursiva: *xSAPtemp*.xls* em pasta e subpastas\n",
    "Carrega cada arquivo com mesmo padrão do BLOCO 4\n",
    "Unifica tudo em um único DataFrame\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# CONFIGURAÇÕES\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "SHEET_NAME = \"Valor da Variação Total\"\n",
    "LINHA_CABECALHO = 33  # Linha 34 do Excel\n",
    "LINHA_INICIO_DADOS = 34\n",
    "\n",
    "# Colunas a extrair (APENAS L-AM, 28 colunas)\n",
    "COLS_EXTRAIR = (11, 39)  # L-AM (índices 11-38)\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# FUNÇÕES AUXILIARES (do BLOCO 4)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "def limpar_nome_coluna(nome):\n",
    "    \"\"\"\n",
    "    Limpa nome de coluna de caracteres especiais\n",
    "    \"\"\"\n",
    "    if pd.isna(nome) or str(nome).strip() == '':\n",
    "        return None\n",
    "\n",
    "    nome_str = str(nome).strip()\n",
    "    nome_str = nome_str.lstrip(\"'\")\n",
    "    nome_str = nome_str.replace('\\n', ' ')\n",
    "    nome_str = nome_str.replace('\\r', ' ')\n",
    "    nome_str = ' '.join(nome_str.split())\n",
    "\n",
    "    return nome_str\n",
    "\n",
    "def tratar_duplicadas(colunas):\n",
    "    \"\"\"\n",
    "    Adiciona sufixo _dup1, _dup2 às duplicadas\n",
    "    \"\"\"\n",
    "    contagem = Counter(colunas)\n",
    "    duplicadas = {n: c for n, c in contagem.items() if c > 1}\n",
    "\n",
    "    if duplicadas:\n",
    "        print(f\"   AVISO: {len(duplicadas)} nomes duplicados\")\n",
    "        for nome, count in list(duplicadas.items())[:3]:\n",
    "            print(f\"      '{nome}': {count} ocorrencias\")\n",
    "\n",
    "    colunas_novas = []\n",
    "    contador = {}\n",
    "\n",
    "    for nome in colunas:\n",
    "        if nome in contador:\n",
    "            contador[nome] += 1\n",
    "            colunas_novas.append(f\"{nome}_dup{contador[nome]}\")\n",
    "        else:\n",
    "            contador[nome] = 0\n",
    "            colunas_novas.append(nome)\n",
    "\n",
    "    return colunas_novas\n",
    "\n",
    "def carregar_arquivo_opav(arquivo_path):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo OPAV seguindo padrão do BLOCO 4\n",
    "\n",
    "    Retorna: DataFrame ou None se erro\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\n📄 Processando: {arquivo_path.name}\")\n",
    "        print(\"   \" + \"-\" * 76)\n",
    "\n",
    "        # Carregar com xlrd\n",
    "        workbook = xlrd.open_workbook(str(arquivo_path))\n",
    "\n",
    "        # Verificar sheet\n",
    "        if SHEET_NAME not in workbook.sheet_names():\n",
    "            print(f\"   ❌ Sheet '{SHEET_NAME}' nao encontrado\")\n",
    "            print(f\"   Sheets disponiveis: {workbook.sheet_names()}\")\n",
    "            return None\n",
    "\n",
    "        sheet = workbook.sheet_by_name(SHEET_NAME)\n",
    "        print(f\"   ✅ Sheet: '{SHEET_NAME}' ({sheet.nrows} linhas × {sheet.ncols} cols)\")\n",
    "\n",
    "        # Converter para DataFrame\n",
    "        data = [sheet.row_values(i) for i in range(sheet.nrows)]\n",
    "        df_bruto = pd.DataFrame(data)\n",
    "\n",
    "        # Extrair cabeçalho (APENAS L-AM)\n",
    "        linha_cab = df_bruto.iloc[LINHA_CABECALHO]\n",
    "        cab_bruto = linha_cab.iloc[COLS_EXTRAIR[0]:COLS_EXTRAIR[1]].tolist()\n",
    "\n",
    "        # Limpar cabeçalho\n",
    "        cab_temp = [limpar_nome_coluna(c) or f'Col_{i}'\n",
    "                    for i, c in enumerate(cab_bruto)]\n",
    "\n",
    "        # Tratar duplicadas\n",
    "        cab_final = tratar_duplicadas(cab_temp)\n",
    "\n",
    "        # Extrair dados (APENAS L-AM)\n",
    "        df_final = df_bruto.iloc[LINHA_INICIO_DADOS:, COLS_EXTRAIR[0]:COLS_EXTRAIR[1]].copy()\n",
    "\n",
    "        df_final.columns = cab_final\n",
    "        df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "        # Adicionar metadados\n",
    "        df_final['_arquivo_origem'] = arquivo_path.name\n",
    "        df_final['_arquivo_path'] = str(arquivo_path)\n",
    "        df_final['_data_carga'] = pd.Timestamp.now()\n",
    "\n",
    "        print(f\"   ✅ Carregado: {len(df_final):,} registros × {len(cab_final)} colunas\")\n",
    "\n",
    "        return df_final\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ ERRO: {str(e)[:100]}\")\n",
    "        import traceback\n",
    "        print(f\"   Detalhes: {traceback.format_exc()[:200]}\")\n",
    "        return None\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1: Determinar pasta base\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 1: Determinar pasta com arquivos OPAV\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "pasta_base = None\n",
    "\n",
    "# OPÇÃO 1: Usar pasta do arquivo já carregado (BLOCO 4)\n",
    "if 'arquivo_opav' in dir():\n",
    "    pasta_arquivo = arquivo_opav.parent\n",
    "    print(f\"📁 Arquivo OPAV ja carregado no BLOCO 4:\")\n",
    "    print(f\"   Arquivo: {arquivo_opav.name}\")\n",
    "    print(f\"   Pasta: {pasta_arquivo}\")\n",
    "    print()\n",
    "\n",
    "    # Verificar se há outros arquivos nessa pasta\n",
    "    outros_arquivos = list(pasta_arquivo.glob('*xSAPtemp*.xls*'))\n",
    "\n",
    "    if len(outros_arquivos) > 1:\n",
    "        print(f\"   ✅ Encontrados {len(outros_arquivos)} arquivos xSAPtemp nesta pasta\")\n",
    "        print(f\"   Usando esta pasta como base\")\n",
    "        pasta_base = pasta_arquivo\n",
    "    elif len(outros_arquivos) == 1:\n",
    "        print(f\"   ⚠️  Apenas 1 arquivo xSAPtemp nesta pasta\")\n",
    "        print(f\"   Vou perguntar se quer buscar em outra pasta\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  Nenhum arquivo xSAPtemp nesta pasta\")\n",
    "        print(f\"   Vou perguntar outra pasta\")\n",
    "\n",
    "# OPÇÃO 2: Perguntar ao usuário\n",
    "if pasta_base is None:\n",
    "    print()\n",
    "    print(\"═\" * 80)\n",
    "    print(\"📂 SELEÇÃO DE PASTA\")\n",
    "    print(\"═\" * 80)\n",
    "    print()\n",
    "    print(\"Opcoes:\")\n",
    "    print(\"   1. Selecionar pasta manualmente\")\n",
    "    if 'arquivo_opav' in dir():\n",
    "        print(f\"   2. Usar pasta do arquivo atual ({arquivo_opav.parent.name})\")\n",
    "    if 'fm' in dir():\n",
    "        print(f\"   3. Usar pasta do FileManager ({fm.diretorios['dados_entrada'].name})\")\n",
    "    print()\n",
    "\n",
    "    escolha = input(\"Escolha (1/2/3): \").strip()\n",
    "\n",
    "    if escolha == '1':\n",
    "        # Janela de seleção\n",
    "        print(\"\\nAbrindo janela de selecao de pasta...\")\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.lift()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        pasta = filedialog.askdirectory(\n",
    "            title=\"Selecione pasta com arquivos OPAV (xSAPtemp...)\"\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not pasta:\n",
    "            raise ValueError(\"Nenhuma pasta selecionada\")\n",
    "\n",
    "        pasta_base = Path(pasta)\n",
    "\n",
    "    elif escolha == '2' and 'arquivo_opav' in dir():\n",
    "        pasta_base = arquivo_opav.parent\n",
    "\n",
    "    elif escolha == '3' and 'fm' in dir():\n",
    "        pasta_base = fm.diretorios['dados_entrada']\n",
    "\n",
    "    else:\n",
    "        # Default: FileManager ou erro\n",
    "        if 'fm' in dir():\n",
    "            pasta_base = fm.diretorios['dados_entrada']\n",
    "        else:\n",
    "            raise ValueError(\"Opcao invalida\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 1.5: Copiar arquivo para pasta FileManager (se necessário)\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'arquivo_opav' in dir() and 'fm' in dir():\n",
    "    # Verificar se arquivo está fora da pasta do FileManager\n",
    "    arquivo_atual = arquivo_opav\n",
    "    pasta_fm = fm.diretorios['dados_entrada']\n",
    "\n",
    "    if arquivo_atual.parent != pasta_fm:\n",
    "        print()\n",
    "        print(\"═\" * 80)\n",
    "        print(\"📋 ARQUIVO FORA DA PASTA DO FILEMANAGER\")\n",
    "        print(\"═\" * 80)\n",
    "        print()\n",
    "        print(f\"Arquivo atual: {arquivo_atual}\")\n",
    "        print(f\"Pasta FileManager: {pasta_fm}\")\n",
    "        print()\n",
    "\n",
    "        # Verificar tamanho\n",
    "        tamanho_mb = arquivo_atual.stat().st_size / (1024 * 1024)\n",
    "        print(f\"Tamanho do arquivo: {tamanho_mb:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "        if tamanho_mb > 50:\n",
    "            print(\"⚠️  Arquivo grande (>50MB)\")\n",
    "            print()\n",
    "            print(\"Opcoes:\")\n",
    "            print(\"   1. Copiar para pasta FileManager (pode demorar)\")\n",
    "            print(\"   2. Buscar na pasta atual do arquivo\")\n",
    "            print(\"   3. Selecionar outra pasta\")\n",
    "            print()\n",
    "\n",
    "            escolha_copia = input(\"Escolha (1/2/3): \").strip()\n",
    "\n",
    "            if escolha_copia == '1':\n",
    "                print(\"\\n📋 Copiando arquivo...\")\n",
    "                import shutil\n",
    "\n",
    "                destino = pasta_fm / arquivo_atual.name\n",
    "\n",
    "                try:\n",
    "                    shutil.copy2(arquivo_atual, destino)\n",
    "                    print(f\"   ✅ Copiado para: {destino}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Erro ao copiar: {str(e)}\")\n",
    "                    print(f\"   Usando pasta original\")\n",
    "                    print()\n",
    "\n",
    "            elif escolha_copia == '2':\n",
    "                print(\"\\n✅ Usando pasta do arquivo atual\")\n",
    "                print()\n",
    "\n",
    "            elif escolha_copia == '3':\n",
    "                print(\"\\n📂 Abrindo janela de selecao...\")\n",
    "                root = tk.Tk()\n",
    "                root.withdraw()\n",
    "                root.lift()\n",
    "                root.attributes('-topmost', True)\n",
    "\n",
    "                pasta = filedialog.askdirectory(\n",
    "                    title=\"Selecione pasta com arquivos OPAV\"\n",
    "                )\n",
    "\n",
    "                root.destroy()\n",
    "\n",
    "                if pasta:\n",
    "                    pasta_base = Path(pasta)\n",
    "                    print(f\"   ✅ Pasta selecionada: {pasta_base}\")\n",
    "                print()\n",
    "        else:\n",
    "            # Arquivo pequeno (<50MB), copiar automaticamente\n",
    "            print(\"✅ Arquivo pequeno (<50MB)\")\n",
    "            print(\"   Copiando para pasta FileManager...\")\n",
    "\n",
    "            import shutil\n",
    "            destino = pasta_fm / arquivo_atual.name\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(arquivo_atual, destino)\n",
    "                print(f\"   ✅ Copiado para: {destino.name}\")\n",
    "                print()\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️  Erro ao copiar: {str(e)}\")\n",
    "                print(f\"   Continuando com pasta original\")\n",
    "                print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"✅ PASTA BASE DEFINIDA: {pasta_base}\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 2: Buscar arquivos recursivamente\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 2: Buscando arquivos xSAPtemp recursivamente...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Buscar com glob recursivo\n",
    "padroes = ['*xSAPtemp*.xls', '*xSAPtemp*.xlsx']\n",
    "arquivos_encontrados = []\n",
    "\n",
    "for padrao in padroes:\n",
    "    arquivos_encontrados.extend(pasta_base.rglob(padrao))\n",
    "\n",
    "# Remover duplicatas (caso encontre mesmo arquivo com ambos padrões)\n",
    "arquivos_encontrados = list(set(arquivos_encontrados))\n",
    "\n",
    "# Ordenar por nome\n",
    "arquivos_encontrados.sort(key=lambda x: x.name)\n",
    "\n",
    "print(f\"✅ Encontrados: {len(arquivos_encontrados)} arquivos\")\n",
    "print()\n",
    "\n",
    "if len(arquivos_encontrados) == 0:\n",
    "    print(\"❌ NENHUM ARQUIVO ENCONTRADO!\")\n",
    "    print()\n",
    "    print(\"Padrões buscados:\")\n",
    "    for padrao in padroes:\n",
    "        print(f\"   • {padrao}\")\n",
    "    print()\n",
    "    print(f\"Pasta base: {pasta_base}\")\n",
    "    print()\n",
    "    raise ValueError(\"Nenhum arquivo xSAPtemp encontrado\")\n",
    "\n",
    "# Listar arquivos encontrados\n",
    "print(\"📋 ARQUIVOS ENCONTRADOS:\")\n",
    "print(\"-\" * 80)\n",
    "for i, arq in enumerate(arquivos_encontrados, 1):\n",
    "    # Caminho relativo à pasta base\n",
    "    rel_path = arq.relative_to(pasta_base)\n",
    "    tamanho_mb = arq.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   {i:2d}. {arq.name}\")\n",
    "    print(f\"       Pasta: {rel_path.parent}\")\n",
    "    print(f\"       Tamanho: {tamanho_mb:.2f} MB\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Confirmação do usuário\n",
    "print(\"═\" * 80)\n",
    "print(\"⚠️  CONFIRMAÇÃO NECESSÁRIA\")\n",
    "print(\"═\" * 80)\n",
    "print()\n",
    "print(f\"Foram encontrados {len(arquivos_encontrados)} arquivos.\")\n",
    "print(\"Todos serão processados e unificados em um único DataFrame.\")\n",
    "print()\n",
    "print(\"Deseja prosseguir?\")\n",
    "print(\"   [ENTER] = SIM, continuar\")\n",
    "print(\"   [Ctrl+C] = NÃO, cancelar\")\n",
    "print()\n",
    "\n",
    "input(\"Pressione ENTER para continuar...\")\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 3: Carregar todos os arquivos\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 3: Carregando todos os arquivos...\")\n",
    "print(\"═\" * 80)\n",
    "\n",
    "dataframes = []\n",
    "erros = []\n",
    "\n",
    "for i, arquivo in enumerate(arquivos_encontrados, 1):\n",
    "    print(f\"\\n[{i}/{len(arquivos_encontrados)}] Processando...\")\n",
    "\n",
    "    df = carregar_arquivo_opav(arquivo)\n",
    "\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "    else:\n",
    "        erros.append(arquivo.name)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"RESUMO DO CARREGAMENTO:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   ✅ Sucesso: {len(dataframes)} arquivos\")\n",
    "print(f\"   ❌ Erros: {len(erros)} arquivos\")\n",
    "\n",
    "if erros:\n",
    "    print(f\"\\n   Arquivos com erro:\")\n",
    "    for erro in erros:\n",
    "        print(f\"      • {erro}\")\n",
    "\n",
    "print()\n",
    "\n",
    "if len(dataframes) == 0:\n",
    "    raise ValueError(\"Nenhum arquivo foi carregado com sucesso!\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 4: Unificar DataFrames\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 4: Unificando DataFrames...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Concatenar verticalmente\n",
    "df_unificado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(f\"✅ DataFrame unificado criado\")\n",
    "print(f\"   Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   Colunas: {len(df_unificado.columns)}\")\n",
    "print()\n",
    "\n",
    "# Estatísticas por arquivo\n",
    "print(\"📊 REGISTROS POR ARQUIVO:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "contagem_por_arquivo = df_unificado['_arquivo_origem'].value_counts().sort_index()\n",
    "\n",
    "for arquivo, count in contagem_por_arquivo.items():\n",
    "    pct = (count / len(df_unificado)) * 100\n",
    "    print(f\"   {arquivo}: {count:,} registros ({pct:.1f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 5: Validações\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 5: Validações...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Verificar duplicatas\n",
    "print(\"🔍 Verificando duplicatas...\")\n",
    "\n",
    "# Colunas chave (sem metadados)\n",
    "colunas_chave = [c for c in df_unificado.columns\n",
    "                 if not c.startswith('_')][:7]\n",
    "\n",
    "print(f\"   Colunas chave: {colunas_chave[:5]}...\")\n",
    "\n",
    "duplicatas = df_unificado.duplicated(subset=colunas_chave)\n",
    "n_duplicatas = duplicatas.sum()\n",
    "\n",
    "if n_duplicatas > 0:\n",
    "    print(f\"   ⚠️  {n_duplicatas:,} linhas duplicadas encontradas\")\n",
    "    print(f\"   Mantendo primeira ocorrência...\")\n",
    "    df_unificado = df_unificado[~duplicatas].reset_index(drop=True)\n",
    "    print(f\"   ✅ Após remover: {len(df_unificado):,} registros\")\n",
    "else:\n",
    "    print(f\"   ✅ Nenhuma duplicata encontrada\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Valores nulos em colunas críticas\n",
    "print(\"🔍 Verificando nulos em colunas críticas...\")\n",
    "\n",
    "colunas_criticas = ['Centro', 'Produto', 'Ano civil/mês']\n",
    "\n",
    "for col in colunas_criticas:\n",
    "    if col in df_unificado.columns:\n",
    "        nulos = df_unificado[col].isna().sum()\n",
    "        if nulos > 0:\n",
    "            print(f\"   ⚠️  '{col}': {nulos:,} nulos\")\n",
    "        else:\n",
    "            print(f\"   ✅ '{col}': 0 nulos\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 6: Preview e Estatísticas\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 6: PREVIEW E ESTATISTICAS\")\n",
    "print(\"═\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"Primeiras 7 colunas (DIMENSOES):\")\n",
    "colunas_dim = [c for c in df_unificado.columns if not c.startswith('_')][:7]\n",
    "print(df_unificado[colunas_dim].head(5).to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Ultimas 3 colunas (METADADOS):\")\n",
    "print(df_unificado[['_arquivo_origem', '_arquivo_path', '_data_carga']].head(3).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Estatísticas resumidas\n",
    "print(\"📊 ESTATISTICAS GERAIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"   Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   Colunas totais: {len(df_unificado.columns)}\")\n",
    "print(f\"   Arquivos unificados: {len(dataframes)}\")\n",
    "print(f\"   Período de carga: {df_unificado['_data_carga'].min()} a {df_unificado['_data_carga'].max()}\")\n",
    "\n",
    "# Dimensões únicas\n",
    "if 'Centro' in df_unificado.columns:\n",
    "    print(f\"   Centros únicos: {df_unificado['Centro'].nunique()}\")\n",
    "\n",
    "if 'Produto' in df_unificado.columns:\n",
    "    print(f\"   Produtos únicos: {df_unificado['Produto'].nunique()}\")\n",
    "\n",
    "if 'Ano civil/mês' in df_unificado.columns:\n",
    "    print(f\"   Períodos únicos: {df_unificado['Ano civil/mês'].nunique()}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# ETAPA 7: Salvar Backup\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"ETAPA 7: Salvando backup...\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "if 'fm' in dir():\n",
    "    timestamp = fm.timestamp\n",
    "    arquivo_destino = fm.diretorios['dados_processados'] / f\"AIVI_OPAV_UNIFICADO_{timestamp}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        df_unificado.to_excel(arquivo_destino, index=False, engine='openpyxl')\n",
    "        fm.logger.info(f\"OPAV unificado: {arquivo_destino.name} ({len(df_unificado)} registros)\")\n",
    "        print(f\"   ✅ Backup: {arquivo_destino.name}\")\n",
    "        print(f\"   📁 Local: {arquivo_destino.parent}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  Erro ao salvar: {str(e)}\")\n",
    "        fm.logger.error(f\"Erro backup OPAV unificado: {str(e)}\")\n",
    "else:\n",
    "    print(\"   ⚠️  FileManager não disponível - backup ignorado\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# RESULTADO FINAL\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "print(\"║\" + \" ✅ UNIFICAÇÃO CONCLUÍDA COM SUCESSO \".center(78) + \"║\")\n",
    "print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "print()\n",
    "\n",
    "print(\"RESUMO FINAL:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   📄 Arquivos processados: {len(dataframes)}/{len(arquivos_encontrados)}\")\n",
    "print(f\"   📊 Registros totais: {len(df_unificado):,}\")\n",
    "print(f\"   📋 Colunas: {len(df_unificado.columns)}\")\n",
    "print(f\"   🗂️  Estrutura:\")\n",
    "print(f\"       • Dimensões: 7\")\n",
    "print(f\"       • Movimentações: {len(df_unificado.columns) - 10}\")\n",
    "print(f\"       • Metadados: 3\")\n",
    "print()\n",
    "\n",
    "# Salvar na variável global\n",
    "df_opav_unificado = df_unificado\n",
    "arquivos_opav_processados = [arq.name for arq in arquivos_encontrados if carregar_arquivo_opav(arq) is not None]\n",
    "\n",
    "print(\"VARIAVEIS DISPONIVEIS:\")\n",
    "print(\"   df_opav_unificado - DataFrame unificado\")\n",
    "print(\"   arquivos_opav_processados - Lista de arquivos\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FIM BLOCO 5\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "122aa20ef772bcdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                   BLOCO 5: UNIFICADOR DE ARQUIVOS OPAV BW                    ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "ETAPA 1: Determinar pasta com arquivos OPAV\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📁 Arquivo OPAV ja carregado no BLOCO 4:\n",
      "   Arquivo: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   Pasta: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\n",
      "\n",
      "   ⚠️  Apenas 1 arquivo xSAPtemp nesta pasta\n",
      "   Vou perguntar se quer buscar em outra pasta\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📂 SELEÇÃO DE PASTA\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Opcoes:\n",
      "   1. Selecionar pasta manualmente\n",
      "   2. Usar pasta do arquivo atual (02_Dados_Entrada)\n",
      "   3. Usar pasta do FileManager (02_Dados_Entrada)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "✅ PASTA BASE DEFINIDA: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\n",
      "================================================================================\n",
      "\n",
      "ETAPA 2: Buscando arquivos xSAPtemp recursivamente...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ Encontrados: 1 arquivos\n",
      "\n",
      "📋 ARQUIVOS ENCONTRADOS:\n",
      "--------------------------------------------------------------------------------\n",
      "    1. Cópia de xSAPtemp4687_JAN_25.xls\n",
      "       Pasta: .\n",
      "       Tamanho: 15.88 MB\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⚠️  CONFIRMAÇÃO NECESSÁRIA\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Foram encontrados 1 arquivos.\n",
      "Todos serão processados e unificados em um único DataFrame.\n",
      "\n",
      "Deseja prosseguir?\n",
      "   [ENTER] = SIM, continuar\n",
      "   [Ctrl+C] = NÃO, cancelar\n",
      "\n",
      "\n",
      "ETAPA 3: Carregando todos os arquivos...\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "[1/1] Processando...\n",
      "\n",
      "📄 Processando: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   ----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 11:33:03 | INFO     | OPAV unificado: AIVI_OPAV_UNIFICADO_20251015_110105.xlsx (200 registros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Sheet: 'Valor da Variação Total' (1001 linhas × 60 cols)\n",
      "   ✅ Carregado: 967 registros × 28 colunas\n",
      "\n",
      "================================================================================\n",
      "RESUMO DO CARREGAMENTO:\n",
      "================================================================================\n",
      "   ✅ Sucesso: 1 arquivos\n",
      "   ❌ Erros: 0 arquivos\n",
      "\n",
      "ETAPA 4: Unificando DataFrames...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✅ DataFrame unificado criado\n",
      "   Registros totais: 967\n",
      "   Colunas: 31\n",
      "\n",
      "📊 REGISTROS POR ARQUIVO:\n",
      "--------------------------------------------------------------------------------\n",
      "   Cópia de xSAPtemp4687_JAN_25.xls: 967 registros (100.0%)\n",
      "\n",
      "ETAPA 5: Validações...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Verificando duplicatas...\n",
      "   Colunas chave: ['Centro de lucro', 'Ano civil/mês', 'Centro', 'Col_3', 'HierarqPrd']...\n",
      "   ⚠️  767 linhas duplicadas encontradas\n",
      "   Mantendo primeira ocorrência...\n",
      "   ✅ Após remover: 200 registros\n",
      "\n",
      "🔍 Verificando nulos em colunas críticas...\n",
      "   ✅ 'Centro': 0 nulos\n",
      "   ✅ 'Produto': 0 nulos\n",
      "   ✅ 'Ano civil/mês': 0 nulos\n",
      "\n",
      "ETAPA 6: PREVIEW E ESTATISTICAS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Primeiras 7 colunas (DIMENSOES):\n",
      "Centro de lucro Ano civil/mês Centro Col_3           HierarqPrd    Produto                      Col_6\n",
      "       ACPBOPAV       01.2025   5126  BAV1       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.001.422    JET A NAO TABELADO - LI\n",
      "       ACPBOPAV       01.2025   5126  BAV1 Querosene de Aviação 01.003.826 JET A INTERNACIONAL I - LI\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Gasolina Comum 01.000.078           GASOLINA COMUM C\n",
      "       ACPBOPAV       01.2025   5105  BAV2       Diesel - Comum 01.011.674          ÓLEO DIESEL B S10\n",
      "\n",
      "Ultimas 3 colunas (METADADOS):\n",
      "                 _arquivo_origem                                                                                                                                               _arquivo_path                _data_carga\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "Cópia de xSAPtemp4687_JAN_25.xls E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\02_Dados_Entrada\\Cópia de xSAPtemp4687_JAN_25.xls 2025-10-15 11:33:03.714694\n",
      "\n",
      "📊 ESTATISTICAS GERAIS:\n",
      "--------------------------------------------------------------------------------\n",
      "   Registros totais: 200\n",
      "   Colunas totais: 31\n",
      "   Arquivos unificados: 1\n",
      "   Período de carga: 2025-10-15 11:33:03.714694 a 2025-10-15 11:33:03.714694\n",
      "   Centros únicos: 89\n",
      "   Produtos únicos: 15\n",
      "   Períodos únicos: 2\n",
      "\n",
      "ETAPA 7: Salvando backup...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   ✅ Backup: AIVI_OPAV_UNIFICADO_20251015_110105.xlsx\n",
      "   📁 Local: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\AIVI\\AIVI-INTEGRAÇÃO\\AIVI_DataIntegration_20251015_110105\\03_Dados_Processados\n",
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                      ✅ UNIFICAÇÃO CONCLUÍDA COM SUCESSO                      ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "RESUMO FINAL:\n",
      "--------------------------------------------------------------------------------\n",
      "   📄 Arquivos processados: 1/1\n",
      "   📊 Registros totais: 200\n",
      "   📋 Colunas: 31\n",
      "   🗂️  Estrutura:\n",
      "       • Dimensões: 7\n",
      "       • Movimentações: 21\n",
      "       • Metadados: 3\n",
      "\n",
      "\n",
      "📄 Processando: Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   ----------------------------------------------------------------------------\n",
      "   ✅ Sheet: 'Valor da Variação Total' (1001 linhas × 60 cols)\n",
      "   ✅ Carregado: 967 registros × 28 colunas\n",
      "VARIAVEIS DISPONIVEIS:\n",
      "   df_opav_unificado - DataFrame unificado\n",
      "   arquivos_opav_processados - Lista de arquivos\n",
      "\n",
      "================================================================================\n",
      "FIM BLOCO 5\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e7b9900a4c7e6c9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T18:05:58.248659Z",
     "start_time": "2025-10-15T18:05:56.955605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# BLOCO 0A: DETECTOR DE ARQUIVO DESCONHECIDO\n",
    "# Sistema inteligente para processar arquivos Excel de estrutura desconhecida\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class DetectorArquivoDesconhecido:\n",
    "    \"\"\"\n",
    "    Sistema para detectar automaticamente estrutura de arquivos Excel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, arquivo_path, fm=None):\n",
    "        self.arquivo_path = Path(arquivo_path)\n",
    "        self.fm = fm\n",
    "        self.nome_arquivo = self.arquivo_path.name\n",
    "        self.workbook = None\n",
    "        self.sheet_detectada = None\n",
    "        self.linha_cabecalho = None\n",
    "        self.linha_dados_inicio = None\n",
    "        self.df_bruto = None\n",
    "        self.df_limpo = None\n",
    "        self.log = []\n",
    "\n",
    "    def processar(self):\n",
    "        \"\"\"\n",
    "        Processamento completo do arquivo\n",
    "        \"\"\"\n",
    "        self._log(\"🔍 INICIANDO DETECÇÃO AUTOMÁTICA\", nivel=\"TITULO\")\n",
    "        self._log(f\"📁 Arquivo: {self.nome_arquivo}\")\n",
    "\n",
    "        # 1. Carregar workbook\n",
    "        self._carregar_workbook()\n",
    "\n",
    "        # 2. Detectar sheet correto\n",
    "        self._detectar_sheet()\n",
    "\n",
    "        # 3. Detectar linha de cabeçalho\n",
    "        self._detectar_cabecalho()\n",
    "\n",
    "        # 4. Extrair e limpar dados\n",
    "        self._extrair_dados()\n",
    "\n",
    "        # 5. Limpar estrutura\n",
    "        self._limpar_estrutura()\n",
    "\n",
    "        # 6. Relatório final\n",
    "        self._gerar_relatorio()\n",
    "\n",
    "        return self.df_limpo\n",
    "\n",
    "    def _carregar_workbook(self):\n",
    "        \"\"\"\n",
    "        Carrega workbook Excel\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📂 FASE 1: Carregamento do Arquivo\", nivel=\"SECAO\")\n",
    "\n",
    "        try:\n",
    "            # Tentar xlrd primeiro (mais robusto para .xls)\n",
    "            self.workbook = xlrd.open_workbook(str(self.arquivo_path))\n",
    "            self._log(f\"✅ Carregado com xlrd\")\n",
    "            self._log(f\"   Formato: XLS (Excel Antigo)\")\n",
    "        except Exception as e1:\n",
    "            # Fallback para pandas (xlsx, xlsm)\n",
    "            try:\n",
    "                self.workbook = pd.ExcelFile(str(self.arquivo_path))\n",
    "                self._log(f\"✅ Carregado com pandas\")\n",
    "                self._log(f\"   Formato: XLSX/XLSM (Excel Moderno)\")\n",
    "            except Exception as e2:\n",
    "                raise ValueError(f\"❌ Não foi possível carregar arquivo:\\n  xlrd: {e1}\\n  pandas: {e2}\")\n",
    "\n",
    "        # Listar sheets\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheets = self.workbook.sheet_names()\n",
    "        else:\n",
    "            sheets = self.workbook.sheet_names\n",
    "\n",
    "        self._log(f\"📊 Sheets encontradas: {len(sheets)}\")\n",
    "        for i, sheet in enumerate(sheets, 1):\n",
    "            self._log(f\"   {i}. {sheet}\")\n",
    "\n",
    "    def _detectar_sheet(self):\n",
    "        \"\"\"\n",
    "        Detecta sheet com dados relevantes\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📊 FASE 2: Detecção de Sheet\", nivel=\"SECAO\")\n",
    "\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheets = self.workbook.sheet_names()\n",
    "        else:\n",
    "            sheets = self.workbook.sheet_names\n",
    "\n",
    "        # REGRAS DE DETECÇÃO (ordem de prioridade)\n",
    "        regras = [\n",
    "            # BW específico\n",
    "            (r\"Valor da Variação Total\", \"BW - Variação Total\"),\n",
    "            (r\"Variação.*Total\", \"Variação Total (genérico)\"),\n",
    "            (r\"OPAV\", \"OPAV\"),\n",
    "            # Genéricas\n",
    "            (r\"(?i)dados\", \"Dados\"),\n",
    "            (r\"(?i)relat[oó]rio\", \"Relatório\"),\n",
    "            (r\"(?i)export\", \"Export\"),\n",
    "            (r\"(?i)result\", \"Result\"),\n",
    "        ]\n",
    "\n",
    "        candidatos = []\n",
    "\n",
    "        for sheet_name in sheets:\n",
    "            for padrao, descricao in regras:\n",
    "                if re.search(padrao, sheet_name):\n",
    "                    # Carregar amostra para validar\n",
    "                    validacao = self._validar_sheet(sheet_name)\n",
    "                    candidatos.append({\n",
    "                        'nome': sheet_name,\n",
    "                        'descricao': descricao,\n",
    "                        'score': validacao['score'],\n",
    "                        'linhas': validacao['linhas'],\n",
    "                        'colunas': validacao['colunas']\n",
    "                    })\n",
    "                    self._log(f\"   ✅ Candidato: '{sheet_name}' ({descricao})\")\n",
    "                    self._log(f\"      Score: {validacao['score']:.2f} | Linhas: {validacao['linhas']} | Colunas: {validacao['colunas']}\")\n",
    "                    break\n",
    "\n",
    "        if not candidatos:\n",
    "            # Se nenhum match, usar primeira sheet não vazia\n",
    "            self._log(\"   ⚠️  Nenhum match por padrão, analisando todas sheets...\")\n",
    "            for sheet_name in sheets:\n",
    "                validacao = self._validar_sheet(sheet_name)\n",
    "                if validacao['score'] > 0:\n",
    "                    candidatos.append({\n",
    "                        'nome': sheet_name,\n",
    "                        'descricao': 'Primeira não vazia',\n",
    "                        'score': validacao['score'],\n",
    "                        'linhas': validacao['linhas'],\n",
    "                        'colunas': validacao['colunas']\n",
    "                    })\n",
    "\n",
    "        if not candidatos:\n",
    "            raise ValueError(\"❌ Nenhuma sheet com dados foi encontrada\")\n",
    "\n",
    "        # Selecionar melhor candidato (maior score)\n",
    "        melhor = max(candidatos, key=lambda x: x['score'])\n",
    "        self.sheet_detectada = melhor['nome']\n",
    "\n",
    "        self._log(f\"\\n   🎯 SHEET SELECIONADA: '{self.sheet_detectada}'\")\n",
    "        self._log(f\"      {melhor['descricao']} | Score: {melhor['score']:.2f}\")\n",
    "\n",
    "    def _validar_sheet(self, sheet_name):\n",
    "        \"\"\"\n",
    "        Valida se sheet contém dados úteis\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(self.workbook, xlrd.Book):\n",
    "                sheet = self.workbook.sheet_by_name(sheet_name)\n",
    "                linhas = sheet.nrows\n",
    "                colunas = sheet.ncols\n",
    "                # Amostra: primeira linha não vazia\n",
    "                amostra = []\n",
    "                for i in range(min(50, linhas)):\n",
    "                    row = sheet.row_values(i)\n",
    "                    if any(str(c).strip() for c in row):\n",
    "                        amostra.append(row)\n",
    "                        if len(amostra) >= 10:\n",
    "                            break\n",
    "            else:\n",
    "                df_sample = pd.read_excel(self.workbook, sheet_name=sheet_name, nrows=50)\n",
    "                linhas = len(df_sample)\n",
    "                colunas = len(df_sample.columns)\n",
    "                amostra = df_sample.values.tolist()\n",
    "\n",
    "            # Calcular score\n",
    "            score = 0.0\n",
    "            if linhas > 10:\n",
    "                score += 1.0\n",
    "            if colunas > 5:\n",
    "                score += 1.0\n",
    "            if linhas > 100:\n",
    "                score += 0.5\n",
    "            if colunas > 15:\n",
    "                score += 0.5\n",
    "\n",
    "            # Penalizar sheets muito pequenas\n",
    "            if linhas < 5 or colunas < 3:\n",
    "                score = 0.0\n",
    "\n",
    "            return {\n",
    "                'score': score,\n",
    "                'linhas': linhas,\n",
    "                'colunas': colunas\n",
    "            }\n",
    "        except:\n",
    "            return {'score': 0.0, 'linhas': 0, 'colunas': 0}\n",
    "\n",
    "    def _detectar_cabecalho(self):\n",
    "        \"\"\"\n",
    "        Detecta linha de cabeçalho automaticamente\n",
    "        \"\"\"\n",
    "        self._log(\"\\n🔍 FASE 3: Detecção de Cabeçalho\", nivel=\"SECAO\")\n",
    "\n",
    "        # Carregar primeiras 100 linhas\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheet = self.workbook.sheet_by_name(self.sheet_detectada)\n",
    "            linhas_amostra = []\n",
    "            for i in range(min(100, sheet.nrows)):\n",
    "                linhas_amostra.append(sheet.row_values(i))\n",
    "        else:\n",
    "            df_amostra = pd.read_excel(\n",
    "                self.workbook,\n",
    "                sheet_name=self.sheet_detectada,\n",
    "                nrows=100,\n",
    "                header=None\n",
    "            )\n",
    "            linhas_amostra = df_amostra.values.tolist()\n",
    "\n",
    "        # Análise linha por linha\n",
    "        scores = []\n",
    "        for idx, linha in enumerate(linhas_amostra):\n",
    "            score = self._avaliar_linha_cabecalho(linha, idx)\n",
    "            scores.append({\n",
    "                'linha': idx,\n",
    "                'score': score,\n",
    "                'conteudo_sample': linha[:5]  # Primeiras 5 colunas\n",
    "            })\n",
    "\n",
    "        # Ordenar por score\n",
    "        scores_ordenados = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        # Mostrar top 5\n",
    "        self._log(\"   🏆 Top 5 candidatos a cabeçalho:\")\n",
    "        for i, item in enumerate(scores_ordenados[:5], 1):\n",
    "            self._log(f\"      {i}. Linha {item['linha']+1} (Excel) - Score: {item['score']:.2f}\")\n",
    "            self._log(f\"         Sample: {item['conteudo_sample']}\")\n",
    "\n",
    "        # Selecionar melhor\n",
    "        melhor = scores_ordenados[0]\n",
    "        self.linha_cabecalho = melhor['linha']\n",
    "        self.linha_dados_inicio = self.linha_cabecalho + 1\n",
    "\n",
    "        self._log(f\"\\n   🎯 CABEÇALHO DETECTADO: Linha {self.linha_cabecalho + 1} (Excel)\")\n",
    "        self._log(f\"      Início dos dados: Linha {self.linha_dados_inicio + 1} (Excel)\")\n",
    "\n",
    "    def _avaliar_linha_cabecalho(self, linha, idx):\n",
    "        \"\"\"\n",
    "        Avalia se uma linha é candidata a cabeçalho\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "\n",
    "        # Converter para strings\n",
    "        celulas = [str(c).strip() for c in linha if str(c).strip()]\n",
    "\n",
    "        if not celulas:\n",
    "            return 0.0\n",
    "\n",
    "        # CRITÉRIO 1: Quantidade de células não vazias (peso 2.0)\n",
    "        prop_nao_vazias = len(celulas) / len(linha)\n",
    "        score += prop_nao_vazias * 2.0\n",
    "\n",
    "        # CRITÉRIO 2: Células com texto (não só números) (peso 1.5)\n",
    "        tem_texto = sum(1 for c in celulas if re.search(r'[a-zA-Z]', c))\n",
    "        prop_texto = tem_texto / len(celulas) if celulas else 0\n",
    "        score += prop_texto * 1.5\n",
    "\n",
    "        # CRITÉRIO 3: Palavras-chave de cabeçalho (peso 3.0)\n",
    "        keywords = [\n",
    "            'centro', 'produto', 'material', 'código', 'cod', 'cód',\n",
    "            'data', 'período', 'ano', 'mês', 'mes',\n",
    "            'quantidade', 'valor', 'volume', 'expedição', 'variação',\n",
    "            'limite', 'batente', 'sigla', 'base', 'região', 'regiao',\n",
    "            'nome', 'descrição', 'descricao', 'tipo', 'status'\n",
    "        ]\n",
    "\n",
    "        texto_linha = ' '.join(celulas).lower()\n",
    "        keywords_encontradas = sum(1 for kw in keywords if kw in texto_linha)\n",
    "        score += (keywords_encontradas / len(keywords)) * 3.0\n",
    "\n",
    "        # CRITÉRIO 4: Tamanho médio das células (cabeçalhos tendem a ser curtos) (peso 1.0)\n",
    "        tamanho_medio = np.mean([len(c) for c in celulas])\n",
    "        if 5 <= tamanho_medio <= 50:\n",
    "            score += 1.0\n",
    "        elif tamanho_medio > 100:\n",
    "            score -= 0.5  # Penalizar linhas muito longas\n",
    "\n",
    "        # CRITÉRIO 5: Unicidade (cabeçalhos não devem ter repetições) (peso 1.5)\n",
    "        contador = Counter(celulas)\n",
    "        repeticoes = sum(1 for c, n in contador.items() if n > 1)\n",
    "        if repeticoes == 0:\n",
    "            score += 1.5\n",
    "        else:\n",
    "            score -= repeticoes * 0.3\n",
    "\n",
    "        # CRITÉRIO 6: Posição (linhas mais acima têm vantagem) (peso 0.5)\n",
    "        if idx < 50:\n",
    "            score += (50 - idx) / 100\n",
    "\n",
    "        # CRITÉRIO 7: Formato típico BW (linha ~30-40)\n",
    "        if 30 <= idx <= 40:\n",
    "            score += 0.5\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _extrair_dados(self):\n",
    "        \"\"\"\n",
    "        Extrai dados a partir da linha detectada\n",
    "        \"\"\"\n",
    "        self._log(\"\\n📊 FASE 4: Extração de Dados\", nivel=\"SECAO\")\n",
    "\n",
    "        if isinstance(self.workbook, xlrd.Book):\n",
    "            sheet = self.workbook.sheet_by_name(self.sheet_detectada)\n",
    "\n",
    "            # Extrair todas as linhas\n",
    "            data = []\n",
    "            for i in range(sheet.nrows):\n",
    "                data.append(sheet.row_values(i))\n",
    "\n",
    "            self.df_bruto = pd.DataFrame(data)\n",
    "\n",
    "            # Definir cabeçalho\n",
    "            cabecalho_bruto = self.df_bruto.iloc[self.linha_cabecalho].tolist()\n",
    "\n",
    "            # Extrair dados\n",
    "            self.df_bruto = self.df_bruto.iloc[self.linha_dados_inicio:].copy()\n",
    "            self.df_bruto.columns = cabecalho_bruto\n",
    "\n",
    "        else:\n",
    "            # pandas\n",
    "            self.df_bruto = pd.read_excel(\n",
    "                self.workbook,\n",
    "                sheet_name=self.sheet_detectada,\n",
    "                header=self.linha_cabecalho\n",
    "            )\n",
    "\n",
    "        self.df_bruto = self.df_bruto.reset_index(drop=True)\n",
    "\n",
    "        self._log(f\"✅ Dados extraídos\")\n",
    "        self._log(f\"   Registros: {len(self.df_bruto):,}\")\n",
    "        self._log(f\"   Colunas: {len(self.df_bruto.columns)}\")\n",
    "\n",
    "    def _limpar_estrutura(self):\n",
    "        \"\"\"\n",
    "        Limpa estrutura do DataFrame\n",
    "        \"\"\"\n",
    "        self._log(\"\\n🧹 FASE 5: Limpeza de Estrutura\", nivel=\"SECAO\")\n",
    "\n",
    "        df = self.df_bruto.copy()\n",
    "\n",
    "        # 1. Remover colunas completamente vazias\n",
    "        colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "        if colunas_vazias:\n",
    "            self._log(f\"   🗑️  Removendo {len(colunas_vazias)} colunas vazias\")\n",
    "            df = df.drop(columns=colunas_vazias)\n",
    "\n",
    "        # 2. Remover linhas completamente vazias\n",
    "        linhas_vazias = df.index[df.isna().all(axis=1)].tolist()\n",
    "        if linhas_vazias:\n",
    "            self._log(f\"   🗑️  Removendo {len(linhas_vazias)} linhas vazias\")\n",
    "            df = df.dropna(how='all')\n",
    "\n",
    "        # 3. Limpar nomes de colunas\n",
    "        self._log(\"   🧹 Limpando nomes de colunas...\")\n",
    "        colunas_limpas = []\n",
    "        for col in df.columns:\n",
    "            col_limpo = str(col).strip()\n",
    "            col_limpo = col_limpo.lstrip(\"'\")  # Excel adiciona '\n",
    "            col_limpo = col_limpo.replace('\\n', ' ')\n",
    "            col_limpo = col_limpo.replace('\\r', '')\n",
    "            col_limpo = ' '.join(col_limpo.split())  # Múltiplos espaços\n",
    "            colunas_limpas.append(col_limpo)\n",
    "\n",
    "        df.columns = colunas_limpas\n",
    "\n",
    "        # 4. Renomear colunas duplicadas\n",
    "        contagem = Counter(colunas_limpas)\n",
    "        duplicadas = {c: n for c, n in contagem.items() if n > 1}\n",
    "\n",
    "        if duplicadas:\n",
    "            self._log(f\"   ⚠️  Renomeando {len(duplicadas)} colunas duplicadas:\")\n",
    "            colunas_finais = []\n",
    "            contador = {}\n",
    "\n",
    "            for col in colunas_limpas:\n",
    "                if col in duplicadas:\n",
    "                    if col not in contador:\n",
    "                        contador[col] = 0\n",
    "                        colunas_finais.append(col)\n",
    "                    else:\n",
    "                        contador[col] += 1\n",
    "                        novo_nome = f\"{col}_dup{contador[col]}\"\n",
    "                        colunas_finais.append(novo_nome)\n",
    "                        self._log(f\"      '{col}' → '{novo_nome}'\")\n",
    "                else:\n",
    "                    colunas_finais.append(col)\n",
    "\n",
    "            df.columns = colunas_finais\n",
    "\n",
    "        # 5. Remover linhas de totais/resultados\n",
    "        padroes_remover = [\n",
    "            r'(?i)^total',\n",
    "            r'(?i)^resultado',\n",
    "            r'(?i)^soma',\n",
    "            r'(?i)^subtotal',\n",
    "            r'(?i)^grand total'\n",
    "        ]\n",
    "\n",
    "        linhas_remover = []\n",
    "        for idx, row in df.iterrows():\n",
    "            primeira_celula = str(row.iloc[0]).strip().lower()\n",
    "            for padrao in padroes_remover:\n",
    "                if re.search(padrao, primeira_celula):\n",
    "                    linhas_remover.append(idx)\n",
    "                    break\n",
    "\n",
    "        if linhas_remover:\n",
    "            self._log(f\"   🗑️  Removendo {len(linhas_remover)} linhas de totais/resultados\")\n",
    "            df = df.drop(index=linhas_remover)\n",
    "\n",
    "        # 6. Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        self.df_limpo = df\n",
    "\n",
    "        self._log(f\"\\n✅ Limpeza concluída\")\n",
    "        self._log(f\"   Registros finais: {len(self.df_limpo):,}\")\n",
    "        self._log(f\"   Colunas finais: {len(self.df_limpo.columns)}\")\n",
    "\n",
    "    def _gerar_relatorio(self):\n",
    "        \"\"\"\n",
    "        Gera relatório final de detecção\n",
    "        \"\"\"\n",
    "        self._log(\"\\n\" + \"=\"*80, nivel=\"TITULO\")\n",
    "        self._log(\"📋 RELATÓRIO FINAL DE DETECÇÃO\", nivel=\"TITULO\")\n",
    "        self._log(\"=\"*80, nivel=\"TITULO\")\n",
    "\n",
    "        self._log(f\"\\n📁 Arquivo: {self.nome_arquivo}\")\n",
    "        self._log(f\"📊 Sheet: {self.sheet_detectada}\")\n",
    "        self._log(f\"📍 Cabeçalho: Linha {self.linha_cabecalho + 1} (Excel)\")\n",
    "        self._log(f\"📍 Dados: Linha {self.linha_dados_inicio + 1} (Excel)\")\n",
    "\n",
    "        self._log(f\"\\n📊 Resultado Final:\")\n",
    "        self._log(f\"   Registros: {len(self.df_limpo):,}\")\n",
    "        self._log(f\"   Colunas: {len(self.df_limpo.columns)}\")\n",
    "\n",
    "        self._log(f\"\\n📋 Colunas detectadas:\")\n",
    "        for i, col in enumerate(self.df_limpo.columns, 1):\n",
    "            self._log(f\"   {i:2d}. {col}\")\n",
    "\n",
    "    def _log(self, mensagem, nivel=\"INFO\"):\n",
    "        \"\"\"\n",
    "        Sistema de log\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        if nivel == \"TITULO\":\n",
    "            print(mensagem)\n",
    "        elif nivel == \"SECAO\":\n",
    "            print(f\"\\n{mensagem}\")\n",
    "            print(\"─\" * 80)\n",
    "        else:\n",
    "            print(mensagem)\n",
    "\n",
    "        self.log.append({\n",
    "            'timestamp': timestamp,\n",
    "            'nivel': nivel,\n",
    "            'mensagem': mensagem\n",
    "        })\n",
    "\n",
    "    def exportar_log(self, pasta_destino):\n",
    "        \"\"\"\n",
    "        Exporta log para arquivo\n",
    "        \"\"\"\n",
    "        log_df = pd.DataFrame(self.log)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        arquivo_log = Path(pasta_destino) / f\"LOG_DeteccaoAutomatica_{timestamp}.xlsx\"\n",
    "\n",
    "        log_df.to_excel(arquivo_log, index=False)\n",
    "        print(f\"\\n💾 Log salvo: {arquivo_log}\")\n",
    "\n",
    "        return arquivo_log\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# EXEMPLO DE USO\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Usar FileManager se disponível\n",
    "    if 'fm' in dir():\n",
    "        pasta_entrada = fm.diretorios['dados_entrada']\n",
    "        pasta_logs = fm.diretorios['logs']\n",
    "    else:\n",
    "        pasta_entrada = Path('02_Dados_Entrada')\n",
    "        pasta_logs = Path('logs')\n",
    "\n",
    "    # Selecionar arquivo\n",
    "    arquivos_disponiveis = list(pasta_entrada.glob('*.xls*'))\n",
    "\n",
    "    print(\"📁 Arquivos disponíveis:\")\n",
    "    for i, arq in enumerate(arquivos_disponiveis, 1):\n",
    "        print(f\"   {i}. {arq.name}\")\n",
    "\n",
    "    escolha = int(input(\"\\nEscolha um arquivo (número): \")) - 1\n",
    "    arquivo_selecionado = arquivos_disponiveis[escolha]\n",
    "\n",
    "    # Processar\n",
    "    detector = DetectorArquivoDesconhecido(arquivo_selecionado)\n",
    "    df_resultado = detector.processar()\n",
    "\n",
    "    # Exportar log\n",
    "    detector.exportar_log(pasta_logs)\n",
    "\n",
    "    # Salvar resultado\n",
    "    arquivo_saida = pasta_entrada.parent / '03_Dados_Processados' / f\"Detectado_{arquivo_selecionado.stem}.xlsx\"\n",
    "    df_resultado.to_excel(arquivo_saida, index=False)\n",
    "    print(f\"💾 Resultado salvo: {arquivo_saida}\")"
   ],
   "id": "4a5f4951d942e0c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Arquivos disponíveis:\n",
      "   1. AIVI_OPAV_BW_20251015_110105.xlsx\n",
      "   2. Centros_BR_20251015_110105.xlsx\n",
      "   3. Cópia de xSAPtemp4687_JAN_25.xls\n",
      "   4. SAP_YSMM_Limpo_20251015_110105.xlsx\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 506\u001B[39m\n\u001B[32m    503\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, arq \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(arquivos_disponiveis, \u001B[32m1\u001B[39m):\n\u001B[32m    504\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m   \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marq.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m506\u001B[39m escolha = \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43mEscolha um arquivo (número): \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m - \u001B[32m1\u001B[39m\n\u001B[32m    507\u001B[39m arquivo_selecionado = arquivos_disponiveis[escolha]\n\u001B[32m    509\u001B[39m \u001B[38;5;66;03m# Processar\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34b56a7611fbc6aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
