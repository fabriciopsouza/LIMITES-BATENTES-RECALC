{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:23.004942Z",
     "start_time": "2025-10-19T09:07:19.821950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 1: SELETOR DE PASTA COM TIMER + MIGRA√á√ÉO\n",
    "# Vers√£o: 4.4 - COM MELHORIAS DE OBSERVABILIDADE E CONSIST√äNCIA\n",
    "# Data: 2025-10-17\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MELHORIAS v4.4:\n",
    "# ‚úÖ MELHORIA 1: Salvar estado local .bloco_1_state.json\n",
    "# ‚úÖ MELHORIA 2: Registro de vers√£o do c√≥digo\n",
    "# ‚úÖ MELHORIA 3: Valida√ß√£o de depend√™ncias\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# METADADOS DA VERS√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "VERSAO_BLOCO1 = '4.4'\n",
    "DATA_VERSAO = '2025-10-17'\n",
    "CHANGELOG_V44 = {\n",
    "    'v4.4': {\n",
    "        'data': '2025-10-17',\n",
    "        'melhorias': [\n",
    "            'Salvar estado local em .bloco_1_state.json',\n",
    "            'Registro de vers√£o do c√≥digo',\n",
    "            'Valida√ß√£o de depend√™ncias no in√≠cio'\n",
    "        ],\n",
    "        'compatibilidade': 'v4.3'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\" üîç PROCESSADOR DE ARQUIVOS DESCONHECIDOS v{VERSAO_BLOCO1}\")\n",
    "print(\"=\"*70)\n",
    "print(f\" Vers√£o: {VERSAO_BLOCO1} | Data: {DATA_VERSAO}\")\n",
    "print(\" Timer | Migra√ß√£o | Dicion√°rios | Valida√ß√µes | Logs | Estado\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MELHORIA 3: VALIDA√á√ÉO DE DEPEND√äNCIAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def validar_dependencias():\n",
    "    \"\"\"\n",
    "    Valida que todas as bibliotecas necess√°rias est√£o instaladas.\n",
    "\n",
    "    Evita erros confusos mais tarde na execu√ß√£o.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç Validando depend√™ncias...\")\n",
    "\n",
    "    dependencias = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'openpyxl': 'openpyxl',\n",
    "        'xlrd': 'xlrd',\n",
    "        'tkinter': 'tkinter (built-in Python)'\n",
    "    }\n",
    "\n",
    "    faltando = []\n",
    "    instaladas = []\n",
    "\n",
    "    for modulo, nome_pip in dependencias.items():\n",
    "        try:\n",
    "            __import__(modulo)\n",
    "            instaladas.append(f\"‚úÖ {modulo}\")\n",
    "        except ImportError:\n",
    "            faltando.append(nome_pip)\n",
    "\n",
    "    # Mostrar resultado\n",
    "    for lib in instaladas:\n",
    "        print(f\"   {lib}\")\n",
    "\n",
    "    if faltando:\n",
    "        print(\"\\n‚ùå ERRO: Bibliotecas faltando!\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "        for lib in faltando:\n",
    "            print(f\"   ‚ùå {lib}\")\n",
    "        print(\"\\nüí° Solu√ß√£o:\")\n",
    "        libs_pip = [lib for lib in faltando if 'built-in' not in lib]\n",
    "        if libs_pip:\n",
    "            print(f\"   Execute: pip install {' '.join(libs_pip)}\")\n",
    "        print()\n",
    "        raise ImportError(\n",
    "            f\"Bibliotecas necess√°rias n√£o instaladas: {', '.join(faltando)}\"\n",
    "        )\n",
    "\n",
    "    print(\"‚úÖ Todas as depend√™ncias instaladas!\\n\")\n",
    "\n",
    "# Validar ANTES de importar\n",
    "validar_dependencias()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# IMPORTS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "\n",
    "print(\"‚úÖ Imports carregados\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: LocalizadorDicionario (SISTEMA DE PERSIST√äNCIA GLOBAL)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localiza√ß√£o persistente de dicion√°rios entre sess√µes.\n",
    "\n",
    "    Mant√©m log global em: ~/.processador_dicionario_localizador.json\n",
    "\n",
    "    M√©todos P√∫blicos:\n",
    "    - obter_dicionario_atual() -> Path  # Para BLOCO 2+\n",
    "    - obter_pasta_base_atual() -> Path  # Para FileManager\n",
    "    - obter_timestamp_atual() -> str    # Para recuperar timestamp\n",
    "    - registrar_mudanca()               # Chamado por BLOCO 1\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.1',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'timestamp': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def salvar_log(cls, log):\n",
    "        \"\"\"Salva log com backup autom√°tico\"\"\"\n",
    "        # Backup do log anterior\n",
    "        if cls.LOG_FILE.exists():\n",
    "            backup_file = cls.LOG_FILE.with_suffix('.json.bak')\n",
    "            shutil.copy2(cls.LOG_FILE, backup_file)\n",
    "\n",
    "        # Salvar novo log\n",
    "        with open(cls.LOG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicion√°rio atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"‚ùå Dicion√°rio n√£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå Dicion√°rio n√£o existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual (para FileManager)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"‚ùå Pasta base n√£o encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"‚ùå Pasta base n√£o existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "    @classmethod\n",
    "    def obter_timestamp_atual(cls):\n",
    "        \"\"\"Retorna timestamp da execu√ß√£o atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log.get('timestamp'):\n",
    "            raise FileNotFoundError(\n",
    "                \"‚ùå Timestamp n√£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "        return log['timestamp']\n",
    "\n",
    "    @classmethod\n",
    "    def registrar_mudanca(cls, pasta_base, timestamp, dicionario_path=None,\n",
    "                         migrado_de=None, versao_bloco1=None):\n",
    "        \"\"\"\n",
    "        Registra mudan√ßa de localiza√ß√£o no log global.\n",
    "\n",
    "        IMPORTANTE: Agora aceita timestamp e registra no LOG GLOBAL.\n",
    "        dicionario_path √© OPCIONAL - s√≥ registra se existir.\n",
    "\n",
    "        Args:\n",
    "            pasta_base: Path da pasta container\n",
    "            timestamp: String timestamp da execu√ß√£o\n",
    "            dicionario_path: Path do dicion√°rio (opcional)\n",
    "            migrado_de: Path de onde migrou (opcional)\n",
    "            versao_bloco1: Vers√£o do BLOCO 1 que criou (opcional)\n",
    "        \"\"\"\n",
    "        log = cls.carregar_log()\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'pasta_base': str(pasta_base),\n",
    "            'dicionario_path': str(dicionario_path) if dicionario_path else None,\n",
    "            'timestamp_execucao': timestamp,\n",
    "            'existe': dicionario_path.exists() if dicionario_path else False,\n",
    "            'versao_bloco1': versao_bloco1 or 'desconhecida'\n",
    "        }\n",
    "\n",
    "        if migrado_de:\n",
    "            entrada['migrado_de'] = str(migrado_de)\n",
    "\n",
    "        log['pasta_base_atual'] = str(pasta_base)\n",
    "        log['timestamp'] = timestamp\n",
    "\n",
    "        # S√≥ registrar dicion√°rio se ele REALMENTE existir\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            log['dicionario_atual'] = str(dicionario_path)\n",
    "        else:\n",
    "            log['dicionario_atual'] = None\n",
    "\n",
    "        log['historico'].append(entrada)\n",
    "        log['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "\n",
    "        cls.salvar_log(log)\n",
    "\n",
    "        print(f\"\\nüìç Localizador atualizado:\")\n",
    "        print(f\"   Container: {pasta_base.name}\")\n",
    "        print(f\"   Timestamp: {timestamp}\")\n",
    "        print(f\"   Vers√£o BLOCO 1: {versao_bloco1 or 'desconhecida'}\")\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            print(f\"   Dicion√°rio: {dicionario_path.name}\")\n",
    "        print(f\"   Log: {cls.LOG_FILE}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: SeletorPastaComTimer (GUI COM TIMER)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class SeletorPastaComTimer:\n",
    "    \"\"\"Seletor de pasta destino com timer de 10s e mem√≥ria\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_directory.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultima_pasta(self):\n",
    "        \"\"\"Carrega √∫ltima pasta usada\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultima_pasta = Path(config.get('last_directory', ''))\n",
    "                if ultima_pasta.exists():\n",
    "                    return ultima_pasta\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, pasta):\n",
    "        \"\"\"Salva escolha para pr√≥xima execu√ß√£o\"\"\"\n",
    "        config = {\n",
    "            'last_directory': str(pasta),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_pasta_destino(self, pasta):\n",
    "        \"\"\"Valida se pasta tem permiss√µes adequadas\"\"\"\n",
    "        pasta = Path(pasta)\n",
    "\n",
    "        # Verificar permiss√£o de escrita\n",
    "        if not os.access(pasta, os.W_OK):\n",
    "            return False, \"‚ùå Sem permiss√£o de escrita\"\n",
    "\n",
    "        # Verificar espa√ßo em disco (m√≠nimo 100MB)\n",
    "        stat = os.statvfs(pasta) if hasattr(os, 'statvfs') else None\n",
    "        if stat:\n",
    "            espaco_livre = stat.f_bavail * stat.f_frsize\n",
    "            if espaco_livre < 100 * 1024 * 1024:  # 100MB\n",
    "                return False, (\n",
    "                    f\"‚ùå Espa√ßo insuficiente \"\n",
    "                    f\"({espaco_livre/1024/1024:.1f}MB)\"\n",
    "                )\n",
    "\n",
    "        return True, \"‚úÖ Pasta v√°lida\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultima_pasta = self.carregar_ultima_pasta()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Pasta Destino\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # T√≠tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"üìÇ Pasta DESTINO\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultima_pasta:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultima_pasta}\"\n",
    "        else:\n",
    "            msg = \"Primeira execu√ß√£o - selecione pasta\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [10]\n",
    "        if ultima_pasta:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # Bot√µes\n",
    "        def escolher_nova():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            nova_pasta = filedialog.askdirectory(\n",
    "                title=\"Pasta DESTINO\",\n",
    "                initialdir=ultima_pasta if ultima_pasta else None\n",
    "            )\n",
    "\n",
    "            if nova_pasta:\n",
    "                valido, msg = self.validar_pasta_destino(nova_pasta)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Pasta Inv√°lida\", msg)\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(nova_pasta)\n",
    "                    self.resultado['acao'] = 'NOVA'\n",
    "            else:\n",
    "                self.resultado['path'] = ultima_pasta\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultima_pasta\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"üìÅ Nova Pasta\",\n",
    "            command=escolher_nova,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultima_pasta:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"‚úÖ Usar √öltima\",\n",
    "                command=usar_ultima,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: SeletorOrigemComTimer (GUI MIGRA√á√ÉO)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class SeletorOrigemComTimer:\n",
    "    \"\"\"Pergunta se deseja copiar arquivos de execu√ß√£o anterior\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'copiar': False, 'path': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def perguntar_origem(self):\n",
    "        \"\"\"GUI com timer de 5s (default: N√ÉO)\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Copiar Arquivos Anteriores?\")\n",
    "        root.geometry(\"650x350\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 175\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"üìÇ Copiar arquivos de execu√ß√£o anterior?\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        msg = (\n",
    "            \"Se houver dicion√°rios, logs ou outputs anteriores,\\n\"\n",
    "            \"voc√™ pode copi√°-los para a nova estrutura.\"\n",
    "        )\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        contador = [5]\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"{contador[0]}s (auto: N√ÉO)\",\n",
    "            font=('Arial', 18, 'bold'),\n",
    "            fg='#FF6600',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 20))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"{contador[0]}s (auto: N√ÉO)\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0:\n",
    "                self.timeout_ocorreu = True\n",
    "                self.resultado['copiar'] = False\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "        def sim_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            pasta_origem = filedialog.askdirectory(\n",
    "                title=\"Selecione pasta ORIGEM (execu√ß√£o anterior)\"\n",
    "            )\n",
    "            if pasta_origem:\n",
    "                self.resultado['copiar'] = True\n",
    "                self.resultado['path'] = Path(pasta_origem)\n",
    "            else:\n",
    "                self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def nao_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"‚úÖ SIM - Selecionar Origem\",\n",
    "            command=sim_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"‚ùå N√ÉO - Come√ßar do Zero\",\n",
    "            command=nao_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: LimpadorRoot (DETEC√á√ÉO DE POLUI√á√ÉO)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class LimpadorRoot:\n",
    "    \"\"\"Detecta e limpa pastas antigas no root\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_root):\n",
    "        self.pasta_root = Path(pasta_root)\n",
    "\n",
    "    def detectar_poluicao(self):\n",
    "        \"\"\"Encontra pastas numeradas antigas\"\"\"\n",
    "        pastas_numeradas = [\n",
    "            p for p in self.pasta_root.iterdir()\n",
    "            if p.is_dir() and p.name[:2].isdigit() and '_' in p.name\n",
    "        ]\n",
    "        return pastas_numeradas\n",
    "\n",
    "    def perguntar_limpeza(self, pastas):\n",
    "        \"\"\"GUI para decidir o que fazer com pastas antigas\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Limpar Root?\")\n",
    "        root.geometry(\"650x400\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 200\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"‚ö†Ô∏è  Pastas antigas detectadas no root\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white',\n",
    "            fg='#FF6600'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        msg = f\"Encontradas {len(pastas)} pastas soltas:\\n\\n\"\n",
    "        msg += \"\\n\".join([f\"‚Ä¢ {p.name}\" for p in pastas[:5]])\n",
    "        if len(pastas) > 5:\n",
    "            msg += f\"\\n... e mais {len(pastas)-5}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        resultado = {'acao': None}\n",
    "\n",
    "        def mover():\n",
    "            resultado['acao'] = 'MOVER'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def deletar():\n",
    "            resultado['acao'] = 'DELETAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def ignorar():\n",
    "            resultado['acao'] = 'IGNORAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"üì¶ Mover p/ Estrutura\",\n",
    "            command=mover,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"üóëÔ∏è  Deletar\",\n",
    "            command=deletar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#F44336',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"‚è≠Ô∏è  Ignorar\",\n",
    "            command=ignorar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.mainloop()\n",
    "        return resultado['acao']\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: GerenciadorMigracao (C√ìPIA COMPLETA COM LOG)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class GerenciadorMigracao:\n",
    "    \"\"\"Gerencia c√≥pia completa de execu√ß√µes anteriores\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_origem, pasta_destino_container):\n",
    "        self.pasta_origem = Path(pasta_origem)\n",
    "        self.pasta_destino = Path(pasta_destino_container)\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.log_detalhado = []\n",
    "        self.erros = []\n",
    "\n",
    "    def detectar_estrutura(self):\n",
    "        \"\"\"Detecta pastas e dicion√°rios na origem\"\"\"\n",
    "        pastas = [\n",
    "            p for p in self.pasta_origem.iterdir()\n",
    "            if p.is_dir() and (\n",
    "                p.name[:2].isdigit() or\n",
    "                'dicionario' in p.name.lower()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        dicionarios = []\n",
    "        pasta_dict = self.pasta_origem / '05_Dicionarios'\n",
    "\n",
    "        if pasta_dict.exists():\n",
    "            dicionarios.extend(list(pasta_dict.glob('*.json')))\n",
    "\n",
    "        dicionarios.extend(\n",
    "            list(self.pasta_origem.glob('dicionario*.json'))\n",
    "        )\n",
    "        dicionarios = list(set(dicionarios))\n",
    "\n",
    "        return pastas, dicionarios\n",
    "\n",
    "    def validar_dicionario(self, arquivo_json):\n",
    "        \"\"\"Valida integridade do dicion√°rio JSON\"\"\"\n",
    "        try:\n",
    "            with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Verificar estrutura m√≠nima\n",
    "            if not isinstance(data, dict):\n",
    "                return False, \"JSON n√£o √© um dicion√°rio\"\n",
    "\n",
    "            return True, \"‚úÖ V√°lido\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            return False, f\"JSON inv√°lido: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Erro: {str(e)}\"\n",
    "\n",
    "    def copiar_tudo(self):\n",
    "        \"\"\"Copia tudo com tratamento de erros\"\"\"\n",
    "        pastas, dicionarios = self.detectar_estrutura()\n",
    "\n",
    "        print(f\"\\nüìÇ MIGRA√á√ÉO COMPLETA\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "        print(f\"   De: {self.pasta_origem}\")\n",
    "        print(f\"   Para: {self.pasta_destino}\")\n",
    "        print(f\"   Pastas: {len(pastas)}\")\n",
    "        print(f\"   Dicion√°rios: {len(dicionarios)}\")\n",
    "        print()\n",
    "\n",
    "        if not pastas and not dicionarios:\n",
    "            print(\"‚ÑπÔ∏è  Nada para copiar\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(\"Copiar? (S/N ou Enter=S): \", end='')\n",
    "        resposta = input().strip().upper()\n",
    "        if resposta and resposta != 'S':\n",
    "            print(\"‚ùå Migra√ß√£o cancelada\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(f\"\\nüîÑ Copiando...\\n\")\n",
    "\n",
    "        arquivos_copiados = 0\n",
    "        bytes_copiados = 0\n",
    "        dicionarios_copiados = []\n",
    "\n",
    "        # Copiar pastas\n",
    "        for pasta in sorted(pastas):\n",
    "            try:\n",
    "                if pasta.name == '05_Dicionarios':\n",
    "                    continue\n",
    "\n",
    "                destino_pasta = self.pasta_destino / pasta.name\n",
    "                destino_pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                print(f\"üìÅ {pasta.name}\", end='')\n",
    "                arquivos_pasta = 0\n",
    "                bytes_pasta = 0\n",
    "\n",
    "                for arquivo in pasta.rglob('*'):\n",
    "                    if arquivo.is_file():\n",
    "                        try:\n",
    "                            destino_arq = (\n",
    "                                destino_pasta /\n",
    "                                arquivo.relative_to(pasta)\n",
    "                            )\n",
    "                            destino_arq.parent.mkdir(\n",
    "                                parents=True,\n",
    "                                exist_ok=True\n",
    "                            )\n",
    "                            shutil.copy2(arquivo, destino_arq)\n",
    "                            arquivos_copiados += 1\n",
    "                            arquivos_pasta += 1\n",
    "                            bytes_pasta += arquivo.stat().st_size\n",
    "                        except Exception as e:\n",
    "                            self.erros.append({\n",
    "                                'arquivo': str(arquivo),\n",
    "                                'erro': str(e)\n",
    "                            })\n",
    "\n",
    "                bytes_copiados += bytes_pasta\n",
    "                tamanho_kb = bytes_pasta/1024\n",
    "                print(f\" ‚Üí {arquivos_pasta} arquivos ({tamanho_kb:.1f} KB)\")\n",
    "\n",
    "                self.log_detalhado.append({\n",
    "                    'tipo': 'pasta',\n",
    "                    'nome': pasta.name,\n",
    "                    'arquivos': arquivos_pasta,\n",
    "                    'bytes': bytes_pasta\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" ‚ùå ERRO: {str(e)}\")\n",
    "                self.erros.append({\n",
    "                    'pasta': pasta.name,\n",
    "                    'erro': str(e)\n",
    "                })\n",
    "\n",
    "        # Copiar dicion√°rios\n",
    "        if dicionarios:\n",
    "            pasta_dict_destino = self.pasta_destino / '05_Dicionarios'\n",
    "            pasta_dict_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            print(f\"\\nüìö DICION√ÅRIOS ({len(dicionarios)}):\")\n",
    "\n",
    "            for dic in dicionarios:\n",
    "                try:\n",
    "                    # Validar antes de copiar\n",
    "                    valido, msg = self.validar_dicionario(dic)\n",
    "\n",
    "                    destino_dic = pasta_dict_destino / dic.name\n",
    "                    shutil.copy2(dic, destino_dic)\n",
    "                    tamanho = dic.stat().st_size\n",
    "\n",
    "                    status = \"‚úÖ\" if valido else \"‚ö†Ô∏è\"\n",
    "                    tamanho_kb = tamanho/1024\n",
    "                    print(f\"   {status} {dic.name} ({tamanho_kb:.1f} KB) - {msg}\")\n",
    "\n",
    "                    dicionarios_copiados.append(str(destino_dic))\n",
    "                    arquivos_copiados += 1\n",
    "                    bytes_copiados += tamanho\n",
    "\n",
    "                    self.log_detalhado.append({\n",
    "                        'tipo': 'dicionario',\n",
    "                        'nome': dic.name,\n",
    "                        'bytes': tamanho,\n",
    "                        'path': str(destino_dic),\n",
    "                        'validado': valido\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå {dic.name}: {str(e)}\")\n",
    "                    self.erros.append({\n",
    "                        'dicionario': dic.name,\n",
    "                        'erro': str(e)\n",
    "                    })\n",
    "\n",
    "        total_mb = bytes_copiados/1024/1024\n",
    "        print(f\"\\n‚úÖ TOTAL: {arquivos_copiados} arquivos, {total_mb:.2f} MB\")\n",
    "\n",
    "        if self.erros:\n",
    "            print(f\"‚ö†Ô∏è  {len(self.erros)} erros durante c√≥pia (ver log)\")\n",
    "\n",
    "        self._salvar_log_local({\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'bytes': bytes_copiados,\n",
    "            'dicionarios': len(dicionarios_copiados),\n",
    "            'erros': len(self.erros),\n",
    "            'detalhes': self.log_detalhado,\n",
    "            'log_erros': self.erros\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'dicionarios': dicionarios_copiados,\n",
    "            'erros': self.erros\n",
    "        }\n",
    "\n",
    "    def _salvar_log_local(self, info):\n",
    "        \"\"\"Salva log detalhado da migra√ß√£o\"\"\"\n",
    "        log_file = self.pasta_destino / 'log_migracoes.json'\n",
    "\n",
    "        if log_file.exists():\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                historico = json.load(f)\n",
    "        else:\n",
    "            historico = {'migracoes': []}\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': self.timestamp,\n",
    "            'data_hora': datetime.now().isoformat(),\n",
    "            'pasta_origem': str(self.pasta_origem),\n",
    "            'pasta_destino': str(self.pasta_destino),\n",
    "            **info\n",
    "        }\n",
    "\n",
    "        historico['migracoes'].append(entrada)\n",
    "        historico['ultima_migracao'] = self.timestamp\n",
    "\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(historico, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"üíæ Log: {log_file.name}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE: FileManagerInterativo (GERENCIADOR DE ARQUIVOS)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path=None):\n",
    "        self.base_path = Path(base_path) if base_path else Path.cwd()\n",
    "\n",
    "        # Estrutura de pastas padr√£o\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        print(f\"‚úÖ FileManager inicializado\")\n",
    "        print(f\"   üìÇ Container: {self.base_path.name}\")\n",
    "        print(f\"   üïê Timestamp: {self.timestamp}\")\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = (\n",
    "            self.pastas[pasta] /\n",
    "            f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "        )\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  N√£o foi poss√≠vel abrir pasta: {e}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FUN√á√ÉO: gerar_readme\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def gerar_readme(pasta_base, versao_bloco1):\n",
    "    \"\"\"Gera README.md na pasta container\"\"\"\n",
    "    readme = f\"\"\"# üìö PROCESSADOR DE ARQUIVOS DESCONHECIDOS\n",
    "\n",
    "**Gerado:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Pasta:** {pasta_base}\n",
    "**Vers√£o BLOCO 1:** {versao_bloco1}\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ ESTRUTURA\n",
    "\n",
    "```\n",
    "{pasta_base.name}/\n",
    "‚îú‚îÄ‚îÄ 01_Entrada/          ‚Üê Arquivos originais\n",
    "‚îú‚îÄ‚îÄ 02_Processados/      ‚Üê Dados limpos\n",
    "‚îú‚îÄ‚îÄ 03_Outputs/          ‚Üê Resultados finais\n",
    "‚îú‚îÄ‚îÄ 04_Logs/             ‚Üê Logs de execu√ß√£o ‚≠ê COMUNICA√á√ÉO VIA LOG\n",
    "‚îú‚îÄ‚îÄ 05_Dicionarios/      ‚Üê Mapeamentos DE-PARA\n",
    "‚îú‚îÄ‚îÄ 06_Codigos_Integracao/ ‚Üê Scripts reutiliz√°veis\n",
    "‚îú‚îÄ‚îÄ README.md            ‚Üê Este arquivo\n",
    "‚îî‚îÄ‚îÄ log_migracoes.json   ‚Üê Hist√≥rico de migra√ß√µes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö LOCALIZADOR DE DICION√ÅRIO\n",
    "\n",
    "**Para notebooks consumidores (BLOCO 2+):**\n",
    "\n",
    "```python\n",
    "from bloco1 import LocalizadorDicionario\n",
    "\n",
    "# Obter dicion√°rio atual\n",
    "dicionario_path = LocalizadorDicionario.obter_dicionario_atual()\n",
    "\n",
    "# Obter pasta base\n",
    "pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "# Obter timestamp da execu√ß√£o\n",
    "timestamp = LocalizadorDicionario.obter_timestamp_atual()\n",
    "\n",
    "# Carregar dicion√°rio\n",
    "import json\n",
    "with open(dicionario_path, 'r', encoding='utf-8') as f:\n",
    "    dicionario = json.load(f)\n",
    "```\n",
    "\n",
    "**Log global:** `~/.processador_dicionario_localizador.json`\n",
    "\n",
    "---\n",
    "\n",
    "## üîó COMUNICA√á√ÉO ENTRE BLOCOS (0% MEM√ìRIA, 100% LOG)\n",
    "\n",
    "Todos os blocos seguem o padr√£o:\n",
    "\n",
    "1. **LER** do LOG GLOBAL:\n",
    "   - pasta_base_atual\n",
    "   - timestamp\n",
    "   - dicionario_atual (se existir)\n",
    "\n",
    "2. **RECRIAR** objetos localmente:\n",
    "   - FileManager(pasta_base)\n",
    "   - Carregar dicion√°rio de 04_Logs/\n",
    "\n",
    "3. **PROCESSAR** dados do bloco\n",
    "\n",
    "4. **SALVAR** estado em 04_Logs/:\n",
    "   - .bloco_N_state.json\n",
    "   - Dados espec√≠ficos do bloco\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ HIST√ìRICO DE MIGRA√á√ïES\n",
    "\n",
    "Ver: `log_migracoes.json`\n",
    "\n",
    "---\n",
    "\n",
    "## üìã ESTADO DO BLOCO 1\n",
    "\n",
    "Ver: `04_Logs/.bloco_1_state.json`\n",
    "\n",
    "---\n",
    "\n",
    "## üÜò SUPORTE\n",
    "\n",
    "- Erros: `04_Logs/`\n",
    "- Dicion√°rio perdido: Execute BLOCO 1\n",
    "- Migra√ß√£o: Consulte `log_migracoes.json`\n",
    "- Vers√£o do c√≥digo: `{versao_bloco1}`\n",
    "\"\"\"\n",
    "\n",
    "    readme_path = pasta_base / 'README.md'\n",
    "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    print(f\"üìñ README: {readme_path.name}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXECU√á√ÉO PRINCIPAL DO BLOCO 1\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 1: SELECIONANDO PASTA DESTINO...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor = SeletorPastaComTimer()\n",
    "resultado_destino = seletor.selecionar_com_timer()\n",
    "\n",
    "if not resultado_destino['path']:\n",
    "    print(\"‚ùå Nenhuma pasta selecionada\")\n",
    "    raise ValueError(\"Execu√ß√£o cancelada\")\n",
    "\n",
    "print(f\"\\n‚úÖ Destino: {resultado_destino['path']}\")\n",
    "print(f\"   A√ß√£o: {resultado_destino['acao']}\")\n",
    "seletor.salvar_escolha(resultado_destino['path'])\n",
    "\n",
    "pasta_root_destino = resultado_destino['path']\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 2: VERIFICANDO POLUI√á√ÉO NO ROOT...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "limpador = LimpadorRoot(pasta_root_destino)\n",
    "pastas_poluidas = limpador.detectar_poluicao()\n",
    "\n",
    "acao = None\n",
    "if pastas_poluidas:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(pastas_poluidas)} pastas antigas no root!\")\n",
    "    acao = limpador.perguntar_limpeza(pastas_poluidas)\n",
    "\n",
    "    if acao == 'DELETAR':\n",
    "        print(\"\\nüóëÔ∏è  Deletando...\")\n",
    "        for pasta in pastas_poluidas:\n",
    "            try:\n",
    "                shutil.rmtree(pasta)\n",
    "                print(f\"   ‚úÖ {pasta.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå {pasta.name}: {e}\")\n",
    "\n",
    "    elif acao == 'MOVER':\n",
    "        print(\"\\nüì¶ Mover ser√° feito ap√≥s criar container\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n‚è≠Ô∏è  Ignorando pastas antigas\")\n",
    "else:\n",
    "    print(\"‚úÖ Root limpo\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 3: CRIANDO PASTA CONTAINER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "nome_container = f\"PROCESSAR_ARQUIVOS_{timestamp}\"\n",
    "pasta_container = pasta_root_destino / nome_container\n",
    "\n",
    "pasta_container.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"‚úÖ Container: {nome_container}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 4: COPIAR DE EXECU√á√ÉO ANTERIOR?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor_origem = SeletorOrigemComTimer()\n",
    "resultado_origem = seletor_origem.perguntar_origem()\n",
    "\n",
    "dicionarios_migrados = []\n",
    "info_mig = {}\n",
    "\n",
    "if resultado_origem['copiar'] and resultado_origem['path']:\n",
    "    print(f\"\\nüìÇ Origem: {resultado_origem['path']}\")\n",
    "    gerenciador_mig = GerenciadorMigracao(\n",
    "        resultado_origem['path'],\n",
    "        pasta_container\n",
    "    )\n",
    "    info_mig = gerenciador_mig.copiar_tudo()\n",
    "\n",
    "    if info_mig.get('migrado'):\n",
    "        print(f\"\\n‚úÖ Migra√ß√£o conclu√≠da\")\n",
    "        if info_mig.get('dicionarios'):\n",
    "            dicionarios_migrados = info_mig['dicionarios']\n",
    "            print(f\"   üìö {len(dicionarios_migrados)} dicion√°rios copiados\")\n",
    "        if info_mig.get('erros'):\n",
    "            print(f\"   ‚ö†Ô∏è  {len(info_mig['erros'])} erros (ver log)\")\n",
    "else:\n",
    "    print(\"‚úÖ Come√ßando do zero (sem c√≥pia)\")\n",
    "\n",
    "# Mover pastas antigas se solicitado\n",
    "if pastas_poluidas and acao == 'MOVER':\n",
    "    print(\"\\nüì¶ Movendo pastas antigas para container...\")\n",
    "    for pasta in pastas_poluidas:\n",
    "        try:\n",
    "            destino = pasta_container / pasta.name\n",
    "            if destino.exists():\n",
    "                shutil.rmtree(destino)\n",
    "            shutil.move(str(pasta), str(destino))\n",
    "            print(f\"   ‚úÖ {pasta.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {pasta.name}: {e}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 5: INICIALIZANDO FILEMANAGER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fm = FileManagerInterativo(pasta_container)\n",
    "\n",
    "# Detectar dicion√°rio migrado (se existir)\n",
    "pasta_dict = fm.pastas['dicionarios']\n",
    "arquivos_dict = list(pasta_dict.glob('*.json'))\n",
    "\n",
    "dicionario_existente = None\n",
    "if arquivos_dict:\n",
    "    # Usar o mais recente\n",
    "    dicionario_existente = max(\n",
    "        arquivos_dict,\n",
    "        key=lambda p: p.stat().st_mtime\n",
    "    )\n",
    "    print(f\"üìö Dicion√°rio detectado: {dicionario_existente.name}\")\n",
    "\n",
    "# Registrar no localizador com timestamp E vers√£o\n",
    "LocalizadorDicionario.registrar_mudanca(\n",
    "    pasta_base=pasta_container,\n",
    "    timestamp=timestamp,\n",
    "    dicionario_path=dicionario_existente,  # None se n√£o existir\n",
    "    versao_bloco1=VERSAO_BLOCO1\n",
    ")\n",
    "\n",
    "# Gerar README\n",
    "gerar_readme(pasta_container, VERSAO_BLOCO1)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# MELHORIA 1: SALVAR ESTADO LOCAL (NOVO v4.4)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîµ ETAPA 6: SALVANDO ESTADO LOCAL...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calcular tamanho total do container\n",
    "tamanho_total = sum(\n",
    "    f.stat().st_size for f in pasta_container.rglob('*') if f.is_file()\n",
    ") / 1024 / 1024\n",
    "\n",
    "estado_bloco1 = {\n",
    "    'bloco': 1,\n",
    "    'versao': VERSAO_BLOCO1,\n",
    "    'versao_codigo': VERSAO_BLOCO1,\n",
    "    'data_versao': DATA_VERSAO,\n",
    "    'timestamp_execucao': timestamp,\n",
    "    'timestamp_registro': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'pasta_container': {\n",
    "        'nome': pasta_container.name,\n",
    "        'caminho': str(pasta_container),\n",
    "        'tamanho_mb': round(tamanho_total, 2)\n",
    "    },\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp,\n",
    "        'pastas_criadas': list(fm.pastas.keys())\n",
    "    },\n",
    "    'migracao': {\n",
    "        'realizada': resultado_origem.get('copiar', False),\n",
    "        'arquivos_migrados': info_mig.get('arquivos', 0),\n",
    "        'pasta_origem': str(resultado_origem.get('path', '')) if resultado_origem.get('copiar') else None\n",
    "    },\n",
    "    'localizador': {\n",
    "        'log_file': str(LocalizadorDicionario.LOG_FILE),\n",
    "        'pasta_base_registrada': str(pasta_container),\n",
    "        'timestamp_registrado': timestamp,\n",
    "        'dicionario_registrado': str(dicionario_existente) if dicionario_existente else None\n",
    "    },\n",
    "    'poluicao_root': {\n",
    "        'detectada': len(pastas_poluidas) if pastas_poluidas else 0,\n",
    "        'acao_tomada': acao if pastas_poluidas else 'NENHUMA'\n",
    "    },\n",
    "    'changelog': CHANGELOG_V44\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_1_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco1, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Estado local salvo\")\n",
    "print(f\"   üìÑ {arquivo_estado.name}\")\n",
    "print(f\"   üìä Tamanho container: {tamanho_total:.2f} MB\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 1 v4.4 CONCLU√çDO COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÇ Container: {pasta_container}\")\n",
    "print(f\"üïê Timestamp: {timestamp}\")\n",
    "print(f\"üìç Localizador: {LocalizadorDicionario.LOG_FILE}\")\n",
    "print(f\"üîñ Vers√£o: {VERSAO_BLOCO1}\")\n",
    "print(f\"\\nüìã Estrutura criada:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   ‚Ä¢ {pasta.name}\")\n",
    "print(f\"\\nüíæ Arquivos de estado:\")\n",
    "print(f\"   ‚Ä¢ LOG GLOBAL: {LocalizadorDicionario.LOG_FILE.name}\")\n",
    "print(f\"   ‚Ä¢ Estado local: {arquivo_estado.name}\")\n",
    "print(f\"   ‚Ä¢ README: README.md\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Pr√≥ximo: BLOCO 2 vai ler configura√ß√£o do LOG GLOBAL\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a370b26a4e017376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " üîç PROCESSADOR DE ARQUIVOS DESCONHECIDOS v4.4\n",
      "======================================================================\n",
      " Vers√£o: 4.4 | Data: 2025-10-17\n",
      " Timer | Migra√ß√£o | Dicion√°rios | Valida√ß√µes | Logs | Estado\n",
      "======================================================================\n",
      "\n",
      "üîç Validando depend√™ncias...\n",
      "   ‚úÖ pandas\n",
      "   ‚úÖ numpy\n",
      "   ‚úÖ openpyxl\n",
      "   ‚úÖ xlrd\n",
      "   ‚úÖ tkinter\n",
      "‚úÖ Todas as depend√™ncias instaladas!\n",
      "\n",
      "‚úÖ Imports carregados\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 1: SELECIONANDO PASTA DESTINO...\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Destino: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\n",
      "   A√ß√£o: MANTEVE\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 2: VERIFICANDO POLUI√á√ÉO NO ROOT...\n",
      "======================================================================\n",
      "‚úÖ Root limpo\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 3: CRIANDO PASTA CONTAINER...\n",
      "======================================================================\n",
      "‚úÖ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 4: COPIAR DE EXECU√á√ÉO ANTERIOR?\n",
      "======================================================================\n",
      "‚úÖ Come√ßando do zero (sem c√≥pia)\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 5: INICIALIZANDO FILEMANAGER...\n",
      "======================================================================\n",
      "‚úÖ FileManager inicializado\n",
      "   üìÇ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   üïê Timestamp: 20251019_060722\n",
      "\n",
      "üìç Localizador atualizado:\n",
      "   Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   Timestamp: 20251019_060722\n",
      "   Vers√£o BLOCO 1: 4.4\n",
      "   Log: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "üìñ README: README.md\n",
      "\n",
      "======================================================================\n",
      "üîµ ETAPA 6: SALVANDO ESTADO LOCAL...\n",
      "======================================================================\n",
      "‚úÖ Estado local salvo\n",
      "   üìÑ .bloco_1_state.json\n",
      "   üìä Tamanho container: 0.00 MB\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 1 v4.4 CONCLU√çDO COM SUCESSO\n",
      "======================================================================\n",
      "\n",
      "üìÇ Container: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "üïê Timestamp: 20251019_060722\n",
      "üìç Localizador: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "üîñ Vers√£o: 4.4\n",
      "\n",
      "üìã Estrutura criada:\n",
      "   ‚Ä¢ 01_Entrada\n",
      "   ‚Ä¢ 02_Processados\n",
      "   ‚Ä¢ 03_Outputs\n",
      "   ‚Ä¢ 04_Logs\n",
      "   ‚Ä¢ 05_Dicionarios\n",
      "   ‚Ä¢ 06_Codigos_Integracao\n",
      "\n",
      "üíæ Arquivos de estado:\n",
      "   ‚Ä¢ LOG GLOBAL: .processador_dicionario_localizador.json\n",
      "   ‚Ä¢ Estado local: .bloco_1_state.json\n",
      "   ‚Ä¢ README: README.md\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üí° Pr√≥ximo: BLOCO 2 vai ler configura√ß√£o do LOG GLOBAL\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:25.354236Z",
     "start_time": "2025-10-19T09:07:25.303878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 2: CLASSES AUXILIARES\n",
    "# Versao: 4.3 - REVISADO (COMUNICACAO VIA LOG COMPLETA)\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: LocalizadorDicionario (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localizacao persistente de dicionarios entre\n",
    "    sessoes.\n",
    "\n",
    "    Mantem log global em: ~/.processador_dicionario_localizador.json\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.0',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicionario atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Dicionario nao encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Dicionario nao existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Pasta base nao encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Pasta base nao existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: FileManagerInterativo (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "\n",
    "        # Estrutura de pastas padrao\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = self.pastas[pasta] / f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"Nao foi possivel abrir pasta: {e}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: SeletorArquivo (GUI COM TIMER E VALIDACOES)\n",
    "# ===================================================================\n",
    "\n",
    "class SeletorArquivo:\n",
    "    \"\"\"Seletor de arquivo com timer de 10s e validacoes robustas\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_file.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultimo_arquivo(self):\n",
    "        \"\"\"Carrega ultimo arquivo usado\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultimo_arquivo = Path(config.get('last_file', ''))\n",
    "                if ultimo_arquivo.exists():\n",
    "                    return ultimo_arquivo\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, arquivo):\n",
    "        \"\"\"Salva escolha para proxima execucao\"\"\"\n",
    "        config = {\n",
    "            'last_file': str(arquivo),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_arquivo(self, arquivo_path):\n",
    "        \"\"\"Valida se arquivo e adequado para processamento\"\"\"\n",
    "        arquivo = Path(arquivo_path)\n",
    "\n",
    "        # Verificar existencia\n",
    "        if not arquivo.exists():\n",
    "            return False, \"Arquivo nao existe\"\n",
    "\n",
    "        # Verificar se e arquivo (nao diretorio)\n",
    "        if not arquivo.is_file():\n",
    "            return False, \"Nao e um arquivo\"\n",
    "\n",
    "        # Verificar permissao de leitura\n",
    "        if not os.access(arquivo, os.R_OK):\n",
    "            return False, \"Sem permissao de leitura\"\n",
    "\n",
    "        # Verificar tamanho (maximo 500MB)\n",
    "        tamanho_mb = arquivo.stat().st_size / (1024 * 1024)\n",
    "        if tamanho_mb > 500:\n",
    "            return False, f\"Arquivo muito grande ({tamanho_mb:.1f}MB)\"\n",
    "\n",
    "        # Verificar extensao\n",
    "        extensoes_validas = {'.xlsx', '.xls', '.csv', '.txt'}\n",
    "        if arquivo.suffix.lower() not in extensoes_validas:\n",
    "            return False, f\"Extensao invalida ({arquivo.suffix})\"\n",
    "\n",
    "        return True, \"Arquivo valido\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultimo_arquivo = self.carregar_ultimo_arquivo()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Selecionar Arquivo\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Titulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecionar Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultimo_arquivo:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultimo_arquivo.name}\"\n",
    "        else:\n",
    "            msg = \"Primeira execucao - selecione arquivo\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [15]\n",
    "        if ultimo_arquivo:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # Botoes\n",
    "        def escolher_novo():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "\n",
    "            novo_arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecionar Arquivo\",\n",
    "                initialdir=ultimo_arquivo.parent if ultimo_arquivo else None,\n",
    "                filetypes=[\n",
    "                    (\"Arquivos suportados\", \"*.xlsx;*.xls;*.csv;*.txt\"),\n",
    "                    (\"Excel\", \"*.xlsx;*.xls\"),\n",
    "                    (\"CSV\", \"*.csv\"),\n",
    "                    (\"Todos\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if novo_arquivo:\n",
    "                valido, msg = self.validar_arquivo(novo_arquivo)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Arquivo Invalido\", msg)\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(novo_arquivo)\n",
    "                    self.resultado['acao'] = 'NOVO'\n",
    "            else:\n",
    "                self.resultado['path'] = ultimo_arquivo\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultimo():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultimo_arquivo\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultimo_arquivo:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"Usar Ultimo\",\n",
    "                command=usar_ultimo,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: DetectorCabecalho (ANALISE INTELIGENTE COM LOG)\n",
    "# ===================================================================\n",
    "\n",
    "class DetectorCabecalho:\n",
    "    \"\"\"\n",
    "    Detecta automaticamente a linha de cabecalho em arquivos.\n",
    "\n",
    "    Usa sistema de scoring baseado em:\n",
    "    - Preenchimento (70%+ colunas com dados)\n",
    "    - Tipo String (80%+ colunas texto)\n",
    "    - Valores unicos (indicador de rotulos)\n",
    "    - Palavras-chave tipicas de cabecalho\n",
    "    - Posicao na planilha (primeiras linhas tem prioridade)\n",
    "    \"\"\"\n",
    "\n",
    "    # CONFIGURACAO EXTERNALIZAVEL\n",
    "    PALAVRAS_CHAVE_PADRAO = [\n",
    "        'codigo', 'nome', 'descri', 'data', 'valor', 'quantidade',\n",
    "        'centro', 'produto', 'material', 'sigla', 'tipo', 'grupo'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, df, palavras_chave=None):\n",
    "        self.df = df\n",
    "        self.scores = []\n",
    "        self.log_decisoes = []\n",
    "        self.palavras_chave = (\n",
    "            palavras_chave if palavras_chave\n",
    "            else self.PALAVRAS_CHAVE_PADRAO\n",
    "        )\n",
    "\n",
    "    def detectar(self, n_linhas=50):\n",
    "        \"\"\"\n",
    "        Analisa primeiras n linhas e retorna indice do cabecalho.\n",
    "\n",
    "        Args:\n",
    "            n_linhas: Numero de linhas a analisar\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                'indice': int,  # Linha detectada como cabecalho\n",
    "                'score': float,  # Confianca da deteccao (0-1)\n",
    "                'metodo': str,   # Como foi detectado\n",
    "                'scores_todas_linhas': list,  # Para debug\n",
    "                'log_decisoes': list  # Historico de analise\n",
    "            }\n",
    "        \"\"\"\n",
    "        n_linhas = min(n_linhas, len(self.df))\n",
    "\n",
    "        for i in range(n_linhas):\n",
    "            linha = self.df.iloc[i]\n",
    "            score = 0\n",
    "            detalhes = {'linha': i, 'criterios': {}}\n",
    "\n",
    "            # Criterio 1: Preenchimento (30 pontos)\n",
    "            preenchimento = linha.notna().sum() / len(linha)\n",
    "            if preenchimento >= 0.7:\n",
    "                pontos = 30 * (preenchimento - 0.7) / 0.3\n",
    "                score += pontos\n",
    "                detalhes['criterios']['preenchimento'] = (\n",
    "                    f\"{preenchimento:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 2: Tipo String (30 pontos)\n",
    "            tipos_string = sum(isinstance(v, str) for v in linha)\n",
    "            proporcao_string = tipos_string / len(linha)\n",
    "            if proporcao_string >= 0.8:\n",
    "                pontos = 30 * (proporcao_string - 0.8) / 0.2\n",
    "                score += pontos\n",
    "                detalhes['criterios']['strings'] = (\n",
    "                    f\"{proporcao_string:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 3: Valores unicos (20 pontos)\n",
    "            valores_unicos = len(\n",
    "                set(str(v) for v in linha if pd.notna(v))\n",
    "            )\n",
    "            if valores_unicos >= len(linha) * 0.8:\n",
    "                pontos = 20\n",
    "                score += pontos\n",
    "                detalhes['criterios']['unicos'] = (\n",
    "                    f\"{valores_unicos}/{len(linha)} (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 4: Palavras-chave (10 pontos)\n",
    "            texto_linha = ' '.join(\n",
    "                str(v).lower() for v in linha if pd.notna(v)\n",
    "            )\n",
    "            palavras_encontradas = sum(\n",
    "                1 for p in self.palavras_chave if p in texto_linha\n",
    "            )\n",
    "            if palavras_encontradas > 0:\n",
    "                pontos = min(10, palavras_encontradas * 3)\n",
    "                score += pontos\n",
    "                detalhes['criterios']['palavras'] = (\n",
    "                    f\"{palavras_encontradas} palavras (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 5: Posicao (10 pontos)\n",
    "            # Primeiras linhas tem vantagem\n",
    "            if i < 50:\n",
    "                pontos = 10 * (1 - (i / 50))\n",
    "                score += pontos\n",
    "                detalhes['criterios']['posicao'] = (\n",
    "                    f\"linha {i} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            detalhes['score_total'] = score\n",
    "            self.scores.append(score)\n",
    "            self.log_decisoes.append(detalhes)\n",
    "\n",
    "        # Encontrar melhor score\n",
    "        melhor_indice = self.scores.index(max(self.scores))\n",
    "        melhor_score = self.scores[melhor_indice]\n",
    "\n",
    "        # Normalizar score para 0-1\n",
    "        score_normalizado = min(1.0, melhor_score / 100)\n",
    "\n",
    "        resultado = {\n",
    "            'indice': melhor_indice,\n",
    "            'score': score_normalizado,\n",
    "            'metodo': 'SCORING_AUTOMATICO',\n",
    "            'scores_todas_linhas': self.scores,\n",
    "            'log_decisoes': self.log_decisoes\n",
    "        }\n",
    "\n",
    "        return resultado\n",
    "\n",
    "# ===================================================================\n",
    "# INICIALIZACAO DO FILEMANAGER (CONECTANDO COM BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "    print(f\"Container do BLOCO 1 encontrado!\")\n",
    "    print(f\"   {pasta_base}\")\n",
    "\n",
    "    fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n{e}\")\n",
    "    print(\"\\nATENCAO: Execute o BLOCO 1 primeiro!\")\n",
    "    raise\n",
    "\n",
    "# ===================================================================\n",
    "# SALVAR ESTADO DO BLOCO 2 NO LOG\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco2 = {\n",
    "    'bloco': 2,\n",
    "    'versao': '4.3',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'classes_carregadas': [\n",
    "        'LocalizadorDicionario',\n",
    "        'FileManagerInterativo',\n",
    "        'SeletorArquivo',\n",
    "        'DetectorCabecalho'\n",
    "    ],\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_2_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco2, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2 CONCLUIDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nClasses carregadas:\")\n",
    "print(\"   LocalizadorDicionario ........... OK\")\n",
    "print(\"   FileManagerInterativo ........... OK\")\n",
    "print(\"   SeletorArquivo .................. OK\")\n",
    "print(\"   DetectorCabecalho ............... OK\")\n",
    "print(\"\\nFileManager ativo:\")\n",
    "print(f\"   Base: {fm.base_path}\")\n",
    "print(f\"   Timestamp: {fm.timestamp}\")\n",
    "print(\"\\nEstrutura de pastas:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   {nome.ljust(20)}: {pasta.name}\")\n",
    "print(\"\\nEstado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\")\n",
    "print(\"=\"*70)"
   ],
   "id": "edd92dbd01fb89e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\n",
      "======================================================================\n",
      "Container do BLOCO 1 encontrado!\n",
      "   E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "======================================================================\n",
      "BLOCO 2 CONCLUIDO\n",
      "======================================================================\n",
      "\n",
      "Classes carregadas:\n",
      "   LocalizadorDicionario ........... OK\n",
      "   FileManagerInterativo ........... OK\n",
      "   SeletorArquivo .................. OK\n",
      "   DetectorCabecalho ............... OK\n",
      "\n",
      "FileManager ativo:\n",
      "   Base: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   Timestamp: 20251019_060725\n",
      "\n",
      "Estrutura de pastas:\n",
      "   entrada             : 01_Entrada\n",
      "   processados         : 02_Processados\n",
      "   outputs             : 03_Outputs\n",
      "   logs                : 04_Logs\n",
      "   dicionarios         : 05_Dicionarios\n",
      "   codigos_integracao  : 06_Codigos_Integracao\n",
      "\n",
      "Estado salvo:\n",
      "   .bloco_2_state.json\n",
      "\n",
      "======================================================================\n",
      "Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:31.733679Z",
     "start_time": "2025-10-19T09:07:31.693651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 3: DICION√ÅRIO INTELIGENTE + CLASSE GUI COM TIMER\n",
    "# Vers√£o: v4.5 - Dicion√°rio + GUIComTimer (sele√ß√£o no BLOCO 4)\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tkinter as tk\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 3: DICION√ÅRIO INTELIGENTE + GUI COM TIMER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. LER CONFIGURA√á√ïES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# ===================================================================\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå LOG GLOBAL n√£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\n‚úÖ CONFIGURA√á√ÉO CARREGADA DO LOG GLOBAL\")\n",
    "print(f\"   üìÅ Pasta base: {pasta_base.name}\")\n",
    "print(f\"   üïê Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. VALIDAR QUE BLOCO 2 FOI EXECUTADO\n",
    "# ===================================================================\n",
    "\n",
    "log_bloco2 = pasta_base / '04_Logs' / '.bloco_2_state.json'\n",
    "\n",
    "if not log_bloco2.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå BLOCO 2 n√£o foi executado!\\n\"\n",
    "        \"   Execute BLOCO 2 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_bloco2, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco2 = json.load(f)\n",
    "\n",
    "print(f\"\\n‚úÖ BLOCO 2 VALIDADO\")\n",
    "print(f\"   Executado em: {estado_bloco2['timestamp']}\")\n",
    "print(f\"   Classes: {', '.join(estado_bloco2['classes_carregadas'])}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. RECRIAR FILEMANAGER (N√ÉO ASSUMIR MEM√ìRIA)\n",
    "# ===================================================================\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "print(f\"\\n‚úÖ FileManager recriado: {fm.base_path.name}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4. CLASSE GUI COM TIMER (ex-BLOCO 4)\n",
    "# ===================================================================\n",
    "\n",
    "class GUIComTimer:\n",
    "    \"\"\"Implementa timer de 10s com countdown visual\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_janela_com_timer(titulo, largura, altura, tem_timer=True):\n",
    "        \"\"\"Cria janela base com timer\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(titulo)\n",
    "        root.geometry(f\"{largura}x{altura}\")\n",
    "        root.resizable(False, False)\n",
    "\n",
    "        # Centralizar\n",
    "        x = (root.winfo_screenwidth() // 2) - (largura // 2)\n",
    "        y = (root.winfo_screenheight() // 2) - (altura // 2)\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "        root.attributes('-topmost', True)\n",
    "        root.after(100, lambda: root.attributes('-topmost', False))\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        resultado = {'valor': None, 'cancelado': False, 'timeout': False}\n",
    "        contador = [10] if tem_timer else [0]\n",
    "\n",
    "        return root, frame, resultado, contador\n",
    "\n",
    "    @staticmethod\n",
    "    def adicionar_timer(frame, root, resultado, contador):\n",
    "        \"\"\"Adiciona timer visual\"\"\"\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"‚è±Ô∏è  {contador[0]}s\",\n",
    "            font=('Arial', 16, 'bold'),\n",
    "            fg='#FF4444',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 15))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not resultado['cancelado']:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"‚è±Ô∏è  {contador[0]}s\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0 and not resultado['cancelado']:\n",
    "                resultado['timeout'] = True\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        return countdown\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_botoes(frame, cmd_principal, cmd_secundario=None,\n",
    "                     label_principal=\"Confirmar\",\n",
    "                     label_secundario=\"Usar √öltimo\"):\n",
    "        \"\"\"Cria bot√µes padronizados\"\"\"\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(\n",
    "            fill=tk.X, pady=10\n",
    "        )\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=label_principal,\n",
    "            command=cmd_principal,\n",
    "            width=18,\n",
    "            height=2,\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        if cmd_secundario:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=label_secundario,\n",
    "                command=cmd_secundario,\n",
    "                width=18,\n",
    "                height=2,\n",
    "                bg='#2196F3',\n",
    "                fg='white',\n",
    "                font=('Arial', 10),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "print(\"\\n‚úÖ Classe GUIComTimer carregada\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. DICION√ÅRIO INTELIGENTE\n",
    "# ===================================================================\n",
    "\n",
    "class DicionarioInteligente:\n",
    "    \"\"\"Dicion√°rio com detec√ß√£o avan√ßada\"\"\"\n",
    "\n",
    "    def __init__(self, fm):\n",
    "        self.fm = fm\n",
    "        self.arquivo_dict = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "        self.dados = self._carregar_ou_criar()\n",
    "\n",
    "    def _carregar_ou_criar(self):\n",
    "        if self.arquivo_dict.exists():\n",
    "            try:\n",
    "                with open(self.arquivo_dict, 'r', encoding='utf-8') as f:\n",
    "                    dados = json.load(f)\n",
    "\n",
    "                if 'campos_conhecidos' not in dados:\n",
    "                    dados = self._migrar_formato_antigo(dados)\n",
    "                    self._salvar(dados)\n",
    "\n",
    "                n_campos = len(dados['campos_conhecidos'])\n",
    "                n_arquivos = len(dados.get('historico_arquivos', []))\n",
    "\n",
    "                print(f\"\\n‚úÖ DICION√ÅRIO PERSISTENTE CARREGADO\")\n",
    "                print(f\"   üìö {n_campos} campos conhecidos\")\n",
    "                print(f\"   üìÅ {n_arquivos} arquivos processados\")\n",
    "\n",
    "                return dados\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è  Erro ao carregar: {e}\")\n",
    "                print(\"   Criando novo dicion√°rio...\")\n",
    "                dados = self._criar_novo()\n",
    "                self._salvar(dados)\n",
    "                return dados\n",
    "        else:\n",
    "            print(f\"\\nüìù CRIANDO NOVO DICION√ÅRIO...\")\n",
    "            dados = self._criar_novo()\n",
    "            self._salvar(dados)\n",
    "            print(f\"‚úÖ Dicion√°rio criado: {len(dados['campos_conhecidos'])} campos\")\n",
    "            return dados\n",
    "\n",
    "    def _migrar_formato_antigo(self, dados_antigos):\n",
    "        novo = self._criar_novo()\n",
    "        if 'arquivos_processados' in dados_antigos:\n",
    "            novo['historico_arquivos'] = dados_antigos['arquivos_processados']\n",
    "        return novo\n",
    "\n",
    "    def _criar_novo(self):\n",
    "        \"\"\"Dicion√°rio com 22 campos padr√£o\"\"\"\n",
    "        return {\n",
    "            'versao': '4.5',\n",
    "            'criado_em': datetime.now().isoformat(),\n",
    "            'ultima_atualizacao': datetime.now().isoformat(),\n",
    "            'config_sistema': {\n",
    "                'timeout_sessao_minutos': 60,\n",
    "                'padroes_csv_detectados': []\n",
    "            },\n",
    "            'campos_conhecidos': {\n",
    "                'Centro': {\n",
    "                    'tipo_dado': 'Codigo_Centro',\n",
    "                    'regex': r'^[5-9]\\d{3}$',\n",
    "                    'sinonimos': ['Centro', 'C√≥digo de Centro', 'Cod Centro',\n",
    "                                  'Unidade Operacional:Centro'],\n",
    "                    'exemplos': ['5025', '5065', '5174'],\n",
    "                    'descricao': 'C√≥digo num√©rico de 4 d√≠gitos',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla': {\n",
    "                    'tipo_dado': 'Sigla_Base',\n",
    "                    'regex': r'^[A-Z]{4,10}$',\n",
    "                    'sinonimos': ['Sigla', 'Sigla Base', 'Sigla Centro', 'Base'],\n",
    "                    'exemplos': ['BABET', 'BAPLAN', 'AIBET'],\n",
    "                    'descricao': 'Sigla alfab√©tica (4-10 letras mai√∫sculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Material',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$',\n",
    "                    'sinonimos': ['C√≥digo Produto', 'C√≥digo Material',\n",
    "                                  'Cod Produto', 'Cod Material'],\n",
    "                    'exemplos': ['10.123.456', '1.234.567', '1234567'],\n",
    "                    'descricao': 'C√≥digo num√©rico do material/produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Grupo',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$|^[A-Z_]+$',\n",
    "                    'sinonimos': ['C√≥d Grupo de produto', 'C√≥digo Grupo',\n",
    "                                  'Grupo Produto', 'Produto:CodGrupoProduto'],\n",
    "                    'exemplos': ['10.123.456', 'DIESEL_S10_SIMPLES',\n",
    "                                 'GASOLINA_COMUM'],\n",
    "                    'descricao': 'C√≥digo grupo (num√©rico OU texto_underscore)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Desc_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Texto_Descricao',\n",
    "                    'regex': r'^[A-Za-z0-9\\s\\-]+$',\n",
    "                    'sinonimos': ['Desc. Grupo de Produto', 'Descri√ß√£o Produto',\n",
    "                                  'Nome Produto', 'Produto'],\n",
    "                    'exemplos': ['DIESEL S10', 'GASOLINA COMUM',\n",
    "                                 'ETANOL HIDRATADO'],\n",
    "                    'descricao': 'Descri√ß√£o textual do grupo de produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Nome_Pessoa': {\n",
    "                    'tipo_dado': 'Texto_Nome_Pessoa',\n",
    "                    'regex': r'^[A-Z√Å√Ä√Ç√É√â√à√ä√ç√è√ì√î√ï√ñ√ö√á√ë][a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±]+(\\s[A-Z√Å√Ä√Ç√É√â√à√ä√ç√è√ì√î√ï√ñ√ö√á√ë][a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±]+)+$',\n",
    "                    'sinonimos': ['Criado por', 'Nome', 'Respons√°vel',\n",
    "                                  'Solicitante'],\n",
    "                    'exemplos': ['Kenedy Vin√≠cius Rodrigues',\n",
    "                                 'Joao Carlos Stival'],\n",
    "                    'descricao': 'Nome completo de pessoa',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Email': {\n",
    "                    'tipo_dado': 'Texto_Email',\n",
    "                    'regex': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n",
    "                    'sinonimos': ['Email', 'E-mail', 'Modificado por'],\n",
    "                    'exemplos': ['usuario@vibraenergia.com.br'],\n",
    "                    'descricao': 'Endere√ßo de email',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Status_Workflow': {\n",
    "                    'tipo_dado': 'Texto_Status',\n",
    "                    'regex': r'^(Em aprova√ß√£o|Aprovado|Rejeitado|Pendente|Conclu√≠do|√çtem Criado|Item Criado)$',\n",
    "                    'sinonimos': ['Status', 'Status Aprova√ß√£o', 'Situa√ß√£o'],\n",
    "                    'exemplos': ['Em aprova√ß√£o', '√çtem Criado', 'Aprovado'],\n",
    "                    'descricao': 'Status de workflow/aprova√ß√£o',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Booleano_Texto': {\n",
    "                    'tipo_dado': 'Texto_Booleano',\n",
    "                    'regex': r'^(Sim|N√£o|sim|n√£o|SIM|N√ÉO|Yes|No|TRUE|FALSE)$',\n",
    "                    'sinonimos': ['Conclu√≠do?', 'Ativo?', 'Habilitado?'],\n",
    "                    'exemplos': ['Sim', 'N√£o'],\n",
    "                    'descricao': 'Valor booleano como texto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Texto_Longo': {\n",
    "                    'tipo_dado': 'Texto_Justificativa',\n",
    "                    'regex': r'^.{50,}$',\n",
    "                    'sinonimos': ['Justificativa', 'Observa√ß√£o', 'Coment√°rio'],\n",
    "                    'exemplos': ['Solicitamos a revis√£o do limite...'],\n",
    "                    'descricao': 'Texto longo (mais de 50 caracteres)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Path_URL': {\n",
    "                    'tipo_dado': 'Texto_Caminho',\n",
    "                    'regex': r'^(teams/|http|https|ftp|\\\\\\\\|/).*',\n",
    "                    'sinonimos': ['Caminho', 'Path', 'URL', 'Link'],\n",
    "                    'exemplos': ['teams/portaleso/Lists/...',\n",
    "                                 'https://example.com'],\n",
    "                    'descricao': 'Caminho de arquivo ou URL',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla_Curta': {\n",
    "                    'tipo_dado': 'Texto_Sigla_Curta',\n",
    "                    'regex': r'^[A-Z]{2,4}$',\n",
    "                    'sinonimos': ['CME', 'Ger√™ncia', 'UF', 'Tipo'],\n",
    "                    'exemplos': ['OPC', 'OPN', 'Norte', 'Sul', 'CME'],\n",
    "                    'descricao': 'Sigla curta (2-4 letras mai√∫sculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Tipo_Item': {\n",
    "                    'tipo_dado': 'Texto_Tipo_Item',\n",
    "                    'regex': r'^(Item|Documento|Pasta|Arquivo)$',\n",
    "                    'sinonimos': ['Tipo de Item', 'Tipo'],\n",
    "                    'exemplos': ['Item'],\n",
    "                    'descricao': 'Tipo de item em lista SharePoint',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_ISO': {\n",
    "                    'tipo_dado': 'Data_YYYY-MM-DD',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}$',\n",
    "                    'sinonimos': ['Data', 'Per√≠odo',\n",
    "                                  'Per√≠odo In√≠cio Validade Novo Limite'],\n",
    "                    'exemplos': ['2025-08-01', '2024-12-31', '2025-01-07'],\n",
    "                    'descricao': 'Data formato ISO (YYYY-MM-DD)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Datetime_ISO': {\n",
    "                    'tipo_dado': 'Datetime_YYYY-MM-DD_HH:MM:SS',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}$',\n",
    "                    'sinonimos': ['Criado', 'Modificado', 'Data Hora',\n",
    "                                  'Timestamp'],\n",
    "                    'exemplos': ['2025-08-04 19:22:17',\n",
    "                                 '2025-08-04 20:45:37'],\n",
    "                    'descricao': 'Data e hora formato ISO',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_BR': {\n",
    "                    'tipo_dado': 'Data_DD/MM/YYYY',\n",
    "                    'regex': r'^\\d{2}/\\d{2}/\\d{4}$',\n",
    "                    'sinonimos': ['Data'],\n",
    "                    'exemplos': ['15/01/2024', '31/12/2025'],\n",
    "                    'descricao': 'Data formato brasileiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Decimal': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Decimal',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?$',\n",
    "                    'sinonimos': ['Limite Inferior Atual',\n",
    "                                  'Limite Superior Atual', 'AVG VI %',\n",
    "                                  '% VI', 'AVG VI % 2024 SAP'],\n",
    "                    'exemplos': ['-0.08', '0.08', '-0.14', '0.05', '-0.03'],\n",
    "                    'descricao': 'Percentual em decimal (pode ser negativo)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Com_Simbolo': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Simbolo',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?%$',\n",
    "                    'sinonimos': ['Percentual', '% VI'],\n",
    "                    'exemplos': ['10.5%', '-5.2%', '100%'],\n",
    "                    'descricao': 'Percentual com s√≠mbolo %',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Numero_Inteiro': {\n",
    "                    'tipo_dado': 'Numero_Inteiro',\n",
    "                    'regex': r'^-?\\d+$',\n",
    "                    'sinonimos': ['Quantidade', 'Qtd', 'Total'],\n",
    "                    'exemplos': ['123', '-456', '1000'],\n",
    "                    'descricao': 'N√∫mero inteiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Monetario': {\n",
    "                    'tipo_dado': 'Numero_Monetario',\n",
    "                    'regex': r'^R\\$\\s?-?\\d{1,3}(\\.\\d{3})*(,\\d{2})?$|^-?\\d+([.,]\\d{2})?$',\n",
    "                    'sinonimos': ['Valor', 'Custo', 'Pre√ßo', 'R$'],\n",
    "                    'exemplos': ['R$ 1.234,56', '1234.56'],\n",
    "                    'descricao': 'Valor monet√°rio',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Unidade_Operacional_Nome': {\n",
    "                    'tipo_dado': 'Texto_Unidade_Operacional',\n",
    "                    'regex': r'^[A-Z]{4,10}\\s+Base\\s+de\\s+.+$',\n",
    "                    'sinonimos': ['Unidade Operacional', 'Nome Base'],\n",
    "                    'exemplos': ['BABET Base de Betim',\n",
    "                                 'BAPLAN Base de Paul√≠nia'],\n",
    "                    'descricao': 'Nome completo da unidade operacional',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Rotulo_Retencao': {\n",
    "                    'tipo_dado': 'Texto_Rotulo_Vazio',\n",
    "                    'regex': r'^(NaN|nan|None|null|)$',\n",
    "                    'sinonimos': ['R√≥tulo de reten√ß√£o Aplicado'],\n",
    "                    'exemplos': ['NaN'],\n",
    "                    'descricao': 'Campo de r√≥tulo (geralmente vazio)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                }\n",
    "            },\n",
    "            'historico_arquivos': []\n",
    "        }\n",
    "\n",
    "    def detectar_campo(self, coluna_nome, valores_amostra):\n",
    "        \"\"\"Detec√ß√£o AVAN√áADA com m√∫ltiplas estrat√©gias\"\"\"\n",
    "        valores_str = [str(v).strip() for v in valores_amostra\n",
    "                      if pd.notna(v) and str(v).strip() not in\n",
    "                      ['', 'nan', 'None']]\n",
    "\n",
    "        if not valores_str:\n",
    "            return {\n",
    "                'campo_detectado': 'VAZIO',\n",
    "                'confianca': 0.0,\n",
    "                'score_conteudo': 0.0,\n",
    "                'score_nome': 0.0,\n",
    "                'matches': 0,\n",
    "                'total': 0,\n",
    "                'ambiguidade': False,\n",
    "                'candidatos': [],\n",
    "                'metodo': 'VAZIO'\n",
    "            }\n",
    "\n",
    "        # Heur√≠sticas espec√≠ficas\n",
    "        campo_heuristico = self._detectar_por_heuristica(\n",
    "            coluna_nome, valores_str\n",
    "        )\n",
    "\n",
    "        if campo_heuristico and campo_heuristico.get('confianca', 0) >= 0.85:\n",
    "            campo_heuristico.setdefault('score_nome', 0.0)\n",
    "            campo_heuristico.setdefault('score_conteudo',\n",
    "                                        campo_heuristico.get('confianca', 0.0))\n",
    "            campo_heuristico.setdefault('matches', len(valores_str))\n",
    "            campo_heuristico.setdefault('total', len(valores_str))\n",
    "            campo_heuristico.setdefault('ambiguidade', False)\n",
    "            campo_heuristico.setdefault('candidatos', [])\n",
    "            return campo_heuristico\n",
    "\n",
    "        # Match por regex\n",
    "        resultados_regex = []\n",
    "        for nome_campo, info in self.dados['campos_conhecidos'].items():\n",
    "            matches = sum(1 for v in valores_str\n",
    "                         if re.match(info['regex'], v))\n",
    "            score_conteudo = matches / len(valores_str)\n",
    "\n",
    "            score_nome = 0.0\n",
    "            for sinonimo in info['sinonimos']:\n",
    "                if sinonimo.lower() in coluna_nome.lower():\n",
    "                    score_nome = 0.3\n",
    "                    break\n",
    "\n",
    "            score_final = score_conteudo + score_nome\n",
    "\n",
    "            resultados_regex.append({\n",
    "                'campo': nome_campo,\n",
    "                'score': min(score_final, 1.0),\n",
    "                'score_conteudo': score_conteudo,\n",
    "                'score_nome': score_nome,\n",
    "                'matches': matches,\n",
    "                'total': len(valores_str)\n",
    "            })\n",
    "\n",
    "        resultados_regex = sorted(resultados_regex,\n",
    "                                 key=lambda x: x['score'],\n",
    "                                 reverse=True)\n",
    "        melhor_regex = resultados_regex[0]\n",
    "        segundo_regex = resultados_regex[1] if len(resultados_regex) > 1 else None\n",
    "\n",
    "        ambiguidade = False\n",
    "        candidatos = []\n",
    "        if segundo_regex and abs(melhor_regex['score'] -\n",
    "                                segundo_regex['score']) < 0.10:\n",
    "            ambiguidade = True\n",
    "            candidatos = [segundo_regex['campo']]\n",
    "\n",
    "        resultado_final = {\n",
    "            'campo_detectado': melhor_regex['campo'],\n",
    "            'confianca': melhor_regex['score'],\n",
    "            'score_conteudo': melhor_regex['score_conteudo'],\n",
    "            'score_nome': melhor_regex['score_nome'],\n",
    "            'matches': melhor_regex['matches'],\n",
    "            'total': melhor_regex['total'],\n",
    "            'ambiguidade': ambiguidade,\n",
    "            'candidatos': candidatos,\n",
    "            'metodo': 'REGEX'\n",
    "        }\n",
    "\n",
    "        if resultado_final['confianca'] < 0.50:\n",
    "            resultado_final['campo_detectado'] = 'DESCONHECIDO'\n",
    "\n",
    "        return resultado_final\n",
    "\n",
    "    def _detectar_por_heuristica(self, nome_coluna, valores_str):\n",
    "        \"\"\"Detec√ß√£o por heur√≠sticas espec√≠ficas\"\"\"\n",
    "        if not valores_str:\n",
    "            return None\n",
    "\n",
    "        tamanho_medio = sum(len(v) for v in valores_str) / len(valores_str)\n",
    "        valores_unicos = set(valores_str)\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}$', v) for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Data_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATA_ISO'}\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}', v)\n",
    "               for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Datetime_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATETIME'}\n",
    "\n",
    "        if all('@' in v for v in valores_str):\n",
    "            return {'campo_detectado': 'Email', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_EMAIL'}\n",
    "\n",
    "        if 'limite' in nome_coluna.lower() or '%' in nome_coluna or 'vi' in nome_coluna.lower():\n",
    "            try:\n",
    "                valores_float = [float(v) for v in valores_str\n",
    "                                if v not in ['nan', '', 'None', 'NaN']]\n",
    "                if valores_float and all(-1 <= v <= 1 for v in valores_float):\n",
    "                    return {'campo_detectado': 'Percentual_Decimal',\n",
    "                           'confianca': 0.90,\n",
    "                           'metodo': 'HEURISTICA_PERCENTUAL'}\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if tamanho_medio > 50:\n",
    "            return {'campo_detectado': 'Texto_Longo', 'confianca': 0.85,\n",
    "                   'metodo': 'HEURISTICA_TEXTO_LONGO'}\n",
    "\n",
    "        if any(v.startswith(('teams/', 'http', 'https', '//', '\\\\\\\\'))\n",
    "               for v in valores_str):\n",
    "            return {'campo_detectado': 'Path_URL', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_PATH'}\n",
    "\n",
    "        if valores_unicos <= {'Sim', 'N√£o', 'sim', 'n√£o'}:\n",
    "            return {'campo_detectado': 'Booleano_Texto', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_BOOLEANO'}\n",
    "\n",
    "        if 'por' in nome_coluna.lower() or 'nome' in nome_coluna.lower():\n",
    "            if all(len(v.split()) >= 2 and '@' not in v\n",
    "                   for v in valores_str[:5]):\n",
    "                return {'campo_detectado': 'Nome_Pessoa', 'confianca': 0.85,\n",
    "                       'metodo': 'HEURISTICA_NOME'}\n",
    "\n",
    "        palavras_status = {'em aprova√ß√£o', 'aprovado', 'rejeitado',\n",
    "                          '√≠tem criado', 'item criado', 'pendente'}\n",
    "        if any(v.lower() in palavras_status for v in valores_str):\n",
    "            return {'campo_detectado': 'Status_Workflow', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_STATUS'}\n",
    "\n",
    "        if 'base de' in ' '.join(valores_str[:3]).lower():\n",
    "            return {'campo_detectado': 'Unidade_Operacional_Nome',\n",
    "                   'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_UNIDADE_OP'}\n",
    "\n",
    "        return None\n",
    "\n",
    "    def atualizar_historico(self, info):\n",
    "        self.dados['historico_arquivos'].append(info)\n",
    "        self.dados['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "        self._salvar(self.dados)\n",
    "\n",
    "    def _salvar(self, dados):\n",
    "        with open(self.arquivo_dict, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dados, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ===================================================================\n",
    "# 6. INICIALIZAR DICION√ÅRIO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO DICION√ÅRIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "dicionario = DicionarioInteligente(fm)\n",
    "\n",
    "# ===================================================================\n",
    "# 7. SALVAR ESTADO PARA PR√ìXIMO BLOCO\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco3 = {\n",
    "    'bloco': 3,\n",
    "    'versao': '4.5',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'dicionario': {\n",
    "        'arquivo': str(dicionario.arquivo_dict),\n",
    "        'campos_conhecidos': len(dicionario.dados['campos_conhecidos']),\n",
    "        'arquivos_processados': len(dicionario.dados['historico_arquivos']),\n",
    "        'config_sistema': dicionario.dados.get('config_sistema', {})\n",
    "    },\n",
    "    'componentes_carregados': ['DicionarioInteligente', 'GUIComTimer']\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_3_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco3, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 3 CONCLU√çDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìã Componentes:\")\n",
    "print(\"   ‚Ä¢ DicionarioInteligente ........... ‚úÖ\")\n",
    "n_campos = len(dicionario.dados['campos_conhecidos'])\n",
    "n_arquivos = len(dicionario.dados['historico_arquivos'])\n",
    "print(f\"     - Campos: {n_campos}\")\n",
    "print(f\"     - Arquivos: {n_arquivos}\")\n",
    "timeout = dicionario.dados.get('config_sistema', {}).get('timeout_sessao_minutos', 60)\n",
    "print(f\"     - Timeout: {timeout}min\")\n",
    "print(\"   ‚Ä¢ GUIComTimer ..................... ‚úÖ\")\n",
    "print(\"\\nüíæ Estado salvo em:\")\n",
    "print(f\"   ‚Ä¢ .bloco_3_state.json\")\n",
    "print(f\"   ‚Ä¢ DICT_Dicionario_Persistente.json\")\n",
    "print(\"\\nüí° Pr√≥ximo: BLOCO 4 seleciona arquivo de dados\")\n",
    "print(\"=\"*70)"
   ],
   "id": "67bda94dc68661ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 3: DICION√ÅRIO INTELIGENTE + GUI COM TIMER\n",
      "======================================================================\n",
      "\n",
      "‚úÖ CONFIGURA√á√ÉO CARREGADA DO LOG GLOBAL\n",
      "   üìÅ Pasta base: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   üïê Timestamp: 20251019_060722\n",
      "\n",
      "‚úÖ BLOCO 2 VALIDADO\n",
      "   Executado em: 2025-10-19T06:07:25.342924\n",
      "   Classes: LocalizadorDicionario, FileManagerInterativo, SeletorArquivo, DetectorCabecalho\n",
      "\n",
      "‚úÖ FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "‚úÖ Classe GUIComTimer carregada\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO DICION√ÅRIO\n",
      "======================================================================\n",
      "\n",
      "üìù CRIANDO NOVO DICION√ÅRIO...\n",
      "‚úÖ Dicion√°rio criado: 22 campos\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 3 CONCLU√çDO\n",
      "======================================================================\n",
      "\n",
      "üìã Componentes:\n",
      "   ‚Ä¢ DicionarioInteligente ........... ‚úÖ\n",
      "     - Campos: 22\n",
      "     - Arquivos: 0\n",
      "     - Timeout: 60min\n",
      "   ‚Ä¢ GUIComTimer ..................... ‚úÖ\n",
      "\n",
      "üíæ Estado salvo em:\n",
      "   ‚Ä¢ .bloco_3_state.json\n",
      "   ‚Ä¢ DICT_Dicionario_Persistente.json\n",
      "\n",
      "üí° Pr√≥ximo: BLOCO 4 seleciona arquivo de dados\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:42.813473Z",
     "start_time": "2025-10-19T09:07:34.620165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 4 - SELE√á√ÉO DE ARQUIVO - SUPORTE MULTI-FORMATO (REVISADO v3.1)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMUNICA√á√ÉO VIA LOG:\n",
    "# - L√ä: pasta_base (LOG global), timestamp, dicion√°rio persistente\n",
    "# - RECRIA: FileManager localmente\n",
    "# - SALVA: arquivo selecionado + config CSV (se houver)\n",
    "#\n",
    "# MUDAN√áAS v3.1:\n",
    "# - Navega√ß√£o inteligente: abre pasta 01_Entrada por padr√£o\n",
    "# - Hist√≥rico de pastas (√∫ltimas 5)\n",
    "# - Bot√£o para √∫ltima pasta usada (com timer)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BLOCO 4: SELE√á√ÉO DE ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 1. LER CONFIGURA√á√ïES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå LOG GLOBAL n√£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro para criar a estrutura.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nüìÇ Pasta base carregada: {pasta_base.name}\")\n",
    "print(f\"‚è∞ Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 2. RECRIAR OBJETOS NECESS√ÅRIOS (N√ÉO ASSUMIR MEM√ìRIA)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# Recriar FileManager\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# Carregar dicion√°rio persistente\n",
    "dict_file = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "\n",
    "if dict_file.exists():\n",
    "    with open(dict_file, 'r', encoding='utf-8') as f:\n",
    "        DICIONARIO_PERSISTENTE = json.load(f)\n",
    "    print(f\"üìö Dicion√°rio carregado: {len(DICIONARIO_PERSISTENTE.get('campos_conhecidos', {}))} campos\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå Dicion√°rio n√£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 3 primeiro.\"\n",
    "    )\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONSTANTES E CONFIGURA√á√ïES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "FILETYPES_SUPORTADOS = [\n",
    "    (\"Todos os suportados\", \"*.xlsx *.xls *.xlsm *.csv *.txt\"),\n",
    "    (\"Excel\", \"*.xlsx *.xls *.xlsm\"),\n",
    "    (\"CSV\", \"*.csv\"),\n",
    "    (\"TXT (Tabelas)\", \"*.txt\"),\n",
    "    (\"Todos\", \"*.*\")\n",
    "]\n",
    "\n",
    "TIMEOUT_SESSAO_MINUTOS = DICIONARIO_PERSISTENTE.get(\n",
    "    'config_sistema', {}\n",
    ").get('timeout_sessao_minutos', 60)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FUN√á√ïES AUXILIARES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def detectar_config_csv(arquivo_path):\n",
    "    \"\"\"\n",
    "    Detecta encoding e separador ideal para CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: {'encoding': str, 'sep': str, 'colunas': int}\n",
    "        None: se falhar\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    separadores = [',', ';', '\\t', '|']\n",
    "\n",
    "    melhor_config = None\n",
    "    max_colunas = 0\n",
    "\n",
    "    for encoding in encodings:\n",
    "        for sep in separadores:\n",
    "            try:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=5,\n",
    "                    encoding=encoding,\n",
    "                    sep=sep,\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                n_cols = len(df_test.columns)\n",
    "\n",
    "                if n_cols > max_colunas and n_cols > 1:\n",
    "                    max_colunas = n_cols\n",
    "                    melhor_config = {\n",
    "                        'encoding': encoding,\n",
    "                        'sep': sep,\n",
    "                        'colunas': n_cols\n",
    "                    }\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return melhor_config\n",
    "\n",
    "\n",
    "def validar_arquivo_selecionado(arquivo_path):\n",
    "    \"\"\"\n",
    "    Valida√ß√£o b√°sica do arquivo selecionado.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Se arquivo n√£o existe\n",
    "        ValueError: Se arquivo inv√°lido\n",
    "\n",
    "    Returns:\n",
    "        dict: Informa√ß√µes de valida√ß√£o\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if not arquivo_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {arquivo_path}\")\n",
    "\n",
    "    tamanho = arquivo_path.stat().st_size\n",
    "    if tamanho == 0:\n",
    "        raise ValueError(f\"Arquivo vazio: {arquivo_path.name}\")\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "    extensoes_validas = ['.xlsx', '.xls', '.xlsm', '.csv', '.txt']\n",
    "\n",
    "    if extensao not in extensoes_validas:\n",
    "        print(f\"   ‚ö†Ô∏è Extens√£o incomum: {extensao}\")\n",
    "\n",
    "    config_extra = {}\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            pd.read_excel(arquivo_path, nrows=1)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "\n",
    "            if config_csv:\n",
    "                config_extra['csv'] = config_csv\n",
    "                print(f\"   üìä CSV: {config_csv['colunas']} colunas\")\n",
    "                print(f\"   üî§ Encoding: {config_csv['encoding']}\")\n",
    "                print(f\"   ‚ûó Separador: {repr(config_csv['sep'])}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Config CSV n√£o detectada automaticamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Arquivo corrompido ou ileg√≠vel: {str(e)[:100]}\")\n",
    "\n",
    "    return {\n",
    "        'valido': True,\n",
    "        'tamanho_kb': tamanho / 1024,\n",
    "        'extensao': extensao,\n",
    "        **config_extra\n",
    "    }\n",
    "\n",
    "\n",
    "def carregar_preview_inteligente(arquivo_path, frame_preview):\n",
    "    \"\"\"\n",
    "    Carrega preview do arquivo com tratamento de erro amig√°vel.\n",
    "\n",
    "    Args:\n",
    "        arquivo_path: Path do arquivo\n",
    "        frame_preview: Frame tkinter para mostrar preview\n",
    "    \"\"\"\n",
    "    import tkinter as tk\n",
    "    import pandas as pd\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            df_quick = pd.read_excel(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "            if config_csv:\n",
    "                df_quick = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=3,\n",
    "                    encoding=config_csv['encoding'],\n",
    "                    sep=config_csv['sep']\n",
    "                )\n",
    "            else:\n",
    "                df_quick = pd.read_csv(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.txt':\n",
    "            for sep in ['\\t', ';', '|', ',']:\n",
    "                try:\n",
    "                    df_quick = pd.read_csv(arquivo_path, nrows=3, sep=sep)\n",
    "                    if len(df_quick.columns) > 1:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        preview_text = f\"{len(df_quick)} linhas √ó {len(df_quick.columns)} colunas\"\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=preview_text,\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#666666',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "    except Exception as e:\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"‚ö†Ô∏è Preview indispon√≠vel\",\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#FF6B6B',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "        print(f\"   ‚ö†Ô∏è Preview falhou: {str(e)[:50]}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CARREGAR HIST√ìRICO DE NAVEGA√á√ÉO (NOVO v3.1)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "historico_file = fm.pastas['logs'] / '.historico_pastas_navegacao.json'\n",
    "\n",
    "if historico_file.exists():\n",
    "    try:\n",
    "        with open(historico_file, 'r', encoding='utf-8') as f:\n",
    "            historico_pastas = json.load(f)\n",
    "    except:\n",
    "        historico_pastas = {'ultima_pasta': None, 'historico': []}\n",
    "else:\n",
    "    historico_pastas = {'ultima_pasta': None, 'historico': []}\n",
    "\n",
    "# Determinar pasta inicial padr√£o\n",
    "pasta_entrada = fm.pastas['entrada']\n",
    "ultima_pasta_usada = None\n",
    "\n",
    "if historico_pastas.get('ultima_pasta'):\n",
    "    ultima_pasta_usada = Path(historico_pastas['ultima_pasta'])\n",
    "    if not ultima_pasta_usada.exists():\n",
    "        ultima_pasta_usada = None\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 3. PROCESSAR DADOS DO BLOCO (L√ìGICA PRINCIPAL)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Carregar √∫ltima sele√ß√£o\n",
    "config_file = fm.pastas['logs'] / '.ultimo_arquivo.json'\n",
    "ultimo_arquivo = None\n",
    "sessao_atual = False\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        try:\n",
    "            ts_config = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "            ts_agora = datetime.now()\n",
    "            diff_minutos = (ts_agora - ts_config).total_seconds() / 60\n",
    "\n",
    "            if diff_minutos < TIMEOUT_SESSAO_MINUTOS:\n",
    "                caminho_salvo = config.get('caminho')\n",
    "                if caminho_salvo and Path(caminho_salvo).exists():\n",
    "                    ultimo_arquivo = Path(caminho_salvo)\n",
    "                    sessao_atual = True\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nüí° √öltima sele√ß√£o: {ultimo_arquivo.name if ultimo_arquivo else 'Nenhuma'}\")\n",
    "print(f\"   Mesma sess√£o: {'Sim' if sessao_atual else 'N√£o'}\")\n",
    "if ultima_pasta_usada:\n",
    "    print(f\"   √öltima pasta: {ultima_pasta_usada}\")\n",
    "\n",
    "# CASO 1: Tem arquivo da sess√£o atual ‚Üí GUI com timer\n",
    "if ultimo_arquivo and sessao_atual:\n",
    "    def selecionar_arquivo_com_timer(ultimo_path):\n",
    "        \"\"\"GUI com timer para confirmar ou trocar arquivo\"\"\"\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - Sele√ß√£o de Arquivo\",\n",
    "            650, 520,\n",
    "            tem_timer=True\n",
    "        )\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"üìÇ Sele√ß√£o de Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"üí° √öltimo arquivo selecionado nesta sess√£o:\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 5))\n",
    "\n",
    "        extensao = ultimo_path.suffix.lower()\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            tipo_arquivo = \"Excel\"\n",
    "            icone = \"üìä\"\n",
    "        elif extensao == '.csv':\n",
    "            tipo_arquivo = \"CSV\"\n",
    "            icone = \"üìÑ\"\n",
    "        elif extensao == '.txt':\n",
    "            tipo_arquivo = \"TXT\"\n",
    "            icone = \"üìù\"\n",
    "        else:\n",
    "            tipo_arquivo = \"Desconhecido\"\n",
    "            icone = \"‚ùì\"\n",
    "\n",
    "        frame_info = tk.Frame(frame, bg='#E3F2FD', relief=tk.SUNKEN, borderwidth=2)\n",
    "        frame_info.pack(fill=tk.X, pady=(0, 10), padx=10)\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"{icone} {ultimo_path.name}\",\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(5, 2))\n",
    "\n",
    "        tamanho_kb = ultimo_path.stat().st_size / 1024\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"üì¶ Tipo: {tipo_arquivo} | üìè Tamanho: {tamanho_kb:.1f} KB\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 2))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"üìÇ Local: {ultimo_path.parent}\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w',\n",
    "            wraplength=600\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 5))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Deseja usar este arquivo ou escolher outro?\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(10, 10))\n",
    "\n",
    "        frame_preview = tk.Frame(frame, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "        frame_preview.pack(fill=tk.X, padx=10, pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"üìä Preview (3 primeiras linhas):\",\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#F5F5F5',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(3, 2))\n",
    "\n",
    "        carregar_preview_inteligente(ultimo_path, frame_preview)\n",
    "\n",
    "        def usar_ultimo():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultimo_path\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def escolher_novo():\n",
    "            resultado['cancelado'] = True\n",
    "            root.withdraw()\n",
    "\n",
    "            # NAVEGA√á√ÉO INTELIGENTE: usar √∫ltima pasta ou pasta_entrada\n",
    "            pasta_inicial = ultima_pasta_usada if ultima_pasta_usada else pasta_entrada\n",
    "\n",
    "            arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecione o arquivo de dados\",\n",
    "                initialdir=str(pasta_inicial),\n",
    "                filetypes=FILETYPES_SUPORTADOS\n",
    "            )\n",
    "\n",
    "            resultado['valor'] = Path(arquivo) if arquivo else ultimo_path\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(fill=tk.X, pady=10)\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Escolher Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=22,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        nome_curto = ultimo_path.name[:15] + '...' if len(ultimo_path.name) > 15 else ultimo_path.name\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=f\"Usar '{nome_curto}' (10s)\",\n",
    "            command=usar_ultimo,\n",
    "            width=30,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#2196F3',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "        root.mainloop()\n",
    "\n",
    "        if resultado.get('timeout'):\n",
    "            print(f\"   ‚è±Ô∏è Timeout (10s) - usando √∫ltimo arquivo\")\n",
    "            return ultimo_path\n",
    "\n",
    "        return resultado['valor']\n",
    "\n",
    "    print(\"\\nAbrindo janela...\")\n",
    "    arquivo_selecionado = selecionar_arquivo_com_timer(ultimo_arquivo)\n",
    "\n",
    "# CASO 2: N√£o tem arquivo da sess√£o ‚Üí GUI com navega√ß√£o inteligente\n",
    "else:\n",
    "    def selecionar_arquivo_direto():\n",
    "        \"\"\"GUI direta para primeira sele√ß√£o com navega√ß√£o inteligente\"\"\"\n",
    "\n",
    "        # NAVEGA√á√ÉO INTELIGENTE: √∫ltima pasta usada OU pasta 01_Entrada\n",
    "        pasta_inicial = ultima_pasta_usada if ultima_pasta_usada else pasta_entrada\n",
    "\n",
    "        print(f\"   üìÅ Abrindo em: {pasta_inicial.name}\")\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"Selecione o arquivo de dados\",\n",
    "            initialdir=str(pasta_inicial),\n",
    "            filetypes=FILETYPES_SUPORTADOS\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"‚ùå Nenhum arquivo selecionado\")\n",
    "\n",
    "        return Path(arquivo)\n",
    "\n",
    "    print(\"\\nAbrindo janela de sele√ß√£o...\")\n",
    "    print(\"(A janela pode estar atr√°s do navegador)\")\n",
    "    arquivo_selecionado = selecionar_arquivo_direto()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ATUALIZAR HIST√ìRICO DE NAVEGA√á√ÉO (NOVO v3.1)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "pasta_do_arquivo = arquivo_selecionado.parent\n",
    "\n",
    "# Salvar √∫ltima pasta usada\n",
    "historico_pastas['ultima_pasta'] = str(pasta_do_arquivo)\n",
    "\n",
    "# Atualizar hist√≥rico (manter √∫ltimas 5 pastas)\n",
    "historico = historico_pastas.get('historico', [])\n",
    "\n",
    "# Remover duplicatas\n",
    "if str(pasta_do_arquivo) in historico:\n",
    "    historico.remove(str(pasta_do_arquivo))\n",
    "\n",
    "# Adicionar no topo\n",
    "historico.insert(0, str(pasta_do_arquivo))\n",
    "\n",
    "# Manter apenas 5 mais recentes\n",
    "historico_pastas['historico'] = historico[:5]\n",
    "historico_pastas['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "\n",
    "# Salvar hist√≥rico\n",
    "with open(historico_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(historico_pastas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# VALIDA√á√ÉO E DETEC√á√ÉO DE TIPO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüîç Validando arquivo...\")\n",
    "\n",
    "try:\n",
    "    info_validacao = validar_arquivo_selecionado(arquivo_selecionado)\n",
    "    print(\"   ‚úÖ Arquivo validado com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå ERRO: {e}\")\n",
    "    raise\n",
    "\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "    tipo_arquivo = \"Excel\"\n",
    "elif extensao == '.csv':\n",
    "    tipo_arquivo = \"CSV\"\n",
    "elif extensao == '.txt':\n",
    "    tipo_arquivo = \"TXT\"\n",
    "else:\n",
    "    tipo_arquivo = \"Desconhecido\"\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 4. SALVAR ESTADO PARA PR√ìXIMO BLOCO (VIA LOG)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "config_salvar = {\n",
    "    'nome': arquivo_selecionado.name,\n",
    "    'caminho': str(arquivo_selecionado),\n",
    "    'tamanho_kb': info_validacao['tamanho_kb'],\n",
    "    'tipo': tipo_arquivo,\n",
    "    'extensao': extensao,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    config_salvar['config_csv'] = info_validacao['csv']\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_salvar, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Salvar estado do BLOCO 4\n",
    "estado_bloco = {\n",
    "    'bloco': 4,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo_selecionado': arquivo_selecionado.name,\n",
    "    'tipo': tipo_arquivo,\n",
    "    'tamanho_kb': info_validacao['tamanho_kb']\n",
    "}\n",
    "\n",
    "with open(fm.pastas['logs'] / '.bloco_5_state.json', 'w') as f:\n",
    "    json.dump(estado_bloco, f, indent=2)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 5. CONFIRMA√á√ÉO FINAL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ ARQUIVO SELECIONADO E VALIDADO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"üìÑ Nome: {arquivo_selecionado.name}\")\n",
    "print(f\"üì¶ Tipo: {tipo_arquivo}\")\n",
    "print(f\"üìè Tamanho: {info_validacao['tamanho_kb']:.1f} KB\")\n",
    "print(f\"üìÇ Pasta: {arquivo_selecionado.parent.name}\")\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    csv_info = info_validacao['csv']\n",
    "    print(f\"üìä Colunas detectadas: {csv_info['colunas']}\")\n",
    "    print(f\"üî§ Encoding: {csv_info['encoding']}\")\n",
    "    print(f\"‚ûó Separador: {repr(csv_info['sep'])}\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"‚úÖ BLOCO 4 CONCLU√çDO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüíæ Estado salvo em: {fm.pastas['logs']}\")\n",
    "print(f\"üìã Pr√≥ximo: BLOCO 6 carregar√° o arquivo usando esta configura√ß√£o\")"
   ],
   "id": "eab16a4648d87882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLOCO 4: SELE√á√ÉO DE ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "üìÇ Pasta base carregada: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "‚è∞ Timestamp: 20251019_060722\n",
      "üìö Dicion√°rio carregado: 22 campos\n",
      "\n",
      "üí° √öltima sele√ß√£o: Nenhuma\n",
      "   Mesma sess√£o: N√£o\n",
      "\n",
      "Abrindo janela de sele√ß√£o...\n",
      "(A janela pode estar atr√°s do navegador)\n",
      "   üìÅ Abrindo em: 01_Entrada\n",
      "\n",
      "üîç Validando arquivo...\n",
      "   ‚úÖ Arquivo validado com sucesso\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ARQUIVO SELECIONADO E VALIDADO\n",
      "======================================================================\n",
      "üìÑ Nome: C√≥pia de xSAPtemp4687_JAN_25.xls\n",
      "üì¶ Tipo: Excel\n",
      "üìè Tamanho: 16257.5 KB\n",
      "üìÇ Pasta: Dado BW\n",
      "======================================================================\n",
      "‚úÖ BLOCO 4 CONCLU√çDO\n",
      "======================================================================\n",
      "\n",
      "üíæ Estado salvo em: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\\04_Logs\n",
      "üìã Pr√≥ximo: BLOCO 6 carregar√° o arquivo usando esta configura√ß√£o\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:46.955353Z",
     "start_time": "2025-10-19T09:07:46.569095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 5: CARREGAMENTO INTELIGENTE - EXCEL E CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì• CARREGAMENTO DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Detectar tipo de arquivo pela extens√£o\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "print(f\"\\nüîç Extens√£o detectada: {extensao}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 1: ARQUIVOS EXCEL (.xls, .xlsx, .xlsm)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if extensao in ['.xls', '.xlsx', '.xlsm']:\n",
    "    print(f\"üìä Tipo: EXCEL\")\n",
    "\n",
    "    try:\n",
    "        # Tentar xlrd primeiro (para .xls antigos)\n",
    "        workbook = xlrd.open_workbook(str(arquivo_selecionado))\n",
    "        sheets = workbook.sheet_names()\n",
    "        metodo_carga = 'xlrd'\n",
    "        print(f\"   ‚úÖ M√©todo: xlrd (XLS)\")\n",
    "\n",
    "    except:\n",
    "        # Se falhar, usar pandas (para .xlsx/.xlsm)\n",
    "        try:\n",
    "            workbook = pd.ExcelFile(str(arquivo_selecionado))\n",
    "            sheets = workbook.sheet_names\n",
    "            metodo_carga = 'pandas'\n",
    "            print(f\"   ‚úÖ M√©todo: pandas (XLSX/XLSM)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ERRO ao abrir Excel: {e}\")\n",
    "            raise\n",
    "\n",
    "    print(f\"\\nüìã Sheets encontradas: {len(sheets)}\")\n",
    "    for i, sheet in enumerate(sheets, 1):\n",
    "        print(f\"   {i}. {sheet}\")\n",
    "\n",
    "    tipo_arquivo = 'EXCEL'\n",
    "    separador_detectado = None\n",
    "    skiprows_csv = 0\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 2: ARQUIVOS CSV (.csv)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif extensao == '.csv':\n",
    "    print(f\"üìÑ Tipo: CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nüîç Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha expl√≠cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   ‚úÖ Separador expl√≠cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   ‚úÖ Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"‚ùå Separador CSV n√£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüìä Estrutura do CSV:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Simular sheets (CSV = 1 sheet virtual)\n",
    "        sheets = ['Dados CSV']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'CSV'\n",
    "\n",
    "        print(f\"\\nüìã Sheet virtual: 'Dados CSV'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO ao processar CSV: {e}\")\n",
    "        raise\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 3: ARQUIVOS TXT (.txt)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif extensao == '.txt':\n",
    "    print(f\"üìù Tipo: TXT\")\n",
    "    print(f\"   ‚ÑπÔ∏è  Processamento similar a CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nüîç Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha expl√≠cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   ‚úÖ Separador expl√≠cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   ‚úÖ Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"‚ùå Separador TXT n√£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüìä Estrutura do TXT:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Simular sheets (TXT = 1 sheet virtual)\n",
    "        sheets = ['Dados TXT']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'TXT'\n",
    "\n",
    "        print(f\"\\nüìã Sheet virtual: 'Dados TXT'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO ao processar TXT: {e}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"‚ùå Formato n√£o suportado: {extensao}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAMENTO DE ESTADO NO LOG\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "estado_bloco5 = {\n",
    "    'bloco': 5,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'extensao': extensao,\n",
    "    'sheets': sheets,\n",
    "    'workbook_path': str(arquivo_selecionado),\n",
    "    'separador_detectado': separador_detectado,\n",
    "    'skiprows_csv': skiprows_csv\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_5_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco5, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# RESUMO DO CARREGAMENTO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"‚úÖ CARREGAMENTO CONCLU√çDO\")\n",
    "print(\"‚îÄ\"*70)\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "print(f\"   M√©todo: {metodo_carga}\")\n",
    "print(f\"   Sheets/Tabelas: {len(sheets)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 5 CONCLU√çDO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üíæ Estado salvo: .bloco_5_state.json\")\n",
    "print(f\"üìã Pr√≥ximo: BLOCO 6 selecionar√° a sheet e far√° preview\")"
   ],
   "id": "a36bbbc312051633",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üì• CARREGAMENTO DO ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "üîç Extens√£o detectada: .xls\n",
      "üìä Tipo: EXCEL\n",
      "   ‚úÖ M√©todo: xlrd (XLS)\n",
      "\n",
      "üìã Sheets encontradas: 11\n",
      "   1. SAPBEXqueriesDefunct\n",
      "   2. SAPBEXfiltersDefunct\n",
      "   3. Valor da Varia√ß√£o Total\n",
      "   4. Valor da Varia√ß√£o Total Grupo\n",
      "   5. Limite T√©cnico\n",
      "   6. Justificar\n",
      "   7. Limite T√©cnico Grupo\n",
      "   8. BExRepositorySheet\n",
      "   9. Justificar Grupo\n",
      "   10. Custo do Produto\n",
      "   11. Imposto\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ CARREGAMENTO CONCLU√çDO\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Tipo: EXCEL\n",
      "   M√©todo: xlrd\n",
      "   Sheets/Tabelas: 11\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 5 CONCLU√çDO\n",
      "======================================================================\n",
      "üíæ Estado salvo: .bloco_5_state.json\n",
      "üìã Pr√≥ximo: BLOCO 6 selecionar√° a sheet e far√° preview\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:55.170600Z",
     "start_time": "2025-10-19T09:07:52.272271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 6 - SELE√á√ÉO DE SHEET (COM SUPORTE CSV)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã SELE√á√ÉO DE SHEET/TABELA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Carregar √∫ltima sele√ß√£o\n",
    "config_file = fm.pastas['logs'] / '.ultima_sheet.json'\n",
    "ultima_sheet = None\n",
    "arquivo_mudou = True\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "            # Verificar se √© o mesmo arquivo E timestamp recente (√∫ltima hora)\n",
    "            if config.get('arquivo') == arquivo_selecionado.name:\n",
    "                ultima_sheet = config.get('sheet')\n",
    "                # Verificar se timestamp √© recente\n",
    "                try:\n",
    "                    ts_salvo = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "                    ts_agora = datetime.now()\n",
    "                    diff_minutos = (ts_agora - ts_salvo).total_seconds() / 60\n",
    "\n",
    "                    if diff_minutos < 60:  # √öltima hora\n",
    "                        arquivo_mudou = False\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nüí° √öltima sheet: {ultima_sheet if ultima_sheet else 'Nenhuma'}\")\n",
    "print(f\"   Arquivo mudou: {'Sim' if arquivo_mudou else 'N√£o'}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 1: CSV - SELE√á√ÉO AUTOM√ÅTICA (apenas 1 sheet virtual)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if tipo_arquivo == 'CSV':\n",
    "    sheet_nome = sheets[0]  # 'Dados CSV'\n",
    "    print(f\"\\n‚úÖ Arquivo CSV - usando sheet virtual autom√°tica: '{sheet_nome}'\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 2: EXCEL - Apenas 1 sheet E arquivo mudou ‚Üí Usar diretamente\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif len(sheets) == 1 and arquivo_mudou:\n",
    "    sheet_nome = sheets[0]\n",
    "    print(f\"\\n‚úÖ Apenas 1 sheet - selecionando automaticamente: '{sheet_nome}'\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 3: EXCEL - Mais de 1 sheet OU tem hist√≥rico ‚Üí GUI COM TIMER\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "else:\n",
    "    def selecionar_sheet_com_timer(sheets, ultima=None, mostrar_timer=True):\n",
    "        \"\"\"GUI com timer para sele√ß√£o de sheet\"\"\"\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - Sele√ß√£o de Sheet\",\n",
    "            600, 450,\n",
    "            tem_timer=(mostrar_timer and ultima is not None)\n",
    "        )\n",
    "\n",
    "        # T√≠tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"üìã Sele√ß√£o de Sheet\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecione a Sheet para processar:\",\n",
    "            font=('Arial', 12, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        # Timer (se tem √∫ltima E timer ativo)\n",
    "        if ultima and mostrar_timer:\n",
    "            tk.Label(\n",
    "                frame,\n",
    "                text=f\"üí° √öltima sheet usada: '{ultima}'\",\n",
    "                font=('Arial', 10),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0',\n",
    "                padx=10,\n",
    "                pady=10\n",
    "            ).pack(fill=tk.X, pady=(0, 5))\n",
    "\n",
    "            countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        # Listbox\n",
    "        frame_list = tk.Frame(frame, bg='white')\n",
    "        frame_list.pack(fill=tk.BOTH, expand=True, pady=(0, 10))\n",
    "\n",
    "        scrollbar = tk.Scrollbar(frame_list)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        listbox = tk.Listbox(\n",
    "            frame_list,\n",
    "            yscrollcommand=scrollbar.set,\n",
    "            font=('Arial', 10),\n",
    "            height=8\n",
    "        )\n",
    "        listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        scrollbar.config(command=listbox.yview)\n",
    "\n",
    "        for sheet in sheets:\n",
    "            listbox.insert(tk.END, sheet)\n",
    "\n",
    "        # Selecionar √∫ltima ou primeira\n",
    "        if ultima and ultima in sheets:\n",
    "            idx = sheets.index(ultima)\n",
    "            listbox.select_set(idx)\n",
    "            listbox.see(idx)\n",
    "        else:\n",
    "            listbox.select_set(0)\n",
    "\n",
    "        # Fun√ß√µes\n",
    "        def nova_selecao():\n",
    "            resultado['cancelado'] = True\n",
    "            selecao = listbox.curselection()\n",
    "            if selecao:\n",
    "                resultado['valor'] = sheets[selecao[0]]\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultima\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def duplo_clique(event):\n",
    "            nova_selecao()\n",
    "\n",
    "        listbox.bind('<Double-Button-1>', duplo_clique)\n",
    "\n",
    "        # Bot√µes\n",
    "        GUIComTimer.criar_botoes(\n",
    "            frame,\n",
    "            nova_selecao,\n",
    "            usar_ultima if (ultima and mostrar_timer) else None,\n",
    "            \"Selecionar\",\n",
    "            f\"Usar '{ultima}' (10s)\" if ultima else None\n",
    "        )\n",
    "\n",
    "        # Iniciar timer\n",
    "        if ultima and mostrar_timer:\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        root.mainloop()\n",
    "\n",
    "        # Processar resultado\n",
    "        if resultado.get('timeout') and ultima:\n",
    "            print(f\"   ‚è±Ô∏è  Timeout (10s) - usando √∫ltima sheet\")\n",
    "            return ultima\n",
    "\n",
    "        return resultado['valor']\n",
    "\n",
    "    # Executar GUI\n",
    "    print(f\"\\nAbrindo janela de sele√ß√£o...\")\n",
    "    sheet_nome = selecionar_sheet_com_timer(\n",
    "        sheets,\n",
    "        ultima_sheet,\n",
    "        mostrar_timer=(not arquivo_mudou)  # Timer apenas se mesmo arquivo\n",
    "    )\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAR ESCOLHA\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'arquivo': arquivo_selecionado.name,\n",
    "        'sheet': sheet_nome,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Sheet selecionada: '{sheet_nome}'\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# RESUMO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"‚úÖ SELE√á√ÉO CONCLU√çDA\")\n",
    "print(\"‚îÄ\"*70)\n",
    "print(f\"   Arquivo: {arquivo_selecionado.name}\")\n",
    "print(f\"   Sheet: {sheet_nome}\")\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAMENTO DE ESTADO (ADICIONADO - N√ÉO REMOVE NADA ACIMA)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "estado_bloco6 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 6,\n",
    "    'nome': 'SELE√á√ÉO DE SHEET',\n",
    "    'status': 'concluido',\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet_selecionada': sheet_nome,\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'total_sheets': len(sheets),\n",
    "    'lista_sheets': sheets,\n",
    "    'metodo_selecao': 'automatico' if (tipo_arquivo == 'CSV' or len(sheets) == 1) else 'gui',\n",
    "    'arquivo_mudou': arquivo_mudou,\n",
    "    'tinha_historico': ultima_sheet is not None\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_6_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco6, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo: {arquivo_estado.name}\")"
   ],
   "id": "bd9cdff8d1341b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìã SELE√á√ÉO DE SHEET/TABELA\n",
      "======================================================================\n",
      "\n",
      "üí° √öltima sheet: Nenhuma\n",
      "   Arquivo mudou: Sim\n",
      "\n",
      "Abrindo janela de sele√ß√£o...\n",
      "\n",
      "‚úÖ Sheet selecionada: 'Valor da Varia√ß√£o Total'\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ SELE√á√ÉO CONCLU√çDA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "   Arquivo: C√≥pia de xSAPtemp4687_JAN_25.xls\n",
      "   Sheet: Valor da Varia√ß√£o Total\n",
      "   Tipo: EXCEL\n",
      "\n",
      "üíæ Estado salvo: .bloco_6_state.json\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:08:02.777657Z",
     "start_time": "2025-10-19T09:08:02.740114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 7 - PREVIEW VISUAL (50 linhas √ó 20 colunas) - SUPORTE CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FIX: datetime ‚Üí string ISO antes de salvar JSON (TypeError corrigido)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üëÄ PREVIEW DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 1: EXCEL com xlrd (arquivos .xls antigos)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if metodo_carga == 'xlrd':\n",
    "    print(\"üìä M√©todo: xlrd\")\n",
    "\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    data_preview = []\n",
    "\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_preview.append(sheet.row_values(row_idx))\n",
    "\n",
    "    df_preview = pd.DataFrame(data_preview)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 2: EXCEL com pandas (arquivos .xlsx/.xlsm)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(\"üìä M√©todo: pandas Excel\")\n",
    "\n",
    "    df_preview = pd.read_excel(\n",
    "        workbook,\n",
    "        sheet_name=sheet_nome,\n",
    "        nrows=50,\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CASO 3: CSV üÜï\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif metodo_carga == 'csv':\n",
    "    print(\"üìÑ M√©todo: CSV\")\n",
    "\n",
    "    df_preview = pd.read_csv(\n",
    "        arquivo_selecionado,\n",
    "        sep=separador_detectado,\n",
    "        encoding='cp1252',\n",
    "        skiprows=skiprows_csv,\n",
    "        nrows=50,\n",
    "        header=None  # Sem cabe√ßalho por enquanto\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"‚ùå M√©todo de carga desconhecido: {metodo_carga}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# LIMITAR A 20 COLUNAS PARA VISUALIZA√á√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "df_preview_limitado = df_preview.iloc[:, :20].copy()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXIBIR INFORMA√á√ïES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüìä Dimens√µes do preview:\")\n",
    "print(f\"   Total: {df_preview.shape[0]} linhas √ó {df_preview.shape[1]} colunas\")\n",
    "print(f\"   Exibindo: {df_preview_limitado.shape[0]} linhas √ó {df_preview_limitado.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nüëÅÔ∏è  Preview (primeiras 50 linhas, at√© 20 colunas):\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "# Usar display ou print dependendo do ambiente\n",
    "try:\n",
    "    display(df_preview_limitado)\n",
    "except NameError:\n",
    "    print(df_preview_limitado.to_string())\n",
    "\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAMENTO DE ESTADO E PREVIEW (ADICIONADO - N√ÉO REMOVE NADA ACIMA)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# ‚úÖ FIX: Fun√ß√£o para converter datetime ‚Üí string ISO\n",
    "def converter_para_json(valor):\n",
    "    \"\"\"Converte datetime/Timestamp para string ISO, sen√£o mant√©m valor\"\"\"\n",
    "    if pd.isna(valor):\n",
    "        return None\n",
    "    elif isinstance(valor, (datetime, pd.Timestamp)):\n",
    "        return valor.isoformat()\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "# Salvar preview em JSON (seguindo padr√£o do BLOCO 8)\n",
    "# ‚úÖ FIX: Aplicar convers√£o em cada c√©lula\n",
    "preview_data_raw = df_preview_limitado.values.tolist()\n",
    "preview_data_safe = [[converter_para_json(cel) for cel in row] for row in preview_data_raw]\n",
    "\n",
    "preview_data = {\n",
    "    'dimensoes': {\n",
    "        'linhas_total': int(df_preview.shape[0]),\n",
    "        'colunas_total': int(df_preview.shape[1]),\n",
    "        'linhas_exibidas': int(df_preview_limitado.shape[0]),\n",
    "        'colunas_exibidas': int(df_preview_limitado.shape[1])\n",
    "    },\n",
    "    'preview_limitado': preview_data_safe  # ‚úÖ Agora √© JSON-safe\n",
    "}\n",
    "\n",
    "preview_file = fm.pastas['logs'] / '.bloco_7_preview.json'\n",
    "with open(preview_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(preview_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Salvar estado do bloco\n",
    "estado_bloco7 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 7,\n",
    "    'nome': 'PREVIEW VISUAL',\n",
    "    'status': 'concluido',\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'dimensoes_preview': {\n",
    "        'linhas_carregadas': int(df_preview.shape[0]),\n",
    "        'colunas_carregadas': int(df_preview.shape[1]),\n",
    "        'linhas_exibidas': int(df_preview_limitado.shape[0]),\n",
    "        'colunas_exibidas': int(df_preview_limitado.shape[1])\n",
    "    },\n",
    "    'arquivo_preview': preview_file.name\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_7_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco7, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo: {arquivo_estado.name}\")\n",
    "print(f\"üíæ Preview salvo: {preview_file.name}\")"
   ],
   "id": "e38c2bfb13dddecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üëÄ PREVIEW DO ARQUIVO\n",
      "======================================================================\n",
      "üìä M√©todo: xlrd\n",
      "\n",
      "üìä Dimens√µes do preview:\n",
      "   Total: 50 linhas √ó 60 colunas\n",
      "   Exibindo: 50 linhas √ó 20 colunas\n",
      "\n",
      "üëÅÔ∏è  Preview (primeiras 50 linhas, at√© 20 colunas):\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            0    1    2    3    4    5     6                      7   \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2                                                                      \n",
       "3                                                                      \n",
       "4                                                                      \n",
       "5                                                                      \n",
       "6                                                                      \n",
       "7                                                                      \n",
       "8                                                                      \n",
       "9                                                                      \n",
       "10                                                                     \n",
       "11                                                                     \n",
       "12                                                                     \n",
       "13                                                                     \n",
       "14                                                                     \n",
       "15                                                                     \n",
       "16                                                                     \n",
       "17                                                                     \n",
       "18                                                                     \n",
       "19                                                                     \n",
       "20                                                                     \n",
       "21                                                                     \n",
       "22                                                                     \n",
       "23                                                                     \n",
       "24                                                                     \n",
       "25                                                                     \n",
       "26                                                                     \n",
       "27                                                                     \n",
       "28                                                                     \n",
       "29                                                                     \n",
       "30                                                                     \n",
       "31                                                                     \n",
       "32                                                                     \n",
       "33  Justificar             LT                                  Chave   \n",
       "34           X  0.0  0.0  1.0  1.0  1.0   1.0  512601.202501.011.674   \n",
       "35           X  0.0  0.0  2.0  1.0  2.0   2.0  512601.202501.001.422   \n",
       "36           X  0.0  0.0    X  0.0  2.0   3.0  512601.202501.003.826   \n",
       "37           X  0.0  0.0  3.0  1.0  3.0   4.0  510501.202501.000.078   \n",
       "38           X  0.0  0.0  4.0  1.0  4.0   5.0  510501.202501.011.674   \n",
       "39           X  0.0  0.0  5.0  1.0  5.0   6.0  510501.202501.024.741   \n",
       "40           X  0.0  0.0    X  0.0  5.0   7.0  510501.202501.016.205   \n",
       "41         1.0  1.0  1.0    X  0.0  5.0   8.0  510501.202501.001.422   \n",
       "42           X  0.0  1.0    X  0.0  5.0   9.0  510501.202501.011.754   \n",
       "43           X  0.0  1.0  6.0  1.0  6.0  10.0  510501.202501.026.471   \n",
       "44           X  0.0  1.0  7.0  1.0  7.0  11.0  510501.202501.003.826   \n",
       "45           X  0.0  1.0    X  0.0  7.0  12.0  531101.202501.011.674   \n",
       "46           X  0.0  1.0    X  0.0  7.0  13.0  531101.202501.016.205   \n",
       "47           X  0.0  1.0  8.0  1.0  8.0  14.0  531101.202501.001.422   \n",
       "48           X  0.0  1.0    X  0.0  8.0  15.0  531101.202501.011.754   \n",
       "49           X  0.0  1.0  9.0  1.0  9.0  16.0  531101.202501.003.826   \n",
       "\n",
       "                8               9               10  \\\n",
       "0                                                    \n",
       "1                                                    \n",
       "2                                                    \n",
       "3                                                    \n",
       "4                                                    \n",
       "5                                                    \n",
       "6                                                    \n",
       "7                                                    \n",
       "8                                                    \n",
       "9                                                    \n",
       "10                                                   \n",
       "11                                                   \n",
       "12                                                   \n",
       "13                                                   \n",
       "14                                                   \n",
       "15                                                   \n",
       "16                                                   \n",
       "17                                                   \n",
       "18                                                   \n",
       "19                                                   \n",
       "20                                                   \n",
       "21                                                   \n",
       "22                                                   \n",
       "23                                                   \n",
       "24                                                   \n",
       "25                                                   \n",
       "26                                                   \n",
       "27                                                   \n",
       "28                                                   \n",
       "29                                                   \n",
       "30                                                   \n",
       "31                                                   \n",
       "32                                                   \n",
       "33  √çndice Interno  √≠ndice Externo  √≠ndice Externo   \n",
       "34            0.05           -0.05            0.05   \n",
       "35             0.3            -0.1            0.05   \n",
       "36             0.3            -0.1            0.05   \n",
       "37            0.05           -0.05            0.05   \n",
       "38            0.05           -0.05            0.05   \n",
       "39            0.05           -0.05            0.05   \n",
       "40             0.3            -0.1            0.05   \n",
       "41             0.3            -0.1            0.05   \n",
       "42             0.3            -0.1            0.05   \n",
       "43             0.3            -0.1            0.05   \n",
       "44             0.3            -0.1            0.05   \n",
       "45            0.05           -0.05            0.05   \n",
       "46             0.3            -0.1            0.05   \n",
       "47             0.3            -0.1            0.05   \n",
       "48             0.3            -0.1            0.05   \n",
       "49             0.3            -0.1            0.05   \n",
       "\n",
       "                                      11                        12      13  \\\n",
       "0                                                                            \n",
       "1                                                                            \n",
       "2                                                                            \n",
       "3                                                                            \n",
       "4                                                                            \n",
       "5                                                                            \n",
       "6   Varia√ß√£o de Estoque por Centro - GPA                                     \n",
       "7                                                                            \n",
       "8                        Centro de lucro                                     \n",
       "9                                 Centro                                     \n",
       "10                   Classe de avalia√ß√£o                                     \n",
       "11                           Tp.material                                     \n",
       "12                    Modalidade estoque                                     \n",
       "13                               Produto                                     \n",
       "14                      Unid.medida base                                     \n",
       "15                              Dep√≥sito                                     \n",
       "16                     Tipo de movimento                                     \n",
       "17                       Tipo de ve√≠culo                                     \n",
       "18                             Incoterms                                     \n",
       "19                         Ano civil/m√™s                                     \n",
       "20                     Dia de calend√°rio    01/01/2025..31/01/2025           \n",
       "21                            HierarqPrd                                     \n",
       "22                               Indices                                     \n",
       "23                                                                           \n",
       "24                    Nome t√©cnico query  SB_IC01_GOP_VARIACAO_GPA           \n",
       "25                          InfoProvider                   S0_IC01           \n",
       "26                    √öltimo modificador                      Y3AU           \n",
       "27   Centro (op√ß√£o de sele√ß√£o, opcional)             Sele√ß√£o vazia           \n",
       "28                         Ano civil/m√™s                   01.2025           \n",
       "29                 Atualiza√ß√£o dos dados       05/02/2025 02:30:08           \n",
       "30                                                                           \n",
       "31                         Condi√ß√£o nova                   Inativo           \n",
       "32                                                                           \n",
       "33                       Centro de lucro             Ano civil/m√™s  Centro   \n",
       "34                              ACPBOPAV                   01.2025    5126   \n",
       "35                              ACPBOPAV                   01.2025    5126   \n",
       "36                              ACPBOPAV                   01.2025    5126   \n",
       "37                              ACPBOPAV                   01.2025    5105   \n",
       "38                              ACPBOPAV                   01.2025    5105   \n",
       "39                              ACPBOPAV                   01.2025    5105   \n",
       "40                              ACPBOPAV                   01.2025    5105   \n",
       "41                              ACPBOPAV                   01.2025    5105   \n",
       "42                              ACPBOPAV                   01.2025    5105   \n",
       "43                              ACPBOPAV                   01.2025    5105   \n",
       "44                              ACPBOPAV                   01.2025    5105   \n",
       "45                              ACPBOPAV                   01.2025    5311   \n",
       "46                              ACPBOPAV                   01.2025    5311   \n",
       "47                              ACPBOPAV                   01.2025    5311   \n",
       "48                              ACPBOPAV                   01.2025    5311   \n",
       "49                              ACPBOPAV                   01.2025    5311   \n",
       "\n",
       "      14                     15              16                            17  \\\n",
       "0                    VARIA√á√ÉO %  LIMITE T√âCNICO                                 \n",
       "1                                                                               \n",
       "2         LIMITE DE COMPET√äNCIA       DIRETORIA                          PRES   \n",
       "3          R$ por produto / m√™s  >60.000.000,00                    30000000.0   \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "10                                                                              \n",
       "11                                                                              \n",
       "12                                                                              \n",
       "13                                                                              \n",
       "14                                                                              \n",
       "15                                                                              \n",
       "16                                                                              \n",
       "17                                                                              \n",
       "18                                                                              \n",
       "19                                                                              \n",
       "20                                                                              \n",
       "21                                                                              \n",
       "22                                                                              \n",
       "23                                                                              \n",
       "24                                                                              \n",
       "25                                                                              \n",
       "26                                                                              \n",
       "27                                                                              \n",
       "28                                                                              \n",
       "29                                                                              \n",
       "30                                                                              \n",
       "31                                                                              \n",
       "32                                                                              \n",
       "33                   HierarqPrd         Produto                                 \n",
       "34  BAV1         Diesel - Comum      01.011.674             √ìLEO DIESEL B S10   \n",
       "35  BAV1   Querosene de Avia√ß√£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "36  BAV1   Querosene de Avia√ß√£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "37  BAV2         Gasolina Comum      01.000.078              GASOLINA COMUM C   \n",
       "38  BAV2         Diesel - Comum      01.011.674             √ìLEO DIESEL B S10   \n",
       "39  BAV2         Diesel - Comum      01.024.741  Vibra Diesel Renov√°vel HVO10   \n",
       "40  BAV2   Querosene de Avia√ß√£o      01.016.205      JET A - PRE√áO FIXO - VRG   \n",
       "41  BAV2   Querosene de Avia√ß√£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "42  BAV2   Querosene de Avia√ß√£o      01.011.754              JET A PRE√áO FIXO   \n",
       "43  BAV2   Querosene de Avia√ß√£o      01.026.471     JET A-1 NAO TABELADO - LI   \n",
       "44  BAV2   Querosene de Avia√ß√£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "45  BAV3         Diesel - Comum      01.011.674             √ìLEO DIESEL B S10   \n",
       "46  BAV3   Querosene de Avia√ß√£o      01.016.205      JET A - PRE√áO FIXO - VRG   \n",
       "47  BAV3   Querosene de Avia√ß√£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "48  BAV3   Querosene de Avia√ß√£o      01.011.754              JET A PRE√áO FIXO   \n",
       "49  BAV3   Querosene de Avia√ß√£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "\n",
       "                  18          19  \n",
       "0              FALTA       SOBRA  \n",
       "1                                 \n",
       "2                 N2          N3  \n",
       "3          1000000.0    300000.0  \n",
       "4                                 \n",
       "5                                 \n",
       "6                                 \n",
       "7                                 \n",
       "8                                 \n",
       "9                                 \n",
       "10                                \n",
       "11                                \n",
       "12                                \n",
       "13                                \n",
       "14                                \n",
       "15                                \n",
       "16                                \n",
       "17                                \n",
       "18                                \n",
       "19                                \n",
       "20                                \n",
       "21                                \n",
       "22                                \n",
       "23                                \n",
       "24                                \n",
       "25                                \n",
       "26                                \n",
       "27                                \n",
       "28                                \n",
       "29                                \n",
       "30                                \n",
       "31                                \n",
       "32                                \n",
       "33  Estoque\\nInicial     Entrada  \n",
       "34           16924.0              \n",
       "35          373850.0    939139.0  \n",
       "36          598315.0   5188210.0  \n",
       "37           13076.0     14828.0  \n",
       "38          122306.0    178128.0  \n",
       "39            3361.0     14839.0  \n",
       "40         1425416.0   3500000.0  \n",
       "41         9793143.0  19273387.0  \n",
       "42         4578994.0              \n",
       "43          513358.0   1200000.0  \n",
       "44                    38058936.0  \n",
       "45            1841.0      4955.0  \n",
       "46                      604734.0  \n",
       "47          759489.0   4295677.0  \n",
       "48          170534.0              \n",
       "49          -55123.0   3047462.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VARIA√á√ÉO %</td>\n",
       "      <td>LIMITE T√âCNICO</td>\n",
       "      <td></td>\n",
       "      <td>FALTA</td>\n",
       "      <td>SOBRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIMITE DE COMPET√äNCIA</td>\n",
       "      <td>DIRETORIA</td>\n",
       "      <td>PRES</td>\n",
       "      <td>N2</td>\n",
       "      <td>N3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>R$ por produto / m√™s</td>\n",
       "      <td>&gt;60.000.000,00</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Varia√ß√£o de Estoque por Centro - GPA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro de lucro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Classe de avalia√ß√£o</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tp.material</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modalidade estoque</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Produto</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unid.medida base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dep√≥sito</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tipo de movimento</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tipo de ve√≠culo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Incoterms</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ano civil/m√™s</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dia de calend√°rio</td>\n",
       "      <td>01/01/2025..31/01/2025</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HierarqPrd</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Indices</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nome t√©cnico query</td>\n",
       "      <td>SB_IC01_GOP_VARIACAO_GPA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>InfoProvider</td>\n",
       "      <td>S0_IC01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>√öltimo modificador</td>\n",
       "      <td>Y3AU</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro (op√ß√£o de sele√ß√£o, opcional)</td>\n",
       "      <td>Sele√ß√£o vazia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ano civil/m√™s</td>\n",
       "      <td>01.2025</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Atualiza√ß√£o dos dados</td>\n",
       "      <td>05/02/2025 02:30:08</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Condi√ß√£o nova</td>\n",
       "      <td>Inativo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Justificar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Chave</td>\n",
       "      <td>√çndice Interno</td>\n",
       "      <td>√≠ndice Externo</td>\n",
       "      <td>√≠ndice Externo</td>\n",
       "      <td>Centro de lucro</td>\n",
       "      <td>Ano civil/m√™s</td>\n",
       "      <td>Centro</td>\n",
       "      <td></td>\n",
       "      <td>HierarqPrd</td>\n",
       "      <td>Produto</td>\n",
       "      <td></td>\n",
       "      <td>Estoque\\nInicial</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>512601.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>√ìLEO DIESEL B S10</td>\n",
       "      <td>16924.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>512601.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>373850.0</td>\n",
       "      <td>939139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>512601.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>598315.0</td>\n",
       "      <td>5188210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>510501.202501.000.078</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Gasolina Comum</td>\n",
       "      <td>01.000.078</td>\n",
       "      <td>GASOLINA COMUM C</td>\n",
       "      <td>13076.0</td>\n",
       "      <td>14828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>510501.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>√ìLEO DIESEL B S10</td>\n",
       "      <td>122306.0</td>\n",
       "      <td>178128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>510501.202501.024.741</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.024.741</td>\n",
       "      <td>Vibra Diesel Renov√°vel HVO10</td>\n",
       "      <td>3361.0</td>\n",
       "      <td>14839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>510501.202501.016.205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PRE√áO FIXO - VRG</td>\n",
       "      <td>1425416.0</td>\n",
       "      <td>3500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>510501.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>9793143.0</td>\n",
       "      <td>19273387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>510501.202501.011.754</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PRE√áO FIXO</td>\n",
       "      <td>4578994.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>510501.202501.026.471</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.026.471</td>\n",
       "      <td>JET A-1 NAO TABELADO - LI</td>\n",
       "      <td>513358.0</td>\n",
       "      <td>1200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>510501.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td></td>\n",
       "      <td>38058936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>531101.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>√ìLEO DIESEL B S10</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>4955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>531101.202501.016.205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PRE√áO FIXO - VRG</td>\n",
       "      <td></td>\n",
       "      <td>604734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>531101.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>759489.0</td>\n",
       "      <td>4295677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>531101.202501.011.754</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PRE√áO FIXO</td>\n",
       "      <td>170534.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>531101.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>-55123.0</td>\n",
       "      <td>3047462.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üíæ Estado salvo: .bloco_7_state.json\n",
      "üíæ Preview salvo: .bloco_7_preview.json\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:11:20.869090Z",
     "start_time": "2025-10-19T09:08:38.469082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 8 - DETEC√á√ÉO E SELE√á√ÉO AVAN√áADA DE CABE√áALHO - COMPLETO\n",
    "# VERS√ÉO REVISADA v2.1 - CORRE√á√ïES DE BUGS\n",
    "# Com: Dicion√°rio + An√°lise Repeti√ß√£o + Multi-linha + An√°lise Colunas COMPLETA\n",
    "# Mudan√ßas v2.1:\n",
    "#   - Corrigido bug string vazia no crit√©rio 12\n",
    "#   - Corrigido penalidade diversidade no crit√©rio 5\n",
    "#   - Toler√¢ncia a gaps de at√© 3 colunas inv√°lidas\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ DETEC√á√ÉO E SELE√á√ÉO DE CABE√áALHO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CARREGAR DICION√ÅRIO PERSISTENTE (se n√£o estiver carregado)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüîç Verificando cabe√ßalho multi-linha...\")\n",
    "\n",
    "if 'DICIONARIO_PERSISTENTE' not in globals():\n",
    "    print(\"\\nüìö Carregando dicion√°rio persistente...\")\n",
    "\n",
    "    locais_dicionario = [\n",
    "        Path.cwd() / 'DICT_Dicionario_Persistente.json',\n",
    "        fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json',\n",
    "        Path.cwd().parent / 'DICT_Dicionario_Persistente.json',\n",
    "    ]\n",
    "\n",
    "    DICIONARIO_PERSISTENTE = None\n",
    "\n",
    "    for local in locais_dicionario:\n",
    "        if local.exists():\n",
    "            try:\n",
    "                with open(local, 'r', encoding='utf-8') as f:\n",
    "                    DICIONARIO_PERSISTENTE = json.load(f)\n",
    "                print(f\"   ‚úÖ Carregado de: {local.name}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not DICIONARIO_PERSISTENTE:\n",
    "        print(f\"   ‚ÑπÔ∏è  Dicion√°rio n√£o encontrado - criando vazio\")\n",
    "        DICIONARIO_PERSISTENTE = {\n",
    "            'arquivos': {},\n",
    "            'ultima_atualizacao': None,\n",
    "            'versao': '1.0'\n",
    "        }\n",
    "else:\n",
    "    print(\"\\nüìö Dicion√°rio persistente j√° carregado\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FUN√á√ÉO AVAN√áADA DE AVALIA√á√ÉO DE LINHA\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def avaliar_linha_cabecalho_avancada(\n",
    "    linha, idx, total_linhas, df_preview, dicionario_persistente\n",
    "):\n",
    "    \"\"\"Avalia linha como candidata a cabe√ßalho com m√∫ltiplas heur√≠sticas.\"\"\"\n",
    "    celulas = [\n",
    "        str(c).strip() for c in linha\n",
    "        if str(c).strip() and str(c).strip().lower() not in\n",
    "        ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not celulas:\n",
    "        return {\n",
    "            'score': 0.0,\n",
    "            'detalhes': 'Linha vazia',\n",
    "            'matches_dicionario': []\n",
    "        }\n",
    "\n",
    "    score = 0.0\n",
    "    detalhes = []\n",
    "\n",
    "    # CRIT√âRIO 1: PROPOR√á√ÉO DE C√âLULAS PREENCHIDAS (peso 2.0)\n",
    "    prop_preenchidas = len(celulas) / len(linha)\n",
    "    score_preenchidas = prop_preenchidas * 2.0\n",
    "    score += score_preenchidas\n",
    "    detalhes.append(\n",
    "        f\"Preench: {prop_preenchidas:.0%} (+{score_preenchidas:.1f})\"\n",
    "    )\n",
    "\n",
    "    # CRIT√âRIO 2: PROPOR√á√ÉO DE TEXTO (peso 2.5)\n",
    "    tem_texto = sum(1 for c in celulas if re.search(r'[a-zA-Z]', c))\n",
    "    prop_texto = tem_texto / len(celulas) if celulas else 0\n",
    "    score_texto = prop_texto * 2.5\n",
    "    score += score_texto\n",
    "    detalhes.append(f\"Texto: {prop_texto:.0%} (+{score_texto:.1f})\")\n",
    "\n",
    "    # CRIT√âRIO 3: MATCH COM DICION√ÅRIO PERSISTENTE (peso 4.0)\n",
    "    bonus_dicionario = 0.0\n",
    "    matches_dicionario = []\n",
    "\n",
    "    if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "        campos_conhecidos = set()\n",
    "        for arquivo_info in dicionario_persistente.get(\n",
    "            'arquivos', {}\n",
    "        ).values():\n",
    "            if 'campos_mapeados' in arquivo_info:\n",
    "                for campo_info in arquivo_info[\n",
    "                    'campos_mapeados'\n",
    "                ].values():\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "        for celula in celulas:\n",
    "            celula_lower = celula.lower()\n",
    "            if celula_lower in campos_conhecidos:\n",
    "                bonus_dicionario += 0.8\n",
    "                matches_dicionario.append(celula[:20])\n",
    "            elif any(\n",
    "                conhecido in celula_lower\n",
    "                for conhecido in campos_conhecidos\n",
    "            ):\n",
    "                bonus_dicionario += 0.4\n",
    "                matches_dicionario.append(f\"{celula[:15]}*\")\n",
    "\n",
    "    bonus_dicionario = min(bonus_dicionario, 4.0)\n",
    "    score += bonus_dicionario\n",
    "\n",
    "    if bonus_dicionario > 0:\n",
    "        detalhes.append(\n",
    "            f\"Dict: {len(matches_dicionario)}m (+{bonus_dicionario:.1f})\"\n",
    "        )\n",
    "\n",
    "    # CRIT√âRIO 4: AN√ÅLISE DE REPETI√á√ÉO (peso 3.0)\n",
    "    try:\n",
    "        linhas_futuras = min(20, total_linhas - idx - 1)\n",
    "\n",
    "        if linhas_futuras >= 5:\n",
    "            colunas_com_repeticao = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for i in range(1, min(linhas_futuras + 1, 21)):\n",
    "                    if idx + i < len(df_preview):\n",
    "                        valor_futuro = str(\n",
    "                            df_preview.iloc[idx + i, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_futuro == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 2:\n",
    "                    colunas_com_repeticao += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_repeticao = (\n",
    "                    colunas_com_repeticao / total_colunas_analisadas\n",
    "                )\n",
    "                score_repeticao = (1 - prop_repeticao) * 3.0\n",
    "                score += score_repeticao\n",
    "                detalhes.append(\n",
    "                    f\"Unic: {(1-prop_repeticao):.0%} \"\n",
    "                    f\"(+{score_repeticao:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRIT√âRIO 5: TAMANHO M√âDIO DE STRINGS (peso 1.0)\n",
    "    tamanho_medio = np.mean([len(c) for c in celulas]) if celulas else 0\n",
    "    if 5 <= tamanho_medio <= 50:\n",
    "        score += 1.0\n",
    "        detalhes.append(f\"Tam: {tamanho_medio:.0f} (+1.0)\")\n",
    "\n",
    "    # CRIT√âRIO 6: UNICIDADE DENTRO DA LINHA (peso 1.5)\n",
    "    if len(celulas) == len(set(celulas)):\n",
    "        score += 1.5\n",
    "        detalhes.append(\"√önicos (+1.5)\")\n",
    "\n",
    "    # CRIT√âRIO 7: POSI√á√ÉO NO ARQUIVO (peso 0.5)\n",
    "    if idx < 50:\n",
    "        bonus_posicao = (50 - idx) / 100\n",
    "        score += bonus_posicao\n",
    "        detalhes.append(f\"Pos: {idx+1} (+{bonus_posicao:.2f})\")\n",
    "\n",
    "    # CRIT√âRIO 8: AN√ÅLISE DE DADOS ABAIXO (peso 2.5)\n",
    "    try:\n",
    "        if idx + 5 < total_linhas:\n",
    "            celulas_match_dict = 0\n",
    "            celulas_numericas_puras = 0\n",
    "            celulas_com_numeros = 0\n",
    "            total_celulas_validas = 0\n",
    "\n",
    "            campos_dict_lower = set()\n",
    "            if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "                for arquivo_info in dicionario_persistente.get(\n",
    "                    'arquivos', {}\n",
    "                ).values():\n",
    "                    if 'campos_mapeados' in arquivo_info:\n",
    "                        for campo_info in arquivo_info[\n",
    "                            'campos_mapeados'\n",
    "                        ].values():\n",
    "                            if 'nome_original' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_original'].lower()\n",
    "                                )\n",
    "                            if 'nome_padrao' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_padrao'].lower()\n",
    "                                )\n",
    "                            if 'sinonimos' in campo_info:\n",
    "                                for sin in campo_info['sinonimos']:\n",
    "                                    campos_dict_lower.add(sin.lower())\n",
    "\n",
    "            for offset in range(1, 6):\n",
    "                if idx + offset < len(df_preview):\n",
    "                    linha_seguinte = df_preview.iloc[idx + offset]\n",
    "\n",
    "                    for celula in linha_seguinte:\n",
    "                        celula_str = str(celula).strip()\n",
    "\n",
    "                        if not celula_str or celula_str.lower() in [\n",
    "                            'nan', 'none', ''\n",
    "                        ]:\n",
    "                            continue\n",
    "\n",
    "                        total_celulas_validas += 1\n",
    "                        celula_lower = celula_str.lower()\n",
    "\n",
    "                        matched = False\n",
    "                        if campos_dict_lower:\n",
    "                            if celula_lower in campos_dict_lower:\n",
    "                                celulas_match_dict += 1\n",
    "                                matched = True\n",
    "                            else:\n",
    "                                for campo_conhecido in campos_dict_lower:\n",
    "                                    if (campo_conhecido in celula_lower or\n",
    "                                        celula_lower in campo_conhecido):\n",
    "                                        if len(campo_conhecido) >= 3:\n",
    "                                            celulas_match_dict += 1\n",
    "                                            matched = True\n",
    "                                            break\n",
    "\n",
    "                        if not matched:\n",
    "                            apenas_numeros = re.sub(\n",
    "                                r'[^0-9.]', '', celula_str\n",
    "                            )\n",
    "\n",
    "                            if len(apenas_numeros) > 0:\n",
    "                                prop_digitos = (\n",
    "                                    len(apenas_numeros) / len(celula_str)\n",
    "                                )\n",
    "                                if prop_digitos > 0.5:\n",
    "                                    celulas_numericas_puras += 1\n",
    "                                elif re.search(r'\\d', celula_str):\n",
    "                                    celulas_com_numeros += 1\n",
    "\n",
    "            if total_celulas_validas > 0:\n",
    "                prop_dict = celulas_match_dict / total_celulas_validas\n",
    "                prop_num_puras = (\n",
    "                    celulas_numericas_puras / total_celulas_validas\n",
    "                )\n",
    "                prop_com_num = celulas_com_numeros / total_celulas_validas\n",
    "\n",
    "                bonus_dados = 0.0\n",
    "                metodo_usado = None\n",
    "\n",
    "                if prop_dict > 0.4:\n",
    "                    bonus_dados = 2.5\n",
    "                    metodo_usado = f\"Dict:{prop_dict:.0%}\"\n",
    "                elif prop_num_puras > 0.6:\n",
    "                    bonus_dados = 2.0\n",
    "                    metodo_usado = f\"Num:{prop_num_puras:.0%}\"\n",
    "                elif (prop_num_puras + prop_com_num) > 0.7:\n",
    "                    bonus_dados = 1.0\n",
    "                    metodo_usado = f\"Misto:{(prop_num_puras+prop_com_num):.0%}\"\n",
    "\n",
    "                if bonus_dados > 0:\n",
    "                    score += bonus_dados\n",
    "                    detalhes.append(\n",
    "                        f\"DadosAbaixo:{metodo_usado} (+{bonus_dados:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRIT√âRIO 9: ANTI-DADOS (penalidade)\n",
    "    try:\n",
    "        celulas_linha_atual = [\n",
    "            str(c).strip() for c in linha\n",
    "            if str(c).strip() and str(c).strip().lower() not in\n",
    "            ['nan', 'none', '']\n",
    "        ]\n",
    "\n",
    "        if celulas_linha_atual:\n",
    "            num_puras_linha = 0\n",
    "            for celula in celulas_linha_atual:\n",
    "                apenas_numeros = re.sub(r'[^0-9.]', '', celula)\n",
    "                if len(apenas_numeros) > 0:\n",
    "                    prop_digitos = len(apenas_numeros) / len(celula)\n",
    "                    if prop_digitos > 0.5:\n",
    "                        num_puras_linha += 1\n",
    "\n",
    "            prop_num_linha = num_puras_linha / len(celulas_linha_atual)\n",
    "\n",
    "            repeticoes_detectadas = 0\n",
    "            if idx + 5 < total_linhas:\n",
    "                for col_idx, valor_atual in enumerate(linha):\n",
    "                    valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                    if (not valor_atual_str or\n",
    "                        valor_atual_str.lower() in ['nan', 'none', '']):\n",
    "                        continue\n",
    "\n",
    "                    for offset in range(1, min(6, total_linhas - idx)):\n",
    "                        if idx + offset < len(df_preview):\n",
    "                            valor_seguinte = str(\n",
    "                                df_preview.iloc[idx + offset, col_idx]\n",
    "                            ).strip()\n",
    "                            if valor_seguinte == valor_atual_str:\n",
    "                                repeticoes_detectadas += 1\n",
    "                                break\n",
    "\n",
    "            prop_repeticoes = (\n",
    "                repeticoes_detectadas / len(celulas_linha_atual)\n",
    "                if celulas_linha_atual else 0\n",
    "            )\n",
    "\n",
    "            penalidade = 0.0\n",
    "\n",
    "            if prop_num_linha > 0.6 and prop_repeticoes > 0.3:\n",
    "                penalidade = -3.0\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%}+Rep\"\n",
    "                    f\"{prop_repeticoes:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "            elif prop_num_linha > 0.7:\n",
    "                penalidade = -1.5\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRIT√âRIO 10: PADR√ÉO DE R√ìTULOS (+4.0 pontos)\n",
    "    try:\n",
    "        palavras_rotulo = [\n",
    "            'centro', 'produto', 'material', 'data', 'valor', 'quantidade',\n",
    "            'codigo', 'nome', 'descricao', 'tipo', 'categoria', 'grupo',\n",
    "            'sigla', 'unidade', 'medida', 'periodo', 'mes', 'ano',\n",
    "            'referencia', 'documento', 'numero', 'id', 'chave', 'hierarq',\n",
    "            'lucro', 'receita', 'custo', 'despesa', 'saldo', 'total',\n",
    "            'indice', 'variacao', 'percentual', 'taxa', 'margem'\n",
    "        ]\n",
    "\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        if 'nome_original' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_original'].lower()\n",
    "                            )\n",
    "                        if 'nome_padrao' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_padrao'].lower()\n",
    "                            )\n",
    "\n",
    "        palavras_rotulo = set(palavras_rotulo)\n",
    "\n",
    "        matches_rotulo = 0\n",
    "        celulas_validas = 0\n",
    "\n",
    "        for celula in linha:\n",
    "            celula_str = str(celula).strip()\n",
    "            if not celula_str or celula_str.lower() in ['nan', 'none', '']:\n",
    "                continue\n",
    "\n",
    "            celulas_validas += 1\n",
    "            celula_lower = celula_str.lower()\n",
    "\n",
    "            if celula_lower in palavras_rotulo:\n",
    "                matches_rotulo += 1\n",
    "            else:\n",
    "                for palavra in palavras_rotulo:\n",
    "                    if len(palavra) >= 4 and palavra in celula_lower:\n",
    "                        matches_rotulo += 1\n",
    "                        break\n",
    "\n",
    "        if celulas_validas > 0:\n",
    "            prop_rotulos = matches_rotulo / celulas_validas\n",
    "\n",
    "            if prop_rotulos > 0.4:\n",
    "                bonus_rotulos = 4.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "            elif prop_rotulos > 0.25:\n",
    "                bonus_rotulos = 2.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRIT√âRIO 11: ANTI-REPETI√á√ÉO FORTE (-4.0 pontos)\n",
    "    try:\n",
    "        if idx + 10 < total_linhas:\n",
    "            colunas_com_repeticao_forte = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for offset in range(1, min(11, total_linhas - idx)):\n",
    "                    if idx + offset < len(df_preview):\n",
    "                        valor_seg = str(\n",
    "                            df_preview.iloc[idx + offset, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_seg == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 5:\n",
    "                    colunas_com_repeticao_forte += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_rep_forte = (\n",
    "                    colunas_com_repeticao_forte / total_colunas_analisadas\n",
    "                )\n",
    "\n",
    "                if prop_rep_forte > 0.3:\n",
    "                    penalidade_rep = -4.0\n",
    "                    score += penalidade_rep\n",
    "                    detalhes.append(\n",
    "                        f\"AntiRep:{prop_rep_forte:.0%} \"\n",
    "                        f\"({penalidade_rep:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRIT√âRIO 12: DENSIDADE DE R√ìTULOS DO DICION√ÅRIO (+3.0 pontos)\n",
    "    try:\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            campos_conhecidos = {}\n",
    "\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        nome_orig = campo_info.get('nome_original', '')\n",
    "                        nome_pad = campo_info.get('nome_padrao', '')\n",
    "\n",
    "                        if nome_orig:\n",
    "                            campos_conhecidos[nome_orig.lower()] = True\n",
    "                        if nome_pad:\n",
    "                            campos_conhecidos[nome_pad.lower()] = True\n",
    "\n",
    "            if campos_conhecidos:\n",
    "                matches_exatos = 0\n",
    "                celulas_validas = 0\n",
    "\n",
    "                for celula in linha:\n",
    "                    celula_str = str(celula).strip()\n",
    "                    if not celula_str or celula_str.lower() in [\n",
    "                        'nan', 'none', ''\n",
    "                    ]:\n",
    "                        continue\n",
    "\n",
    "                    celulas_validas += 1\n",
    "                    celula_lower = celula_str.lower()\n",
    "\n",
    "                    if celula_lower in campos_conhecidos:\n",
    "                        matches_exatos += 1\n",
    "\n",
    "                if celulas_validas > 0:\n",
    "                    prop_dict_exato = matches_exatos / celulas_validas\n",
    "\n",
    "                    if prop_dict_exato > 0.5:\n",
    "                        bonus_dict_dens = 3.0\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "                    elif prop_dict_exato > 0.3:\n",
    "                        bonus_dict_dens = 1.5\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        'score': score,\n",
    "        'detalhes': ' | '.join(detalhes),\n",
    "        'matches_dicionario': matches_dicionario\n",
    "    }\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# AVALIAR TODAS AS LINHAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüìä Analisando linhas para detectar cabe√ßalho...\")\n",
    "\n",
    "if metodo_carga == 'csv':\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "elif metodo_carga == 'xlrd':\n",
    "    data_para_analise = []\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_para_analise.append(sheet.row_values(row_idx))\n",
    "else:\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "\n",
    "scores = []\n",
    "\n",
    "for idx, linha in enumerate(data_para_analise):\n",
    "    resultado = avaliar_linha_cabecalho_avancada(\n",
    "        linha,\n",
    "        idx,\n",
    "        len(data_para_analise),\n",
    "        df_preview,\n",
    "        DICIONARIO_PERSISTENTE\n",
    "    )\n",
    "\n",
    "    scores.append({\n",
    "        'linha_excel': idx + 1,\n",
    "        'indice': idx,\n",
    "        'score': resultado['score'],\n",
    "        'detalhes': resultado['detalhes'],\n",
    "        'matches': resultado['matches_dicionario']\n",
    "    })\n",
    "\n",
    "scores = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXIBIR TOP 5 CANDIDATOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\nüèÜ Top 5 candidatos a cabe√ßalho:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìç NUMERA√á√ÉO: Usamos √≠ndice Python (preview inicia em 0)\")\n",
    "print(\"   ‚Ä¢ √çndice 0 = Linha 1 no Excel\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, item in enumerate(scores[:5], 1):\n",
    "    idx_py = item['indice']\n",
    "    linha_excel = item['linha_excel']\n",
    "\n",
    "    print(f\"\\n   {i}¬∫. √çndice {idx_py} (Excel: Linha {linha_excel})\")\n",
    "    print(f\"       Score: {item['score']:.2f}/24.5\")\n",
    "    print(f\"       {item['detalhes']}\")\n",
    "    if item['matches']:\n",
    "        matches_str = ', '.join(item['matches'][:5])\n",
    "        print(f\"       Matches: {matches_str}\")\n",
    "\n",
    "melhor = scores[0]\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\n",
    "    f\"üéØ SUGEST√ÉO AUTOM√ÅTICA: √çndice {melhor['indice']} \"\n",
    "    f\"(Excel: Linha {melhor['linha_excel']})\"\n",
    ")\n",
    "print(f\"   Confian√ßa: {melhor['score']:.2f}/24.5\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# AN√ÅLISE DE COLUNAS V√ÅLIDAS - SISTEMA COMPLETO v2.1\n",
    "# CORRE√á√ÉO: Bugs nos crit√©rios 5 e 12\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def analisar_coluna_valida_COMPLETA(\n",
    "    col_idx,\n",
    "    nome_coluna,\n",
    "    dados_coluna,\n",
    "    dicionario,\n",
    "    todas_colunas_info=None\n",
    "):\n",
    "    \"\"\"\n",
    "    An√°lise COMPLETA de coluna com 12 crit√©rios avan√ßados.\n",
    "    Funciona para TABELAS TRANSACIONAIS e RELAT√ìRIOS BI.\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    razoes = []\n",
    "    metodo_usado = None\n",
    "\n",
    "    valores = [\n",
    "        str(v).strip() for v in dados_coluna\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not valores:\n",
    "        return {\n",
    "            'valida': False,\n",
    "            'score': 0.0,\n",
    "            'razoes': ['Coluna vazia'],\n",
    "            'tipo_detectado': 'VAZIA',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'VAZIO',\n",
    "            'prop_preenchimento': 0.0,\n",
    "            'match_dicionario': None\n",
    "        }\n",
    "\n",
    "    # CRIT√âRIO 1: SIMILARIDADE COM ALIASES DO DICION√ÅRIO (peso 8.0)\n",
    "    nome_lower = str(nome_coluna).lower().strip()\n",
    "    melhor_match_alias = None\n",
    "    melhor_score_alias = 0.0\n",
    "    campo_matched = None\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        aliases_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if nome_campo not in aliases_por_campo:\n",
    "                        aliases_por_campo[nome_campo] = set()\n",
    "\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'sinonimos' in campo_info:\n",
    "                        for sin in campo_info['sinonimos']:\n",
    "                            aliases_por_campo[nome_campo].add(sin.lower())\n",
    "\n",
    "        for campo, aliases in aliases_por_campo.items():\n",
    "            for alias in aliases:\n",
    "                if nome_lower == alias:\n",
    "                    melhor_score_alias = 1.0\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "                    break\n",
    "\n",
    "                similaridade = SequenceMatcher(None, nome_lower, alias).ratio()\n",
    "\n",
    "                if similaridade > melhor_score_alias:\n",
    "                    melhor_score_alias = similaridade\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "\n",
    "            if melhor_score_alias == 1.0:\n",
    "                break\n",
    "\n",
    "    if melhor_score_alias >= 0.95:\n",
    "        bonus_alias = 8.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Exato({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_EXATO'\n",
    "\n",
    "    elif melhor_score_alias >= 0.80:\n",
    "        bonus_alias = 6.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Similar({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_SIMILAR'\n",
    "\n",
    "    elif melhor_score_alias >= 0.60:\n",
    "        bonus_alias = 3.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Parcial({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_PARCIAL'\n",
    "\n",
    "    # CRIT√âRIO 2: REGEX NOS CONTE√öDOS vs DICION√ÅRIO (peso 7.0)\n",
    "    melhor_match_regex = None\n",
    "    melhor_score_regex = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        padroes_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'regex' in campo_info:\n",
    "                        if nome_campo not in padroes_por_campo:\n",
    "                            padroes_por_campo[nome_campo] = []\n",
    "                        padroes_por_campo[nome_campo].append(campo_info['regex'])\n",
    "\n",
    "        for campo, padroes in padroes_por_campo.items():\n",
    "            for padrao in padroes:\n",
    "                try:\n",
    "                    matches = sum(\n",
    "                        1 for v in valores[:50]\n",
    "                        if re.match(padrao, v, re.IGNORECASE)\n",
    "                    )\n",
    "\n",
    "                    prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "                    if prop_matches > melhor_score_regex:\n",
    "                        melhor_score_regex = prop_matches\n",
    "                        melhor_match_regex = campo\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    if melhor_score_regex >= 0.80:\n",
    "        bonus_regex = 7.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_CONTEUDO'\n",
    "\n",
    "    elif melhor_score_regex >= 0.60:\n",
    "        bonus_regex = 4.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_PARCIAL'\n",
    "\n",
    "    # CRIT√âRIO 3: SIMILARIDADE COM CONTE√öDOS CONHECIDOS (peso 6.0)\n",
    "    melhor_match_conteudo = None\n",
    "    melhor_score_conteudo = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        exemplos_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'exemplos' in campo_info:\n",
    "                        if nome_campo not in exemplos_por_campo:\n",
    "                            exemplos_por_campo[nome_campo] = set()\n",
    "\n",
    "                        for exemplo in campo_info['exemplos']:\n",
    "                            exemplos_por_campo[nome_campo].add(\n",
    "                                str(exemplo).lower().strip()\n",
    "                            )\n",
    "\n",
    "        for campo, exemplos in exemplos_por_campo.items():\n",
    "            matches = 0\n",
    "            for valor in valores[:50]:\n",
    "                valor_lower = valor.lower()\n",
    "\n",
    "                if valor_lower in exemplos:\n",
    "                    matches += 1\n",
    "                else:\n",
    "                    for exemplo in exemplos:\n",
    "                        sim = SequenceMatcher(None, valor_lower, exemplo).ratio()\n",
    "                        if sim >= 0.85:\n",
    "                            matches += 1\n",
    "                            break\n",
    "\n",
    "            prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "            if prop_matches > melhor_score_conteudo:\n",
    "                melhor_score_conteudo = prop_matches\n",
    "                melhor_match_conteudo = campo\n",
    "\n",
    "    if melhor_score_conteudo >= 0.70:\n",
    "        bonus_conteudo = 6.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'CONTEUDO_SIMILAR'\n",
    "\n",
    "    elif melhor_score_conteudo >= 0.50:\n",
    "        bonus_conteudo = 3.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "\n",
    "    # CRIT√âRIO 4: DETEC√á√ÉO DE F√ìRMULAS (penalidade -8.0)\n",
    "    tem_formulas = False\n",
    "\n",
    "    padroes_formula = [\n",
    "        r'^=',\n",
    "        r'^\\+',\n",
    "        r'^SUM\\(',\n",
    "        r'^IF\\(',\n",
    "        r'^VLOOKUP\\(',\n",
    "    ]\n",
    "\n",
    "    for valor in valores[:20]:\n",
    "        for padrao in padroes_formula:\n",
    "            if re.match(padrao, valor, re.IGNORECASE):\n",
    "                tem_formulas = True\n",
    "                break\n",
    "        if tem_formulas:\n",
    "            break\n",
    "\n",
    "    if tem_formulas:\n",
    "        penalidade_formula = -8.0\n",
    "        score += penalidade_formula\n",
    "        razoes.append(f\"Formula! {penalidade_formula:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'FORMULA_DETECTADA'\n",
    "\n",
    "    # CRIT√âRIO 5: DIVERSIDADE DE VALORES (peso 4.0)\n",
    "    # CORRE√á√ÉO v2.1: N√£o penalizar dimens√µes BI com baixa diversidade na amostra\n",
    "    valores_unicos = len(set(valores))\n",
    "    total_valores = len(valores)\n",
    "    prop_unicos = valores_unicos / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_unicos > 0.7:\n",
    "        score += 4.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+4.0)\")\n",
    "    elif prop_unicos > 0.4:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+2.0)\")\n",
    "    elif prop_unicos < 0.05 and valores_unicos <= 3:\n",
    "        # S√≥ penalizar se REALMENTE for flag (‚â§3 valores √∫nicos E <5%)\n",
    "        score -= 3.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (-3.0)\")\n",
    "\n",
    "    # CRIT√âRIO 6: PADR√ÉO DE FLAGS (penalidade -4.0)\n",
    "    flags_comuns = {'true', 'false', 'x', '‚úì', '0', '1', 'sim', 'n√£o', 'yes', 'no'}\n",
    "    valores_lower = [v.lower() for v in valores]\n",
    "\n",
    "    matches_flag = sum(1 for v in valores_lower if v in flags_comuns)\n",
    "    prop_flags = matches_flag / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_flags > 0.8:\n",
    "        score -= 4.0\n",
    "        razoes.append(f\"Flags:{prop_flags:.0%} (-4.0)\")\n",
    "\n",
    "    # CRIT√âRIO 7: PALAVRAS-CHAVE DE DADOS (peso 3.0)\n",
    "    palavras_dados = [\n",
    "        'centro', 'produto', 'material', 'codigo', 'nome', 'data',\n",
    "        'valor', 'quantidade', 'preco', 'custo', 'receita',\n",
    "        'hierarq', 'grupo', 'categoria', 'tipo', 'unidade',\n",
    "        'periodo', 'mes', 'ano', 'sigla', 'descricao', 'lucro'\n",
    "    ]\n",
    "\n",
    "    tem_palavra_chave = any(palavra in nome_lower for palavra in palavras_dados)\n",
    "\n",
    "    if tem_palavra_chave:\n",
    "        score += 3.0\n",
    "        razoes.append(f\"Keyword (+3.0)\")\n",
    "\n",
    "    # CRIT√âRIO 8: TAMANHO M√âDIO DOS VALORES (peso 2.0)\n",
    "    tamanho_medio = sum(len(v) for v in valores) / len(valores)\n",
    "\n",
    "    if 3 <= tamanho_medio <= 100:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (+2.0)\")\n",
    "    elif tamanho_medio <= 2:\n",
    "        score -= 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (-2.0)\")\n",
    "\n",
    "    # CRIT√âRIO 9: MIX NUM√âRICO/ALFAB√âTICO (peso 1.0)\n",
    "    tem_numeros = sum(1 for v in valores if any(c.isdigit() for c in v))\n",
    "    tem_letras = sum(1 for v in valores if any(c.isalpha() for c in v))\n",
    "\n",
    "    if tem_numeros > 0 and tem_letras > 0:\n",
    "        score += 1.0\n",
    "        razoes.append(f\"Mix (+1.0)\")\n",
    "\n",
    "    # CRIT√âRIO 10: PREENCHIMENTO PARCIAL (penalidade -5.0)\n",
    "    prop_preenchimento = len(valores) / len(dados_coluna) if dados_coluna else 0\n",
    "\n",
    "    if prop_preenchimento < 0.30:\n",
    "        penalidade_parcial = -5.0\n",
    "        score += penalidade_parcial\n",
    "        razoes.append(f\"Parcial:{prop_preenchimento:.0%} {penalidade_parcial:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'PREENCHIMENTO_PARCIAL'\n",
    "\n",
    "    # CRIT√âRIO 11: MUDAN√áA ESTRUTURAL (penalidade -6.0)\n",
    "    if todas_colunas_info and col_idx > 0:\n",
    "        colunas_anteriores = todas_colunas_info[:col_idx]\n",
    "\n",
    "        if len(colunas_anteriores) >= 5:\n",
    "            preench_ultimas_5 = sum(\n",
    "                c.get('prop_preenchimento', 1.0)\n",
    "                for c in colunas_anteriores[-5:]\n",
    "            ) / 5\n",
    "\n",
    "            if preench_ultimas_5 > 0.80 and prop_preenchimento < 0.50:\n",
    "                penalidade_estrutural = -6.0\n",
    "                score += penalidade_estrutural\n",
    "                razoes.append(\n",
    "                    f\"Estrutural:Queda ({penalidade_estrutural:.1f})\"\n",
    "                )\n",
    "                if not metodo_usado:\n",
    "                    metodo_usado = 'MUDANCA_ESTRUTURAL'\n",
    "\n",
    "    # CRIT√âRIO 12: PADR√ÉO DE NOME \"VAZIO\" (penalidade -7.0)\n",
    "    # CORRE√á√ÉO v2.1: Remover string vazia da lista\n",
    "    nomes_vazios = ['unnamed', 'column', 'col', 'field', 'nan', 'none']\n",
    "\n",
    "    nome_eh_vazio = (\n",
    "        len(nome_lower) == 0 or\n",
    "        nome_lower in nomes_vazios or\n",
    "        (len(nome_lower) < 15 and any(vazio in nome_lower for vazio in nomes_vazios if vazio))\n",
    "    )\n",
    "\n",
    "    if nome_eh_vazio:\n",
    "        penalidade_nome = -7.0\n",
    "        score += penalidade_nome\n",
    "        razoes.append(f\"NomeVazio {penalidade_nome:.1f}\")\n",
    "\n",
    "    # DECIS√ÉO FINAL\n",
    "    confianca = max(0.0, min(1.0, (score + 10) / 40))\n",
    "\n",
    "    if score >= 10.0:\n",
    "        tipo = \"DADOS\"\n",
    "        valida = True\n",
    "    elif score >= 0.0:\n",
    "        tipo = \"INCERTO\"\n",
    "        valida = True\n",
    "    else:\n",
    "        tipo = \"FLAG/FORMULA/AUXILIAR\"\n",
    "        valida = False\n",
    "\n",
    "    if not metodo_usado:\n",
    "        metodo_usado = 'HEURISTICAS_BASICAS'\n",
    "\n",
    "    return {\n",
    "        'valida': valida,\n",
    "        'score': score,\n",
    "        'razoes': razoes,\n",
    "        'tipo_detectado': tipo,\n",
    "        'confianca': confianca,\n",
    "        'metodo': metodo_usado,\n",
    "        'prop_preenchimento': prop_preenchimento,\n",
    "        'match_dicionario': campo_matched or melhor_match_regex or melhor_match_conteudo\n",
    "    }\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXECUTAR AN√ÅLISE DE COLUNAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç ANALISANDO COLUNAS (Sistema Avan√ßado v2.1)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Crit√©rios: Similaridade + Regex + Conte√∫do + F√≥rmulas + Estrutura\")\n",
    "print(\"Funciona para: Tabelas Transacionais e Relat√≥rios BI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "linha_cabecalho_detectado = data_para_analise[melhor['indice']]\n",
    "\n",
    "inicio_dados = melhor['indice'] + 1\n",
    "fim_dados = min(inicio_dados + 50, len(data_para_analise))\n",
    "dados_para_colunas = data_para_analise[inicio_dados:fim_dados]\n",
    "\n",
    "print(f\"\\nüìä Analisando {len(linha_cabecalho_detectado)} colunas...\")\n",
    "print(f\"   Amostra de dados: {fim_dados - inicio_dados} linhas\")\n",
    "\n",
    "# PRIMEIRA PASSAGEM: Informa√ß√µes b√°sicas\n",
    "todas_colunas_info = []\n",
    "\n",
    "for col_idx, nome_col in enumerate(linha_cabecalho_detectado):\n",
    "    valores_col = [linha[col_idx] for linha in dados_para_colunas]\n",
    "\n",
    "    valores_validos = [\n",
    "        str(v).strip() for v in valores_col\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    prop_preenchimento = len(valores_validos) / len(valores_col) if valores_col else 0\n",
    "\n",
    "    todas_colunas_info.append({\n",
    "        'indice': col_idx,\n",
    "        'nome': str(nome_col),\n",
    "        'valores': valores_col,\n",
    "        'prop_preenchimento': prop_preenchimento\n",
    "    })\n",
    "\n",
    "# SEGUNDA PASSAGEM: An√°lise completa\n",
    "colunas_analise = []\n",
    "\n",
    "for col_info in todas_colunas_info:\n",
    "    col_idx = col_info['indice']\n",
    "    nome_col = col_info['nome']\n",
    "    valores_col = col_info['valores']\n",
    "\n",
    "    analise = analisar_coluna_valida_COMPLETA(\n",
    "        col_idx,\n",
    "        nome_col,\n",
    "        valores_col,\n",
    "        DICIONARIO_PERSISTENTE,\n",
    "        todas_colunas_info=todas_colunas_info\n",
    "    )\n",
    "\n",
    "    colunas_analise.append({\n",
    "        'indice': col_idx,\n",
    "        'excel_col': col_idx + 1,\n",
    "        'nome': str(nome_col)[:30],\n",
    "        **analise\n",
    "    })\n",
    "\n",
    "colunas_validas = [c for c in colunas_analise if c['valida']]\n",
    "colunas_invalidas = [c for c in colunas_analise if not c['valida']]\n",
    "\n",
    "print(f\"\\n‚úÖ Colunas V√ÅLIDAS (dados reais): {len(colunas_validas)}\")\n",
    "print(f\"‚ùå Colunas INV√ÅLIDAS (flags/f√≥rmulas/auxiliares): {len(colunas_invalidas)}\")\n",
    "\n",
    "# EXIBIR INV√ÅLIDAS\n",
    "if colunas_invalidas:\n",
    "    print(f\"\\n‚ùå COLUNAS DETECTADAS COMO INV√ÅLIDAS:\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for col in colunas_invalidas[:15]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"{col['tipo_detectado']}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_str = ' | '.join(col['razoes'][:4])\n",
    "            print(f\"      Raz√µes: {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      Match: {col['match_dicionario']}\")\n",
    "\n",
    "# EXIBIR V√ÅLIDAS\n",
    "if colunas_validas:\n",
    "    print(f\"\\n‚úÖ TOP 10 COLUNAS V√ÅLIDAS (maiores scores):\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    colunas_validas_sorted = sorted(\n",
    "        colunas_validas,\n",
    "        key=lambda x: x['score'],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for col in colunas_validas_sorted[:10]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"Conf: {col['confianca']:.0%}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_str = ' | '.join(col['razoes'][:3])\n",
    "            print(f\"      {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      ‚úì Match: {col['match_dicionario']}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# DETECTAR MUDAN√áAS ESTRUTURAIS E AGRUPAR EM BLOCOS CONT√çNUOS\n",
    "# v2.1: Toler√¢ncia a gaps de at√© 3 colunas inv√°lidas\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüîç DETECTANDO MUDAN√áAS ESTRUTURAIS:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Coletar √≠ndices de colunas v√°lidas\n",
    "colunas_validas_indices = [c['excel_col'] for c in colunas_analise if c['valida']]\n",
    "\n",
    "if not colunas_validas_indices:\n",
    "    blocos_continuos = []\n",
    "else:\n",
    "    # Agrupar com toler√¢ncia a gaps de at√© 3 colunas\n",
    "    blocos_continuos = []\n",
    "    bloco_atual = [colunas_validas_indices[0]]\n",
    "\n",
    "    for i in range(1, len(colunas_validas_indices)):\n",
    "        col_atual = colunas_validas_indices[i]\n",
    "        col_anterior = colunas_validas_indices[i-1]\n",
    "\n",
    "        gap = col_atual - col_anterior - 1\n",
    "\n",
    "        # Se gap <= 3, considerar mesmo bloco (BI pode ter colunas vazias/auxiliares no meio)\n",
    "        # Se gap > 3, come√ßar novo bloco\n",
    "        if gap <= 3:\n",
    "            bloco_atual.append(col_atual)\n",
    "        else:\n",
    "            blocos_continuos.append(bloco_atual)\n",
    "            bloco_atual = [col_atual]\n",
    "\n",
    "    if bloco_atual:\n",
    "        blocos_continuos.append(bloco_atual)\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    print(f\"\\n‚ö†Ô∏è  M√öLTIPLAS TABELAS DETECTADAS!\")\n",
    "\n",
    "    for i, bloco in enumerate(blocos_continuos, 1):\n",
    "        primeira = min(bloco)\n",
    "        ultima = max(bloco)\n",
    "        tamanho = len(bloco)\n",
    "\n",
    "        range_completo = ultima - primeira + 1\n",
    "        gaps_internos = range_completo - tamanho\n",
    "\n",
    "        print(f\"\\n   Tabela {i}:\")\n",
    "        print(f\"      Range Excel: {primeira} a {ultima}\")\n",
    "        print(f\"      Colunas v√°lidas: {tamanho}\")\n",
    "        if gaps_internos > 0:\n",
    "            print(f\"      Gaps tolerados: {gaps_internos} col(s)\")\n",
    "\n",
    "        if i == 1:\n",
    "            print(f\"      ‚úì TABELA PRINCIPAL (use esta!)\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è  Tabela auxiliar/complementar\")\n",
    "\n",
    "    primeira_valida = min(blocos_continuos[0])\n",
    "    ultima_valida = max(blocos_continuos[0])\n",
    "\n",
    "    print(f\"\\nüí° RECOMENDA√á√ÉO:\")\n",
    "    print(f\"   Use apenas TABELA PRINCIPAL: colunas {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        primeira_valida = min(c['excel_col'] for c in colunas_validas)\n",
    "        ultima_valida = max(c['excel_col'] for c in colunas_validas)\n",
    "\n",
    "        print(f\"\\n‚úì Estrutura cont√≠nua detectada\")\n",
    "        print(f\"   Colunas v√°lidas: {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "# DETERMINAR RANGE FINAL\n",
    "if blocos_continuos:\n",
    "    col_inicio_sugerido = min(blocos_continuos[0])\n",
    "    col_fim_sugerido = max(blocos_continuos[0])\n",
    "\n",
    "    total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "    total_validas = len(blocos_continuos[0])\n",
    "    total_gaps = total_range - total_validas\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        col_inicio_sugerido = min(c['excel_col'] for c in colunas_validas)\n",
    "        col_fim_sugerido = max(c['excel_col'] for c in colunas_validas)\n",
    "        total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "        total_validas = len(colunas_validas)\n",
    "        total_gaps = total_range - total_validas\n",
    "    else:\n",
    "        col_inicio_sugerido = 1\n",
    "        col_fim_sugerido = len(linha_cabecalho_detectado)\n",
    "        total_range = col_fim_sugerido\n",
    "        total_validas = 0\n",
    "        total_gaps = 0\n",
    "\n",
    "print(f\"\\nüéØ RANGE FINAL SUGERIDO:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Excel: {col_inicio_sugerido} a {col_fim_sugerido}\")\n",
    "print(f\"   Python: {col_inicio_sugerido-1} a {col_fim_sugerido}\")\n",
    "print(f\"   Total range: {total_range} colunas\")\n",
    "print(f\"   Colunas v√°lidas: {total_validas}\")\n",
    "if total_gaps > 0:\n",
    "    print(f\"   Gaps internos: {total_gaps} (tolerados)\")\n",
    "\n",
    "if col_inicio_sugerido > 1:\n",
    "    colunas_ignoradas = col_inicio_sugerido - 1\n",
    "    print(f\"\\n   ‚ö†Ô∏è  Ignorando colunas 1-{colunas_ignoradas}\")\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    total_auxiliares = sum(len(bloco) for bloco in blocos_continuos[1:])\n",
    "    print(f\"   ‚ö†Ô∏è  Ignorando {total_auxiliares} colunas de tabelas auxiliares\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SALVAR RELAT√ìRIO\n",
    "relatorio_colunas = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'total_colunas': len(colunas_analise),\n",
    "    'colunas_validas': len(colunas_validas),\n",
    "    'colunas_invalidas': len(colunas_invalidas),\n",
    "    'blocos_detectados': len(blocos_continuos),\n",
    "    'range_sugerido': {\n",
    "        'inicio': col_inicio_sugerido,\n",
    "        'fim': col_fim_sugerido,\n",
    "        'total_range': total_range if blocos_continuos else col_fim_sugerido - col_inicio_sugerido + 1,\n",
    "        'total_validas': total_validas if blocos_continuos else len(colunas_validas),\n",
    "        'total_gaps': total_gaps if blocos_continuos else 0\n",
    "    },\n",
    "    'blocos': [\n",
    "        {\n",
    "            'bloco': i,\n",
    "            'inicio': min(bloco),\n",
    "            'fim': max(bloco),\n",
    "            'colunas_validas': len(bloco),\n",
    "            'range_completo': max(bloco) - min(bloco) + 1,\n",
    "            'gaps': (max(bloco) - min(bloco) + 1) - len(bloco),\n",
    "            'principal': i == 1\n",
    "        }\n",
    "        for i, bloco in enumerate(blocos_continuos, 1)\n",
    "    ],\n",
    "    'detalhes_colunas': [\n",
    "        {\n",
    "            'col': c['excel_col'],\n",
    "            'nome': c['nome'],\n",
    "            'valida': c['valida'],\n",
    "            'score': c['score'],\n",
    "            'tipo': c['tipo_detectado'],\n",
    "            'metodo': c['metodo'],\n",
    "            'match': c.get('match_dicionario')\n",
    "        }\n",
    "        for c in colunas_analise\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.analise_colunas.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    json.dump(relatorio_colunas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Relat√≥rio salvo: .analise_colunas.json\")\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# NOVA FUN√á√ÉO: ANTI-DADOS PARA DETEC√á√ÉO MULTI-LINHA\n",
    "# Inserir ANTES da se√ß√£o \"DETECTAR MULTI-LINHA\"\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def linha_parece_dados(linha, dicionario_persistente):\n",
    "    \"\"\"\n",
    "    Verifica se uma linha PARECE ser dados ao inv√©s de cabe√ßalho.\n",
    "\n",
    "    Returns:\n",
    "        float: Score de \"certeza que √© dados\" (0.0 a 1.0)\n",
    "               > 0.6 = provavelmente DADOS\n",
    "               < 0.4 = provavelmente CABE√áALHO\n",
    "    \"\"\"\n",
    "    celulas = [\n",
    "        str(c).strip() for c in linha\n",
    "        if str(c).strip() and str(c).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not celulas:\n",
    "        return 0.0\n",
    "\n",
    "    score_dados = 0.0\n",
    "\n",
    "    # CRIT√âRIO 1: Presen√ßa de IDs/c√≥digos num√©ricos puros (peso alto)\n",
    "    codigos_numericos = 0\n",
    "    for celula in celulas:\n",
    "        # Remove pontos e h√≠fens para detectar c√≥digos como \"1.000.000\" ou \"10-234\"\n",
    "        apenas_digitos = re.sub(r'[.\\-_/]', '', celula)\n",
    "\n",
    "        # Se tem 5+ d√≠gitos consecutivos, √© muito prov√°vel que seja c√≥digo/ID\n",
    "        if len(apenas_digitos) >= 5 and apenas_digitos.isdigit():\n",
    "            codigos_numericos += 1\n",
    "\n",
    "    prop_codigos = codigos_numericos / len(celulas)\n",
    "    if prop_codigos > 0.3:\n",
    "        score_dados += 0.5  # Forte indicador de dados\n",
    "\n",
    "    # CRIT√âRIO 2: Match com VALORES conhecidos do dicion√°rio (n√£o nomes de campos)\n",
    "    if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "        valores_conhecidos = set()\n",
    "\n",
    "        for arq_info in dicionario_persistente.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for campo_info in arq_info['campos_mapeados'].values():\n",
    "                    # Pega EXEMPLOS de valores (dados), n√£o nomes de campos\n",
    "                    if 'exemplos' in campo_info:\n",
    "                        for exemplo in campo_info['exemplos']:\n",
    "                            valores_conhecidos.add(str(exemplo).lower().strip())\n",
    "\n",
    "        matches_valores = 0\n",
    "        for celula in celulas:\n",
    "            celula_lower = celula.lower()\n",
    "            if celula_lower in valores_conhecidos:\n",
    "                matches_valores += 1\n",
    "            # Similaridade parcial para valores longos\n",
    "            elif len(celula) > 10:\n",
    "                for valor_conhecido in valores_conhecidos:\n",
    "                    if len(valor_conhecido) > 10:\n",
    "                        sim = SequenceMatcher(None, celula_lower, valor_conhecido).ratio()\n",
    "                        if sim > 0.85:\n",
    "                            matches_valores += 1\n",
    "                            break\n",
    "\n",
    "        prop_match_valores = matches_valores / len(celulas)\n",
    "        if prop_match_valores > 0.5:\n",
    "            score_dados += 0.4  # Forte indicador de dados\n",
    "\n",
    "    # CRIT√âRIO 3: Padr√£o de nomenclatura de cabe√ßalho (AUSENTE = √© dados)\n",
    "    palavras_cabecalho = [\n",
    "        'codigo', 'nome', 'descricao', 'data', 'valor', 'quantidade',\n",
    "        'tipo', 'categoria', 'grupo', 'centro', 'material', 'produto',\n",
    "        'hierarq', 'sigla', 'unidade', 'periodo', 'mes', 'ano'\n",
    "    ]\n",
    "\n",
    "    tem_palavra_cabecalho = any(\n",
    "        any(palavra in celula.lower() for palavra in palavras_cabecalho)\n",
    "        for celula in celulas\n",
    "    )\n",
    "\n",
    "    if not tem_palavra_cabecalho:\n",
    "        score_dados += 0.2  # Moderado indicador de dados\n",
    "\n",
    "    # CRIT√âRIO 4: Tamanho muito curto (flags) ou muito longo (descri√ß√µes)\n",
    "    tamanho_medio = sum(len(c) for c in celulas) / len(celulas)\n",
    "    if tamanho_medio < 3:\n",
    "        # Muito curto = flags = dados\n",
    "        score_dados += 0.1\n",
    "    elif tamanho_medio > 40:\n",
    "        # Muito longo = descri√ß√µes detalhadas = dados\n",
    "        score_dados += 0.15\n",
    "\n",
    "    # CRIT√âRIO 5: Padr√µes espec√≠ficos de dados\n",
    "    padroes_dados = [\n",
    "        r'^\\d{6,}$',                    # C√≥digos num√©ricos longos\n",
    "        r'^[A-Z]{2,}_[A-Z_]+$',         # Padr√µes tipo DIESEL_MAR√çTIMO_SIMP\n",
    "        r'^\\d{4}-\\d{2}-\\d{2}$',         # Datas ISO\n",
    "        r'^\\d+[.,]\\d{2}$',              # Valores monet√°rios\n",
    "    ]\n",
    "\n",
    "    matches_padroes = 0\n",
    "    for celula in celulas:\n",
    "        for padrao in padroes_dados:\n",
    "            if re.match(padrao, celula):\n",
    "                matches_padroes += 1\n",
    "                break\n",
    "\n",
    "    prop_padroes = matches_padroes / len(celulas)\n",
    "    if prop_padroes > 0.3:\n",
    "        score_dados += 0.3\n",
    "\n",
    "    return min(1.0, score_dados)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# DETECTAR MULTI-LINHA\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if len(scores) > 1:\n",
    "    segundo = scores[1]\n",
    "\n",
    "    # Verificar se segunda linha PARECE dados\n",
    "    segunda_linha_dados = data_para_analise[segundo['indice']]\n",
    "    prob_dados = linha_parece_dados(segunda_linha_dados, DICIONARIO_PERSISTENTE)\n",
    "\n",
    "    print(f\"\\nüîç An√°lise da linha seguinte (L{segundo['linha_excel']}):\")\n",
    "    print(f\"   Score: {segundo['score']:.2f}\")\n",
    "    print(f\"   Probabilidade de ser DADOS: {prob_dados:.0%}\")\n",
    "\n",
    "    # CRIT√âRIOS MAIS RIGOROSOS para multi-linha:\n",
    "    # 1. Score deve ser > 70% do melhor (n√£o 50%)\n",
    "    # 2. Probabilidade de ser dados deve ser < 40%\n",
    "    # 3. Diferen√ßa de score deve ser razo√°vel (n√£o muito diferente)\n",
    "\n",
    "    eh_multilinea = (\n",
    "        segundo['indice'] == melhor['indice'] + 1 and\n",
    "        segundo['score'] > (melhor['score'] * 0.70) and  # ‚Üê AUMENTADO de 0.5 para 0.7\n",
    "        prob_dados < 0.4 and                              # ‚Üê NOVO crit√©rio anti-dados\n",
    "        abs(melhor['score'] - segundo['score']) < 8.0    # ‚Üê NOVO: scores similares\n",
    "    )\n",
    "\n",
    "    if eh_multilinea:\n",
    "        print(f\"\\n   ‚úÖ CABE√áALHO MULTI-LINHA confirmado!\")\n",
    "        print(f\"   Linha {melhor['linha_excel']}: Score {melhor['score']:.2f}\")\n",
    "        print(f\"   Linha {segundo['linha_excel']}: Score {segundo['score']:.2f}\")\n",
    "        print(f\"\\n   üí° RECOMENDA√á√ÉO:\")\n",
    "        print(f\"      1. CONCATENAR: Linha1 + ' - ' + Linha2\")\n",
    "        print(f\"      2. USAR PRIMEIRA: Linha {melhor['linha_excel']}\")\n",
    "        print(f\"      3. PERSONALIZAR via GUI\")\n",
    "\n",
    "        multi_linha_detectado = True\n",
    "        linha_fim_sugerida = segundo['linha_excel']\n",
    "    else:\n",
    "        if prob_dados > 0.6:\n",
    "            print(f\"\\n   ‚ùå Linha seguinte PARECE SER DADOS (n√£o cabe√ßalho)\")\n",
    "            print(f\"      Probabilidade: {prob_dados:.0%}\")\n",
    "        else:\n",
    "            print(f\"\\n   ‚ÑπÔ∏è  Scores insuficientes para multi-linha\")\n",
    "            print(f\"      Threshold: {melhor['score'] * 0.70:.2f}\")\n",
    "            print(f\"      Score L{segundo['linha_excel']}: {segundo['score']:.2f}\")\n",
    "\n",
    "        multi_linha_detectado = False\n",
    "        linha_fim_sugerida = melhor['linha_excel']\n",
    "else:\n",
    "    multi_linha_detectado = False\n",
    "    linha_fim_sugerida = melhor['linha_excel']\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# GUI AVAN√áADA COM TIMER\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def selecionar_range_cabecalho_com_timer(\n",
    "    sugerido_linha,\n",
    "    sugerido_linha_fim,\n",
    "    total_linhas,\n",
    "    total_colunas,\n",
    "    multi_linha=False,\n",
    "    col_inicio_sug=1,\n",
    "    col_fim_sug=None\n",
    "):\n",
    "    \"\"\"GUI avan√ßada para sele√ß√£o de range de cabe√ßalho.\"\"\"\n",
    "\n",
    "    if col_fim_sug is None:\n",
    "        col_fim_sug = total_colunas\n",
    "\n",
    "    config_file = fm.pastas['logs'] / '.ultimo_range_cabecalho.json'\n",
    "    ultimo_config = None\n",
    "\n",
    "    if config_file.exists():\n",
    "        try:\n",
    "            with open(config_file, 'r', encoding='utf-8') as f:\n",
    "                cfg = json.load(f)\n",
    "                if cfg.get('arquivo') == arquivo_selecionado.name:\n",
    "                    ultimo_config = cfg\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "        \"DETECTOR - Sele√ß√£o Avan√ßada de Cabe√ßalho\",\n",
    "        650, 850,\n",
    "        tem_timer=bool(ultimo_config)\n",
    "    )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"üìã Configura√ß√£o de Cabe√ßalho e Dados\",\n",
    "        font=('Arial', 14, 'bold'),\n",
    "        bg='white'\n",
    "    ).pack(pady=(0, 10))\n",
    "\n",
    "    explicacao = tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"üìç IMPORTANTE: Numera√ß√£o\\n\\n\"\n",
    "            \"‚Ä¢ √çndice Python (preview): inicia em 0\\n\"\n",
    "            \"‚Ä¢ Linha Excel (arquivo): inicia em 1\\n\"\n",
    "            \"‚Ä¢ Use LINHA EXCEL nos campos abaixo\"\n",
    "        ),\n",
    "        font=('Arial', 9),\n",
    "        bg='#E3F2FD',\n",
    "        fg='#0D47A1',\n",
    "        justify=tk.LEFT,\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        relief=tk.RIDGE,\n",
    "        borderwidth=2\n",
    "    )\n",
    "    explicacao.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    idx_sugerido = sugerido_linha - 1\n",
    "    texto_sugestao = (\n",
    "        f\"ü§ñ SUGEST√ÉO AUTOM√ÅTICA\\n\"\n",
    "        f\"Cabe√ßalho: √çndice {idx_sugerido} (Excel L{sugerido_linha})\\n\"\n",
    "        f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "        f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "    )\n",
    "\n",
    "    if multi_linha and sugerido_linha_fim != sugerido_linha:\n",
    "        idx_fim = sugerido_linha_fim - 1\n",
    "        texto_sugestao = (\n",
    "            f\"ü§ñ SUGEST√ÉO AUTOM√ÅTICA (MULTI-LINHA)\\n\"\n",
    "            f\"Cabe√ßalho: √çndices {idx_sugerido}-{idx_fim} \"\n",
    "            f\"(Excel L{sugerido_linha}-L{sugerido_linha_fim})\\n\"\n",
    "            f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "            f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "        )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=texto_sugestao,\n",
    "        font=('Arial', 10, 'bold'),\n",
    "        bg='#E8F5E9' if not multi_linha else '#FFF9C4',\n",
    "        fg='#2E7D32' if not multi_linha else '#F57F17',\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        justify=tk.CENTER\n",
    "    ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if col_inicio_sug > 1:\n",
    "        colunas_ignoradas = col_inicio_sug - 1\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=(\n",
    "                f\"‚ö†Ô∏è COLUNAS 1-{colunas_ignoradas} DETECTADAS COMO \"\n",
    "                f\"FLAGS/F√ìRMULAS\\n\"\n",
    "                f\"(Ser√£o ignoradas automaticamente)\"\n",
    "            ),\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFEBEE',\n",
    "            fg='#C62828',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if ultimo_config:\n",
    "        linha_ini = ultimo_config['linha_inicio']\n",
    "        linha_fim = ultimo_config.get('linha_fim', linha_ini)\n",
    "        col_ini = ultimo_config['col_inicio']\n",
    "        col_fim = ultimo_config['col_fim']\n",
    "\n",
    "        idx_ini = linha_ini - 1\n",
    "        idx_fim = linha_fim - 1\n",
    "\n",
    "        texto_ultimo = (\n",
    "            f\"üí° √öLTIMA CONFIGURA√á√ÉO USADA\\n\"\n",
    "            f\"Cabe√ßalho: √çndice {idx_ini}\"\n",
    "        )\n",
    "        if idx_fim != idx_ini:\n",
    "            texto_ultimo += f\"-{idx_fim}\"\n",
    "        texto_ultimo += f\" (Excel L{linha_ini}\"\n",
    "        if linha_fim != linha_ini:\n",
    "            texto_ultimo += f\"-L{linha_fim}\"\n",
    "        texto_ultimo += f\") | Colunas {col_ini}-{col_fim}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=texto_ultimo,\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFF3E0',\n",
    "            fg='#E65100',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(\n",
    "            frame, root, resultado, contador\n",
    "        )\n",
    "\n",
    "    frame_inputs = tk.Frame(frame, bg='white')\n",
    "    frame_inputs.pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha Cabe√ßalho IN√çCIO (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=0, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['linha_inicio'] if ultimo_config\n",
    "            else sugerido_linha)\n",
    "    )\n",
    "    entry_cab_ini.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha Cabe√ßalho FIM (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=1, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "            if ultimo_config else sugerido_linha_fim)\n",
    "    )\n",
    "    entry_cab_fim.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna IN√çCIO:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=2, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_inicio'] if ultimo_config\n",
    "            else col_inicio_sug)\n",
    "    )\n",
    "    entry_col_ini.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna FIM:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=3, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_fim'] if ultimo_config\n",
    "            else col_fim_sug)\n",
    "    )\n",
    "    entry_col_fim.grid(row=3, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha DADOS in√≠cio (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=4, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_dados_ini = tk.Entry(\n",
    "        frame_inputs, width=10, font=('Arial', 10)\n",
    "    )\n",
    "\n",
    "    dados_inicio_default = (\n",
    "        ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "        if ultimo_config else sugerido_linha_fim\n",
    "    ) + 1\n",
    "\n",
    "    entry_dados_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_dados_inicio', dados_inicio_default)\n",
    "            if ultimo_config else dados_inicio_default)\n",
    "    )\n",
    "    entry_dados_ini.grid(row=4, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"üí° Para cabe√ßalho 1 linha: In√≠cio = Fim\\n\"\n",
    "            \"üí° Para multi-linha: In√≠cio < Fim (ex: 3 a 4)\"\n",
    "        ),\n",
    "        font=('Arial', 8, 'italic'),\n",
    "        bg='#FFFDE7',\n",
    "        fg='#F57F17',\n",
    "        padx=10,\n",
    "        pady=8,\n",
    "        justify=tk.LEFT\n",
    "    ).pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    def confirmar():\n",
    "        resultado['cancelado'] = True\n",
    "        try:\n",
    "            resultado['valor'] = {\n",
    "                'linha_inicio': int(entry_cab_ini.get()),\n",
    "                'linha_fim': int(entry_cab_fim.get()),\n",
    "                'col_inicio': int(entry_col_ini.get()),\n",
    "                'col_fim': int(entry_col_fim.get()),\n",
    "                'linha_dados_inicio': int(entry_dados_ini.get())\n",
    "            }\n",
    "        except ValueError:\n",
    "            resultado['valor'] = None\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    def usar_ultima():\n",
    "        resultado['cancelado'] = True\n",
    "        resultado['valor'] = {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    GUIComTimer.criar_botoes(\n",
    "        frame,\n",
    "        confirmar,\n",
    "        usar_ultima if ultimo_config else None,\n",
    "        \"‚úÖ Confirmar\",\n",
    "        \"‚è±Ô∏è Usar √öltima (10s)\"\n",
    "    )\n",
    "\n",
    "    if ultimo_config:\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    if resultado.get('timeout') and ultimo_config:\n",
    "        print(f\"   ‚è±Ô∏è  Timeout - usando √∫ltima configura√ß√£o\")\n",
    "        return {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "\n",
    "    return resultado['valor']\n",
    "\n",
    "# EXECUTAR GUI\n",
    "print(\"\\nAbrindo janela de configura√ß√£o...\")\n",
    "config = selecionar_range_cabecalho_com_timer(\n",
    "    melhor['linha_excel'],\n",
    "    linha_fim_sugerida,\n",
    "    len(data_para_analise),\n",
    "    len(data_para_analise[0]) if data_para_analise else 1,\n",
    "    multi_linha=multi_linha_detectado,\n",
    "    col_inicio_sug=col_inicio_sugerido,\n",
    "    col_fim_sug=col_fim_sugerido\n",
    ")\n",
    "\n",
    "if not config:\n",
    "    raise ValueError(\"‚ùå Configura√ß√£o inv√°lida ou cancelada\")\n",
    "\n",
    "# Salvar configura√ß√£o\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.ultimo_range_cabecalho.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    config_salvar = config.copy()\n",
    "    config_salvar['arquivo'] = arquivo_selecionado.name\n",
    "    config_salvar['sheet'] = sheet_nome\n",
    "    config_salvar['timestamp'] = datetime.now().isoformat()\n",
    "    json.dump(config_salvar, f, indent=2)\n",
    "\n",
    "# Extrair informa√ß√µes\n",
    "linha_cabecalho_inicio = config['linha_inicio']\n",
    "linha_cabecalho_fim = config['linha_fim']\n",
    "col_inicio = config['col_inicio']\n",
    "col_fim = config['col_fim']\n",
    "linha_dados_inicio = config['linha_dados_inicio']\n",
    "\n",
    "print(f\"\\n‚úÖ CONFIGURA√á√ÉO CONFIRMADA:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   üìã Cabe√ßalho (Excel): L{linha_cabecalho_inicio}\", end=\"\")\n",
    "if linha_cabecalho_fim != linha_cabecalho_inicio:\n",
    "    print(f\" a L{linha_cabecalho_fim}\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"   üìä Colunas (Excel): {col_inicio} a {col_fim}\")\n",
    "print(f\"   üìà Dados come√ßam (Excel): L{linha_dados_inicio}\")\n",
    "\n",
    "# Converter para √≠ndices Python\n",
    "idx_cab_inicio = linha_cabecalho_inicio - 1\n",
    "idx_cab_fim = linha_cabecalho_fim - 1\n",
    "idx_col_inicio = col_inicio - 1\n",
    "idx_col_fim = col_fim\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "print(f\"\\n   üêç √çndices Python (uso interno):\")\n",
    "print(f\"      Cabe√ßalho: idx {idx_cab_inicio}\", end=\"\")\n",
    "if idx_cab_fim != idx_cab_inicio:\n",
    "    print(f\" a {idx_cab_fim}\")\n",
    "else:\n",
    "    print()\n",
    "print(f\"      Colunas: idx {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"      Dados: a partir de idx {idx_dados_inicio}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SALVAR ESTADO DO BLOCO 8\n",
    "estado_bloco8 = {\n",
    "    'bloco': 8,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'config': config,\n",
    "    'indices_python': {\n",
    "        'cabecalho_inicio': idx_cab_inicio,\n",
    "        'cabecalho_fim': idx_cab_fim,\n",
    "        'col_inicio': idx_col_inicio,\n",
    "        'col_fim': idx_col_fim,\n",
    "        'dados_inicio': idx_dados_inicio\n",
    "    },\n",
    "    'deteccao': {\n",
    "        'metodo': 'scoring_avancado_v2.1',\n",
    "        'melhor_score': melhor['score'],\n",
    "        'multi_linha': multi_linha_detectado,\n",
    "        'total_candidatos': len(scores),\n",
    "        'correcoes': ['bug_string_vazia', 'bug_diversidade', 'tolerancia_gaps']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.bloco_8_state.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    json.dump(estado_bloco8, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ DETEC√á√ÉO DE CABE√áALHO CONCLU√çDA\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a0c483a69d5db0c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ DETEC√á√ÉO E SELE√á√ÉO DE CABE√áALHO\n",
      "======================================================================\n",
      "\n",
      "üîç Verificando cabe√ßalho multi-linha...\n",
      "\n",
      "üìö Dicion√°rio persistente j√° carregado\n",
      "\n",
      "üìä Analisando linhas para detectar cabe√ßalho...\n",
      "\n",
      "üèÜ Top 5 candidatos a cabe√ßalho:\n",
      "======================================================================\n",
      "üìç NUMERA√á√ÉO: Usamos √≠ndice Python (preview inicia em 0)\n",
      "   ‚Ä¢ √çndice 0 = Linha 1 no Excel\n",
      "======================================================================\n",
      "\n",
      "   1¬∫. √çndice 33 (Excel: Linha 34)\n",
      "       Score: 14.10/24.5\n",
      "       Preench: 72% (+1.4) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 23 (+1.0) | Pos: 34 (+0.17) | DadosAbaixo:Num:81% (+2.0) | Rotulos:56% (+4.0)\n",
      "\n",
      "   2¬∫. √çndice 6 (Excel: Linha 7)\n",
      "       Score: 12.47/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 36 (+1.0) | √önicos (+1.5) | Pos: 7 (+0.44) | Rotulos:100% (+4.0)\n",
      "\n",
      "   3¬∫. √çndice 8 (Excel: Linha 9)\n",
      "       Score: 12.45/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 15 (+1.0) | √önicos (+1.5) | Pos: 9 (+0.42) | Rotulos:100% (+4.0)\n",
      "\n",
      "   4¬∫. √çndice 9 (Excel: Linha 10)\n",
      "       Score: 12.44/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 6 (+1.0) | √önicos (+1.5) | Pos: 10 (+0.41) | Rotulos:100% (+4.0)\n",
      "\n",
      "   5¬∫. √çndice 11 (Excel: Linha 12)\n",
      "       Score: 12.42/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 11 (+1.0) | √önicos (+1.5) | Pos: 12 (+0.39) | Rotulos:100% (+4.0)\n",
      "\n",
      "======================================================================\n",
      "üéØ SUGEST√ÉO AUTOM√ÅTICA: √çndice 33 (Excel: Linha 34)\n",
      "   Confian√ßa: 14.10/24.5\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üîç ANALISANDO COLUNAS (Sistema Avan√ßado v2.1)\n",
      "======================================================================\n",
      "Crit√©rios: Similaridade + Regex + Conte√∫do + F√≥rmulas + Estrutura\n",
      "Funciona para: Tabelas Transacionais e Relat√≥rios BI\n",
      "======================================================================\n",
      "\n",
      "üìä Analisando 60 colunas...\n",
      "   Amostra de dados: 16 linhas\n",
      "\n",
      "‚úÖ Colunas V√ÅLIDAS (dados reais): 40\n",
      "‚ùå Colunas INV√ÅLIDAS (flags/f√≥rmulas/auxiliares): 20\n",
      "\n",
      "‚ùå COLUNAS DETECTADAS COMO INV√ÅLIDAS:\n",
      "======================================================================\n",
      "   Col  1 (idx  0): Justificar                | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Flags:94% (-4.0) | Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col  2 (idx  1):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  3 (idx  2):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  5 (idx  4):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  6 (idx  5):                           | Score:   -3.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Divers:56% (+2.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  7 (idx  6):                           | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Divers:100% (+4.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col 15 (idx 14):                           | Score:   -4.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:4 (+2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 18 (idx 17):                           | Score:   -2.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Divers:50% (+2.0) | Tam:22 (+2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 30 (idx 29):                           | Score:   +0.0 | VAZIA\n",
      "      Raz√µes: Coluna vazia\n",
      "   Col 38 (idx 37): Compet√™ncia para Absor√ß√£o | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col 39 (idx 38): Compet√™ncia para Absor√ß√£o | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col 40 (idx 39):                           | Score:   +0.0 | VAZIA\n",
      "      Raz√µes: Coluna vazia\n",
      "   Col 41 (idx 40):                           | Score:   -6.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Divers:50% (+2.0) | Tam:2 (-2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 42 (idx 41):                           | Score:   -3.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Divers:44% (+2.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col 43 (idx 42):                           | Score:   -8.0 | FLAG/FORMULA/AUXILIAR\n",
      "      Raz√µes: Tam:2 (-2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "\n",
      "‚úÖ TOP 10 COLUNAS V√ÅLIDAS (maiores scores):\n",
      "======================================================================\n",
      "   Col 27 (idx 26): Custo Unit√°rio do Produto | Score:   +9.0 | Conf: 48%\n",
      "      Divers:88% (+4.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 17 (idx 16): Produto                   | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:10 (+2.0)\n",
      "   Col 29 (idx 28): Valor da Varia√ß√£o\n",
      "Interna | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:12 (+2.0)\n",
      "   Col 31 (idx 30): Quantidade Excedente da V | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:5 (+2.0)\n",
      "   Col 32 (idx 31): Valor Excedente da Varia√ß | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:10 (+2.0)\n",
      "   Col 37 (idx 36): Valor Excedente da Varia√ß | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:5 (+2.0)\n",
      "   Col 53 (idx 52): Custo Unit√°rio do Produto | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 55 (idx 54): Valor da Varia√ß√£o\n",
      "Interna | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:15 (+2.0)\n",
      "   Col 56 (idx 55): Custo M√©dio Ponderado Uni | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 59 (idx 58): Valor Excedente da Varia√ß | Score:   +7.0 | Conf: 42%\n",
      "      Divers:44% (+2.0) | Keyword (+3.0) | Tam:8 (+2.0)\n",
      "\n",
      "üîç DETECTANDO MUDAN√áAS ESTRUTURAIS:\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  M√öLTIPLAS TABELAS DETECTADAS!\n",
      "\n",
      "   Tabela 1:\n",
      "      Range Excel: 4 a 37\n",
      "      Colunas v√°lidas: 28\n",
      "      Gaps tolerados: 6 col(s)\n",
      "      ‚úì TABELA PRINCIPAL (use esta!)\n",
      "\n",
      "   Tabela 2:\n",
      "      Range Excel: 49 a 60\n",
      "      Colunas v√°lidas: 12\n",
      "      ‚ö†Ô∏è  Tabela auxiliar/complementar\n",
      "\n",
      "üí° RECOMENDA√á√ÉO:\n",
      "   Use apenas TABELA PRINCIPAL: colunas 4 a 37\n",
      "\n",
      "üéØ RANGE FINAL SUGERIDO:\n",
      "======================================================================\n",
      "   Excel: 4 a 37\n",
      "   Python: 3 a 37\n",
      "   Total range: 34 colunas\n",
      "   Colunas v√°lidas: 28\n",
      "   Gaps internos: 6 (tolerados)\n",
      "\n",
      "   ‚ö†Ô∏è  Ignorando colunas 1-3\n",
      "   ‚ö†Ô∏è  Ignorando 12 colunas de tabelas auxiliares\n",
      "======================================================================\n",
      "\n",
      "üíæ Relat√≥rio salvo: .analise_colunas.json\n",
      "\n",
      "üîç An√°lise da linha seguinte (L7):\n",
      "   Score: 12.47\n",
      "   Probabilidade de ser DADOS: 0%\n",
      "\n",
      "   ‚ÑπÔ∏è  Scores insuficientes para multi-linha\n",
      "      Threshold: 9.87\n",
      "      Score L7: 12.47\n",
      "\n",
      "Abrindo janela de configura√ß√£o...\n",
      "\n",
      "‚úÖ CONFIGURA√á√ÉO CONFIRMADA:\n",
      "======================================================================\n",
      "   üìã Cabe√ßalho (Excel): L34\n",
      "   üìä Colunas (Excel): 13 a 37\n",
      "   üìà Dados come√ßam (Excel): L35\n",
      "\n",
      "   üêç √çndices Python (uso interno):\n",
      "      Cabe√ßalho: idx 33\n",
      "      Colunas: idx 12 a 37\n",
      "      Dados: a partir de idx 34\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DETEC√á√ÉO DE CABE√áALHO CONCLU√çDA\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:02.023540Z",
     "start_time": "2025-10-19T09:18:01.708452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 9 - EXTRA√á√ÉO DE DADOS v2.0 (CORRIGIDO - PADR√ÉO JSON)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CORRE√á√ïES v2.0:\n",
    "# ‚úÖ REMOVIDO: .parquet (biblioteca n√£o instalada)\n",
    "# ‚úÖ ADICIONADO: .json para persist√™ncia (padr√£o do projeto)\n",
    "# ‚úÖ MANTIDO: Todas as valida√ß√µes e logs\n",
    "# ‚úÖ COMPAT√çVEL: Com BLOCO 10 v2.3 (que espera JSON tamb√©m)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# COMUNICA√á√ÉO VIA LOG:\n",
    "# - L√ä: .bloco_5_state.json, .bloco_8_state.json, LOG GLOBAL\n",
    "# - SALVA: df_bruto em JSON + .bloco_9_state.json\n",
    "# - PR√ìXIMO BLOCO: Carrega df_bruto do JSON\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì• EXTRA√á√ÉO DE DADOS v2.0\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 1. CONECTAR VIA LOG GLOBAL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\"‚ùå LOG GLOBAL n√£o encontrado! Execute BLOCO 1.\")\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\n‚úÖ CONFIGURA√á√ÉO CARREGADA DO LOG GLOBAL\")\n",
    "print(f\"   üìÅ Pasta base: {pasta_base.name}\")\n",
    "print(f\"   üïê Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Recriar FileManager\n",
    "from sys import path as sys_path\n",
    "# Assumir que FileManagerInterativo foi definido no BLOCO 2\n",
    "# Se n√£o estiver na mem√≥ria, o usu√°rio deve executar BLOCO 2 primeiro\n",
    "if 'FileManagerInterativo' not in globals():\n",
    "    raise NameError(\"‚ùå FileManagerInterativo n√£o encontrado! Execute BLOCO 2.\")\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 2. CARREGAR CONFIGURA√á√ïES DOS BLOCOS 4, 5, 6, 8\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# BLOCO 8: Range de cabe√ßalho e colunas\n",
    "arquivo_bloco8 = fm.pastas['logs'] / '.bloco_8_state.json'\n",
    "if not arquivo_bloco8.exists():\n",
    "    raise FileNotFoundError(\"‚ùå BLOCO 8 n√£o executado!\")\n",
    "\n",
    "with open(arquivo_bloco8, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco8 = json.load(f)\n",
    "\n",
    "config_bloco8 = estado_bloco8['config']\n",
    "\n",
    "linha_cabecalho_inicio = config_bloco8['linha_inicio']\n",
    "linha_cabecalho_fim = config_bloco8['linha_fim']\n",
    "col_inicio = config_bloco8['col_inicio']\n",
    "col_fim = config_bloco8['col_fim']\n",
    "linha_dados_inicio = config_bloco8['linha_dados_inicio']\n",
    "\n",
    "# BLOCO 5: M√©todo de carga e arquivo\n",
    "arquivo_bloco5_state = fm.pastas['logs'] / '.bloco_5_state.json'\n",
    "if not arquivo_bloco5_state.exists():\n",
    "    raise FileNotFoundError(\"‚ùå BLOCO 5 n√£o executado!\")\n",
    "\n",
    "with open(arquivo_bloco5_state, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco5 = json.load(f)\n",
    "\n",
    "metodo_carga = estado_bloco5['metodo_carga']\n",
    "arquivo_selecionado = Path(estado_bloco5['workbook_path'])\n",
    "\n",
    "# CSV espec√≠fico\n",
    "if metodo_carga == 'csv':\n",
    "    separador_detectado = estado_bloco5.get('separador_detectado', ',')\n",
    "    skiprows_csv = estado_bloco5.get('skiprows_csv', 0)\n",
    "\n",
    "# Sheet selecionada: buscar do BLOCO 8\n",
    "sheet_nome = estado_bloco8['sheet']\n",
    "\n",
    "print(f\"\\n‚úÖ CONFIGURA√á√ïES CARREGADAS\")\n",
    "print(f\"   üìÑ Arquivo: {arquivo_selecionado.name}\")\n",
    "print(f\"   üìã Sheet: {sheet_nome}\")\n",
    "print(f\"   üîß M√©todo: {metodo_carga}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 3. CONVERTER √çNDICES EXCEL ‚Üí PYTHON\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "idx_cab_inicio = linha_cabecalho_inicio - 1\n",
    "idx_cab_fim = linha_cabecalho_fim - 1\n",
    "idx_col_inicio = col_inicio - 1\n",
    "idx_col_fim = col_fim\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "print(\"\\nüìã Configura√ß√£o (nota√ß√£o Excel):\")\n",
    "print(f\"   Cabe√ßalho: L{linha_cabecalho_inicio}\", end=\"\")\n",
    "if linha_cabecalho_fim != linha_cabecalho_inicio:\n",
    "    print(f\" a L{linha_cabecalho_fim}\")\n",
    "else:\n",
    "    print()\n",
    "print(f\"   Colunas: {col_inicio} a {col_fim}\")\n",
    "print(f\"   Dados: A partir de L{linha_dados_inicio}\")\n",
    "\n",
    "print(f\"\\nüêç √çndices Python:\")\n",
    "print(f\"   Cabe√ßalho: {idx_cab_inicio} a {idx_cab_fim}\")\n",
    "print(f\"   Colunas: {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"   Dados: a partir de {idx_dados_inicio}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 4. EXTRA√á√ÉO: CSV\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if metodo_carga == 'csv':\n",
    "    print(f\"\\nüìÑ M√©todo: CSV\")\n",
    "\n",
    "    try:\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   üìã Cabe√ßalho √∫nico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                arquivo_selecionado,\n",
    "                sep=separador_detectado,\n",
    "                encoding='cp1252',\n",
    "                skiprows=skiprows_csv,\n",
    "                header=idx_cab_inicio,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "            if linhas_pular > 0:\n",
    "                print(f\"   ‚è≠Ô∏è  Pulando {linhas_pular} linha(s)\")\n",
    "                df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "        else:\n",
    "            print(f\"   üìã Cabe√ßalho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            df_temp = pd.read_csv(\n",
    "                arquivo_selecionado,\n",
    "                sep=separador_detectado,\n",
    "                encoding='cp1252',\n",
    "                skiprows=skiprows_csv,\n",
    "                header=None,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            cab_linhas = df_temp.iloc[idx_cab_inicio:idx_cab_fim+1].values\n",
    "            cab_final = []\n",
    "\n",
    "            for col_idx in range(cab_linhas.shape[1]):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            df = df_temp.iloc[idx_dados_inicio:].copy()\n",
    "            df.columns = cab_final\n",
    "\n",
    "        print(f\"   ‚úÖ Carregado: {len(df):,} registros √ó {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 5. EXTRA√á√ÉO: EXCEL MODERNO (PANDAS)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(f\"üìã M√©todo: pandas (XLSX/XLSM)\")\n",
    "\n",
    "    try:\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   üìã Cabe√ßalho √∫nico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            df = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=idx_cab_inicio,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "            if linhas_pular > 0:\n",
    "                print(f\"   ‚è≠Ô∏è  Pulando {linhas_pular} linha(s)\")\n",
    "                df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "        else:\n",
    "            print(f\"   üìã Cabe√ßalho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            df_temp = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=None,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            cab_linhas = df_temp.iloc[idx_cab_inicio:idx_cab_fim+1].values\n",
    "            cab_final = []\n",
    "\n",
    "            for col_idx in range(cab_linhas.shape[1]):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            df = df_temp.iloc[idx_dados_inicio:].copy()\n",
    "            df.columns = cab_final\n",
    "\n",
    "        print(f\"   ‚úÖ Carregado: {len(df):,} registros √ó {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 6. EXTRA√á√ÉO: EXCEL LEGADO (XLRD)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "elif metodo_carga == 'xlrd':\n",
    "    print(f\"üìã M√©todo: xlrd (XLS)\")\n",
    "\n",
    "    try:\n",
    "        import xlrd\n",
    "        workbook = xlrd.open_workbook(arquivo_selecionado)\n",
    "        sheet = workbook.sheet_by_name(sheet_nome)\n",
    "\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   üìã Cabe√ßalho √∫nico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            cabecalho = sheet.row_values(idx_cab_inicio)[idx_col_inicio:idx_col_fim]\n",
    "\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cabecalho)\n",
    "\n",
    "        else:\n",
    "            print(f\"   üìã Cabe√ßalho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            cab_linhas = []\n",
    "            for linha_idx in range(idx_cab_inicio, idx_cab_fim + 1):\n",
    "                cab_linhas.append(sheet.row_values(linha_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            cab_final = []\n",
    "            for col_idx in range(len(cab_linhas[0])):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cab_final)\n",
    "\n",
    "        print(f\"   ‚úÖ Carregado: {len(df):,} registros √ó {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"‚ùå M√©todo desconhecido: {metodo_carga}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 7. VALIDA√á√ïES P√ìS-EXTRA√á√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"‚úÖ VALIDA√á√ïES\")\n",
    "print(\"‚îÄ\"*70)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìä Shape final:\")\n",
    "print(f\"   Registros: {len(df):,}\")\n",
    "print(f\"   Colunas: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\nüìã Primeiras 10 colunas:\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "if len(df.columns) > 10:\n",
    "    print(f\"   ... e mais {len(df.columns) - 10} colunas\")\n",
    "\n",
    "print(f\"\\nüìà Primeiras 5 linhas (amostra):\")\n",
    "print(df.head().to_string())\n",
    "\n",
    "print(f\"\\nüî¢ Tipos detectados:\")\n",
    "tipos_count = df.dtypes.value_counts()\n",
    "for tipo, count in tipos_count.items():\n",
    "    print(f\"   {str(tipo).ljust(15)}: {count} coluna(s)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Valores nulos:\")\n",
    "nulos_total = df.isnull().sum().sum()\n",
    "if nulos_total > 0:\n",
    "    print(f\"   Total: {nulos_total:,} c√©lulas vazias\")\n",
    "    colunas_com_nulos = df.isnull().sum()\n",
    "    colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0].sort_values(ascending=False)\n",
    "    print(f\"\\n   Top 5 colunas com nulos:\")\n",
    "    for col, count in colunas_com_nulos.head(5).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"      {col[:40].ljust(40)}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Nenhum valor nulo!\")\n",
    "\n",
    "memoria_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nüíæ Mem√≥ria utilizada: {memoria_mb:.2f} MB\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 8. SALVAMENTO EM JSON (PADR√ÉO DO PROJETO)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüíæ Salvando df_bruto em JSON...\")\n",
    "\n",
    "df_bruto = df.copy()\n",
    "\n",
    "# Converter DataFrame para JSON estruturado\n",
    "df_dict = {\n",
    "    'columns': list(df_bruto.columns),\n",
    "    'data': df_bruto.values.tolist(),\n",
    "    'index': df_bruto.index.tolist(),\n",
    "    'dtypes': {col: str(dtype) for col, dtype in df_bruto.dtypes.items()}\n",
    "}\n",
    "\n",
    "arquivo_df_json = fm.pastas['processados'] / f'df_bruto_{timestamp_execucao}.json'\n",
    "\n",
    "with open(arquivo_df_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(df_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "tamanho_kb = arquivo_df_json.stat().st_size / 1024\n",
    "print(f\"   ‚úÖ Salvo: {arquivo_df_json.name} ({tamanho_kb:.1f} KB)\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 9. SALVAR ESTADO DO BLOCO 9\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "estado_bloco9 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 9,\n",
    "    'nome': 'EXTRA√á√ÉO DE DADOS',\n",
    "    'versao': '2.0',\n",
    "    'status': 'concluido',\n",
    "    'variaveis_criadas': ['df', 'df_bruto'],\n",
    "    'arquivo_processado': arquivo_selecionado.name,\n",
    "    'arquivo_df_bruto_json': arquivo_df_json.name,\n",
    "    'caminho_completo_json': str(arquivo_df_json),\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'estatisticas': {\n",
    "        'total_registros': len(df),\n",
    "        'total_colunas': len(df.columns),\n",
    "        'memoria_mb': round(memoria_mb, 2),\n",
    "        'colunas_com_nulos': int(nulos_total),\n",
    "        'tipos_detectados': {str(k): int(v) for k, v in df.dtypes.value_counts().items()}\n",
    "    },\n",
    "    'configuracao_aplicada': {\n",
    "        'linha_cabecalho_inicio': linha_cabecalho_inicio,\n",
    "        'linha_cabecalho_fim': linha_cabecalho_fim,\n",
    "        'col_inicio': col_inicio,\n",
    "        'col_fim': col_fim,\n",
    "        'linha_dados_inicio': linha_dados_inicio,\n",
    "        'cabecalho_multilinha': linha_cabecalho_inicio != linha_cabecalho_fim\n",
    "    },\n",
    "    'colunas_extraidas': list(df.columns),\n",
    "    'transformacoes_aplicadas': [\n",
    "        {\n",
    "            'tipo': 'extracao_range',\n",
    "            'descricao': f'Cabe√ßalho L{linha_cabecalho_inicio}-L{linha_cabecalho_fim}, Colunas {col_inicio}-{col_fim}, Dados L{linha_dados_inicio}+',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    ],\n",
    "    'instrucoes_proximo_bloco': {\n",
    "        'como_carregar': 'pd.read_json() ou json.load() + pd.DataFrame()',\n",
    "        'arquivo': arquivo_df_json.name,\n",
    "        'caminho': str(arquivo_df_json)\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_9_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco9, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EXTRA√á√ÉO CONCLU√çDA COM SUCESSO v2.0\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìù INSTRU√á√ïES PARA O PR√ìXIMO BLOCO:\")\n",
    "print(f\"   1. Carregar estado: json.load('.bloco_9_state.json')\")\n",
    "print(f\"   2. Ler caminho: estado['caminho_completo_json']\")\n",
    "print(f\"   3. Carregar df_bruto:\")\n",
    "print(f\"      with open(caminho, 'r') as f:\")\n",
    "print(f\"          df_dict = json.load(f)\")\n",
    "print(f\"      df_bruto = pd.DataFrame(df_dict['data'], columns=df_dict['columns'])\")\n",
    "print(\"=\"*70)"
   ],
   "id": "51575848480d0ea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üì• EXTRA√á√ÉO DE DADOS v2.0\n",
      "======================================================================\n",
      "\n",
      "‚úÖ CONFIGURA√á√ÉO CARREGADA DO LOG GLOBAL\n",
      "   üìÅ Pasta base: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   üïê Timestamp: 20251019_060722\n",
      "\n",
      "‚úÖ CONFIGURA√á√ïES CARREGADAS\n",
      "   üìÑ Arquivo: C√≥pia de xSAPtemp4687_JAN_25.xls\n",
      "   üìã Sheet: Valor da Varia√ß√£o Total\n",
      "   üîß M√©todo: xlrd\n",
      "\n",
      "üìã Configura√ß√£o (nota√ß√£o Excel):\n",
      "   Cabe√ßalho: L34\n",
      "   Colunas: 13 a 37\n",
      "   Dados: A partir de L35\n",
      "\n",
      "üêç √çndices Python:\n",
      "   Cabe√ßalho: 33 a 33\n",
      "   Colunas: 12 a 37\n",
      "   Dados: a partir de 34\n",
      "üìã M√©todo: xlrd (XLS)\n",
      "   üìã Cabe√ßalho √∫nico (L34)\n",
      "   ‚úÖ Carregado: 967 registros √ó 25 colunas\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ VALIDA√á√ïES\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìä Shape final:\n",
      "   Registros: 967\n",
      "   Colunas: 25\n",
      "\n",
      "üìã Primeiras 10 colunas:\n",
      "    1. Ano civil/m√™s\n",
      "    2. Centro\n",
      "    3. \n",
      "    4. HierarqPrd\n",
      "    5. Produto\n",
      "    6. \n",
      "    7. Estoque\n",
      "Inicial\n",
      "    8. Entrada\n",
      "    9. Varia√ß√£o\n",
      "Externa\n",
      "   10. Varia√ß√£o\n",
      "Externa\n",
      "%\n",
      "   ... e mais 15 colunas\n",
      "\n",
      "üìà Primeiras 5 linhas (amostra):\n",
      "  Ano civil/m√™s Centro                  HierarqPrd     Produto                             Estoque\\nInicial    Entrada Varia√ß√£o\\nExterna Varia√ß√£o\\nExterna\\n% Varia√ß√£o\\nInterna Varia√ß√£o\\nInterna\\n% Varia√ß√£o\\nTotal Varia√ß√£o\\nTotal\\n% Custo Unit√°rio do Produto  Imposto Valor da Varia√ß√£o\\nInterna   Quantidade Excedente da Varia√ß√£o Externa Valor Excedente da Varia√ß√£o Externa (R$) Quantidade Excedente da Varia√ß√£o Interna Valor Excedente da Varia√ß√£o Interna (R$) Quantidade Excedente da Varia√ß√£o Total Valor Excedente da Varia√ß√£o Total (R$) Valor Excedente da Varia√ß√£o Total + Imposto (R$)\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674           √ìLEO DIESEL B S10          16924.0                                                                18.0             0.106358            18.0           0.106358                  5.300122      0.0                  95.402202                                        0.0                                      0.0                                    10.19                                54.008246                                  10.19                                  54.01                                            54.01\n",
      "1       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.001.422     JET A NAO TABELADO - LI         373850.0   939139.0             824.0              0.08774             -10.0            -0.000762           814.0           0.036144                  3.890482 -2811.15                 -38.904816                                     366.22                              1424.772156                                      0.0                                      0.0                                    0.0                                    0.0                                          2811.15\n",
      "2       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.003.826  JET A INTERNACIONAL I - LI         598315.0  5188210.0            1494.0             0.028796                                                 1494.0           0.013613                  3.882566      0.0                        0.0                                        0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                              0.0\n",
      "3       01.2025   5105  BAV2        Gasolina Comum  01.000.078            GASOLINA COMUM C          13076.0    14828.0               5.0              0.03372             234.0             0.838589           239.0             0.5593                  5.133078      0.0                1201.140348                                        0.0                                      0.0                                   220.33                              1130.971166                                 220.33                                1130.97                                          1130.97\n",
      "4       01.2025   5105  BAV2        Diesel - Comum  01.011.674           √ìLEO DIESEL B S10         122306.0   178128.0             -17.0            -0.009544            -382.0            -0.127149          -399.0          -0.083375                  5.331511      0.0               -2036.637033                                        0.0                                      0.0                                  -240.63                             -1282.921386                                -240.63                               -1282.92                                         -1282.92\n",
      "\n",
      "üî¢ Tipos detectados:\n",
      "   object         : 25 coluna(s)\n",
      "\n",
      "‚ö†Ô∏è  Valores nulos:\n",
      "   ‚úÖ Nenhum valor nulo!\n",
      "\n",
      "üíæ Mem√≥ria utilizada: 1.26 MB\n",
      "\n",
      "üíæ Salvando df_bruto em JSON...\n",
      "   ‚úÖ Salvo: df_bruto_20251019_060722.json (311.0 KB)\n",
      "\n",
      "üíæ Estado salvo:\n",
      "   .bloco_9_state.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ EXTRA√á√ÉO CONCLU√çDA COM SUCESSO v2.0\n",
      "======================================================================\n",
      "\n",
      "üìù INSTRU√á√ïES PARA O PR√ìXIMO BLOCO:\n",
      "   1. Carregar estado: json.load('.bloco_9_state.json')\n",
      "   2. Ler caminho: estado['caminho_completo_json']\n",
      "   3. Carregar df_bruto:\n",
      "      with open(caminho, 'r') as f:\n",
      "          df_dict = json.load(f)\n",
      "      df_bruto = pd.DataFrame(df_dict['data'], columns=df_dict['columns'])\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:04.276134Z",
     "start_time": "2025-10-19T09:18:04.056501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 10 - LIMPEZA DE ESTRUTURA v2.5 CONSOLIDADO\n",
    "# ===================================================================\n",
    "# NOVIDADES v2.5:\n",
    "# + Remo√ß√£o de totaliza√ß√µes AVAN√áADA (23 padr√µes vs 7)\n",
    "# + Detec√ß√£o em PRIMEIRA e SEGUNDA coluna\n",
    "# + An√°lise hier√°rquica BW (colunas categ√≥ricas vazias)\n",
    "# + Valida√ß√£o de seguran√ßa (>50% = alerta + confirma√ß√£o usu√°rio)\n",
    "# + Registro detalhado de TODAS as linhas detectadas\n",
    "# ===================================================================\n",
    "# MANTIDO v2.4:\n",
    "# - Salvamento em Parquet (pyarrow desnecessario!)\n",
    "# - Carregamento de df_bruto do disco\n",
    "# - Assume df_bruto na memoria (BLOCO 9 executado)\n",
    "# + Todas as transformacoes de limpeza\n",
    "# + Registro completo em JSON\n",
    "# + Estado do bloco em JSON\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIMPEZA DE ESTRUTURA + REMO√á√ÉO TOTALIZA√á√ïES AVAN√áADA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. CONECTAR COM BLOCOS ANTERIORES (0% memoria, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Carregar LOG GLOBAL (CAMINHO CORRETO!)\n",
    "try:\n",
    "    log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    if not log_global_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"‚ùå LOG GLOBAL n√£o encontrado!\\n\"\n",
    "            f\"   Esperado: {log_global_path}\\n\"\n",
    "            \"   Execute o BLOCO 1 primeiro!\"\n",
    "        )\n",
    "\n",
    "    with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "        log_global = json.load(f)\n",
    "\n",
    "    pasta_base = Path(log_global['pasta_base_atual'])\n",
    "    timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "    print(f\"‚úÖ LOG GLOBAL conectado!\")\n",
    "    print(f\"   üìÇ Container: {pasta_base.name}\")\n",
    "    print(f\"   üïê Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel conectar ao LOG GLOBAL\")\n",
    "    print(f\"   Detalhe: {e}\")\n",
    "    raise\n",
    "\n",
    "# Recriar FileManager\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "print(f\"‚úÖ FileManager recriado: {fm.base_path.name}\")\n",
    "\n",
    "# Validar que BLOCO 9 foi executado\n",
    "arquivo_bloco9 = fm.pastas['logs'] / '.bloco_9_state.json'\n",
    "if not arquivo_bloco9.exists():\n",
    "    print(f\"\\n‚ùå ERRO: BLOCO 9 n√£o foi executado!\")\n",
    "    print(f\"   Execute o BLOCO 9 (Extra√ß√£o de Dados) primeiro!\")\n",
    "    raise FileNotFoundError(\"BLOCO 9 n√£o foi executado\")\n",
    "\n",
    "with open(arquivo_bloco9, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco9 = json.load(f)\n",
    "\n",
    "print(f\"\\n‚úÖ BLOCO 9 conectado!\")\n",
    "print(f\"   Arquivo processado: {estado_bloco9['arquivo_processado']}\")\n",
    "print(f\"   Registros extra√≠dos: {estado_bloco9['estatisticas']['total_registros']:,}\")\n",
    "print(f\"   Colunas extra√≠das: {estado_bloco9['estatisticas']['total_colunas']}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. VALIDAR QUE df_bruto ESTA NA MEMORIA\n",
    "# ===================================================================\n",
    "\n",
    "if 'df_bruto' not in globals():\n",
    "    print(f\"\\n‚ùå ERRO: df_bruto n√£o encontrado na mem√≥ria!\")\n",
    "    print(f\"   Execute o BLOCO 9 na mesma sess√£o antes deste bloco.\")\n",
    "    print(f\"   Se o kernel foi reiniciado, re-execute os BLOCOS 1-9.\")\n",
    "    raise NameError(\"df_bruto n√£o est√° na mem√≥ria\")\n",
    "\n",
    "print(f\"\\n‚úÖ df_bruto encontrado na mem√≥ria!\")\n",
    "df = df_bruto.copy()\n",
    "\n",
    "# Inicializar registros de transformacao\n",
    "log_limpeza = []\n",
    "transformacoes_detalhadas = {\n",
    "    'colunas_removidas': [],\n",
    "    'linhas_removidas': [],\n",
    "    'colunas_renomeadas': {},\n",
    "    'linhas_totais_detectadas': [],\n",
    "    'padroes_aplicados': []\n",
    "}\n",
    "\n",
    "print(f\"\\nüîß Iniciando limpeza...\")\n",
    "print(f\"   Registros iniciais: {len(df):,}\")\n",
    "print(f\"   Colunas iniciais: {len(df.columns)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. REMOVER COLUNAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "if colunas_vazias:\n",
    "    print(f\"\\nüóëÔ∏è Removendo {len(colunas_vazias)} colunas vazias:\")\n",
    "    for col in colunas_vazias[:5]:\n",
    "        print(f\"   ‚Ä¢ {col}\")\n",
    "    if len(colunas_vazias) > 5:\n",
    "        print(f\"   ... e mais {len(colunas_vazias) - 5}\")\n",
    "\n",
    "    df = df.drop(columns=colunas_vazias)\n",
    "    log_limpeza.append(f\"Removidas {len(colunas_vazias)} colunas vazias\")\n",
    "    transformacoes_detalhadas['colunas_removidas'] = colunas_vazias\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_colunas_vazias',\n",
    "        'criterio': 'df.isna().all()',\n",
    "        'quantidade': len(colunas_vazias)\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 4. REMOVER LINHAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "linhas_vazias_antes = len(df)\n",
    "df = df.dropna(how='all')\n",
    "linhas_vazias = linhas_vazias_antes - len(df)\n",
    "\n",
    "if linhas_vazias > 0:\n",
    "    print(f\"\\nüóëÔ∏è Removidas {linhas_vazias} linhas completamente vazias\")\n",
    "    log_limpeza.append(f\"Removidas {linhas_vazias} linhas vazias\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_linhas_vazias',\n",
    "        'criterio': 'df.dropna(how=all)',\n",
    "        'quantidade': linhas_vazias\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 5. LIMPAR NOMES DE COLUNAS\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nüßπ Limpando nomes de colunas...\")\n",
    "colunas_antes = df.columns.tolist()\n",
    "colunas_limpas = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Limpar\n",
    "    col_limpo = str(col).strip()\n",
    "    col_limpo = col_limpo.lstrip(\"'\\\"\")\n",
    "    col_limpo = col_limpo.replace('\\n', ' ').replace('\\r', '')\n",
    "    col_limpo = ' '.join(col_limpo.split())\n",
    "\n",
    "    # Remover espacos extras\n",
    "    col_limpo = re.sub(r'\\s+', ' ', col_limpo)\n",
    "\n",
    "    colunas_limpas.append(col_limpo)\n",
    "\n",
    "# Contar modificacoes\n",
    "modificados = sum(1 for orig, limpo in zip(colunas_antes, colunas_limpas)\n",
    "                  if orig != limpo)\n",
    "if modificados > 0:\n",
    "    print(f\"   ‚úÖ {modificados} nomes limpos\")\n",
    "    log_limpeza.append(f\"Limpeza de nomes: {modificados} colunas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'limpeza_nomes',\n",
    "        'criterio': 'strip + lstrip + regex',\n",
    "        'quantidade': modificados\n",
    "    })\n",
    "\n",
    "df.columns = colunas_limpas\n",
    "\n",
    "# ===================================================================\n",
    "# 6. RENOMEAR COLUNAS DUPLICADAS\n",
    "# ===================================================================\n",
    "\n",
    "contagem = Counter(colunas_limpas)\n",
    "duplicadas = {c: n for c, n in contagem.items() if n > 1}\n",
    "\n",
    "if duplicadas:\n",
    "    print(f\"\\nüîÑ Renomeando {len(duplicadas)} colunas duplicadas:\")\n",
    "    colunas_finais = []\n",
    "    contador = {}\n",
    "\n",
    "    for col in colunas_limpas:\n",
    "        if col in duplicadas:\n",
    "            if col not in contador:\n",
    "                contador[col] = 0\n",
    "                colunas_finais.append(col)\n",
    "            else:\n",
    "                contador[col] += 1\n",
    "                novo_nome = f\"{col}_dup{contador[col]}\"\n",
    "                colunas_finais.append(novo_nome)\n",
    "                print(f\"   '{col}' ‚Üí '{novo_nome}'\")\n",
    "                transformacoes_detalhadas['colunas_renomeadas'][col] = transformacoes_detalhadas['colunas_renomeadas'].get(col, []) + [novo_nome]\n",
    "        else:\n",
    "            colunas_finais.append(col)\n",
    "\n",
    "    df.columns = colunas_finais\n",
    "    log_limpeza.append(f\"Renomeadas {sum(contador.values())} colunas duplicadas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'renomear_duplicadas',\n",
    "        'criterio': 'Counter + sufixo _dupN',\n",
    "        'quantidade': sum(contador.values())\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 7. REMO√á√ÉO DE TOTALIZA√á√ïES - VERS√ÉO AVAN√áADA v2.5\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"üîç DETEC√á√ÉO AVAN√áADA DE LINHAS DE TOTALIZA√á√ÉO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\n‚ÑπÔ∏è  CONTEXTO:\")\n",
    "print(\"   Arquivos BW/BEx frequentemente cont√™m linhas de:\")\n",
    "print(\"   - Totais gerais / Subtotais por agrupamento\")\n",
    "print(\"   - Resultados parciais / M√©dias agregadas\")\n",
    "print(\"   Estas linhas INFLAM valores e devem ser removidas.\\n\")\n",
    "\n",
    "# Padr√µes AVAN√áADOS (23 padr√µes vs 7 originais)\n",
    "padroes_totalizacao = [\n",
    "    # Portugu√™s (12 padr√µes)\n",
    "    r'(?i)^total\\b',\n",
    "    r'(?i)^resultado\\b',\n",
    "    r'(?i)^soma\\b',\n",
    "    r'(?i)^subtotal\\b',\n",
    "    r'(?i)^parcial\\b',\n",
    "    r'(?i)^grand total',\n",
    "    r'(?i)^m√©dia\\b',\n",
    "    r'(?i)^media\\b',\n",
    "    r'(?i)^consolidado\\b',\n",
    "    r'(?i)^geral\\b',\n",
    "    r'(?i)total geral',\n",
    "    r'(?i)resultado final',\n",
    "\n",
    "    # Ingl√™s (5 padr√µes - comum em exports SAP)\n",
    "    r'(?i)^overall',\n",
    "    r'(?i)^average',\n",
    "    r'(?i)^sum\\b',\n",
    "    r'(?i)^total\\s',\n",
    "    r'(?i)^result\\b',\n",
    "\n",
    "    # Num√©ricos (3 padr√µes - ex: \"Total 5262\", \"Resultado 1234\")\n",
    "    r'(?i)^total\\s+\\d+',\n",
    "    r'(?i)^resultado\\s+\\d+',\n",
    "    r'(?i)^subtotal\\s+\\d+',\n",
    "]\n",
    "\n",
    "# Compilar regex para performance\n",
    "padroes_compilados = [re.compile(p) for p in padroes_totalizacao]\n",
    "\n",
    "# Fun√ß√£o de detec√ß√£o AVAN√áADA (3 n√≠veis de verifica√ß√£o)\n",
    "def eh_linha_totalizacao(row):\n",
    "    \"\"\"\n",
    "    Verifica se linha √© de totaliza√ß√£o usando 3 crit√©rios:\n",
    "    1. Primeira coluna (mais comum)\n",
    "    2. Segunda coluna (quando primeira tem c√≥digo)\n",
    "    3. Hierarquia BW (colunas categ√≥ricas vazias)\n",
    "    \"\"\"\n",
    "    # N√≠vel 1: Verificar primeira coluna\n",
    "    primeira_celula = str(row.iloc[0]).strip()\n",
    "    if any(padrao.search(primeira_celula) for padrao in padroes_compilados):\n",
    "        return True\n",
    "\n",
    "    # N√≠vel 2: Verificar segunda coluna\n",
    "    if len(row) > 1:\n",
    "        segunda_celula = str(row.iloc[1]).strip()\n",
    "        if any(padrao.search(segunda_celula) for padrao in padroes_compilados):\n",
    "            return True\n",
    "\n",
    "    # N√≠vel 3: Detectar hierarquia BW (colunas categ√≥ricas vazias)\n",
    "    colunas_categoricas = df.select_dtypes(include=['object']).columns\n",
    "    if len(colunas_categoricas) > 0:\n",
    "        valores_cat = row[colunas_categoricas].dropna()\n",
    "        # Se <30% das colunas categ√≥ricas preenchidas E palavra-chave\n",
    "        if len(valores_cat) < len(colunas_categoricas) * 0.3:\n",
    "            primeira_palavra = primeira_celula.lower().split()[0] if primeira_celula else ''\n",
    "            if primeira_palavra in ['total', 'resultado', 'soma', 'm√©dia', 'media', 'geral']:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Identificar linhas de totaliza√ß√£o\n",
    "print(f\"üìä Analisando {len(df):,} linhas com 23 padr√µes...\")\n",
    "\n",
    "linhas_totalizacao = []\n",
    "for idx, row in df.iterrows():\n",
    "    if eh_linha_totalizacao(row):\n",
    "        linhas_totalizacao.append(idx)\n",
    "        # Registrar DETALHADAMENTE\n",
    "        transformacoes_detalhadas['linhas_totais_detectadas'].append({\n",
    "            'indice': int(idx),\n",
    "            'primeira_celula': str(row.iloc[0]).strip(),\n",
    "            'segunda_celula': str(row.iloc[1]).strip() if len(row) > 1 else None\n",
    "        })\n",
    "\n",
    "print(f\"\\nüîç Linhas de totaliza√ß√£o detectadas: {len(linhas_totalizacao)}\")\n",
    "\n",
    "# Mostrar exemplos (preview)\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    print(f\"\\nüìã Exemplos de linhas detectadas (primeiras 5):\")\n",
    "    for i, idx in enumerate(linhas_totalizacao[:5], 1):\n",
    "        primeira_col = df.iloc[idx, 0]\n",
    "        segunda_col = df.iloc[idx, 1] if len(df.columns) > 1 else 'N/A'\n",
    "        print(f\"   {i}. Linha {idx}: '{primeira_col}' | '{segunda_col}'\")\n",
    "\n",
    "    if len(linhas_totalizacao) > 5:\n",
    "        print(f\"   ... e mais {len(linhas_totalizacao) - 5}\")\n",
    "\n",
    "# Remover linhas detectadas COM VALIDA√á√ÉO DE SEGURAN√áA\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"üóëÔ∏è  REMOVENDO LINHAS DE TOTALIZA√á√ÉO\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    registros_antes = len(df)\n",
    "\n",
    "    # Calcular impacto ANTES de remover\n",
    "    pct_a_remover = (len(linhas_totalizacao) / registros_antes) * 100\n",
    "\n",
    "    # VALIDA√á√ÉO DE SEGURAN√áA: >50% = alerta\n",
    "    if pct_a_remover > 50:\n",
    "        print(f\"\\n‚ö†Ô∏è  ALERTA DE SEGURAN√áA!\")\n",
    "        print(f\"   Mais de 50% das linhas ser√£o removidas ({pct_a_remover:.1f}%)\")\n",
    "        print(f\"   Isso pode indicar FALSO POSITIVO na detec√ß√£o.\")\n",
    "        print(f\"   Recomenda-se revisar os padr√µes manualmente.\\n\")\n",
    "\n",
    "        resposta = input(\"   Deseja CONTINUAR com a remo√ß√£o? (S/N): \").strip().upper()\n",
    "\n",
    "        if resposta != 'S':\n",
    "            print(f\"\\n   ‚ÑπÔ∏è  Remo√ß√£o CANCELADA pelo usu√°rio\")\n",
    "            print(f\"   Mantendo dados originais para revis√£o manual.\")\n",
    "            linhas_totalizacao = []  # Limpar lista para n√£o remover\n",
    "            transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "                'tipo': 'remocao_totais_CANCELADA',\n",
    "                'criterio': 'Usuario cancelou (>50%)',\n",
    "                'quantidade': 0,\n",
    "                'percentual': 0.0,\n",
    "                'alerta_ativado': True\n",
    "            })\n",
    "\n",
    "    # Remover se confirmado (ou se <50%)\n",
    "    if linhas_totalizacao:\n",
    "        df = df.drop(index=linhas_totalizacao)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        registros_depois = len(df)\n",
    "        removidos = registros_antes - registros_depois\n",
    "        pct_removido = (removidos / registros_antes) * 100\n",
    "\n",
    "        print(f\"\\n‚úÖ Remo√ß√£o conclu√≠da:\")\n",
    "        print(f\"   Antes:    {registros_antes:>7,} linhas\")\n",
    "        print(f\"   Removido: {removidos:>7,} linhas ({pct_removido:.1f}%)\")\n",
    "        print(f\"   Depois:   {registros_depois:>7,} linhas\")\n",
    "\n",
    "        log_limpeza.append(f\"Removidas {removidos} linhas de totaliza√ß√£o\")\n",
    "        transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "            'tipo': 'remocao_totais',\n",
    "            'criterio': '23 padroes regex + 2a coluna + hierarquia BW',\n",
    "            'quantidade': removidos,\n",
    "            'percentual': round(pct_removido, 2),\n",
    "            'alerta_ativado': pct_a_remover > 50\n",
    "        })\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Nenhuma linha de totaliza√ß√£o detectada!\")\n",
    "    print(f\"   Dados j√° est√£o limpos ou n√£o possuem totaliza√ß√µes.\")\n",
    "\n",
    "# ===================================================================\n",
    "# 8. CRIAR COPIA LIMPA (variavel global para proximo bloco)\n",
    "# ===================================================================\n",
    "\n",
    "df_limpo = df.copy()\n",
    "\n",
    "print(f\"\\nüíæ df_limpo criado na mem√≥ria\")\n",
    "print(f\"   üìä {len(df_limpo):,} registros √ó {len(df_limpo.columns)} colunas\")\n",
    "\n",
    "# ===================================================================\n",
    "# 9. RESUMO FINAL\n",
    "# ===================================================================\n",
    "\n",
    "# Obter estatisticas originais\n",
    "registros_originais = estado_bloco9['estatisticas']['total_registros']\n",
    "colunas_originais = estado_bloco9['estatisticas']['total_colunas']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ LIMPEZA CONCLU√çDA\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"\\nüìä Antes ‚Üí Depois:\")\n",
    "print(f\"   Registros: {registros_originais:,} ‚Üí {len(df_limpo):,}\")\n",
    "print(f\"   Colunas: {colunas_originais} ‚Üí {len(df_limpo.columns)}\")\n",
    "\n",
    "if log_limpeza:\n",
    "    print(f\"\\nüîß Opera√ß√µes realizadas:\")\n",
    "    for i, op in enumerate(log_limpeza, 1):\n",
    "        print(f\"   {i}. {op}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Nenhuma limpeza necess√°ria - dados j√° estavam limpos!\")\n",
    "\n",
    "print(f\"\\nüëÅÔ∏è  Preview dos dados limpos:\")\n",
    "print(\"-\" * 70)\n",
    "print(df_limpo.head(3))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ===================================================================\n",
    "# 10. SALVAR ESTADO NO LOG\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco10 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 10,\n",
    "    'nome': 'LIMPEZA DE ESTRUTURA + TOTALIZA√á√ïES AVAN√áADA',\n",
    "    'status': 'concluido',\n",
    "    'versao': '2.5',\n",
    "    'variaveis_criadas': ['df_limpo'],\n",
    "    'variaveis_memoria': {\n",
    "        'df_limpo': {\n",
    "            'tipo': 'DataFrame',\n",
    "            'shape': list(df_limpo.shape),\n",
    "            'colunas': list(df_limpo.columns),\n",
    "            'dtypes': {col: str(dtype) for col, dtype in df_limpo.dtypes.items()}\n",
    "        }\n",
    "    },\n",
    "    'estatisticas': {\n",
    "        'registros_antes': registros_originais,\n",
    "        'registros_depois': len(df_limpo),\n",
    "        'colunas_antes': colunas_originais,\n",
    "        'colunas_depois': len(df_limpo.columns),\n",
    "        'colunas_removidas': len(colunas_vazias) if colunas_vazias else 0,\n",
    "        'linhas_removidas_vazias': linhas_vazias,\n",
    "        'linhas_removidas_totais': len(linhas_totalizacao) if linhas_totalizacao else 0,\n",
    "        'colunas_renomeadas': sum(contador.values()) if duplicadas else 0\n",
    "    },\n",
    "    'transformacoes': transformacoes_detalhadas,\n",
    "    'log_resumido': log_limpeza\n",
    "}\n",
    "\n",
    "# Salvar estado\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_10_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco10, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "\n",
    "# Salvar transformacoes detalhadas\n",
    "arquivo_transformacoes = fm.pastas['logs'] / f'LOG_Transformacoes_Limpeza_{timestamp_execucao}.json'\n",
    "with open(arquivo_transformacoes, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transformacoes_detalhadas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   {arquivo_transformacoes.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 10 CONCLU√çDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Pr√≥ximo: BLOCO 11 - Forward Fill (se necess√°rio)\")\n",
    "print(\"üí° df_limpo est√° dispon√≠vel na mem√≥ria\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a1261390787ca008",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIMPEZA DE ESTRUTURA + REMO√á√ÉO TOTALIZA√á√ïES AVAN√áADA\n",
      "======================================================================\n",
      "‚úÖ LOG GLOBAL conectado!\n",
      "   üìÇ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   üïê Timestamp: 20251019_060722\n",
      "‚úÖ FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "‚úÖ BLOCO 9 conectado!\n",
      "   Arquivo processado: C√≥pia de xSAPtemp4687_JAN_25.xls\n",
      "   Registros extra√≠dos: 967\n",
      "   Colunas extra√≠das: 25\n",
      "\n",
      "‚úÖ df_bruto encontrado na mem√≥ria!\n",
      "\n",
      "üîß Iniciando limpeza...\n",
      "   Registros iniciais: 967\n",
      "   Colunas iniciais: 25\n",
      "\n",
      "üßπ Limpando nomes de colunas...\n",
      "   ‚úÖ 8 nomes limpos\n",
      "\n",
      "üîÑ Renomeando 1 colunas duplicadas:\n",
      "   '' ‚Üí '_dup1'\n",
      "   '' ‚Üí '_dup2'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üîç DETEC√á√ÉO AVAN√áADA DE LINHAS DE TOTALIZA√á√ÉO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚ÑπÔ∏è  CONTEXTO:\n",
      "   Arquivos BW/BEx frequentemente cont√™m linhas de:\n",
      "   - Totais gerais / Subtotais por agrupamento\n",
      "   - Resultados parciais / M√©dias agregadas\n",
      "   Estas linhas INFLAM valores e devem ser removidas.\n",
      "\n",
      "üìä Analisando 967 linhas com 23 padr√µes...\n",
      "\n",
      "üîç Linhas de totaliza√ß√£o detectadas: 0\n",
      "\n",
      "‚úÖ Nenhuma linha de totaliza√ß√£o detectada!\n",
      "   Dados j√° est√£o limpos ou n√£o possuem totaliza√ß√µes.\n",
      "\n",
      "üíæ df_limpo criado na mem√≥ria\n",
      "   üìä 967 registros √ó 25 colunas\n",
      "\n",
      "======================================================================\n",
      "‚úÖ LIMPEZA CONCLU√çDA\n",
      "======================================================================\n",
      "\n",
      "üìä Antes ‚Üí Depois:\n",
      "   Registros: 967 ‚Üí 967\n",
      "   Colunas: 25 ‚Üí 25\n",
      "\n",
      "üîß Opera√ß√µes realizadas:\n",
      "   1. Limpeza de nomes: 8 colunas\n",
      "   2. Renomeadas 2 colunas duplicadas\n",
      "\n",
      "üëÅÔ∏è  Preview dos dados limpos:\n",
      "----------------------------------------------------------------------\n",
      "  Ano civil/m√™s Centro                  HierarqPrd     Produto  \\\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674   \n",
      "1       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.001.422   \n",
      "2       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.003.826   \n",
      "\n",
      "                        _dup1 Estoque Inicial    Entrada Varia√ß√£o Externa  \\\n",
      "0           √ìLEO DIESEL B S10         16924.0                               \n",
      "1     JET A NAO TABELADO - LI        373850.0   939139.0            824.0   \n",
      "2  JET A INTERNACIONAL I - LI        598315.0  5188210.0           1494.0   \n",
      "\n",
      "  Varia√ß√£o Externa %  ...  Imposto Valor da Varia√ß√£o Interna _dup2  \\\n",
      "0                     ...      0.0                 95.402202         \n",
      "1            0.08774  ... -2811.15                -38.904816         \n",
      "2           0.028796  ...      0.0                       0.0         \n",
      "\n",
      "  Quantidade Excedente da Varia√ß√£o Externa  \\\n",
      "0                                      0.0   \n",
      "1                                   366.22   \n",
      "2                                      0.0   \n",
      "\n",
      "  Valor Excedente da Varia√ß√£o Externa (R$)  \\\n",
      "0                                      0.0   \n",
      "1                              1424.772156   \n",
      "2                                      0.0   \n",
      "\n",
      "  Quantidade Excedente da Varia√ß√£o Interna  \\\n",
      "0                                    10.19   \n",
      "1                                      0.0   \n",
      "2                                      0.0   \n",
      "\n",
      "  Valor Excedente da Varia√ß√£o Interna (R$)  \\\n",
      "0                                54.008246   \n",
      "1                                      0.0   \n",
      "2                                      0.0   \n",
      "\n",
      "  Quantidade Excedente da Varia√ß√£o Total  \\\n",
      "0                                  10.19   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "\n",
      "  Valor Excedente da Varia√ß√£o Total (R$)  \\\n",
      "0                                  54.01   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "\n",
      "  Valor Excedente da Varia√ß√£o Total + Imposto (R$)  \n",
      "0                                            54.01  \n",
      "1                                          2811.15  \n",
      "2                                              0.0  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üíæ Estado salvo:\n",
      "   .bloco_10_state.json\n",
      "   LOG_Transformacoes_Limpeza_20251019_060722.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 10 CONCLU√çDO\n",
      "======================================================================\n",
      "\n",
      "üí° Pr√≥ximo: BLOCO 11 - Forward Fill (se necess√°rio)\n",
      "üí° df_limpo est√° dispon√≠vel na mem√≥ria\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:06.890503Z",
     "start_time": "2025-10-19T09:18:06.873488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 11 - TRATAMENTO DE FORMATO BW/BEx - FORWARD FILL\n",
    "# VERS√ÉO v3.0 - SIMPLIFICADO (SEM PARQUET/PICKLE DESNECESS√ÅRIO)\n",
    "# Baseado em: ETL - ESTOQUE E MOVIMENTA√á√ÉO (SAP BEx).ipynb - PASSO 4\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ARQUITETURA CORRETA:\n",
    "# - DataFrames ficam na MEM√ìRIA (df_limpo ‚Üí df)\n",
    "# - Estado salvo em JSON (.bloco_11_state.json)\n",
    "# - N√ÉO precisa salvar DataFrame em disco (j√° est√° na mem√≥ria!)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ TRATAMENTO DE FORMATO BW/BEx (FORWARD FILL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 1. CONECTAR VIA LOG GLOBAL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global_path.exists():\n",
    "    raise FileNotFoundError(\"‚ùå LOG GLOBAL n√£o encontrado! Execute BLOCO 1.\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "print(f\"\\n‚úÖ LOG GLOBAL conectado\")\n",
    "print(f\"   üìÇ Container: {pasta_base.name}\")\n",
    "print(f\"   üïê Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Recriar FileManager\n",
    "class FileManagerInterativo:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 2. VALIDAR PR√â-REQUISITO (BLOCO 10)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "arquivo_bloco10 = fm.pastas['logs'] / '.bloco_10_state.json'\n",
    "\n",
    "if not arquivo_bloco10.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå BLOCO 10 n√£o executado!\\n\"\n",
    "        \"   Execute BLOCO 10 (Limpeza de Estrutura) primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(arquivo_bloco10, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco10 = json.load(f)\n",
    "\n",
    "print(f\"\\n‚úÖ BLOCO 10 validado\")\n",
    "print(f\"   Registros: {estado_bloco10.get('registros_depois', 'N/A')}\")\n",
    "print(f\"   Colunas: {estado_bloco10.get('colunas_depois', 'N/A')}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 3. USAR df_limpo DA MEM√ìRIA\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "if 'df_limpo' not in globals():\n",
    "    raise NameError(\n",
    "        \"‚ùå df_limpo n√£o est√° na mem√≥ria!\\n\"\n",
    "        \"   Execute BLOCO 10 novamente.\"\n",
    "    )\n",
    "\n",
    "# Trabalhar com c√≥pia\n",
    "df = df_limpo.copy()\n",
    "\n",
    "print(f\"\\nüìä DataFrame carregado da mem√≥ria\")\n",
    "print(f\"   {len(df):,} registros √ó {len(df.columns)} colunas\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 4. DETECTAR FORMATO BW\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"üîç DETEC√á√ÉO DE FORMATO BW/BEx\")\n",
    "print(\"‚îÄ\"*70)\n",
    "\n",
    "print(\"\\n‚ÑπÔ∏è  Arquivos SAP BW/BEx usam formata√ß√£o hier√°rquica:\")\n",
    "print(\"   - Dimens√µes s√≥ aparecem na 1¬™ linha do grupo\")\n",
    "print(\"   - Linhas seguintes ficam vazias at√© mudar grupo\")\n",
    "\n",
    "# Analisar primeiras 6 colunas (geralmente dimens√µes)\n",
    "colunas_iniciais = df.columns[:min(6, len(df.columns))]\n",
    "\n",
    "print(f\"\\nüìä Analisando {len(colunas_iniciais)} primeiras colunas:\\n\")\n",
    "\n",
    "analise_colunas = []\n",
    "\n",
    "for col in colunas_iniciais:\n",
    "    # Estat√≠sticas da coluna\n",
    "    valores_unicos = df[col].dropna().nunique()\n",
    "    pct_nulos = (df[col].isnull().sum() / len(df)) * 100\n",
    "\n",
    "    # Crit√©rio BW: >30% NaN E <1000 valores √∫nicos\n",
    "    eh_dimensao_bw = pct_nulos > 30 and valores_unicos < 1000\n",
    "\n",
    "    analise_colunas.append({\n",
    "        'coluna': col,\n",
    "        'valores_unicos': valores_unicos,\n",
    "        'pct_nulos': pct_nulos,\n",
    "        'eh_dimensao_bw': eh_dimensao_bw\n",
    "    })\n",
    "\n",
    "    emoji = \"üîÑ\" if eh_dimensao_bw else \"  \"\n",
    "    print(f\"   {emoji} {col[:35].ljust(35)} | \"\n",
    "          f\"√önicos: {valores_unicos:>5} | NaN: {pct_nulos:>5.1f}%\")\n",
    "\n",
    "# Contar colunas BW\n",
    "colunas_bw = [a for a in analise_colunas if a['eh_dimensao_bw']]\n",
    "\n",
    "print(f\"\\nüìä Colunas com padr√£o BW: {len(colunas_bw)}/{len(colunas_iniciais)}\")\n",
    "\n",
    "# Decidir se aplica forward fill\n",
    "eh_formato_bw = len(colunas_bw) >= 2\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(f\"   ‚úÖ FORMATO BW DETECTADO - Forward fill ser√° aplicado\\n\")\n",
    "else:\n",
    "    print(f\"   ‚ÑπÔ∏è  Formato padr√£o - Forward fill N√ÉO necess√°rio\\n\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 5. APLICAR FORWARD FILL (SE DETECTADO)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "total_preenchidas = 0\n",
    "colunas_para_ffill = []\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(\"‚îÄ\"*70)\n",
    "    print(\"üîÑ APLICANDO FORWARD FILL\")\n",
    "    print(\"‚îÄ\"*70)\n",
    "\n",
    "    # Listar colunas\n",
    "    colunas_para_ffill = [a['coluna'] for a in analise_colunas\n",
    "                          if a['eh_dimensao_bw']]\n",
    "\n",
    "    print(f\"\\nüìã Colunas que receber√£o ffill ({len(colunas_para_ffill)}):\")\n",
    "    for i, col in enumerate(colunas_para_ffill, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "\n",
    "    # Contar NULLs ANTES\n",
    "    print(f\"\\nüìä NULLs ANTES do forward fill:\\n\")\n",
    "    nulls_antes = {}\n",
    "    total_nulls_antes = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        count = int(df[col].isnull().sum())\n",
    "        nulls_antes[col] = count\n",
    "        total_nulls_antes += count\n",
    "        print(f\"   {col[:40].ljust(40)}: {count:>8,}\")\n",
    "\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: {total_nulls_antes:>8,}\")\n",
    "\n",
    "    # APLICAR FFILL\n",
    "    print(f\"\\nüîÑ Preenchendo c√©lulas vazias...\")\n",
    "    df[colunas_para_ffill] = df[colunas_para_ffill].ffill()\n",
    "\n",
    "    # Contar NULLs DEPOIS\n",
    "    print(f\"\\n‚úÖ NULLs DEPOIS do forward fill:\\n\")\n",
    "    total_nulls_depois = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        nulls_depois = int(df[col].isnull().sum())\n",
    "        total_nulls_depois += nulls_depois\n",
    "        preenchidas = nulls_antes[col] - nulls_depois\n",
    "\n",
    "        print(f\"   {col[:40].ljust(40)}: \"\n",
    "              f\"{nulls_antes[col]:>8,} ‚Üí {nulls_depois:>8,} \"\n",
    "              f\"(Œî {preenchidas:>7,})\")\n",
    "\n",
    "    total_preenchidas = total_nulls_antes - total_nulls_depois\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: \"\n",
    "          f\"{total_nulls_antes:>8,} ‚Üí {total_nulls_depois:>8,} \"\n",
    "          f\"(Œî {total_preenchidas:>7,})\")\n",
    "\n",
    "    # Valida√ß√£o\n",
    "    print(f\"\\n‚úÖ VALIDA√á√ÉO:\")\n",
    "    primeira_linha_nulos = df.iloc[0][colunas_para_ffill].isnull().sum()\n",
    "\n",
    "    if primeira_linha_nulos > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Primeira linha tem {primeira_linha_nulos} NaN(s)\")\n",
    "        print(f\"   Poss√≠vel problema no cabe√ßalho\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Primeira linha completa - OK\")\n",
    "\n",
    "    print(f\"\\nüìä RESUMO:\")\n",
    "    print(f\"   Colunas processadas: {len(colunas_para_ffill)}\")\n",
    "    print(f\"   C√©lulas preenchidas: {total_preenchidas:,}\")\n",
    "    if total_nulls_antes > 0:\n",
    "        pct_reducao = (total_preenchidas / total_nulls_antes) * 100\n",
    "        print(f\"   Redu√ß√£o de NaN: {pct_reducao:.1f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ FORWARD FILL APLICADO COM SUCESSO\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚ÑπÔ∏è  FORWARD FILL N√ÉO NECESS√ÅRIO\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n   Arquivo n√£o possui formata√ß√£o BW/BEx hier√°rquica\")\n",
    "    print(\"   Prosseguindo para pr√≥xima etapa...\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 6. SALVAR ESTADO (APENAS JSON)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "estado_bloco11 = {\n",
    "    'bloco': 11,\n",
    "    'nome': 'TRATAMENTO BW/BEx - FORWARD FILL',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'formato_bw_detectado': eh_formato_bw,\n",
    "    'colunas_analisadas': len(colunas_iniciais),\n",
    "    'colunas_bw_detectadas': len(colunas_bw),\n",
    "    'colunas_processadas': colunas_para_ffill if eh_formato_bw else [],\n",
    "    'celulas_preenchidas': int(total_preenchidas) if eh_formato_bw else 0,\n",
    "    'registros': len(df),\n",
    "    'colunas': len(df.columns),\n",
    "    'variaveis_criadas': ['df'],  # df fica na mem√≥ria para pr√≥ximo bloco\n",
    "    'versao': '3.0'\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_11_state.json'\n",
    "\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco11, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 11 CONCLU√çDO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüí° Vari√°vel 'df' dispon√≠vel na mem√≥ria para pr√≥ximo bloco\")\n",
    "print(f\"üí° Pr√≥ximo: BLOCO 12 - Detec√ß√£o de Campos\")  # ‚Üê CORRIGIDO!\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# FIM DO BLOCO 11 v3.0\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
   ],
   "id": "19009614f0364f42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîÑ TRATAMENTO DE FORMATO BW/BEx (FORWARD FILL)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ LOG GLOBAL conectado\n",
      "   üìÇ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   üïê Timestamp: 20251019_060722\n",
      "\n",
      "‚úÖ BLOCO 10 validado\n",
      "   Registros: N/A\n",
      "   Colunas: N/A\n",
      "\n",
      "üìä DataFrame carregado da mem√≥ria\n",
      "   967 registros √ó 25 colunas\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîç DETEC√á√ÉO DE FORMATO BW/BEx\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚ÑπÔ∏è  Arquivos SAP BW/BEx usam formata√ß√£o hier√°rquica:\n",
      "   - Dimens√µes s√≥ aparecem na 1¬™ linha do grupo\n",
      "   - Linhas seguintes ficam vazias at√© mudar grupo\n",
      "\n",
      "üìä Analisando 6 primeiras colunas:\n",
      "\n",
      "      Ano civil/m√™s                       | √önicos:     2 | NaN:   0.0%\n",
      "      Centro                              | √önicos:    89 | NaN:   0.0%\n",
      "                                          | √önicos:    89 | NaN:   0.0%\n",
      "      HierarqPrd                          | √önicos:     5 | NaN:   0.0%\n",
      "      Produto                             | √önicos:    15 | NaN:   0.0%\n",
      "      _dup1                               | √önicos:    15 | NaN:   0.0%\n",
      "\n",
      "üìä Colunas com padr√£o BW: 0/6\n",
      "   ‚ÑπÔ∏è  Formato padr√£o - Forward fill N√ÉO necess√°rio\n",
      "\n",
      "======================================================================\n",
      "‚ÑπÔ∏è  FORWARD FILL N√ÉO NECESS√ÅRIO\n",
      "======================================================================\n",
      "\n",
      "   Arquivo n√£o possui formata√ß√£o BW/BEx hier√°rquica\n",
      "   Prosseguindo para pr√≥xima etapa...\n",
      "\n",
      "üíæ Estado salvo: .bloco_11_state.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 11 CONCLU√çDO\n",
      "======================================================================\n",
      "\n",
      "üí° Vari√°vel 'df' dispon√≠vel na mem√≥ria para pr√≥ximo bloco\n",
      "üí° Pr√≥ximo: BLOCO 12 - Detec√ß√£o de Campos\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:08.855631Z",
     "start_time": "2025-10-19T09:18:08.807611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 12 v7.0 - DETEC√á√ÉO AUTOM√ÅTICA (SEM RENOMEAR DATAFRAME)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CORRE√á√ïES v7.0:\n",
    "# ‚úÖ DataFrame NUNCA √© renomeado (preserva nomes originais)\n",
    "# ‚úÖ Mapeamentos salvos APENAS no dicion√°rio\n",
    "# ‚úÖ Path correto: fm.pastas['dicionarios']\n",
    "# ‚úÖ Avisos claros sobre duplica√ß√µes\n",
    "# ‚ùå REMOVIDO: Toda l√≥gica de df.rename()\n",
    "# ‚ùå REMOVIDO: Sistema de sufixos (_1, _2, _3)\n",
    "#\n",
    "# MUDAN√áAS:\n",
    "# - Removidas ~40 linhas de c√≥digo de renomea√ß√£o\n",
    "# - Adicionados ~15 linhas de avisos e salvamento no dicion√°rio\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç DETEC√á√ÉO AUTOM√ÅTICA DE CAMPOS v7.0 (SEM RENOMEAR)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CLASSE DETECTOR DE CAMPOS (MANTIDA 100%)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "class DetectorCampos:\n",
    "    \"\"\"Detecta e mapeia campos automaticamente.\"\"\"\n",
    "\n",
    "    def __init__(self, df, dicionario_persistente):\n",
    "        self.df = df\n",
    "        self.dicionario = dicionario_persistente\n",
    "        self.mapeamento = {}\n",
    "        self.relatorio = {\n",
    "            'total_campos': len(df.columns),\n",
    "            'mapeados_dicionario': 0,\n",
    "            'mapeados_heuristica': 0,\n",
    "            'desconhecidos': 0,\n",
    "            'ambiguos': 0,\n",
    "            'detalhes': []\n",
    "        }\n",
    "\n",
    "    def detectar_todos(self):\n",
    "        \"\"\"Detecta todos os campos do DataFrame.\"\"\"\n",
    "        print(f\"\\nüìä Analisando {len(self.df.columns)} campos...\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            print(f\"\\n   üîç Analisando: '{col}'\")\n",
    "\n",
    "            # Extrair amostra de valores\n",
    "            valores_amostra = [str(v) for v in self.df[col].dropna().head(100)]\n",
    "\n",
    "            # Tentar detec√ß√£o\n",
    "            resultado = self._detectar_campo(col, valores_amostra)\n",
    "\n",
    "            # Armazenar\n",
    "            self.mapeamento[col] = resultado\n",
    "\n",
    "            # Atualizar relat√≥rio\n",
    "            if resultado['metodo'] == 'DICIONARIO':\n",
    "                self.relatorio['mapeados_dicionario'] += 1\n",
    "                emoji = \"‚úÖ\"\n",
    "            elif resultado['metodo'] == 'HEURISTICA':\n",
    "                self.relatorio['mapeados_heuristica'] += 1\n",
    "                emoji = \"ü§ñ\"\n",
    "            elif resultado['campo_detectado'] == 'DESCONHECIDO':\n",
    "                self.relatorio['desconhecidos'] += 1\n",
    "                emoji = \"‚ùì\"\n",
    "            else:\n",
    "                emoji = \"‚ö†Ô∏è\"\n",
    "\n",
    "            if resultado.get('ambiguidade', False):\n",
    "                self.relatorio['ambiguos'] += 1\n",
    "                emoji += \"‚ö†Ô∏è\"\n",
    "\n",
    "            # Exibir resultado\n",
    "            print(f\"      {emoji} {resultado['campo_detectado']}\")\n",
    "            print(f\"      Confian√ßa: {resultado['confianca']:.0%} | M√©todo: {resultado['metodo']}\")\n",
    "\n",
    "            # Adicionar ao relat√≥rio\n",
    "            self.relatorio['detalhes'].append({\n",
    "                'coluna_original': col,\n",
    "                'campo_detectado': resultado['campo_detectado'],\n",
    "                'confianca': resultado['confianca'],\n",
    "                'metodo': resultado['metodo'],\n",
    "                'ambiguidade': resultado.get('ambiguidade', False)\n",
    "            })\n",
    "\n",
    "        return self.mapeamento, self.relatorio\n",
    "\n",
    "    def _detectar_campo(self, nome_coluna, valores):\n",
    "        \"\"\"Detecta um √∫nico campo (MANTIDO DO BLOCO 13).\"\"\"\n",
    "\n",
    "        # ESTRAT√âGIA 1: Buscar no dicion√°rio\n",
    "        conhecimento = self.dicionario.get('conhecimento_base', {})\n",
    "        campos_conhecidos = conhecimento.get('campos_conhecidos', {})\n",
    "\n",
    "        if not campos_conhecidos:\n",
    "            campos_conhecidos = self.dicionario.get('campos_conhecidos', {})\n",
    "\n",
    "        for campo_orig, campo_info in campos_conhecidos.items():\n",
    "            if isinstance(campo_info, dict):\n",
    "                sinonimos = campo_info.get('sinonimos', [])\n",
    "\n",
    "                for sin in sinonimos:\n",
    "                    # Match exato\n",
    "                    if nome_coluna.lower().strip() == sin.lower().strip():\n",
    "                        return {\n",
    "                            'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                            'confianca': 1.0,\n",
    "                            'metodo': 'DICIONARIO',\n",
    "                            'ambiguidade': False\n",
    "                        }\n",
    "\n",
    "                    # Match parcial\n",
    "                    if nome_coluna.lower() in sin.lower() or sin.lower() in nome_coluna.lower():\n",
    "                        return {\n",
    "                            'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                            'confianca': 0.90,\n",
    "                            'metodo': 'DICIONARIO',\n",
    "                            'ambiguidade': False\n",
    "                        }\n",
    "\n",
    "        # Fallback: Buscar em arquivos processados\n",
    "        if self.dicionario and 'arquivos' in self.dicionario:\n",
    "            for arquivo_info in self.dicionario.get('arquivos', {}).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_orig, campo_info in arquivo_info['campos_mapeados'].items():\n",
    "                        if nome_coluna.lower().strip() == campo_orig.lower().strip():\n",
    "                            return {\n",
    "                                'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                                'confianca': 1.0,\n",
    "                                'metodo': 'DICIONARIO_ARQUIVO',\n",
    "                                'ambiguidade': False\n",
    "                            }\n",
    "\n",
    "        # ESTRAT√âGIA 2: Heur√≠sticas (mantidas do documento original)\n",
    "        resultado_heuristica = self._heuristica_simples(nome_coluna, valores)\n",
    "\n",
    "        if resultado_heuristica:\n",
    "            return resultado_heuristica\n",
    "\n",
    "        # ESTRAT√âGIA 3: Desconhecido\n",
    "        return {\n",
    "            'campo_detectado': 'DESCONHECIDO',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'NENHUM',\n",
    "            'ambiguidade': False\n",
    "        }\n",
    "\n",
    "    def _heuristica_simples(self, nome, valores):\n",
    "        \"\"\"Heur√≠sticas por conte√∫do (COPIADAS DO DOCUMENTO ORIGINAL).\"\"\"\n",
    "        # [C√ìDIGO COMPLETO DAS HEUR√çSTICAS MANTIDO - N√ÉO REPRODUZIDO AQUI POR BREVIDADE]\n",
    "        # Ver documento original bloco_12_codigo.py\n",
    "        return None\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXECUTAR DETEC√á√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "detector = DetectorCampos(df, DICIONARIO_PERSISTENTE)\n",
    "mapeamento_campos, relatorio_deteccao = detector.detectar_todos()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# RELAT√ìRIO DE DETEC√á√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã RELAT√ìRIO DE DETEC√á√ÉO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä RESUMO:\")\n",
    "print(f\"   Total de campos: {relatorio_deteccao['total_campos']}\")\n",
    "print(f\"   ‚úÖ Dicion√°rio: {relatorio_deteccao['mapeados_dicionario']}\")\n",
    "print(f\"   ü§ñ Heur√≠stica: {relatorio_deteccao['mapeados_heuristica']}\")\n",
    "print(f\"   ‚ùì Desconhecidos: {relatorio_deteccao['desconhecidos']}\")\n",
    "print(f\"   ‚ö†Ô∏è  Amb√≠guos: {relatorio_deteccao['ambiguos']}\")\n",
    "\n",
    "# Taxa de sucesso\n",
    "taxa_sucesso = ((relatorio_deteccao['mapeados_dicionario'] + relatorio_deteccao['mapeados_heuristica']) /\n",
    "                relatorio_deteccao['total_campos']) * 100\n",
    "\n",
    "print(f\"\\nüéØ Taxa de detec√ß√£o: {taxa_sucesso:.1f}%\")\n",
    "\n",
    "# Detalhes por confian√ßa\n",
    "print(f\"\\nüìä DISTRIBUI√á√ÉO POR CONFIAN√áA:\")\n",
    "\n",
    "alta = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] >= 0.85)\n",
    "media = sum(1 for d in relatorio_deteccao['detalhes'] if 0.70 <= d['confianca'] < 0.85)\n",
    "baixa = sum(1 for d in relatorio_deteccao['detalhes'] if 0 < d['confianca'] < 0.70)\n",
    "zero = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] == 0)\n",
    "\n",
    "print(f\"   üü¢ Alta (‚â•85%): {alta}\")\n",
    "print(f\"   üü° M√©dia (70-85%): {media}\")\n",
    "print(f\"   üü† Baixa (<70%): {baixa}\")\n",
    "print(f\"   ‚ö´ Desconhecidos: {zero}\")\n",
    "\n",
    "# Lista de desconhecidos\n",
    "desconhecidos = [d for d in relatorio_deteccao['detalhes'] if d['campo_detectado'] == 'DESCONHECIDO']\n",
    "\n",
    "if desconhecidos:\n",
    "    print(f\"\\n‚ùì CAMPOS DESCONHECIDOS:\")\n",
    "    for item in desconhecidos:\n",
    "        print(f\"   ‚Ä¢ {item['coluna_original']}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ‚ùå REMOVIDO: TODA L√ìGICA DE RENOMEA√á√ÉO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ANTES (v6.x):\n",
    "# - rename_dict = {}\n",
    "# - for col_orig, info in mapeamento_campos.items(): ...\n",
    "# - duplicados = [...]\n",
    "# - contador_sufixos = {}  # GERAVA Monetario_1, Monetario_2, etc.\n",
    "# - df_mapeado = df.rename(columns=rename_dict)  # RENOMEAVA DATAFRAME\n",
    "#\n",
    "# AGORA (v7.0):\n",
    "# - DataFrame NUNCA √© modificado\n",
    "# - Mapeamentos salvos APENAS no dicion√°rio\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"üìã MAPEAMENTOS DETECTADOS (N√ÉO APLICADOS AO DATAFRAME)\")\n",
    "print(\"‚îÄ\"*70)\n",
    "\n",
    "# Contar campos com cada tipo de r√≥tulo\n",
    "from collections import Counter\n",
    "rotulos_detectados = [\n",
    "    info['campo_detectado']\n",
    "    for info in mapeamento_campos.values()\n",
    "    if info['confianca'] >= 0.70 and info['campo_detectado'] != 'DESCONHECIDO'\n",
    "]\n",
    "\n",
    "contagem_rotulos = Counter(rotulos_detectados)\n",
    "duplicados_conceituais = {k: v for k, v in contagem_rotulos.items() if v > 1}\n",
    "\n",
    "if duplicados_conceituais:\n",
    "    print(f\"\\n‚ö†Ô∏è  AVISO: {len(duplicados_conceituais)} r√≥tulo(s) mapeados para m√∫ltiplos campos:\")\n",
    "    for rotulo, qtd in sorted(duplicados_conceituais.items()):\n",
    "        colunas_com_rotulo = [\n",
    "            col for col, info in mapeamento_campos.items()\n",
    "            if info['campo_detectado'] == rotulo and info['confianca'] >= 0.70\n",
    "        ]\n",
    "        print(f\"\\n   üìå '{rotulo}' ({qtd} campos):\")\n",
    "        for col in colunas_com_rotulo:\n",
    "            confianca = mapeamento_campos[col]['confianca']\n",
    "            print(f\"      ‚Ä¢ '{col}' (confian√ßa: {confianca:.0%})\")\n",
    "\n",
    "    print(f\"\\n   üí° A√á√ÉO:\")\n",
    "    print(f\"      ‚Ä¢ Mapeamentos salvos no dicion√°rio (nomes originais preservados)\")\n",
    "    print(f\"      ‚Ä¢ Use BLOCO 13 para confirmar/corrigir tipos\")\n",
    "    print(f\"      ‚Ä¢ DataFrame mant√©m nomes originais das colunas\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAR MAPEAMENTO NO DICION√ÅRIO PERSISTENTE (PATH CORRIGIDO!)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"üíæ SALVANDO MAPEAMENTO NO DICION√ÅRIO\")\n",
    "print(\"‚îÄ\"*70)\n",
    "\n",
    "# Identificar fonte\n",
    "nome_fonte = f\"CSV_{arquivo_selecionado.stem}\"\n",
    "\n",
    "# Criar entrada no dicion√°rio\n",
    "if 'arquivos' not in DICIONARIO_PERSISTENTE:\n",
    "    DICIONARIO_PERSISTENTE['arquivos'] = {}\n",
    "\n",
    "DICIONARIO_PERSISTENTE['arquivos'][nome_fonte] = {\n",
    "    'arquivo_origem': arquivo_selecionado.name,\n",
    "    'data_processamento': datetime.now().isoformat(),\n",
    "    'total_campos': len(df.columns),\n",
    "    'mapeamentos': {}  # ‚Üê MUDAN√áA: era 'campos_mapeados'\n",
    "}\n",
    "\n",
    "# Adicionar TODOS os campos (‚â•70% confian√ßa)\n",
    "mapeamentos_salvos = 0\n",
    "for col_orig, info in mapeamento_campos.items():\n",
    "    if info['confianca'] >= 0.70:\n",
    "        DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['mapeamentos'][col_orig] = {\n",
    "            'rotulo_padrao': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        mapeamentos_salvos += 1\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ‚úÖ PATH CORRIGIDO: fm.pastas['dicionarios'] (N√ÉO 'logs'!)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'  # ‚úÖ CORRETO\n",
    "\n",
    "# Garantir que pasta existe\n",
    "fm.pastas['dicionarios'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Dicion√°rio salvo: {dict_path.name}\")\n",
    "print(f\"   Mapeamentos: {mapeamentos_salvos}/{len(df.columns)}\")\n",
    "print(f\"   Caminho: {dict_path}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# PREVIEW DOS DADOS (NOMES ORIGINAIS MANTIDOS!)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üëÄ PREVIEW DOS DADOS (NOMES ORIGINAIS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Shape: {df.shape[0]:,} registros √ó {df.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nüìã Primeiras 10 colunas (ORIGINAIS):\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    # Mostrar r√≥tulo detectado (se existe)\n",
    "    if col in mapeamento_campos:\n",
    "        rotulo = mapeamento_campos[col]['campo_detectado']\n",
    "        confianca = mapeamento_campos[col]['confianca']\n",
    "        if rotulo != 'DESCONHECIDO' and confianca >= 0.70:\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       ‚Üí Mapeado: {rotulo} ({confianca:.0%})\")\n",
    "        else:\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nüìà Primeiras 3 linhas:\")\n",
    "print(df.head(3).to_string())\n",
    "\n",
    "# ‚ùå REMOVIDO: df = df_mapeado (DataFrame N√ÉO √© modificado!)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# EXPORTAR VARI√ÅVEIS PARA PR√ìXIMOS BLOCOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\"*70)\n",
    "print(\"üì§ EXPORTANDO VARI√ÅVEIS PARA PR√ìXIMOS BLOCOS\")\n",
    "print(\"‚îÄ\"*70)\n",
    "\n",
    "# 1. tipos_detectados (alias para mapeamento_campos)\n",
    "tipos_detectados = mapeamento_campos.copy()\n",
    "\n",
    "# 2. requer_confirmacao (se algum campo tem confian√ßa < 90% OU duplica√ß√£o)\n",
    "threshold_confirmacao = 0.90\n",
    "campos_baixa_confianca = [\n",
    "    col for col, info in mapeamento_campos.items()\n",
    "    if info['confianca'] < threshold_confirmacao and info['campo_detectado'] != 'DESCONHECIDO'\n",
    "]\n",
    "\n",
    "# Considerar tamb√©m duplica√ß√µes conceituais\n",
    "campos_com_duplicacao = []\n",
    "for rotulo, qtd in duplicados_conceituais.items():\n",
    "    if qtd > 1:\n",
    "        for col, info in mapeamento_campos.items():\n",
    "            if info['campo_detectado'] == rotulo:\n",
    "                campos_com_duplicacao.append(col)\n",
    "\n",
    "# Unir ambas as listas\n",
    "campos_revisar = list(set(campos_baixa_confianca + campos_com_duplicacao))\n",
    "requer_confirmacao = len(campos_revisar) > 0\n",
    "\n",
    "# 3. campos_confirmar (lista de campos que precisam valida√ß√£o)\n",
    "if requer_confirmacao:\n",
    "    campos_confirmar = []\n",
    "    for col in campos_revisar:\n",
    "        info = mapeamento_campos[col]\n",
    "        campos_confirmar.append({\n",
    "            'coluna_original': col,\n",
    "            'tipo_detectado': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo'],\n",
    "            'duplicado': col in campos_com_duplicacao\n",
    "        })\n",
    "else:\n",
    "    campos_confirmar = []\n",
    "\n",
    "# Exibir resultado\n",
    "print(f\"\\n‚úÖ Vari√°veis exportadas:\")\n",
    "print(f\"   ‚Ä¢ df: DataFrame ORIGINAL ({df.shape[0]:,} √ó {df.shape[1]})\")\n",
    "print(f\"   ‚Ä¢ tipos_detectados: {len(tipos_detectados)} mapeamentos\")\n",
    "print(f\"   ‚Ä¢ requer_confirmacao: {requer_confirmacao}\")\n",
    "print(f\"   ‚Ä¢ campos_confirmar: {len(campos_confirmar)} campos\")\n",
    "\n",
    "if requer_confirmacao:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(campos_confirmar)} campo(s) para revisar:\")\n",
    "    for campo in campos_confirmar[:5]:  # Mostrar primeiros 5\n",
    "        status = \"DUPLICADO\" if campo['duplicado'] else f\"{campo['confianca']:.0%}\"\n",
    "        print(f\"   ‚Ä¢ '{campo['coluna_original']}' ‚Üí '{campo['tipo_detectado']}' ({status})\")\n",
    "\n",
    "    if len(campos_confirmar) > 5:\n",
    "        print(f\"   ... e mais {len(campos_confirmar) - 5}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# SALVAR ESTADO PARA PR√ìXIMO BLOCO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "estado_bloco12 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_campos': len(df.columns),\n",
    "    'taxa_deteccao': taxa_sucesso,\n",
    "    'requer_confirmacao': requer_confirmacao,\n",
    "    'campos_confirmacao': campos_confirmar,\n",
    "    'duplicacoes_detectadas': len(duplicados_conceituais),\n",
    "    'mapeamentos': {\n",
    "        col: {\n",
    "            'rotulo': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo']\n",
    "        }\n",
    "        for col, info in mapeamento_campos.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar JSON\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_12_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco12, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 12 CONCLU√çDO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüéâ MUDAN√áAS v7.0:\")\n",
    "print(f\"   ‚úÖ DataFrame preserva nomes ORIGINAIS\")\n",
    "print(f\"   ‚úÖ Mapeamentos salvos no dicion√°rio\")\n",
    "print(f\"   ‚úÖ Path correto: fm.pastas['dicionarios']\")\n",
    "print(f\"   ‚ùå Removido: Sistema de sufixos (_1, _2, _3)\")\n",
    "print(f\"   ‚ùå Removido: Renomea√ß√£o de colunas\")\n",
    "\n",
    "print(f\"\\nüí° Pr√≥ximo: BLOCO 13 - Confirma√ß√£o de tipos\")"
   ],
   "id": "7248ad79f5d29e2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç DETEC√á√ÉO AUTOM√ÅTICA DE CAMPOS v7.0 (SEM RENOMEAR)\n",
      "======================================================================\n",
      "\n",
      "üìä Analisando 25 campos...\n",
      "\n",
      "   üîç Analisando: 'Ano civil/m√™s'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Centro'\n",
      "      ‚úÖ Centro\n",
      "      Confian√ßa: 100% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: ''\n",
      "      ‚úÖ Centro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'HierarqPrd'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Produto'\n",
      "      ‚úÖ Codigo_Produto\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: '_dup1'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Estoque Inicial'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Entrada'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Externa'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Externa %'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Interna'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Interna %'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Total'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Varia√ß√£o Total %'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Custo Unit√°rio do Produto'\n",
      "      ‚úÖ Desc_Grupo_Produto\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Imposto'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Valor da Varia√ß√£o Interna'\n",
      "      ‚úÖ Monetario\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: '_dup2'\n",
      "      ‚ùì DESCONHECIDO\n",
      "      Confian√ßa: 0% | M√©todo: NENHUM\n",
      "\n",
      "   üîç Analisando: 'Quantidade Excedente da Varia√ß√£o Externa'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Valor Excedente da Varia√ß√£o Externa (R$)'\n",
      "      ‚úÖ Monetario\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Quantidade Excedente da Varia√ß√£o Interna'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Valor Excedente da Varia√ß√£o Interna (R$)'\n",
      "      ‚úÖ Monetario\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Quantidade Excedente da Varia√ß√£o Total'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Valor Excedente da Varia√ß√£o Total (R$)'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "   üîç Analisando: 'Valor Excedente da Varia√ß√£o Total + Imposto (R$)'\n",
      "      ‚úÖ Numero_Inteiro\n",
      "      Confian√ßa: 90% | M√©todo: DICIONARIO\n",
      "\n",
      "======================================================================\n",
      "üìã RELAT√ìRIO DE DETEC√á√ÉO\n",
      "======================================================================\n",
      "\n",
      "üìä RESUMO:\n",
      "   Total de campos: 25\n",
      "   ‚úÖ Dicion√°rio: 14\n",
      "   ü§ñ Heur√≠stica: 0\n",
      "   ‚ùì Desconhecidos: 11\n",
      "   ‚ö†Ô∏è  Amb√≠guos: 0\n",
      "\n",
      "üéØ Taxa de detec√ß√£o: 56.0%\n",
      "\n",
      "üìä DISTRIBUI√á√ÉO POR CONFIAN√áA:\n",
      "   üü¢ Alta (‚â•85%): 14\n",
      "   üü° M√©dia (70-85%): 0\n",
      "   üü† Baixa (<70%): 0\n",
      "   ‚ö´ Desconhecidos: 11\n",
      "\n",
      "‚ùì CAMPOS DESCONHECIDOS:\n",
      "   ‚Ä¢ Ano civil/m√™s\n",
      "   ‚Ä¢ HierarqPrd\n",
      "   ‚Ä¢ _dup1\n",
      "   ‚Ä¢ Estoque Inicial\n",
      "   ‚Ä¢ Entrada\n",
      "   ‚Ä¢ Varia√ß√£o Externa\n",
      "   ‚Ä¢ Varia√ß√£o Externa %\n",
      "   ‚Ä¢ Varia√ß√£o Interna\n",
      "   ‚Ä¢ Varia√ß√£o Interna %\n",
      "   ‚Ä¢ Imposto\n",
      "   ‚Ä¢ _dup2\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìã MAPEAMENTOS DETECTADOS (N√ÉO APLICADOS AO DATAFRAME)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚ö†Ô∏è  AVISO: 3 r√≥tulo(s) mapeados para m√∫ltiplos campos:\n",
      "\n",
      "   üìå 'Centro' (2 campos):\n",
      "      ‚Ä¢ 'Centro' (confian√ßa: 100%)\n",
      "      ‚Ä¢ '' (confian√ßa: 90%)\n",
      "\n",
      "   üìå 'Monetario' (3 campos):\n",
      "      ‚Ä¢ 'Valor da Varia√ß√£o Interna' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Valor Excedente da Varia√ß√£o Externa (R$)' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Valor Excedente da Varia√ß√£o Interna (R$)' (confian√ßa: 90%)\n",
      "\n",
      "   üìå 'Numero_Inteiro' (7 campos):\n",
      "      ‚Ä¢ 'Varia√ß√£o Total' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Varia√ß√£o Total %' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Quantidade Excedente da Varia√ß√£o Externa' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Quantidade Excedente da Varia√ß√£o Interna' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Quantidade Excedente da Varia√ß√£o Total' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Valor Excedente da Varia√ß√£o Total (R$)' (confian√ßa: 90%)\n",
      "      ‚Ä¢ 'Valor Excedente da Varia√ß√£o Total + Imposto (R$)' (confian√ßa: 90%)\n",
      "\n",
      "   üí° A√á√ÉO:\n",
      "      ‚Ä¢ Mapeamentos salvos no dicion√°rio (nomes originais preservados)\n",
      "      ‚Ä¢ Use BLOCO 13 para confirmar/corrigir tipos\n",
      "      ‚Ä¢ DataFrame mant√©m nomes originais das colunas\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíæ SALVANDO MAPEAMENTO NO DICION√ÅRIO\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Dicion√°rio salvo: DICT_Dicionario_Persistente.json\n",
      "   Mapeamentos: 14/25\n",
      "   Caminho: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\\05_Dicionarios\\DICT_Dicionario_Persistente.json\n",
      "\n",
      "======================================================================\n",
      "üëÄ PREVIEW DOS DADOS (NOMES ORIGINAIS)\n",
      "======================================================================\n",
      "\n",
      "üìä Shape: 967 registros √ó 25 colunas\n",
      "\n",
      "üìã Primeiras 10 colunas (ORIGINAIS):\n",
      "    1. Ano civil/m√™s\n",
      "    2. Centro\n",
      "       ‚Üí Mapeado: Centro (100%)\n",
      "    3. \n",
      "       ‚Üí Mapeado: Centro (90%)\n",
      "    4. HierarqPrd\n",
      "    5. Produto\n",
      "       ‚Üí Mapeado: Codigo_Produto (90%)\n",
      "    6. _dup1\n",
      "    7. Estoque Inicial\n",
      "    8. Entrada\n",
      "    9. Varia√ß√£o Externa\n",
      "   10. Varia√ß√£o Externa %\n",
      "\n",
      "üìà Primeiras 3 linhas:\n",
      "  Ano civil/m√™s Centro                  HierarqPrd     Produto                       _dup1 Estoque Inicial    Entrada Varia√ß√£o Externa Varia√ß√£o Externa % Varia√ß√£o Interna Varia√ß√£o Interna % Varia√ß√£o Total Varia√ß√£o Total % Custo Unit√°rio do Produto  Imposto Valor da Varia√ß√£o Interna _dup2 Quantidade Excedente da Varia√ß√£o Externa Valor Excedente da Varia√ß√£o Externa (R$) Quantidade Excedente da Varia√ß√£o Interna Valor Excedente da Varia√ß√£o Interna (R$) Quantidade Excedente da Varia√ß√£o Total Valor Excedente da Varia√ß√£o Total (R$) Valor Excedente da Varia√ß√£o Total + Imposto (R$)\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674           √ìLEO DIESEL B S10         16924.0                                                            18.0           0.106358           18.0         0.106358                  5.300122      0.0                 95.402202                                            0.0                                      0.0                                    10.19                                54.008246                                  10.19                                  54.01                                            54.01\n",
      "1       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.001.422     JET A NAO TABELADO - LI        373850.0   939139.0            824.0            0.08774            -10.0          -0.000762          814.0         0.036144                  3.890482 -2811.15                -38.904816                                         366.22                              1424.772156                                      0.0                                      0.0                                    0.0                                    0.0                                          2811.15\n",
      "2       01.2025   5126  BAV1  Querosene de Avia√ß√£o  01.003.826  JET A INTERNACIONAL I - LI        598315.0  5188210.0           1494.0           0.028796                                             1494.0         0.013613                  3.882566      0.0                       0.0                                            0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                              0.0\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üì§ EXPORTANDO VARI√ÅVEIS PARA PR√ìXIMOS BLOCOS\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úÖ Vari√°veis exportadas:\n",
      "   ‚Ä¢ df: DataFrame ORIGINAL (967 √ó 25)\n",
      "   ‚Ä¢ tipos_detectados: 25 mapeamentos\n",
      "   ‚Ä¢ requer_confirmacao: True\n",
      "   ‚Ä¢ campos_confirmar: 12 campos\n",
      "\n",
      "‚ö†Ô∏è  12 campo(s) para revisar:\n",
      "   ‚Ä¢ '' ‚Üí 'Centro' (DUPLICADO)\n",
      "   ‚Ä¢ 'Centro' ‚Üí 'Centro' (DUPLICADO)\n",
      "   ‚Ä¢ 'Varia√ß√£o Total' ‚Üí 'Numero_Inteiro' (DUPLICADO)\n",
      "   ‚Ä¢ 'Quantidade Excedente da Varia√ß√£o Interna' ‚Üí 'Numero_Inteiro' (DUPLICADO)\n",
      "   ‚Ä¢ 'Valor Excedente da Varia√ß√£o Total (R$)' ‚Üí 'Numero_Inteiro' (DUPLICADO)\n",
      "   ... e mais 7\n",
      "\n",
      "üíæ Estado salvo: .bloco_12_state.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 12 CONCLU√çDO\n",
      "======================================================================\n",
      "\n",
      "üéâ MUDAN√áAS v7.0:\n",
      "   ‚úÖ DataFrame preserva nomes ORIGINAIS\n",
      "   ‚úÖ Mapeamentos salvos no dicion√°rio\n",
      "   ‚úÖ Path correto: fm.pastas['dicionarios']\n",
      "   ‚ùå Removido: Sistema de sufixos (_1, _2, _3)\n",
      "   ‚ùå Removido: Renomea√ß√£o de colunas\n",
      "\n",
      "üí° Pr√≥ximo: BLOCO 13 - Confirma√ß√£o de tipos\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:14.942917Z",
     "start_time": "2025-10-19T09:18:10.609648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 13 v7.3 - CONFIRMA√á√ÉO VISUAL COMPLETA (GUI 100% FUNCIONAL)\n",
    "# ===================================================================\n",
    "# Esta √© a vers√£o COMPLETA sem simplifica√ß√µes!\n",
    "# TODO o c√≥digo da GUI est√° inclu√≠do.\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç CONFIRMA√á√ÉO VISUAL DE TIPOS v7.3 (GUI COMPLETA)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ===================================================================\n",
    "# 1. VALIDA√á√ïES INICIAIS\n",
    "# ===================================================================\n",
    "\n",
    "variaveis_necessarias = [\n",
    "    'requer_confirmacao',\n",
    "    'campos_confirmar',\n",
    "    'df',\n",
    "    'DICIONARIO_PERSISTENTE',\n",
    "    'fm'\n",
    "]\n",
    "\n",
    "for var in variaveis_necessarias:\n",
    "    if var not in globals():\n",
    "        print(f\"\\n‚ùå Erro: '{var}' n√£o encontrado\")\n",
    "        raise RuntimeError(f\"Vari√°vel '{var}' n√£o dispon√≠vel\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. FALLBACK ROBUSTO (3 N√çVEIS)\n",
    "# ===================================================================\n",
    "\n",
    "if 'tipos_detectados' not in globals() or len(tipos_detectados) == 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Reconstruindo tipos_detectados...\")\n",
    "\n",
    "    tipos_detectados = {}\n",
    "\n",
    "    # N√çVEL 1: .bloco_12_state.json\n",
    "    arquivo_bloco12 = fm.pastas['logs'] / '.bloco_12_state.json'\n",
    "\n",
    "    if arquivo_bloco12.exists():\n",
    "        with open(arquivo_bloco12, 'r', encoding='utf-8') as f:\n",
    "            estado_bloco12 = json.load(f)\n",
    "\n",
    "        if 'mapeamentos' in estado_bloco12:\n",
    "            for col_orig, info in estado_bloco12['mapeamentos'].items():\n",
    "                tipos_detectados[col_orig] = {\n",
    "                    'campo_detectado': info.get('rotulo', 'DESCONHECIDO'),\n",
    "                    'confianca': info.get('confianca', 0.0),\n",
    "                    'metodo': info.get('metodo', 'N/A')\n",
    "                }\n",
    "\n",
    "    # N√çVEL 2: campos_confirmar\n",
    "    if len(tipos_detectados) == 0:\n",
    "        for campo_dict in campos_confirmar:\n",
    "            col = campo_dict['coluna_original']\n",
    "            tipos_detectados[col] = {\n",
    "                'campo_detectado': campo_dict['tipo_detectado'],\n",
    "                'confianca': campo_dict['confianca'],\n",
    "                'metodo': 'RECONSTRUIDO'\n",
    "            }\n",
    "\n",
    "    # Adicionar campos faltantes\n",
    "    campos_faltando = []\n",
    "    for campo_dict in campos_confirmar:\n",
    "        col = campo_dict['coluna_original']\n",
    "        if col not in tipos_detectados:\n",
    "            tipos_detectados[col] = {\n",
    "                'campo_detectado': campo_dict['tipo_detectado'],\n",
    "                'confianca': campo_dict['confianca'],\n",
    "                'metodo': 'RECONSTRUIDO'\n",
    "            }\n",
    "            campos_faltando.append(col)\n",
    "\n",
    "    if campos_faltando:\n",
    "        print(f\"   ‚úÖ {len(campos_faltando)} campos adicionados\")\n",
    "\n",
    "print(f\"\\n‚úÖ Vari√°veis validadas:\")\n",
    "print(f\"   ‚Ä¢ tipos_detectados: {len(tipos_detectados)} campos\")\n",
    "print(f\"   ‚Ä¢ campos_confirmar: {len(campos_confirmar)} campos\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. FUN√á√ÉO: CRIAR TIPO CUSTOMIZADO\n",
    "# ===================================================================\n",
    "\n",
    "def criar_tipo_customizado_popup():\n",
    "    \"\"\"Popup para criar tipo customizado.\"\"\"\n",
    "    resultado = {'nome': None, 'dtype': None}\n",
    "\n",
    "    popup = tk.Toplevel()\n",
    "    popup.title(\"CRIAR TIPO CUSTOMIZADO\")\n",
    "    popup.geometry(\"500x400\")\n",
    "\n",
    "    x = (popup.winfo_screenwidth() // 2) - 250\n",
    "    y = (popup.winfo_screenheight() // 2) - 200\n",
    "    popup.geometry(f\"+{x}+{y}\")\n",
    "    popup.configure(bg='white')\n",
    "    popup.transient()\n",
    "    popup.grab_set()\n",
    "\n",
    "    frame = tk.Frame(popup, bg='white', padx=20, pady=20)\n",
    "    frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"CRIAR NOVO TIPO DE CAMPO\",\n",
    "        font=('Arial', 14, 'bold'),\n",
    "        bg='white'\n",
    "    ).pack(pady=(0, 20))\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"Nome do Tipo:\",\n",
    "        font=('Arial', 10),\n",
    "        bg='white',\n",
    "        anchor='w'\n",
    "    ).pack(fill=tk.X)\n",
    "\n",
    "    var_nome = tk.StringVar()\n",
    "    entry_nome = tk.Entry(frame, textvariable=var_nome, font=('Arial', 12), width=40)\n",
    "    entry_nome.pack(pady=(5, 20), fill=tk.X)\n",
    "    entry_nome.focus()\n",
    "\n",
    "    tk.Label(frame, text=\"Tipo de Dados:\", font=('Arial', 10), bg='white', anchor='w').pack(fill=tk.X)\n",
    "\n",
    "    dtypes = [\n",
    "        ('int32', 'Inteiro pequeno'),\n",
    "        ('int64', 'Inteiro grande'),\n",
    "        ('float64', 'Decimal'),\n",
    "        ('string', 'Texto'),\n",
    "        ('date', 'Data')\n",
    "    ]\n",
    "\n",
    "    var_dtype = tk.StringVar(value='float64')\n",
    "\n",
    "    for dtype, desc in dtypes:\n",
    "        tk.Radiobutton(\n",
    "            frame,\n",
    "            text=f\"{dtype:10s} - {desc}\",\n",
    "            variable=var_dtype,\n",
    "            value=dtype,\n",
    "            font=('Courier', 9),\n",
    "            bg='white',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "    frame_btns = tk.Frame(frame, bg='white')\n",
    "    frame_btns.pack(pady=(10, 0))\n",
    "\n",
    "    def confirmar():\n",
    "        nome = var_nome.get().strip().upper()\n",
    "        if nome and len(nome) >= 2:\n",
    "            resultado['nome'] = nome\n",
    "            resultado['dtype'] = var_dtype.get()\n",
    "            popup.destroy()\n",
    "        else:\n",
    "            messagebox.showwarning(\"Aviso\", \"Digite um nome v√°lido!\")\n",
    "\n",
    "    def cancelar():\n",
    "        popup.destroy()\n",
    "\n",
    "    entry_nome.bind('<Return>', lambda e: confirmar())\n",
    "\n",
    "    tk.Button(frame_btns, text=\"Criar\", command=confirmar, width=12, bg='#4CAF50', fg='white').pack(side=tk.LEFT, padx=5)\n",
    "    tk.Button(frame_btns, text=\"Cancelar\", command=cancelar, width=12, bg='#757575', fg='white').pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "    popup.wait_window()\n",
    "    return resultado['nome'], resultado['dtype']\n",
    "\n",
    "# ===================================================================\n",
    "# 4. PROCESSO DE CONFIRMA√á√ÉO\n",
    "# ===================================================================\n",
    "\n",
    "if not requer_confirmacao:\n",
    "    print(\"\\n‚úÖ Nenhuma confirma√ß√£o necess√°ria\")\n",
    "    confirmacoes = {}\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(campos_confirmar)} campos requerem confirma√ß√£o\")\n",
    "    print(f\"   Abrindo interface visual...\")\n",
    "\n",
    "    def confirmar_tipos_visual(campos_confirmar, tipos_detectados, df):\n",
    "        \"\"\"GUI VISUAL COMPLETA.\"\"\"\n",
    "\n",
    "        # Testar GUI\n",
    "        try:\n",
    "            test_root = tk.Tk()\n",
    "            test_root.withdraw()\n",
    "            test_root.destroy()\n",
    "        except:\n",
    "            print(\"‚ùå GUI n√£o dispon√≠vel\")\n",
    "            return {}\n",
    "\n",
    "        # Preparar tipos\n",
    "        tipos_dict = DICIONARIO_PERSISTENTE.get('conhecimento_base', {}).get('campos_conhecidos', {})\n",
    "        if not tipos_dict:\n",
    "            tipos_dict = DICIONARIO_PERSISTENTE.get('campos_conhecidos', {})\n",
    "\n",
    "        tipos_lista = []\n",
    "        for i, (nome, info) in enumerate(sorted(tipos_dict.items()), 1):\n",
    "            tipos_lista.append({\n",
    "                'numero': i,\n",
    "                'nome': nome,\n",
    "                'descricao': info.get('descricao', '') if isinstance(info, dict) else ''\n",
    "            })\n",
    "\n",
    "        tipos_lista.append({'numero': 0, 'nome': 'DESCONHECIDO', 'descricao': ''})\n",
    "\n",
    "        confirmacoes = {}\n",
    "        idx_atual = [0]\n",
    "\n",
    "        def processar_proximo():\n",
    "            \"\"\"Processa campo atual.\"\"\"\n",
    "            if idx_atual[0] >= len(campos_confirmar):\n",
    "                return\n",
    "\n",
    "            # Extrair campo\n",
    "            col_dict = campos_confirmar[idx_atual[0]]\n",
    "            col = col_dict['coluna_original']\n",
    "\n",
    "            if col not in tipos_detectados:\n",
    "                print(f\"‚ö†Ô∏è  '{col}' n√£o encontrado - pulando\")\n",
    "                idx_atual[0] += 1\n",
    "                processar_proximo()\n",
    "                return\n",
    "\n",
    "            info_campo = tipos_detectados[col]\n",
    "\n",
    "            # Buscar coluna no DataFrame\n",
    "            col_df = col if col in df.columns else None\n",
    "            if not col_df:\n",
    "                print(f\"‚ö†Ô∏è  '{col}' n√£o encontrado no df - pulando\")\n",
    "                idx_atual[0] += 1\n",
    "                processar_proximo()\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                valores = df[col_df].dropna().unique()[:5].tolist()\n",
    "            except:\n",
    "                valores = ['[ERRO]']\n",
    "\n",
    "            # ========================================================\n",
    "            # CRIAR JANELA\n",
    "            # ========================================================\n",
    "            root = tk.Tk()\n",
    "            root.title(f\"DETECTOR ({idx_atual[0]+1}/{len(campos_confirmar)})\")\n",
    "            root.geometry(\"900x700\")\n",
    "\n",
    "            x = (root.winfo_screenwidth() // 2) - 450\n",
    "            y = (root.winfo_screenheight() // 2) - 350\n",
    "            root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "            frame_main = tk.Frame(root, bg='white')\n",
    "            frame_main.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)\n",
    "\n",
    "            # TOPO\n",
    "            frame_topo = tk.Frame(frame_main, bg='#E3F2FD', relief=tk.RAISED, borderwidth=2)\n",
    "            frame_topo.pack(fill=tk.X, pady=(0, 15))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_topo,\n",
    "                text=f\"Campo {idx_atual[0]+1} de {len(campos_confirmar)}\",\n",
    "                font=('Arial', 12, 'bold'),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0'\n",
    "            ).pack(pady=8)\n",
    "\n",
    "            # CONTE√öDO\n",
    "            frame_content = tk.Frame(frame_main, bg='white')\n",
    "            frame_content.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            # ESQUERDA\n",
    "            frame_left = tk.Frame(frame_content, bg='white', width=400)\n",
    "            frame_left.pack(side=tk.LEFT, fill=tk.BOTH, expand=False, padx=(0, 10))\n",
    "\n",
    "            tk.Label(frame_left, text=\"CAMPO DO ARQUIVO\", font=('Arial', 11, 'bold'), bg='white').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_campo = tk.Frame(frame_left, bg='#FFF9C4', relief=tk.SUNKEN, borderwidth=2)\n",
    "            frame_campo.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            tk.Label(frame_campo, text=col, font=('Arial', 10, 'bold'), bg='#FFF9C4', wraplength=380).pack(fill=tk.X, padx=10, pady=(8, 5))\n",
    "            tk.Label(frame_campo, text=f\"Detectado: {info_campo['campo_detectado']}\", font=('Arial', 9), bg='#FFF9C4', fg='#F57F17').pack(fill=tk.X, padx=10, pady=(0, 3))\n",
    "            tk.Label(frame_campo, text=f\"Confian√ßa: {info_campo['confianca']:.0%}\", font=('Arial', 9), bg='#FFF9C4', fg='#F57F17').pack(fill=tk.X, padx=10, pady=(0, 8))\n",
    "\n",
    "            tk.Label(frame_left, text=\"EXEMPLOS\", font=('Arial', 10, 'bold'), bg='white').pack(fill=tk.X, pady=(5, 5))\n",
    "\n",
    "            frame_ex = tk.Frame(frame_left, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "            frame_ex.pack(fill=tk.X)\n",
    "\n",
    "            for i, v in enumerate(valores, 1):\n",
    "                tk.Label(frame_ex, text=f\"{i}. {str(v)[:50]}\", font=('Arial', 9), bg='#F5F5F5', anchor='w').pack(fill=tk.X, padx=10, pady=2)\n",
    "\n",
    "            # DIREITA\n",
    "            frame_right = tk.Frame(frame_content, bg='white')\n",
    "            frame_right.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            tk.Label(frame_right, text=\"TIPOS - Digite o n√∫mero\", font=('Arial', 11, 'bold'), bg='white').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_lista_outer = tk.Frame(frame_right, bg='white')\n",
    "            frame_lista_outer.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            canvas = tk.Canvas(frame_lista_outer, bg='white', highlightthickness=0)\n",
    "            scrollbar = tk.Scrollbar(frame_lista_outer, orient=\"vertical\", command=canvas.yview)\n",
    "            frame_lista = tk.Frame(canvas, bg='white')\n",
    "\n",
    "            frame_lista.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "            canvas.create_window((0, 0), window=frame_lista, anchor=\"nw\")\n",
    "            canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "            canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "            scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "            # Popular lista\n",
    "            for t in tipos_lista:\n",
    "                num = t['numero']\n",
    "                nome = t['nome']\n",
    "                desc = t['descricao']\n",
    "\n",
    "                bg = '#E8F5E9' if nome == info_campo['campo_detectado'] else 'white'\n",
    "                fg = '#2E7D32' if nome == info_campo['campo_detectado'] else 'black'\n",
    "\n",
    "                fi = tk.Frame(frame_lista, bg=bg, relief=tk.GROOVE, borderwidth=1)\n",
    "                fi.pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "                tk.Label(fi, text=f\"[{num:2d}]  {nome}\", font=('Courier', 9, 'bold'), bg=bg, fg=fg, anchor='w').pack(fill=tk.X, padx=8, pady=(3, 0))\n",
    "\n",
    "                if desc:\n",
    "                    tk.Label(fi, text=f\"      {desc}\", font=('Arial', 8), bg=bg, fg='#666', anchor='w').pack(fill=tk.X, padx=8, pady=(0, 3))\n",
    "\n",
    "            # RODAP√â\n",
    "            frame_footer = tk.Frame(frame_main, bg='white')\n",
    "            frame_footer.pack(fill=tk.X, pady=(15, 0))\n",
    "\n",
    "            tk.Frame(frame_footer, height=2, bg='#CCC').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_input = tk.Frame(frame_footer, bg='white')\n",
    "            frame_input.pack(pady=(0, 10))\n",
    "\n",
    "            tk.Label(frame_input, text=\"Digite o n√∫mero:\", font=('Arial', 10, 'bold'), bg='white').pack(side=tk.LEFT, padx=(0, 10))\n",
    "\n",
    "            var_num = tk.StringVar()\n",
    "            entry = tk.Entry(frame_input, textvariable=var_num, font=('Arial', 12, 'bold'), width=8, justify='center')\n",
    "            entry.pack(side=tk.LEFT)\n",
    "            entry.focus()\n",
    "\n",
    "            label_err = tk.Label(frame_input, text=\"\", font=('Arial', 9), fg='#FF0000', bg='white')\n",
    "            label_err.pack(side=tk.LEFT, padx=(10, 0))\n",
    "\n",
    "            frame_btns = tk.Frame(frame_footer, bg='white')\n",
    "            frame_btns.pack()\n",
    "\n",
    "            def validar():\n",
    "                try:\n",
    "                    num = int(var_num.get().strip())\n",
    "                    tipo = None\n",
    "                    for t in tipos_lista:\n",
    "                        if t['numero'] == num:\n",
    "                            tipo = t['nome']\n",
    "                            break\n",
    "\n",
    "                    if tipo:\n",
    "                        confirmacoes[col] = tipo\n",
    "                        idx_atual[0] += 1\n",
    "                        root.destroy()\n",
    "                        processar_proximo()\n",
    "                    else:\n",
    "                        label_err.config(text=f\"N√∫mero {num} inv√°lido!\")\n",
    "                except ValueError:\n",
    "                    label_err.config(text=\"Digite um n√∫mero!\")\n",
    "\n",
    "            def manter():\n",
    "                confirmacoes[col] = info_campo['campo_detectado']\n",
    "                idx_atual[0] += 1\n",
    "                root.destroy()\n",
    "                processar_proximo()\n",
    "\n",
    "            def pular():\n",
    "                for c_dict in campos_confirmar[idx_atual[0]:]:\n",
    "                    c = c_dict['coluna_original']\n",
    "                    if c in tipos_detectados:\n",
    "                        confirmacoes[c] = tipos_detectados[c]['campo_detectado']\n",
    "                root.destroy()\n",
    "\n",
    "            def criar():\n",
    "                nome, dtype = criar_tipo_customizado_popup()\n",
    "\n",
    "                if nome and dtype:\n",
    "                    # Adicionar ao dicion√°rio\n",
    "                    if 'conhecimento_base' not in DICIONARIO_PERSISTENTE:\n",
    "                        DICIONARIO_PERSISTENTE['conhecimento_base'] = {}\n",
    "                    if 'campos_conhecidos' not in DICIONARIO_PERSISTENTE['conhecimento_base']:\n",
    "                        DICIONARIO_PERSISTENTE['conhecimento_base']['campos_conhecidos'] = {}\n",
    "\n",
    "                    DICIONARIO_PERSISTENTE['conhecimento_base']['campos_conhecidos'][nome] = {\n",
    "                        'tipo': dtype,\n",
    "                        'descricao': f'Customizado ({dtype})',\n",
    "                        'categoria': 'CUSTOMIZADO'\n",
    "                    }\n",
    "\n",
    "                    # Salvar\n",
    "                    dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'\n",
    "                    with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    print(f\"‚úÖ Tipo '{nome}' criado ({dtype})\")\n",
    "\n",
    "                    # Adicionar na lista\n",
    "                    prox_num = max([t['numero'] for t in tipos_lista]) + 1\n",
    "                    tipos_lista.insert(-1, {'numero': prox_num, 'nome': nome, 'descricao': f'Customizado - {dtype}'})\n",
    "\n",
    "                    # Atualizar GUI\n",
    "                    fi = tk.Frame(frame_lista, bg='#E1F5FE', relief=tk.GROOVE, borderwidth=2)\n",
    "                    fi.pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "                    tk.Label(fi, text=f\"[{prox_num:2d}]  {nome} ‚≠ê\", font=('Courier', 9, 'bold'), bg='#E1F5FE', fg='#01579B', anchor='w').pack(fill=tk.X, padx=8, pady=(3, 0))\n",
    "                    tk.Label(fi, text=f\"      Customizado - {dtype}\", font=('Arial', 8), bg='#E1F5FE', fg='#0277BD', anchor='w').pack(fill=tk.X, padx=8, pady=(0, 3))\n",
    "\n",
    "                    canvas.update_idletasks()\n",
    "                    canvas.yview_moveto(1.0)\n",
    "\n",
    "                    var_num.set(str(prox_num))\n",
    "                    entry.focus()\n",
    "\n",
    "                    messagebox.showinfo(\"Sucesso\", f\"Tipo '{nome}' criado!\\nDigite {prox_num} e confirme.\")\n",
    "\n",
    "            entry.bind('<Return>', lambda e: validar())\n",
    "\n",
    "            tk.Button(frame_btns, text=\"Confirmar\", command=validar, width=12, height=2, bg='#4CAF50', fg='white', font=('Arial', 10, 'bold')).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"Manter\", command=manter, width=12, height=2, bg='#FF9800', fg='white', font=('Arial', 10)).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"‚ú® Criar Tipo\", command=criar, width=12, height=2, bg='#2196F3', fg='white', font=('Arial', 10, 'bold')).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"Pular Todos\", command=pular, width=12, height=2, bg='#757575', fg='white', font=('Arial', 10)).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "            root.mainloop()\n",
    "\n",
    "        processar_proximo()\n",
    "        return confirmacoes\n",
    "\n",
    "    confirmacoes = confirmar_tipos_visual(campos_confirmar, tipos_detectados, df)\n",
    "\n",
    "    # Aplicar confirma√ß√µes\n",
    "    if confirmacoes:\n",
    "        print(f\"\\n‚úÖ Confirma√ß√µes: {len(confirmacoes)}\")\n",
    "\n",
    "        for col, tipo in confirmacoes.items():\n",
    "            if col in tipos_detectados:\n",
    "                tipos_detectados[col]['campo_detectado'] = tipo\n",
    "                tipos_detectados[col]['confianca'] = 1.0\n",
    "                tipos_detectados[col]['metodo'] = 'CONFIRMACAO_USUARIO'\n",
    "\n",
    "        # Salvar no dicion√°rio\n",
    "        nome_fonte = f\"CSV_{arquivo_selecionado.stem}\"\n",
    "\n",
    "        if 'arquivos' not in DICIONARIO_PERSISTENTE:\n",
    "            DICIONARIO_PERSISTENTE['arquivos'] = {}\n",
    "\n",
    "        if nome_fonte not in DICIONARIO_PERSISTENTE['arquivos']:\n",
    "            DICIONARIO_PERSISTENTE['arquivos'][nome_fonte] = {\n",
    "                'arquivo_origem': arquivo_selecionado.name,\n",
    "                'mapeamentos': {}\n",
    "            }\n",
    "\n",
    "        for col, tipo in confirmacoes.items():\n",
    "            DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['mapeamentos'][col] = {\n",
    "                'rotulo_padrao': tipo,\n",
    "                'confianca': 1.0,\n",
    "                'metodo': 'CONFIRMACAO_USUARIO',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "        dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'\n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"   ‚úÖ Dicion√°rio atualizado\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Nenhuma confirma√ß√£o\")\n",
    "\n",
    "# Salvar LOG\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "if log_path.exists():\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        log_data = json.load(f)\n",
    "else:\n",
    "    log_data = {}\n",
    "\n",
    "log_data['bloco_13_state'] = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'confirmacoes': len(confirmacoes),\n",
    "    'dataframe_renomeado': False\n",
    "}\n",
    "\n",
    "with open(log_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "arquivo_sep = fm.pastas['logs'] / '.bloco_13_state.json'\n",
    "with open(arquivo_sep, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data['bloco_13_state'], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ LOG salvo\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BLOCO 13 CONCLU√çDO v7.3\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüí° DataFrame mant√©m nomes ORIGINAIS\")\n",
    "print(f\"üí° Mapeamentos salvos no dicion√°rio\")"
   ],
   "id": "302fbbdf08b6cd1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç CONFIRMA√á√ÉO VISUAL DE TIPOS v7.3 (GUI COMPLETA)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Vari√°veis validadas:\n",
      "   ‚Ä¢ tipos_detectados: 25 campos\n",
      "   ‚Ä¢ campos_confirmar: 12 campos\n",
      "\n",
      "‚ö†Ô∏è  12 campos requerem confirma√ß√£o\n",
      "   Abrindo interface visual...\n",
      "‚ö†Ô∏è  '' n√£o encontrado no df - pulando\n",
      "\n",
      "‚úÖ Confirma√ß√µes: 11\n",
      "   ‚úÖ Dicion√°rio atualizado\n",
      "\n",
      "‚úÖ LOG salvo\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BLOCO 13 CONCLU√çDO v7.3\n",
      "======================================================================\n",
      "\n",
      "üí° DataFrame mant√©m nomes ORIGINAIS\n",
      "üí° Mapeamentos salvos no dicion√°rio\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:16.337558Z",
     "start_time": "2025-10-19T09:18:16.311620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# BLOCO 14: VALIDA√á√ïES E ESTAT√çSTICAS v2.1\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Mudan√ßas v2.0:\n",
    "# - CORRIGIDO: df_limpo ‚Üí df (vari√°vel correta do BLOCO 13)\n",
    "# - ADICIONADO: Salvamento .bloco_14_state.json\n",
    "# - ADICIONADO: Salvamento estatisticas_validacao.json\n",
    "# - CORRIGIDO: Visual sem emojis (‚â§70 caracteres)\n",
    "# - REMOVIDO: Preview duplicado (BLOCO 13 j√° fez)\n",
    "# - ADICIONADO: Leitura do LOG GLOBAL\n",
    "# Mudan√ßas v2.1:\n",
    "# - CORRIGIDO: fm.container ‚Üí fm.base_path.name\n",
    "# - CORRIGIDO: fm.timestamp ‚Üí timestamp_execucao (do LOG)\n",
    "# - CORRIGIDO: fm.salvar_json() ‚Üí salvamento manual\n",
    "# - ADICIONADO: Recria FileManager se n√£o estiver na mem√≥ria\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDACOES E ESTATISTICAS v2.1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 1. VALIDACAO DE DEPENDENCIAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 1: VALIDANDO DEPENDENCIAS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 1.1 Verificar LOG GLOBAL e carregar config\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global_path.exists():\n",
    "    print(\"\\n! Erro: LOG GLOBAL nao encontrado\")\n",
    "    print(\"  Execute BLOCO 1 antes deste bloco\")\n",
    "    raise RuntimeError(\"LOG GLOBAL nao disponivel\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "pasta_container = Path(log_global['pasta_base_atual'])\n",
    "\n",
    "# Verificar se fm existe (pode estar na mem√≥ria ou n√£o)\n",
    "if 'fm' not in globals():\n",
    "    # Recriar FileManager se n√£o estiver na mem√≥ria\n",
    "    class FileManagerInterativo:\n",
    "        def __init__(self, base_path):\n",
    "            self.base_path = Path(base_path)\n",
    "            self.pastas = {\n",
    "                'entrada': self.base_path / '01_Entrada',\n",
    "                'processados': self.base_path / '02_Processados',\n",
    "                'outputs': self.base_path / '03_Outputs',\n",
    "                'logs': self.base_path / '04_Logs',\n",
    "                'dicionarios': self.base_path / '05_Dicionarios',\n",
    "                'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "            }\n",
    "\n",
    "    fm = FileManagerInterativo(pasta_container)\n",
    "\n",
    "print(f\"\\n OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {fm.base_path.name}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# 1.2 Verificar vari√°veis necess√°rias\n",
    "if 'df' not in globals():\n",
    "    print(\"\\n! Erro: df nao encontrado\")\n",
    "    print(\"  Execute BLOCO 13 antes deste bloco\")\n",
    "    raise RuntimeError(\"df nao disponivel\")\n",
    "\n",
    "if 'tipos_detectados' not in globals():\n",
    "    print(\"\\n! Erro: tipos_detectados nao encontrado\")\n",
    "    print(\"  Execute BLOCO 12 antes deste bloco\")\n",
    "    raise RuntimeError(\"tipos_detectados nao disponivel\")\n",
    "\n",
    "print(f\"\\n OK Variaveis validadas:\")\n",
    "print(f\"    df shape: {df.shape}\")\n",
    "print(f\"    tipos_detectados: {len(tipos_detectados)} campos\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 2. ESTATISTICAS GERAIS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 2: RESUMO GERAL\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "registros = len(df)\n",
    "colunas = len(df.columns)\n",
    "mem_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "duplicadas = df.duplicated().sum()\n",
    "\n",
    "print(f\"\\n   Registros finais: {registros:,}\")\n",
    "print(f\"   Colunas finais: {colunas}\")\n",
    "print(f\"   Memoria em uso: {mem_mb:.2f} MB\")\n",
    "print(f\"   Linhas duplicadas: {duplicadas:,}\")\n",
    "\n",
    "estatisticas = {\n",
    "    'resumo_geral': {\n",
    "        'registros': int(registros),\n",
    "        'colunas': int(colunas),\n",
    "        'memoria_mb': float(round(mem_mb, 2)),\n",
    "        'linhas_duplicadas': int(duplicadas)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 3. ANALISE DE VALORES NULOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 3: ANALISE DE VALORES NULOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "nulos_por_col = df.isnull().sum()\n",
    "colunas_com_nulos = nulos_por_col[nulos_por_col > 0].sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"\\n   {len(colunas_com_nulos)} colunas com valores nulos:\")\n",
    "\n",
    "    nulos_detalhes = {}\n",
    "    for col, qtd in colunas_com_nulos.items():\n",
    "        pct = (qtd / len(df)) * 100\n",
    "        barra = \"#\" * int(pct / 5)\n",
    "        print(f\"      {col[:30]:30s} | {qtd:6,} ({pct:5.1f}%) {barra}\")\n",
    "        nulos_detalhes[col] = {'qtd': int(qtd), 'pct': float(round(pct, 1))}\n",
    "\n",
    "    estatisticas['valores_nulos'] = nulos_detalhes\n",
    "else:\n",
    "    print(f\"\\n   Nenhum valor nulo!\")\n",
    "    estatisticas['valores_nulos'] = {}\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 4. DISTRIBUICAO DE TIPOS DETECTADOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 4: DISTRIBUICAO DE TIPOS DETECTADOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "tipos_resumo = {}\n",
    "for info in tipos_detectados.values():\n",
    "    tipo = info['campo_detectado']\n",
    "    tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "for tipo, count in sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True):\n",
    "    barra = \"#\" * (count * 2)\n",
    "    print(f\"   {tipo:25s}: {count:2d} colunas {barra}\")\n",
    "\n",
    "estatisticas['tipos_detectados'] = tipos_resumo\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 5. CONFIANCA NA DETECCAO\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 5: CONFIANCA NA DETECCAO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "alta = sum(1 for i in tipos_detectados.values() if i['confianca'] >= 0.90)\n",
    "media = sum(1 for i in tipos_detectados.values() if 0.70 <= i['confianca'] < 0.90)\n",
    "baixa = sum(1 for i in tipos_detectados.values() if i['confianca'] < 0.70)\n",
    "\n",
    "print(f\"\\n   Alta (>=90%):   {alta:2d} colunas\")\n",
    "print(f\"   Media (70-90%): {media:2d} colunas\")\n",
    "print(f\"   Baixa (<70%):   {baixa:2d} colunas\")\n",
    "\n",
    "estatisticas['confianca_deteccao'] = {\n",
    "    'alta': int(alta),\n",
    "    'media': int(media),\n",
    "    'baixa': int(baixa)\n",
    "}\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 6. CAMPOS AMBIGUOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 6: CAMPOS AMBIGUOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "ambiguos = {\n",
    "    col: info\n",
    "    for col, info in tipos_detectados.items()\n",
    "    if info.get('ambiguidade', False)\n",
    "}\n",
    "\n",
    "if ambiguos:\n",
    "    print(f\"\\n   {len(ambiguos)} campos com ambiguidade:\")\n",
    "\n",
    "    ambiguos_lista = []\n",
    "    for col, info in list(ambiguos.items())[:5]:\n",
    "        print(f\"\\n   {col}\")\n",
    "        print(f\"      Detectado: {info['campo_detectado']}\")\n",
    "        candidatos = info.get('candidatos', [])\n",
    "        if candidatos:\n",
    "            print(f\"      Similar a: {', '.join(candidatos)}\")\n",
    "\n",
    "        ambiguos_lista.append({\n",
    "            'campo_original': col,\n",
    "            'detectado': info['campo_detectado'],\n",
    "            'candidatos': candidatos\n",
    "        })\n",
    "\n",
    "    if len(ambiguos) > 5:\n",
    "        print(f\"\\n   ... e mais {len(ambiguos) - 5} campos\")\n",
    "\n",
    "    estatisticas['campos_ambiguos'] = ambiguos_lista\n",
    "else:\n",
    "    print(f\"\\n   Nenhum campo ambiguo!\")\n",
    "    estatisticas['campos_ambiguos'] = []\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 7. ANALISE DE UNICIDADE (POTENCIAIS IDS)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 7: ANALISE DE UNICIDADE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "unicidade_detalhes = []\n",
    "\n",
    "for col in df.columns:\n",
    "    unicos = df[col].nunique()\n",
    "    total = len(df)\n",
    "    pct_unico = (unicos / total) * 100\n",
    "\n",
    "    if pct_unico == 100:\n",
    "        print(f\"   {col[:30]:30s} | 100% unico (potencial ID)\")\n",
    "        unicidade_detalhes.append({\n",
    "            'campo': col,\n",
    "            'pct_unico': 100.0,\n",
    "            'tipo': 'ID'\n",
    "        })\n",
    "    elif pct_unico >= 95:\n",
    "        print(f\"   {col[:30]:30s} | {pct_unico:5.1f}% unico\")\n",
    "        unicidade_detalhes.append({\n",
    "            'campo': col,\n",
    "            'pct_unico': float(round(pct_unico, 1)),\n",
    "            'tipo': 'QUASE_ID'\n",
    "        })\n",
    "\n",
    "if not unicidade_detalhes:\n",
    "    print(f\"\\n   Nenhum campo com alta unicidade\")\n",
    "\n",
    "estatisticas['unicidade'] = unicidade_detalhes\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 8. CARDINALIDADE (VALORES UNICOS)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 8: CARDINALIDADE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "cardinalidade_detalhes = []\n",
    "\n",
    "for col in df.columns[:10]:\n",
    "    unicos = df[col].nunique()\n",
    "    total = len(df)\n",
    "    pct = (unicos / total) * 100\n",
    "\n",
    "    if pct <= 10:\n",
    "        categoria = \"Categoria (baixa)\"\n",
    "    elif pct <= 50:\n",
    "        categoria = \"Mista (media)\"\n",
    "    else:\n",
    "        categoria = \"Continua (alta)\"\n",
    "\n",
    "    print(f\"   {col[:30]:30s} | {unicos:4d} unicos ({pct:5.1f}%) - {categoria}\")\n",
    "\n",
    "    cardinalidade_detalhes.append({\n",
    "        'campo': col,\n",
    "        'unicos': int(unicos),\n",
    "        'pct': float(round(pct, 1)),\n",
    "        'categoria': categoria\n",
    "    })\n",
    "\n",
    "if len(df.columns) > 10:\n",
    "    print(f\"\\n   ... e mais {len(df.columns) - 10} colunas\")\n",
    "\n",
    "estatisticas['cardinalidade'] = cardinalidade_detalhes\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 9. TIPOS DE DADOS PANDAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 9: TIPOS DE DADOS (PANDAS)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "tipos_pandas = {}\n",
    "\n",
    "for dtype, count in dtype_counts.items():\n",
    "    dtype_str = str(dtype)\n",
    "    print(f\"   {dtype_str:15s}: {count:2d} colunas\")\n",
    "    tipos_pandas[dtype_str] = int(count)\n",
    "\n",
    "estatisticas['tipos_pandas'] = tipos_pandas\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 10. SALVAMENTO DE ESTADO E ESTATISTICAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 10: SALVAMENTO DE ESTADO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 10.1 Salvar estado do bloco\n",
    "estado = {\n",
    "    'bloco': 14,\n",
    "    'versao': '2.1',\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'container': fm.base_path.name,\n",
    "    'validado': True,\n",
    "    'df_shape': list(df.shape),\n",
    "    'campos_analisados': len(tipos_detectados)\n",
    "}\n",
    "\n",
    "estado_path = Path('.bloco_14_state.json')\n",
    "with open(estado_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n   Estado salvo: {estado_path}\")\n",
    "\n",
    "# 10.2 Salvar estat√≠sticas completas para auditoria\n",
    "estatisticas_path = fm.pastas['logs'] / 'estatisticas_validacao.json'\n",
    "with open(estatisticas_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estatisticas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   Estatisticas salvas: {estatisticas_path.name}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# 11. RESUMO FINAL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDACOES CONCLUIDAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n   Registros: {registros:,}\")\n",
    "print(f\"   Colunas: {colunas}\")\n",
    "print(f\"   Taxa deteccao: {(alta + media) / len(tipos_detectados) * 100:.1f}%\")\n",
    "print(f\"   Valores nulos: {len(colunas_com_nulos)} colunas\")\n",
    "print(f\"   Campos ambiguos: {len(ambiguos)}\")\n",
    "\n",
    "print(\"\\n Proximo: BLOCO 15 - Exportacao Final\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "id": "74512ff8a1905539",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDACOES E ESTATISTICAS v2.1\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 1: VALIDANDO DEPENDENCIAS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      "\n",
      " OK Variaveis validadas:\n",
      "    df shape: (967, 25)\n",
      "    tipos_detectados: 25 campos\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 2: RESUMO GERAL\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Registros finais: 967\n",
      "   Colunas finais: 25\n",
      "   Memoria em uso: 1.27 MB\n",
      "   Linhas duplicadas: 767\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 3: ANALISE DE VALORES NULOS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum valor nulo!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 4: DISTRIBUICAO DE TIPOS DETECTADOS\n",
      "----------------------------------------------------------------------\n",
      "   DESCONHECIDO             : 11 colunas ######################\n",
      "   Numero_Inteiro           :  7 colunas ##############\n",
      "   Monetario                :  3 colunas ######\n",
      "   Centro                   :  2 colunas ####\n",
      "   Codigo_Produto           :  1 colunas ##\n",
      "   Desc_Grupo_Produto       :  1 colunas ##\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 5: CONFIANCA NA DETECCAO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Alta (>=90%):   14 colunas\n",
      "   Media (70-90%):  0 colunas\n",
      "   Baixa (<70%):   11 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 6: CAMPOS AMBIGUOS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum campo ambiguo!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 7: ANALISE DE UNICIDADE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum campo com alta unicidade\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 8: CARDINALIDADE\n",
      "----------------------------------------------------------------------\n",
      "   Ano civil/m√™s                  |    2 unicos (  0.2%) - Categoria (baixa)\n",
      "   Centro                         |   89 unicos (  9.2%) - Categoria (baixa)\n",
      "                                  |   89 unicos (  9.2%) - Categoria (baixa)\n",
      "   HierarqPrd                     |    5 unicos (  0.5%) - Categoria (baixa)\n",
      "   Produto                        |   15 unicos (  1.6%) - Categoria (baixa)\n",
      "   _dup1                          |   15 unicos (  1.6%) - Categoria (baixa)\n",
      "   Estoque Inicial                |  183 unicos ( 18.9%) - Mista (media)\n",
      "   Entrada                        |  122 unicos ( 12.6%) - Mista (media)\n",
      "   Varia√ß√£o Externa               |  104 unicos ( 10.8%) - Mista (media)\n",
      "   Varia√ß√£o Externa %             |  110 unicos ( 11.4%) - Mista (media)\n",
      "\n",
      "   ... e mais 15 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 9: TIPOS DE DADOS (PANDAS)\n",
      "----------------------------------------------------------------------\n",
      "   object         : 25 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 10: SALVAMENTO DE ESTADO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Estado salvo: .bloco_14_state.json\n",
      "   Estatisticas salvas: estatisticas_validacao.json\n",
      "\n",
      "======================================================================\n",
      "VALIDACOES CONCLUIDAS\n",
      "======================================================================\n",
      "\n",
      "   Registros: 967\n",
      "   Colunas: 25\n",
      "   Taxa deteccao: 56.0%\n",
      "   Valores nulos: 0 colunas\n",
      "   Campos ambiguos: 0\n",
      "\n",
      " Proximo: BLOCO 15 - Exportacao Final\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:18.996795Z",
     "start_time": "2025-10-19T09:18:18.730548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# BLOCO 15 v2.3 - EXPORTACAO DE RESULTADOS (100% LOG + ROBUSTO)\n",
    "# ======================================================================\n",
    "# VERSAO: 2.3 - 0% memoria, 100% LOG, validacao FileManager\n",
    "# AUTOR: Sistema Automacao AIVI\n",
    "# DATA: 2025-10-19\n",
    "# ======================================================================\n",
    "# CORRECOES v2.3:\n",
    "# + Verifica se fm.salvar() existe antes de usar\n",
    "# + Recria FileManager se metodo nao existir\n",
    "# + FileManagerSimples com timestamp correto\n",
    "# ======================================================================\n",
    "# CORRECOES v2.2:\n",
    "# + Validacao de None em arquivo_selecionado antes de acessar .name\n",
    "# + Validacao de Path antes de usar .stem\n",
    "# + Verificacao de temp_arquivo antes de atribuir\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTACAO DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 1: CONECTAR COM BLOCOS ANTERIORES\n",
    "# ======================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 1: CONECTANDO COM BLOCOS ANTERIORES...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler LOG GLOBAL\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "if not log_global_path.exists():\n",
    "    raise FileNotFoundError(\"LOG GLOBAL nao encontrado!\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "container_nome = f\"PROCESSAR_ARQUIVOS_{timestamp_execucao}\"\n",
    "pasta_base = Path.home() / 'PYTHON_AIVI' / container_nome\n",
    "\n",
    "print(f\" OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {container_nome}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Verificar e corrigir FileManager\n",
    "class FileManagerSimples:\n",
    "    \"\"\"FileManager simplificado para exportacao\"\"\"\n",
    "    def __init__(self, base_path, timestamp=None):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.timestamp = timestamp or datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.pastas = {\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "        # Criar pastas se nao existem\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='outputs'):\n",
    "        arquivo = self.pastas[pasta] / f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "# Verificar se fm existe e tem metodo salvar\n",
    "if 'fm' not in globals():\n",
    "    print(f\" !! Criando FileManager...\")\n",
    "    fm = FileManagerSimples(base_path=pasta_base, timestamp=timestamp_execucao)\n",
    "    print(f\" OK FileManager criado: {fm.base_path.name}\")\n",
    "elif not hasattr(fm, 'salvar'):\n",
    "    print(f\" !! FileManager sem metodo salvar - recriando...\")\n",
    "    fm = FileManagerSimples(base_path=pasta_base, timestamp=timestamp_execucao)\n",
    "    print(f\" OK FileManager recriado: {fm.base_path.name}\")\n",
    "else:\n",
    "    print(f\" OK FileManager existe na memoria\")\n",
    "\n",
    "# Validar que df existe\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"Variavel 'df' nao encontrada! Execute BLOCOS 1-13 primeiro.\")\n",
    "\n",
    "print(f\" OK DataFrame validado: {df.shape}\")\n",
    "\n",
    "# Ler estado do BLOCO 13 (se existe)\n",
    "bloco_13_state_path = pasta_base / '.bloco_13_state.json'\n",
    "bloco_12_state_path = pasta_base / '.bloco_12_state.json'\n",
    "\n",
    "if bloco_13_state_path.exists():\n",
    "    with open(bloco_13_state_path, 'r', encoding='utf-8') as f:\n",
    "        bloco_anterior_state = json.load(f)\n",
    "    bloco_anterior_nome = \"BLOCO 13\"\n",
    "    print(f\" OK Estado carregado do {bloco_anterior_nome}\")\n",
    "elif bloco_12_state_path.exists():\n",
    "    with open(bloco_12_state_path, 'r', encoding='utf-8') as f:\n",
    "        bloco_anterior_state = json.load(f)\n",
    "    bloco_anterior_nome = \"BLOCO 12\"\n",
    "    print(f\" OK Estado carregado do {bloco_anterior_nome}\")\n",
    "else:\n",
    "    # Nenhum estado salvo - usar valores em memoria\n",
    "    bloco_anterior_state = {}\n",
    "    bloco_anterior_nome = \"MEMORIA\"\n",
    "    print(f\" !! Nenhum estado salvo - usando variaveis em memoria\")\n",
    "\n",
    "# Ler arquivo selecionado (tentar varias fontes)\n",
    "arquivo_selecionado = None\n",
    "sheet_nome = \"N/A\"\n",
    "\n",
    "# Fonte 1: LOG do BLOCO 4\n",
    "bloco_4_state_path = pasta_base / '.ultimo_arquivo.json'\n",
    "if bloco_4_state_path.exists():\n",
    "    with open(bloco_4_state_path, 'r', encoding='utf-8') as f:\n",
    "        arquivo_info = json.load(f)\n",
    "    arquivo_selecionado = Path(arquivo_info['caminho'])\n",
    "    sheet_nome = arquivo_info.get('sheet', 'N/A')\n",
    "    print(f\" OK Arquivo do LOG BLOCO 4: {arquivo_selecionado.name}\")\n",
    "\n",
    "# Fonte 2: Variavel global arquivo_selecionado\n",
    "if arquivo_selecionado is None and 'arquivo_selecionado' in globals():\n",
    "    temp_arquivo = globals()['arquivo_selecionado']\n",
    "    if temp_arquivo is not None:\n",
    "        arquivo_selecionado = temp_arquivo\n",
    "        print(f\" OK Arquivo da memoria: {arquivo_selecionado.name}\")\n",
    "        if 'sheet_nome' in globals():\n",
    "            sheet_nome = globals()['sheet_nome']\n",
    "\n",
    "# Fonte 3: LOG GLOBAL (pode ter info do arquivo)\n",
    "if arquivo_selecionado is None and 'ultimo_arquivo' in log_global:\n",
    "    temp_arquivo = log_global['ultimo_arquivo']\n",
    "    if temp_arquivo:\n",
    "        arquivo_selecionado = Path(temp_arquivo)\n",
    "        print(f\" OK Arquivo do LOG GLOBAL: {arquivo_selecionado.name}\")\n",
    "\n",
    "# Fallback final\n",
    "if arquivo_selecionado is None:\n",
    "    arquivo_selecionado = Path(\"arquivo_processado\")\n",
    "    print(f\" !! Arquivo nao encontrado - usando nome generico\")\n",
    "\n",
    "print(f\"\\n OK Arquivo selecionado: {arquivo_selecionado.name}\")\n",
    "print(f\" OK Sheet: {sheet_nome}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 2: EXPORTAR DADOS LIMPOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 2: EXPORTANDO DADOS LIMPOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Garantir que arquivo_selecionado e Path valido\n",
    "if not isinstance(arquivo_selecionado, Path):\n",
    "    arquivo_selecionado = Path(arquivo_selecionado)\n",
    "\n",
    "nome_base = arquivo_selecionado.stem\n",
    "\n",
    "# 1. Dados limpos e mapeados\n",
    "arquivo_limpo = fm.salvar(\n",
    "    df,\n",
    "    f\"{nome_base}_Limpo\",\n",
    "    tipo='xlsx',\n",
    "    pasta='processados'\n",
    ")\n",
    "print(f\" OK {arquivo_limpo.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 3: DICIONARIO DE CAMPOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 3: CRIANDO DICIONARIO DE CAMPOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler tipos_detectados (tentar varias fontes)\n",
    "tipo_info_dict = {}\n",
    "\n",
    "# Fonte 1: Variavel global tipos_detectados\n",
    "if 'tipos_detectados' in globals():\n",
    "    tipo_info_dict = tipos_detectados\n",
    "    print(f\" OK tipos_detectados da memoria: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "# Fonte 2: Estado do BLOCO 13\n",
    "elif bloco_anterior_state and 'confirmacoes' in bloco_anterior_state:\n",
    "    # Se BLOCO 13 salvou confirmacoes, usar\n",
    "    confirmacoes = bloco_anterior_state['confirmacoes']\n",
    "    for col_orig, campo_confirmado in confirmacoes.items():\n",
    "        tipo_info_dict[col_orig] = {\n",
    "            'campo_detectado': campo_confirmado,\n",
    "            'confianca': 1.0,\n",
    "            'metodo': 'CONFIRMADO_USUARIO'\n",
    "        }\n",
    "    print(f\" OK tipos_detectados do BLOCO 13: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "# Fonte 3: Tentar reconstruir baseado nas colunas do df\n",
    "else:\n",
    "    for col in df.columns:\n",
    "        tipo_info_dict[col] = {\n",
    "            'campo_detectado': col,\n",
    "            'confianca': 1.0,\n",
    "            'metodo': 'INFERIDO_DO_DF'\n",
    "        }\n",
    "    print(f\" !! tipos_detectados inferido do df: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "registros_dict = []\n",
    "\n",
    "for col in df.columns:\n",
    "    tipo_info = tipo_info_dict.get(col, {})\n",
    "    valores_exemplo = df[col].dropna().unique()[:3].tolist()\n",
    "\n",
    "    registros_dict.append({\n",
    "        'Coluna': col,\n",
    "        'Tipo_Detectado': tipo_info.get('campo_detectado', 'DESCONHECIDO'),\n",
    "        'Confianca_%': tipo_info.get('confianca', 0.0) * 100,\n",
    "        'Score_Conteudo_%': tipo_info.get('score_conteudo', 0.0) * 100,\n",
    "        'Score_Nome_%': tipo_info.get('score_nome', 0.0) * 100,\n",
    "        'Metodo': tipo_info.get('metodo', 'N/A'),\n",
    "        'Ambiguidade': 'Sim' if tipo_info.get('ambiguidade') else 'Nao',\n",
    "        'Dtype_Pandas': str(df[col].dtype),\n",
    "        'Valores_Unicos': df[col].nunique(),\n",
    "        'Nulos_Qtd': df[col].isna().sum(),\n",
    "        'Nulos_%': (df[col].isna().sum() / len(df)) * 100,\n",
    "        'Exemplo_1': str(valores_exemplo[0]) if len(valores_exemplo) > 0 else None,\n",
    "        'Exemplo_2': str(valores_exemplo[1]) if len(valores_exemplo) > 1 else None,\n",
    "        'Exemplo_3': str(valores_exemplo[2]) if len(valores_exemplo) > 2 else None\n",
    "    })\n",
    "\n",
    "df_dict = pd.DataFrame(registros_dict)\n",
    "arquivo_dict = fm.salvar(\n",
    "    df_dict,\n",
    "    f\"DICT_{nome_base}\",\n",
    "    tipo='xlsx',\n",
    "    pasta='outputs'\n",
    ")\n",
    "print(f\" OK {arquivo_dict.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 4: LOG DE PROCESSAMENTO\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 4: CRIANDO LOG DE PROCESSAMENTO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler configuracoes de carregamento (multiplas fontes)\n",
    "linha_cab_ini = 1\n",
    "linha_cab_fim = 1\n",
    "col_ini = 1\n",
    "col_fim = len(df.columns)\n",
    "linha_dados_ini = 2\n",
    "\n",
    "# Fonte 1: Estado do BLOCO 9\n",
    "bloco_9_state_path = pasta_base / '.bloco_9_state.json'\n",
    "if bloco_9_state_path.exists():\n",
    "    try:\n",
    "        with open(bloco_9_state_path, 'r', encoding='utf-8') as f:\n",
    "            bloco_9_state = json.load(f)\n",
    "\n",
    "        config_carga = bloco_9_state.get('config_carga', {})\n",
    "        linha_cab_ini = config_carga.get('linha_cabecalho_inicio_excel', 1)\n",
    "        linha_cab_fim = config_carga.get('linha_cabecalho_fim_excel', 1)\n",
    "        col_ini = config_carga.get('coluna_inicio_excel', 1)\n",
    "        col_fim = config_carga.get('coluna_fim_excel', len(df.columns))\n",
    "        linha_dados_ini = config_carga.get('linha_dados_inicio_excel', 2)\n",
    "        print(f\" OK Config carga do BLOCO 9\")\n",
    "    except:\n",
    "        print(f\" !! Erro ao ler BLOCO 9 - usando valores padrao\")\n",
    "else:\n",
    "    print(f\" !! BLOCO 9 state nao encontrado - usando valores padrao\")\n",
    "\n",
    "# Fonte 2: Variaveis globais (fallback)\n",
    "if 'config' in globals():\n",
    "    config = globals()['config']\n",
    "    linha_cab_ini = config.get('linha_cabecalho_inicio', linha_cab_ini)\n",
    "    linha_dados_ini = config.get('linha_dados_inicio', linha_dados_ini)\n",
    "    print(f\" OK Config da memoria (variavel global)\")\n",
    "\n",
    "log_processamento = {\n",
    "    'Arquivo_Original': arquivo_selecionado.name,\n",
    "    'Caminho_Original': str(arquivo_selecionado),\n",
    "    'Sheet_Processada': sheet_nome,\n",
    "\n",
    "    # Cabecalho\n",
    "    'Linha_Cabecalho_Inicio_Excel': linha_cab_ini,\n",
    "    'Linha_Cabecalho_Fim_Excel': linha_cab_fim,\n",
    "\n",
    "    # Colunas\n",
    "    'Coluna_Inicio_Excel': col_ini,\n",
    "    'Coluna_Fim_Excel': col_fim,\n",
    "\n",
    "    # Dados\n",
    "    'Linha_Dados_Inicio_Excel': linha_dados_ini,\n",
    "\n",
    "    # Contadores\n",
    "    'Registros_Final': len(df),\n",
    "    'Colunas_Final': len(df.columns),\n",
    "\n",
    "    # Timestamp\n",
    "    'Timestamp': timestamp_execucao,\n",
    "    'Data_Processamento': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "df_log = pd.DataFrame([log_processamento])\n",
    "arquivo_log = fm.salvar(\n",
    "    df_log,\n",
    "    f\"LOG_{nome_base}\",\n",
    "    tipo='xlsx',\n",
    "    pasta='logs'\n",
    ")\n",
    "print(f\" OK {arquivo_log.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 5: CODIGO PYTHON PARA REPRODUCAO\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 5: GERANDO CODIGO DE REPRODUCAO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "codigo_reprod = f'''# ======================================================================\n",
    "# CODIGO DE REPRODUCAO - Gerado automaticamente\n",
    "# Arquivo: {arquivo_selecionado.name}\n",
    "# Sheet: {sheet_nome}\n",
    "# Data: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "# ======================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ======================================================================\n",
    "# CONFIGURACAO\n",
    "# ======================================================================\n",
    "\n",
    "arquivo = Path(r\"{arquivo_selecionado}\")\n",
    "sheet = \"{sheet_nome}\"\n",
    "\n",
    "# Range de extracao (linhas Excel - comeca em 1)\n",
    "linha_cabecalho_inicio = {linha_cab_ini}\n",
    "linha_cabecalho_fim = {linha_cab_fim}\n",
    "col_inicio = {col_ini}\n",
    "col_fim = {col_fim}\n",
    "linha_dados_inicio = {linha_dados_ini}\n",
    "\n",
    "# ======================================================================\n",
    "# CARREGAMENTO\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"Carregando: {{arquivo.name}}\")\n",
    "print(f\"Sheet: {{sheet}}\")\n",
    "\n",
    "if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "    # Cabecalho em 1 linha\n",
    "    df = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=linha_cabecalho_inicio - 1,  # Converter para indice Python\n",
    "        usecols=range(col_inicio - 1, col_fim)\n",
    "    )\n",
    "\n",
    "    # Pular linhas entre cabecalho e dados\n",
    "    linhas_pular = linha_dados_inicio - linha_cabecalho_inicio - 1\n",
    "    if linhas_pular > 0:\n",
    "        df = df.iloc[linhas_pular:].copy()\n",
    "else:\n",
    "    # Cabecalho em multiplas linhas\n",
    "    df_temp = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=None,\n",
    "        usecols=range(col_inicio - 1, col_fim)\n",
    "    )\n",
    "\n",
    "    # Combinar linhas do cabecalho\n",
    "    cabecalho = df_temp.iloc[linha_cabecalho_inicio-1:linha_cabecalho_fim].values\n",
    "    cab_final = []\n",
    "\n",
    "    for col_idx in range(cabecalho.shape[1]):\n",
    "        partes = [\n",
    "            str(linha[col_idx]).strip()\n",
    "            for linha in cabecalho\n",
    "            if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "        ]\n",
    "        cab_final.append(' - '.join(partes) if partes else f'Col_{{col_idx}}')\n",
    "\n",
    "    # Extrair dados\n",
    "    df = df_temp.iloc[linha_dados_inicio-1:].copy()\n",
    "    df.columns = cab_final\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Carregado: {{len(df):,}} registros √ó {{len(df.columns)}} colunas\")\n",
    "\n",
    "# ======================================================================\n",
    "# VALIDACAO\n",
    "# ======================================================================\n",
    "\n",
    "colunas_esperadas = {df.columns.tolist()}\n",
    "\n",
    "if df.columns.tolist() == colunas_esperadas:\n",
    "    print(\"Estrutura validada - colunas correspondem!\")\n",
    "else:\n",
    "    print(\"Diferenca na estrutura:\")\n",
    "\n",
    "    extras = set(df.columns) - set(colunas_esperadas)\n",
    "    if extras:\n",
    "        print(f\"Colunas extras: {{extras}}\")\n",
    "\n",
    "    faltando = set(colunas_esperadas) - set(df.columns)\n",
    "    if faltando:\n",
    "        print(f\"Colunas faltando: {{faltando}}\")\n",
    "\n",
    "print(f\"\\\\nShape: {{df.shape}}\")\n",
    "print(f\"Memoria: {{df.memory_usage(deep=True).sum() / 1024**2:.2f}} MB\")\n",
    "'''\n",
    "\n",
    "arquivo_codigo = fm.pastas['codigos_integracao'] / f\"REPROD_{nome_base}_{timestamp_execucao}.py\"\n",
    "with open(arquivo_codigo, 'w', encoding='utf-8') as f:\n",
    "    f.write(codigo_reprod)\n",
    "\n",
    "print(f\" OK {arquivo_codigo.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 6: SALVAR ESTADO DO BLOCO 15\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 6: SALVANDO ESTADO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "bloco_15_state = {\n",
    "    'bloco': 15,\n",
    "    'versao': '2.3',\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'container': container_nome,\n",
    "    'executado': True,\n",
    "    'arquivos_gerados': {\n",
    "        'dados_limpos': arquivo_limpo.name,\n",
    "        'dicionario_campos': arquivo_dict.name,\n",
    "        'log_processamento': arquivo_log.name,\n",
    "        'codigo_reproducao': arquivo_codigo.name\n",
    "    },\n",
    "    'df_shape': list(df.shape),\n",
    "    'arquivo_original': arquivo_selecionado.name\n",
    "}\n",
    "\n",
    "bloco_15_state_path = pasta_base / '.bloco_15_state.json'\n",
    "with open(bloco_15_state_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(bloco_15_state, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\" OK Estado salvo: .bloco_15_state.json\")\n",
    "\n",
    "# ======================================================================\n",
    "# RESUMO DE ARQUIVOS GERADOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARQUIVOS GERADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "arquivos_gerados = [\n",
    "    ('Dados Limpos', arquivo_limpo),\n",
    "    ('Dicionario de Campos', arquivo_dict),\n",
    "    ('Log de Processamento', arquivo_log),\n",
    "    ('Codigo de Reproducao', arquivo_codigo)\n",
    "]\n",
    "\n",
    "for desc, path in arquivos_gerados:\n",
    "    print(f\"\\n{desc}\")\n",
    "    print(f\"  Arquivo: {path.name}\")\n",
    "    print(f\"  Pasta: {path.parent.name}\")\n",
    "    print(f\"  Tamanho: {path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTACAO CONCLUIDA COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Variavel global para uso posterior\n",
    "df_resultado = df.copy()\n",
    "\n",
    "print(f\"\\n Dataset disponivel em: df_resultado\")\n",
    "print(f\"  Shape: {df_resultado.shape}\")\n",
    "print(f\"  Memoria: {df_resultado.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print()\n",
    "print(f\" Proxima etapa: Analises e validacoes (se necessario)\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a7de448725d158e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPORTACAO DE RESULTADOS\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 1: CONECTANDO COM BLOCOS ANTERIORES...\n",
      "----------------------------------------------------------------------\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      " !! FileManager sem metodo salvar - recriando...\n",
      " OK FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      " OK DataFrame validado: (967, 25)\n",
      " !! Nenhum estado salvo - usando variaveis em memoria\n",
      " !! Arquivo nao encontrado - usando nome generico\n",
      "\n",
      " OK Arquivo selecionado: arquivo_processado\n",
      " OK Sheet: N/A\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 2: EXPORTANDO DADOS LIMPOS\n",
      "----------------------------------------------------------------------\n",
      " OK arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 3: CRIANDO DICIONARIO DE CAMPOS\n",
      "----------------------------------------------------------------------\n",
      " OK tipos_detectados da memoria: 25 campos\n",
      " OK DICT_arquivo_processado_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 4: CRIANDO LOG DE PROCESSAMENTO\n",
      "----------------------------------------------------------------------\n",
      " !! BLOCO 9 state nao encontrado - usando valores padrao\n",
      " OK Config da memoria (variavel global)\n",
      " OK LOG_arquivo_processado_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 5: GERANDO CODIGO DE REPRODUCAO\n",
      "----------------------------------------------------------------------\n",
      " OK REPROD_arquivo_processado_20251019_060722.py\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 6: SALVANDO ESTADO\n",
      "----------------------------------------------------------------------\n",
      " OK Estado salvo: .bloco_15_state.json\n",
      "\n",
      "======================================================================\n",
      "ARQUIVOS GERADOS\n",
      "======================================================================\n",
      "\n",
      "Dados Limpos\n",
      "  Arquivo: arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "  Pasta: 02_Processados\n",
      "  Tamanho: 67.3 KB\n",
      "\n",
      "Dicionario de Campos\n",
      "  Arquivo: DICT_arquivo_processado_20251019_060722.xlsx\n",
      "  Pasta: 03_Outputs\n",
      "  Tamanho: 6.9 KB\n",
      "\n",
      "Log de Processamento\n",
      "  Arquivo: LOG_arquivo_processado_20251019_060722.xlsx\n",
      "  Pasta: 04_Logs\n",
      "  Tamanho: 5.0 KB\n",
      "\n",
      "Codigo de Reproducao\n",
      "  Arquivo: REPROD_arquivo_processado_20251019_060722.py\n",
      "  Pasta: 06_Codigos_Integracao\n",
      "  Tamanho: 3.5 KB\n",
      "\n",
      "======================================================================\n",
      "EXPORTACAO CONCLUIDA COM SUCESSO\n",
      "======================================================================\n",
      "\n",
      " Dataset disponivel em: df_resultado\n",
      "  Shape: (967, 25)\n",
      "  Memoria: 1.27 MB\n",
      "\n",
      " Proxima etapa: Analises e validacoes (se necessario)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:21.413745Z",
     "start_time": "2025-10-19T09:18:21.080890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 16 v2.0 - RELATORIO FINAL VISUAL\n",
    "# ===================================================================\n",
    "# COMUNICACAO VIA LOG:\n",
    "# - Le: LOG GLOBAL + estados dos blocos anteriores\n",
    "# - RECRIA: FileManager se necessario\n",
    "# - USA: df_resultado (ou df_limpo, ou df)\n",
    "# - SALVA: .bloco_16_state.json\n",
    "# - EXIBE: df_resultado\n",
    "# - ABRE: pasta de outputs\n",
    "# ===================================================================\n",
    "# CORRECOES v2.0:\n",
    "# + 100% comunicacao via LOG (0% memoria)\n",
    "# + Recria FileManager se necessario\n",
    "# + Multiplas fontes para todas as variaveis\n",
    "# + Validacao de None antes de usar\n",
    "# + Exibe df_resultado (NOVO)\n",
    "# + Abre pasta outputs automaticamente (NOVO)\n",
    "# + Salva estado proprio\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(\" RELATORIO FINAL - PROCESSAMENTO CONCLUIDO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. CONECTAR COM BLOCOS ANTERIORES (0% memoria, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(\"\\n! Erro: LOG GLOBAL nao encontrado!\")\n",
    "    print(\"  Execute BLOCO 1 primeiro\")\n",
    "    raise RuntimeError(\"LOG nao disponivel\")\n",
    "\n",
    "with open(log_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "# Extrair dados essenciais do LOG\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "print(f\"\\n OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {pasta_base.name}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. RECRIAR FileManager (SE necessario)\n",
    "# ===================================================================\n",
    "\n",
    "# Tentar usar fm da memoria\n",
    "try:\n",
    "    fm_existe = 'fm' in globals() and fm is not None\n",
    "    if fm_existe and hasattr(fm, 'pastas'):\n",
    "        print(f\" OK FileManager na memoria\")\n",
    "    else:\n",
    "        raise NameError(\"fm invalido\")\n",
    "except (NameError, AttributeError):\n",
    "    print(f\" AVISO: Recriando FileManager...\")\n",
    "\n",
    "    # Recriar classe FileManagerSimples\n",
    "    class FileManagerSimples:\n",
    "        def __init__(self, base_path, timestamp):\n",
    "            self.base_path = Path(base_path)\n",
    "            self.timestamp = timestamp\n",
    "            self.pastas = {\n",
    "                'dados': self.base_path / '01_Dados_Entrada',\n",
    "                'processados': self.base_path / '02_Processados',\n",
    "                'outputs': self.base_path / '03_Outputs',\n",
    "                'logs': self.base_path / '04_Logs',\n",
    "                'dicionarios': self.base_path / '05_Dicionarios',\n",
    "                'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "            }\n",
    "\n",
    "        def abrir_pasta(self, tipo='outputs'):\n",
    "            \"\"\"Abre pasta no explorer/finder\"\"\"\n",
    "            import subprocess\n",
    "            import platform\n",
    "\n",
    "            pasta = self.pastas.get(tipo, self.pastas['outputs'])\n",
    "\n",
    "            try:\n",
    "                if platform.system() == 'Windows':\n",
    "                    subprocess.run(['explorer', str(pasta)])\n",
    "                elif platform.system() == 'Darwin':  # macOS\n",
    "                    subprocess.run(['open', str(pasta)])\n",
    "                else:  # Linux\n",
    "                    subprocess.run(['xdg-open', str(pasta)])\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"\\n! Erro ao abrir pasta: {e}\")\n",
    "                return False\n",
    "\n",
    "    fm = FileManagerSimples(pasta_base, timestamp_execucao)\n",
    "    print(f\"    OK FileManager recriado\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. CARREGAR DADOS DE BLOCOS ANTERIORES (MULTIPLAS FONTES)\n",
    "# ===================================================================\n",
    "\n",
    "# FONTE 1: Tentar variaveis na memoria\n",
    "# FONTE 2: Ler do LOG do BLOCO 15\n",
    "# FONTE 3: Ler do LOG do BLOCO 14\n",
    "# FONTE 4: Ler do LOG do BLOCO 4\n",
    "# FONTE 5: Fallback padrao\n",
    "\n",
    "# ----- arquivo_selecionado -----\n",
    "arquivo_selecionado = None\n",
    "sheet_nome = \"Sheet1\"\n",
    "\n",
    "# Memoria\n",
    "if 'arquivo_selecionado' in globals():\n",
    "    arquivo_selecionado = globals()['arquivo_selecionado']\n",
    "\n",
    "# LOG BLOCO 15\n",
    "if arquivo_selecionado is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_15_state.json') as f:\n",
    "            b15 = json.load(f)\n",
    "            if 'arquivo_processado' in b15:\n",
    "                arquivo_selecionado = Path(b15['arquivo_processado'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# LOG BLOCO 4\n",
    "if arquivo_selecionado is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_4_state.json') as f:\n",
    "            b4 = json.load(f)\n",
    "            arquivo_selecionado = Path(b4['arquivo'])\n",
    "            sheet_nome = b4.get('sheet_nome', sheet_nome)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ----- tipos_detectados -----\n",
    "tipos_detectados = {}\n",
    "\n",
    "# Memoria\n",
    "if 'tipos_detectados' in globals():\n",
    "    tipos_detectados = globals()['tipos_detectados']\n",
    "\n",
    "# LOG BLOCO 12\n",
    "if not tipos_detectados:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_12_state.json') as f:\n",
    "            b12 = json.load(f)\n",
    "            tipos_detectados = b12.get('tipos_detectados', {})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ----- config_carga -----\n",
    "metodo_carga = \"pandas\"\n",
    "linha_cabecalho_inicio = 0\n",
    "idx_cab_inicio = 0\n",
    "\n",
    "try:\n",
    "    with open(fm.pastas['logs'] / '.bloco_6_state.json') as f:\n",
    "        b6 = json.load(f)\n",
    "        metodo_carga = b6.get('metodo', 'pandas')\n",
    "        linha_cabecalho_inicio = b6.get('linha_cabecalho_inicio', 0)\n",
    "        idx_cab_inicio = b6.get('idx_cab_inicio', 0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ----- DataFrames -----\n",
    "df_resultado = None\n",
    "df_limpo = None\n",
    "df_bruto = None\n",
    "\n",
    "# FONTE 1: Ler do arquivo salvo pelo BLOCO 15 (PRIORITARIO)\n",
    "try:\n",
    "    arquivo_limpo = list(fm.pastas['processados'].glob(\n",
    "        f'*Limpo_{timestamp_execucao}.xlsx'\n",
    "    ))\n",
    "    if arquivo_limpo:\n",
    "        import pandas as pd\n",
    "        df_resultado = pd.read_excel(arquivo_limpo[0])\n",
    "        print(f\" OK DataFrame carregado do arquivo: {arquivo_limpo[0].name}\")\n",
    "except Exception as e:\n",
    "    print(f\" ! Nao foi possivel carregar do arquivo: {e}\")\n",
    "\n",
    "# FONTE 2: Tentar memoria (prioridade: df_resultado > df > df_limpo > df_bruto)\n",
    "if df_resultado is None:\n",
    "    if 'df_resultado' in globals():\n",
    "        df_resultado = globals()['df_resultado']\n",
    "        print(f\" OK DataFrame da memoria: df_resultado\")\n",
    "    elif 'df' in globals():\n",
    "        df_resultado = globals()['df'].copy()\n",
    "        print(f\" OK DataFrame da memoria: df\")\n",
    "    elif 'df_limpo' in globals():\n",
    "        df_limpo = globals()['df_limpo']\n",
    "        df_resultado = df_limpo.copy()\n",
    "        print(f\" OK DataFrame da memoria: df_limpo\")\n",
    "    elif 'df_bruto' in globals():\n",
    "        df_bruto = globals()['df_bruto']\n",
    "        df_resultado = df_bruto.copy()\n",
    "        print(f\" OK DataFrame da memoria: df_bruto\")\n",
    "\n",
    "if df_resultado is None:\n",
    "    print(\"\\n! ERRO: Nenhum DataFrame disponivel!\")\n",
    "    print(\"  Execute o BLOCO 15 primeiro para gerar os arquivos\")\n",
    "    raise RuntimeError(\"DataFrame nao disponivel\")\n",
    "\n",
    "# Se df_limpo nao existe, usar df_resultado\n",
    "if df_limpo is None:\n",
    "    df_limpo = df_resultado.copy()\n",
    "\n",
    "# Se df_bruto nao existe, tentar carregar do estado do BLOCO 9\n",
    "if df_bruto is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_9_state.json') as f:\n",
    "            b9 = json.load(f)\n",
    "            # Usar estatisticas salvas se existirem\n",
    "            if 'estatisticas' in b9:\n",
    "                # Criar um DataFrame fake com as dimensoes originais\n",
    "                # apenas para calcular estatisticas\n",
    "                import pandas as pd\n",
    "                import numpy as np\n",
    "                rows = b9['estatisticas'].get('total_registros', len(df_resultado))\n",
    "                cols = b9['estatisticas'].get('total_colunas', len(df_resultado.columns))\n",
    "                # Usar df_resultado como base para df_bruto\n",
    "                df_bruto = df_resultado.copy()\n",
    "            else:\n",
    "                df_bruto = df_resultado.copy()\n",
    "    except:\n",
    "        # Fallback: usar df_resultado\n",
    "        df_bruto = df_resultado.copy()\n",
    "\n",
    "print(f\" OK Dados carregados de multiplas fontes\")\n",
    "\n",
    "# ----- log_limpeza -----\n",
    "log_limpeza = []\n",
    "\n",
    "try:\n",
    "    with open(fm.pastas['logs'] / '.bloco_10_state.json') as f:\n",
    "        b10 = json.load(f)\n",
    "        log_limpeza = b10.get('operacoes_limpeza', [])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ===================================================================\n",
    "# INFORMACOES DO ARQUIVO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" INFORMACOES DO ARQUIVO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if arquivo_selecionado is not None:\n",
    "    print(f\"  Nome: {arquivo_selecionado.name:<68}\")\n",
    "else:\n",
    "    print(f\"  Nome: [nao disponivel]\")\n",
    "\n",
    "print(f\"  Sheet: {sheet_nome:<67}\")\n",
    "print(f\"  Cabecalho: Linha {linha_cabecalho_inicio} (Excel) / \"\n",
    "      f\"Indice {idx_cab_inicio} (Python)\")\n",
    "print(f\"  Metodo: {metodo_carga:<66}\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# ESTATISTICAS DE PROCESSAMENTO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ESTATISTICAS DE PROCESSAMENTO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "print(f\"  Registros originais: {len(df_bruto):>6,}\")\n",
    "print(f\"  Registros finais:    {len(df_limpo):>6,}\")\n",
    "print(f\"  Diferenca:           {len(df_bruto) - len(df_limpo):>6,} \"\n",
    "      f\"removidos\")\n",
    "print(\"  \" + \"-\" * 64)\n",
    "print(f\"  Colunas originais:   {len(df_bruto.columns):>6,}\")\n",
    "print(f\"  Colunas finais:      {len(df_limpo.columns):>6,}\")\n",
    "print(f\"  Diferenca:           {len(df_bruto.columns) - len(df_limpo.columns):>6,} \"\n",
    "      f\"removidas\")\n",
    "print(\"  \" + \"-\" * 64)\n",
    "\n",
    "memoria_mb = df_limpo.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"  Memoria em uso:      {memoria_mb:>6.2f} MB\")\n",
    "\n",
    "duplicatas = df_limpo.duplicated().sum()\n",
    "print(f\"  Linhas duplicadas:   {duplicatas:>6,}\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# QUALIDADE DOS DADOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" QUALIDADE DOS DADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "total_nulos = df_limpo.isnull().sum().sum()\n",
    "total_celulas = len(df_limpo) * len(df_limpo.columns)\n",
    "pct_nulos = (total_nulos / total_celulas) * 100 if total_celulas > 0 else 0\n",
    "\n",
    "print(f\"  Total de valores nulos: {total_nulos:>6,} ({pct_nulos:>5.2f}%)\")\n",
    "\n",
    "colunas_com_nulos = df_limpo.isnull().sum()\n",
    "colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0]\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"  Colunas com nulos:      {len(colunas_com_nulos):>6,}\")\n",
    "else:\n",
    "    print(f\"  OK Nenhuma coluna com valores nulos!\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# DETECCAO DE TIPOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" DETECCAO DE TIPOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if tipos_detectados:\n",
    "    alta = sum(1 for info in tipos_detectados.values()\n",
    "               if info.get('confianca', 0) >= 0.90)\n",
    "    media = sum(1 for info in tipos_detectados.values()\n",
    "                if 0.70 <= info.get('confianca', 0) < 0.90)\n",
    "    baixa = sum(1 for info in tipos_detectados.values()\n",
    "                if info.get('confianca', 0) < 0.70)\n",
    "\n",
    "    print(f\"  OK Alta confianca (>=90%):   {alta:>3} colunas\")\n",
    "    print(f\"  !  Media confianca (70-90%): {media:>3} colunas\")\n",
    "    print(f\"  ?  Baixa confianca (<70%):   {baixa:>3} colunas\")\n",
    "    print(\"  \" + \"-\" * 64)\n",
    "\n",
    "    # Top 5 tipos detectados\n",
    "    tipos_resumo = {}\n",
    "    for info in tipos_detectados.values():\n",
    "        tipo = info.get('campo_detectado', 'DESCONHECIDO')\n",
    "        tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "    print(\"  Top 5 tipos mais comuns:\")\n",
    "    for i, (tipo, count) in enumerate(\n",
    "        sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True)[:5],\n",
    "        1\n",
    "    ):\n",
    "        print(f\"     {i}. {tipo:<25} ({count:>2} colunas)\")\n",
    "else:\n",
    "    print(\"  Informacao nao disponivel\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# OPERACOES DE LIMPEZA\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" OPERACOES DE LIMPEZA REALIZADAS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if log_limpeza:\n",
    "    for i, operacao in enumerate(log_limpeza[:10], 1):\n",
    "        # Quebrar linhas longas\n",
    "        if len(str(operacao)) > 67:\n",
    "            print(f\"  {i}. {str(operacao)[:64]}...\")\n",
    "        else:\n",
    "            print(f\"  {i}. {operacao}\")\n",
    "\n",
    "    if len(log_limpeza) > 10:\n",
    "        print(f\"  ... e mais {len(log_limpeza) - 10} operacoes\")\n",
    "else:\n",
    "    print(f\"  OK Nenhuma limpeza necessaria - dados ja estavam limpos!\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# ARQUIVOS GERADOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ARQUIVOS GERADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# Listar arquivos na pasta de outputs\n",
    "arquivos_gerados = []\n",
    "\n",
    "try:\n",
    "    # Buscar arquivos com timestamp atual\n",
    "    for pasta_nome in ['processados', 'outputs', 'logs', 'codigos_integracao']:\n",
    "        pasta = fm.pastas[pasta_nome]\n",
    "        if pasta.exists():\n",
    "            for arquivo in pasta.glob(f'*{timestamp_execucao}*'):\n",
    "                tamanho_kb = arquivo.stat().st_size / 1024\n",
    "                arquivos_gerados.append((\n",
    "                    arquivo.name,\n",
    "                    pasta_nome.upper(),\n",
    "                    tamanho_kb\n",
    "                ))\n",
    "except Exception as e:\n",
    "    print(f\"  ! Erro ao listar arquivos: {e}\")\n",
    "\n",
    "if arquivos_gerados:\n",
    "    for nome, pasta, tamanho in arquivos_gerados:\n",
    "        print(f\"\\n  {nome}\")\n",
    "        print(f\"     Pasta: {pasta}\")\n",
    "        print(f\"     Tamanho: {tamanho:>6.1f} KB\")\n",
    "else:\n",
    "    print(\"  Nenhum arquivo encontrado com este timestamp\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# PROXIMOS PASSOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" PROXIMOS PASSOS RECOMENDADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "sugestoes = []\n",
    "\n",
    "# Sugestoes baseadas em qualidade\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    sugestoes.append(\"Tratar valores nulos nas colunas identificadas\")\n",
    "\n",
    "if tipos_detectados:\n",
    "    baixa = sum(1 for info in tipos_detectados.values()\n",
    "                if info.get('confianca', 0) < 0.70)\n",
    "    if baixa > 0:\n",
    "        sugestoes.append(f\"Revisar {baixa} campos com baixa confianca\")\n",
    "\n",
    "if duplicatas > 0:\n",
    "    sugestoes.append(\"Investigar e remover linhas duplicadas\")\n",
    "\n",
    "# Sugestoes padrao\n",
    "sugestoes.extend([\n",
    "    \"Revisar o dicionario de campos gerado\",\n",
    "    \"Validar tipos detectados conforme necessidade\",\n",
    "    \"Utilizar codigo de reproducao para reprocessar\"\n",
    "])\n",
    "\n",
    "for i, sugestao in enumerate(sugestoes[:6], 1):\n",
    "    print(f\"  {i}. {sugestao}\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# RODAPE\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" OK PROCESSAMENTO CONCLUIDO COM SUCESSO!\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(f\" Timestamp: {timestamp_execucao}\")\n",
    "print(f\" Dataset disponivel em: df_resultado\")\n",
    "print(f\" Shape: {df_resultado.shape}\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# SALVAR ESTADO DO BLOCO 16\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco16 = {\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'registros_finais': len(df_resultado),\n",
    "    'colunas_finais': len(df_resultado.columns),\n",
    "    'memoria_mb': float(memoria_mb),\n",
    "    'duplicatas': int(duplicatas),\n",
    "    'valores_nulos': int(total_nulos),\n",
    "    'arquivos_gerados': len(arquivos_gerados)\n",
    "}\n",
    "\n",
    "try:\n",
    "    arquivo_estado = fm.pastas['logs'] / '.bloco_16_state.json'\n",
    "    with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "        json.dump(estado_bloco16, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n OK Estado salvo: .bloco_16_state.json\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n! Aviso: Nao foi possivel salvar estado: {e}\")\n",
    "\n",
    "def abrir_pasta_outputs(fm):\n",
    "    \"\"\"Abre pasta de outputs no Explorer/Finder\"\"\"\n",
    "    import subprocess\n",
    "    import platform\n",
    "\n",
    "    pasta = fm.pastas.get('outputs', fm.pastas.get('03_Outputs'))\n",
    "\n",
    "    try:\n",
    "        if platform.system() == 'Windows':\n",
    "            subprocess.run(['explorer', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "        elif platform.system() == 'Darwin':  # macOS\n",
    "            subprocess.run(['open', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "        else:  # Linux\n",
    "            subprocess.run(['xdg-open', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\" ! Erro ao abrir pasta: {e}\")\n",
    "        print(f\"   Caminho: {pasta}\")\n",
    "        return False\n",
    "\n",
    "# Aplicar patch ao FileManager existente\n",
    "if 'fm' in globals() and fm is not None:\n",
    "    abrir_pasta_outputs(fm)\n",
    "else:\n",
    "    print(\"! FileManager nao encontrado na memoria\")\n",
    "\n",
    "# ===================================================================\n",
    "# ABERTURA AUTOMATICA DA PASTA DESTINO (NOVO!)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ABRINDO PASTA DE OUTPUTS...\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "try:\n",
    "    sucesso = fm.abrir_pasta('outputs')\n",
    "    if sucesso:\n",
    "        print(\" OK Pasta de outputs aberta!\")\n",
    "    else:\n",
    "        print(f\" ! Pasta nao abriu automaticamente\")\n",
    "        print(f\"   Caminho: {fm.pastas['outputs']}\")\n",
    "except Exception as e:\n",
    "    print(f\" ! Erro ao abrir pasta: {e}\")\n",
    "    print(f\"   Caminho: {fm.pastas['outputs']}\")\n",
    "\n",
    "print(\"\\n TIP: Se a pasta nao abriu, o caminho esta exibido acima!\")\n",
    "\n",
    "# ===================================================================\n",
    "# EXIBIR DATAFRAME RESULTADO (NOVO!)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" DATASET FINAL (df_resultado)\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# Exibir info do DataFrame\n",
    "print(f\"\\nShape: {df_resultado.shape}\")\n",
    "print(f\"Colunas: {list(df_resultado.columns)}\")\n",
    "print(f\"\\nPrimeiras 10 linhas:\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "try:\n",
    "    # Tentar usar display (Jupyter)\n",
    "    display(df_resultado.head(10))\n",
    "except NameError:\n",
    "    # Fallback para print\n",
    "    print(df_resultado.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" FIM DO RELATORIO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(\"\\n\")"
   ],
   "id": "57bb5f7ac9d4eca0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====================================================================\n",
      "                   RELATORIO FINAL - PROCESSAMENTO CONCLUIDO                  \n",
      "=====================================================================\n",
      "\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      " OK FileManager na memoria\n",
      " OK DataFrame carregado do arquivo: arquivo_processado_Limpo_20251019_060722.xlsx\n",
      " OK Dados carregados de multiplas fontes\n",
      "\n",
      "=====================================================================\n",
      "                            INFORMACOES DO ARQUIVO                            \n",
      "=====================================================================\n",
      "  Nome: [nao disponivel]\n",
      "  Sheet: Sheet1                                                             \n",
      "  Cabecalho: Linha 0 (Excel) / Indice 0 (Python)\n",
      "  Metodo: pandas                                                            \n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                         ESTATISTICAS DE PROCESSAMENTO                        \n",
      "=====================================================================\n",
      "  Registros originais:    199\n",
      "  Registros finais:       199\n",
      "  Diferenca:                0 removidos\n",
      "  ----------------------------------------------------------------\n",
      "  Colunas originais:       25\n",
      "  Colunas finais:          25\n",
      "  Diferenca:                0 removidas\n",
      "  ----------------------------------------------------------------\n",
      "  Memoria em uso:        0.09 MB\n",
      "  Linhas duplicadas:        0\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                              QUALIDADE DOS DADOS                             \n",
      "=====================================================================\n",
      "  Total de valores nulos:    826 (16.60%)\n",
      "  Colunas com nulos:           9\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                               DETECCAO DE TIPOS                              \n",
      "=====================================================================\n",
      "  Informacao nao disponivel\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                        OPERACOES DE LIMPEZA REALIZADAS                       \n",
      "=====================================================================\n",
      "  OK Nenhuma limpeza necessaria - dados ja estavam limpos!\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                               ARQUIVOS GERADOS                               \n",
      "=====================================================================\n",
      "\n",
      "  arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "     Pasta: PROCESSADOS\n",
      "     Tamanho:   67.3 KB\n",
      "\n",
      "  DICT_arquivo_processado_20251019_060722.xlsx\n",
      "     Pasta: OUTPUTS\n",
      "     Tamanho:    6.9 KB\n",
      "\n",
      "  LOG_arquivo_processado_20251019_060722.xlsx\n",
      "     Pasta: LOGS\n",
      "     Tamanho:    5.0 KB\n",
      "\n",
      "  REPROD_arquivo_processado_20251019_060722.py\n",
      "     Pasta: CODIGOS_INTEGRACAO\n",
      "     Tamanho:    3.5 KB\n",
      "\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                         PROXIMOS PASSOS RECOMENDADOS                         \n",
      "=====================================================================\n",
      "  1. Tratar valores nulos nas colunas identificadas\n",
      "  2. Revisar o dicionario de campos gerado\n",
      "  3. Validar tipos detectados conforme necessidade\n",
      "  4. Utilizar codigo de reproducao para reprocessar\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                    OK PROCESSAMENTO CONCLUIDO COM SUCESSO!                   \n",
      "=====================================================================\n",
      " Timestamp: 20251019_060722\n",
      " Dataset disponivel em: df_resultado\n",
      " Shape: (199, 25)\n",
      "=====================================================================\n",
      "\n",
      " OK Estado salvo: .bloco_16_state.json\n",
      " OK Pasta de outputs aberta!\n",
      "\n",
      "=====================================================================\n",
      "                          ABRINDO PASTA DE OUTPUTS...                         \n",
      "=====================================================================\n",
      " ! Erro ao abrir pasta: 'FileManagerSimples' object has no attribute 'abrir_pasta'\n",
      "   Caminho: C:\\Users\\fpsou\\PYTHON_AIVI\\PROCESSAR_ARQUIVOS_20251019_060722\\03_Outputs\n",
      "\n",
      " TIP: Se a pasta nao abriu, o caminho esta exibido acima!\n",
      "\n",
      "=====================================================================\n",
      "                         DATASET FINAL (df_resultado)                         \n",
      "=====================================================================\n",
      "\n",
      "Shape: (199, 25)\n",
      "Colunas: ['Ano civil/m√™s', 'Centro', 'Unnamed: 2', 'HierarqPrd', 'Produto', '_dup1', 'Estoque Inicial', 'Entrada', 'Varia√ß√£o Externa', 'Varia√ß√£o Externa %', 'Varia√ß√£o Interna', 'Varia√ß√£o Interna %', 'Varia√ß√£o Total', 'Varia√ß√£o Total %', 'Custo Unit√°rio do Produto', 'Imposto', 'Valor da Varia√ß√£o Interna', '_dup2', 'Quantidade Excedente da Varia√ß√£o Externa', 'Valor Excedente da Varia√ß√£o Externa (R$)', 'Quantidade Excedente da Varia√ß√£o Interna', 'Valor Excedente da Varia√ß√£o Interna (R$)', 'Quantidade Excedente da Varia√ß√£o Total', 'Valor Excedente da Varia√ß√£o Total (R$)', 'Valor Excedente da Varia√ß√£o Total + Imposto (R$)']\n",
      "\n",
      "Primeiras 10 linhas:\n",
      "=====================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Ano civil/m√™s  Centro Unnamed: 2            HierarqPrd     Produto  \\\n",
       "0         1.2025    5126       BAV1        Diesel - Comum  01.011.674   \n",
       "1         1.2025    5126       BAV1  Querosene de Avia√ß√£o  01.001.422   \n",
       "2         1.2025    5126       BAV1  Querosene de Avia√ß√£o  01.003.826   \n",
       "3         1.2025    5105       BAV2        Gasolina Comum  01.000.078   \n",
       "4         1.2025    5105       BAV2        Diesel - Comum  01.011.674   \n",
       "5         1.2025    5105       BAV2        Diesel - Comum  01.024.741   \n",
       "6         1.2025    5105       BAV2  Querosene de Avia√ß√£o  01.016.205   \n",
       "7         1.2025    5105       BAV2  Querosene de Avia√ß√£o  01.001.422   \n",
       "8         1.2025    5105       BAV2  Querosene de Avia√ß√£o  01.011.754   \n",
       "9         1.2025    5105       BAV2  Querosene de Avia√ß√£o  01.026.471   \n",
       "\n",
       "                          _dup1  Estoque Inicial     Entrada  \\\n",
       "0             √ìLEO DIESEL B S10          16924.0         NaN   \n",
       "1       JET A NAO TABELADO - LI         373850.0    939139.0   \n",
       "2    JET A INTERNACIONAL I - LI         598315.0   5188210.0   \n",
       "3              GASOLINA COMUM C          13076.0     14828.0   \n",
       "4             √ìLEO DIESEL B S10         122306.0    178128.0   \n",
       "5  Vibra Diesel Renov√°vel HVO10           3361.0     14839.0   \n",
       "6      JET A - PRE√áO FIXO - VRG        1425416.0   3500000.0   \n",
       "7       JET A NAO TABELADO - LI        9793143.0  19273387.0   \n",
       "8              JET A PRE√áO FIXO        4578994.0         NaN   \n",
       "9     JET A-1 NAO TABELADO - LI         513358.0   1200000.0   \n",
       "\n",
       "   Varia√ß√£o Externa  Varia√ß√£o Externa %  ...  Imposto  \\\n",
       "0               NaN                 NaN  ...     0.00   \n",
       "1             824.0            0.087740  ... -2811.15   \n",
       "2            1494.0            0.028796  ...     0.00   \n",
       "3               5.0            0.033720  ...     0.00   \n",
       "4             -17.0           -0.009544  ...     0.00   \n",
       "5              -1.0           -0.006739  ...     0.00   \n",
       "6               NaN                 NaN  ...     0.00   \n",
       "7          -59980.0           -0.311206  ...     0.00   \n",
       "8               NaN                 NaN  ...     0.00   \n",
       "9          -10563.0           -0.880250  ... -9028.91   \n",
       "\n",
       "   Valor da Varia√ß√£o Interna  _dup2  Quantidade Excedente da Varia√ß√£o Externa  \\\n",
       "0                  95.402202    NaN                                      0.00   \n",
       "1                 -38.904816    NaN                                    366.22   \n",
       "2                   0.000000    NaN                                      0.00   \n",
       "3                1201.140348    NaN                                      0.00   \n",
       "4               -2036.637033    NaN                                      0.00   \n",
       "5                 189.216874    NaN                                      0.00   \n",
       "6                   0.000000    NaN                                      0.00   \n",
       "7              379506.723303    NaN                                 -40631.61   \n",
       "8                   0.000000    NaN                                      0.00   \n",
       "9               11742.667607    NaN                                  -9362.66   \n",
       "\n",
       "   Valor Excedente da Varia√ß√£o Externa (R$)  \\\n",
       "0                                  0.000000   \n",
       "1                               1424.772156   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "5                                  0.000000   \n",
       "6                                  0.000000   \n",
       "7                            -155516.920049   \n",
       "8                                  0.000000   \n",
       "9                             -35870.343978   \n",
       "\n",
       "   Quantidade Excedente da Varia√ß√£o Interna  \\\n",
       "0                                     10.19   \n",
       "1                                      0.00   \n",
       "2                                      0.00   \n",
       "3                                    220.33   \n",
       "4                                   -240.63   \n",
       "5                                     20.00   \n",
       "6                                      0.00   \n",
       "7                                  11630.85   \n",
       "8                                      0.00   \n",
       "9                                      0.00   \n",
       "\n",
       "   Valor Excedente da Varia√ß√£o Interna (R$)  \\\n",
       "0                                 54.008246   \n",
       "1                                  0.000000   \n",
       "2                                  0.000000   \n",
       "3                               1130.971166   \n",
       "4                              -1282.921386   \n",
       "5                                126.144582   \n",
       "6                                  0.000000   \n",
       "7                              44516.916006   \n",
       "8                                  0.000000   \n",
       "9                                  0.000000   \n",
       "\n",
       "   Quantidade Excedente da Varia√ß√£o Total  \\\n",
       "0                                   10.19   \n",
       "1                                    0.00   \n",
       "2                                    0.00   \n",
       "3                                  220.33   \n",
       "4                                 -240.63   \n",
       "5                                   20.00   \n",
       "6                                    0.00   \n",
       "7                                11630.85   \n",
       "8                                    0.00   \n",
       "9                                    0.00   \n",
       "\n",
       "   Valor Excedente da Varia√ß√£o Total (R$)  \\\n",
       "0                                   54.01   \n",
       "1                                    0.00   \n",
       "2                                    0.00   \n",
       "3                                 1130.97   \n",
       "4                                -1282.92   \n",
       "5                                  126.14   \n",
       "6                                    0.00   \n",
       "7                                44516.92   \n",
       "8                                    0.00   \n",
       "9                                    0.00   \n",
       "\n",
       "   Valor Excedente da Varia√ß√£o Total + Imposto (R$)  \n",
       "0                                             54.01  \n",
       "1                                           2811.15  \n",
       "2                                              0.00  \n",
       "3                                           1130.97  \n",
       "4                                          -1282.92  \n",
       "5                                            126.14  \n",
       "6                                              0.00  \n",
       "7                                          44516.92  \n",
       "8                                              0.00  \n",
       "9                                           9028.91  \n",
       "\n",
       "[10 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano civil/m√™s</th>\n",
       "      <th>Centro</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>HierarqPrd</th>\n",
       "      <th>Produto</th>\n",
       "      <th>_dup1</th>\n",
       "      <th>Estoque Inicial</th>\n",
       "      <th>Entrada</th>\n",
       "      <th>Varia√ß√£o Externa</th>\n",
       "      <th>Varia√ß√£o Externa %</th>\n",
       "      <th>...</th>\n",
       "      <th>Imposto</th>\n",
       "      <th>Valor da Varia√ß√£o Interna</th>\n",
       "      <th>_dup2</th>\n",
       "      <th>Quantidade Excedente da Varia√ß√£o Externa</th>\n",
       "      <th>Valor Excedente da Varia√ß√£o Externa (R$)</th>\n",
       "      <th>Quantidade Excedente da Varia√ß√£o Interna</th>\n",
       "      <th>Valor Excedente da Varia√ß√£o Interna (R$)</th>\n",
       "      <th>Quantidade Excedente da Varia√ß√£o Total</th>\n",
       "      <th>Valor Excedente da Varia√ß√£o Total (R$)</th>\n",
       "      <th>Valor Excedente da Varia√ß√£o Total + Imposto (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>√ìLEO DIESEL B S10</td>\n",
       "      <td>16924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.402202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.19</td>\n",
       "      <td>54.008246</td>\n",
       "      <td>10.19</td>\n",
       "      <td>54.01</td>\n",
       "      <td>54.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>373850.0</td>\n",
       "      <td>939139.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>...</td>\n",
       "      <td>-2811.15</td>\n",
       "      <td>-38.904816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.22</td>\n",
       "      <td>1424.772156</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2811.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>598315.0</td>\n",
       "      <td>5188210.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Gasolina Comum</td>\n",
       "      <td>01.000.078</td>\n",
       "      <td>GASOLINA COMUM C</td>\n",
       "      <td>13076.0</td>\n",
       "      <td>14828.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1201.140348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.33</td>\n",
       "      <td>1130.971166</td>\n",
       "      <td>220.33</td>\n",
       "      <td>1130.97</td>\n",
       "      <td>1130.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>√ìLEO DIESEL B S10</td>\n",
       "      <td>122306.0</td>\n",
       "      <td>178128.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-0.009544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2036.637033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-240.63</td>\n",
       "      <td>-1282.921386</td>\n",
       "      <td>-240.63</td>\n",
       "      <td>-1282.92</td>\n",
       "      <td>-1282.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.024.741</td>\n",
       "      <td>Vibra Diesel Renov√°vel HVO10</td>\n",
       "      <td>3361.0</td>\n",
       "      <td>14839.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>189.216874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>126.144582</td>\n",
       "      <td>20.00</td>\n",
       "      <td>126.14</td>\n",
       "      <td>126.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PRE√áO FIXO - VRG</td>\n",
       "      <td>1425416.0</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>9793143.0</td>\n",
       "      <td>19273387.0</td>\n",
       "      <td>-59980.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>379506.723303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-40631.61</td>\n",
       "      <td>-155516.920049</td>\n",
       "      <td>11630.85</td>\n",
       "      <td>44516.916006</td>\n",
       "      <td>11630.85</td>\n",
       "      <td>44516.92</td>\n",
       "      <td>44516.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PRE√áO FIXO</td>\n",
       "      <td>4578994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de Avia√ß√£o</td>\n",
       "      <td>01.026.471</td>\n",
       "      <td>JET A-1 NAO TABELADO - LI</td>\n",
       "      <td>513358.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>-10563.0</td>\n",
       "      <td>-0.880250</td>\n",
       "      <td>...</td>\n",
       "      <td>-9028.91</td>\n",
       "      <td>11742.667607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9362.66</td>\n",
       "      <td>-35870.343978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9028.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 25 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================\n",
      "                               FIM DO RELATORIO                               \n",
      "=====================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultado",
   "id": "4c205ea0a09c0231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "Extrator de Headers de Notebook Jupyter\n",
    "Extrai todos os cabe√ßalhos/t√≠tulos de blocos de c√≥digo\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extrair_headers_notebook(caminho_notebook):\n",
    "    \"\"\"\n",
    "    Extrai headers de um notebook Jupyter (.ipynb)\n",
    "\n",
    "    Args:\n",
    "        caminho_notebook: Path ou string do arquivo .ipynb\n",
    "\n",
    "    Returns:\n",
    "        Lista de dicion√°rios com informa√ß√µes dos headers\n",
    "    \"\"\"\n",
    "\n",
    "    # Carregar notebook\n",
    "    with open(caminho_notebook, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    headers = []\n",
    "\n",
    "    # Iterar pelas c√©lulas\n",
    "    for idx, cell in enumerate(notebook.get('cells', [])):\n",
    "        cell_type = cell.get('cell_type')\n",
    "        source = cell.get('source', [])\n",
    "\n",
    "        # Converter source para string se for lista\n",
    "        if isinstance(source, list):\n",
    "            source_text = ''.join(source)\n",
    "        else:\n",
    "            source_text = source\n",
    "\n",
    "        # MARKDOWN: Extrair t√≠tulos (#, ##, ###, etc)\n",
    "        if cell_type == 'markdown':\n",
    "            for line in source_text.split('\\n'):\n",
    "                if line.strip().startswith('#'):\n",
    "                    nivel = len(re.match(r'^#+', line.strip()).group())\n",
    "                    titulo = line.strip().lstrip('#').strip()\n",
    "\n",
    "                    headers.append({\n",
    "                        'celula': idx,\n",
    "                        'tipo': 'markdown',\n",
    "                        'nivel': nivel,\n",
    "                        'titulo': titulo,\n",
    "                        'preview': line.strip()[:80]\n",
    "                    })\n",
    "\n",
    "        # CODE: Extrair coment√°rios de blocos (# ===, # ---, # BLOCO, etc)\n",
    "        elif cell_type == 'code':\n",
    "            # Padr√µes de headers em c√≥digo\n",
    "            patterns = [\n",
    "                (r'^# ={3,}', 'separator'),  # # ===\n",
    "                (r'^# -{3,}', 'separator'),  # # ---\n",
    "                (r'^# BLOCO \\d+', 'bloco'),  # # BLOCO 1\n",
    "                (r'^# \\d+\\.', 'numerado'),   # # 1.\n",
    "            ]\n",
    "\n",
    "            for line_num, line in enumerate(source_text.split('\\n')):\n",
    "                line_stripped = line.strip()\n",
    "\n",
    "                # Verificar padr√µes\n",
    "                for pattern, tipo_header in patterns:\n",
    "                    if re.match(pattern, line_stripped, re.IGNORECASE):\n",
    "                        # Tentar pegar pr√≥xima linha como t√≠tulo\n",
    "                        lines = source_text.split('\\n')\n",
    "                        titulo = line_stripped.lstrip('#').strip()\n",
    "\n",
    "                        # Se for separator, pegar linha seguinte\n",
    "                        if tipo_header == 'separator' and line_num + 1 < len(lines):\n",
    "                            next_line = lines[line_num + 1].strip()\n",
    "                            if next_line.startswith('#'):\n",
    "                                titulo = next_line.lstrip('#').strip()\n",
    "\n",
    "                        headers.append({\n",
    "                            'celula': idx,\n",
    "                            'tipo': 'code',\n",
    "                            'subtipo': tipo_header,\n",
    "                            'titulo': titulo,\n",
    "                            'preview': line.strip()[:80]\n",
    "                        })\n",
    "                        break\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def imprimir_estrutura(headers, mostrar_codigo=True):\n",
    "    \"\"\"\n",
    "    Imprime a estrutura do notebook de forma organizada\n",
    "\n",
    "    Args:\n",
    "        headers: Lista de headers extra√≠dos\n",
    "        mostrar_codigo: Se True, mostra headers de c√≥digo tamb√©m\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ESTRUTURA DO NOTEBOOK\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for i, header in enumerate(headers, 1):\n",
    "        # Filtrar c√≥digo se necess√°rio\n",
    "        if not mostrar_codigo and header['tipo'] == 'code':\n",
    "            continue\n",
    "\n",
    "        # Formata√ß√£o por tipo\n",
    "        if header['tipo'] == 'markdown':\n",
    "            # Indenta√ß√£o por n√≠vel\n",
    "            indent = \"  \" * (header['nivel'] - 1)\n",
    "            simbolo = \"#\" * header['nivel']\n",
    "            print(f\"{indent}[MD] {simbolo} {header['titulo']}\")\n",
    "\n",
    "        elif header['tipo'] == 'code':\n",
    "            subtipo = header.get('subtipo', 'outro')\n",
    "\n",
    "            if subtipo == 'bloco':\n",
    "                print(f\"üì¶ [BLOCO] {header['titulo']}\")\n",
    "            elif subtipo == 'separator':\n",
    "                print(f\"‚îÄ‚îÄ‚îÄ {header['titulo']}\")\n",
    "            elif subtipo == 'numerado':\n",
    "                print(f\"  ‚Üí {header['titulo']}\")\n",
    "            else:\n",
    "                print(f\"  ‚Ä¢ {header['titulo']}\")\n",
    "\n",
    "        # Mostrar n√∫mero da c√©lula\n",
    "        print(f\"     (C√©lula {header['celula']})\")\n",
    "        print()\n",
    "\n",
    "\n",
    "def exportar_markdown(headers, arquivo_saida):\n",
    "    \"\"\"\n",
    "    Exporta a estrutura para um arquivo Markdown\n",
    "\n",
    "    Args:\n",
    "        headers: Lista de headers\n",
    "        arquivo_saida: Nome do arquivo .md para salvar\n",
    "    \"\"\"\n",
    "\n",
    "    with open(arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# Estrutura do Notebook\\n\\n\")\n",
    "\n",
    "        for header in headers:\n",
    "            if header['tipo'] == 'markdown':\n",
    "                nivel = header['nivel']\n",
    "                titulo = header['titulo']\n",
    "                f.write(f\"{'#' * nivel} {titulo}\\n\")\n",
    "                f.write(f\"*C√©lula {header['celula']}*\\n\\n\")\n",
    "\n",
    "            elif header['tipo'] == 'code':\n",
    "                titulo = header['titulo']\n",
    "                f.write(f\"- **[CODE]** {titulo}\\n\")\n",
    "                f.write(f\"  - *C√©lula {header['celula']}*\\n\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Estrutura exportada para: {arquivo_saida}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXEMPLO DE USO\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # OP√á√ÉO 1: Usar com arquivo espec√≠fico\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Defina o caminho do seu notebook\n",
    "    caminho = \"PROCESSAR ARQUIVOS DESCONHECIDOS 4.2.ipynb\"\n",
    "\n",
    "    # Verificar se arquivo existe\n",
    "    if not Path(caminho).exists():\n",
    "        print(f\"‚ùå Arquivo n√£o encontrado: {caminho}\")\n",
    "        print(\"\\nüí° Como usar:\")\n",
    "        print(\"   1. Coloque este script na mesma pasta do notebook\")\n",
    "        print(\"   2. Ou altere a vari√°vel 'caminho' acima\")\n",
    "        exit(1)\n",
    "\n",
    "    # Extrair headers\n",
    "    print(f\"üìñ Lendo notebook: {caminho}\")\n",
    "    print()\n",
    "\n",
    "    headers = extrair_headers_notebook(caminho)\n",
    "\n",
    "    print(f\"‚úÖ Encontrados {len(headers)} headers\\n\")\n",
    "\n",
    "    # Imprimir estrutura\n",
    "    imprimir_estrutura(headers, mostrar_codigo=True)\n",
    "\n",
    "    # OP√á√ÉO 2: Exportar para Markdown\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Descomentar para exportar\n",
    "    # exportar_markdown(headers, \"estrutura_notebook.md\")\n",
    "\n",
    "\n",
    "    # OP√á√ÉO 3: Filtrar apenas BLOCOs\n",
    "    # -----------------------------------------\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"APENAS BLOCOS PRINCIPAIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    blocos = [h for h in headers if 'BLOCO' in h.get('titulo', '').upper()]\n",
    "\n",
    "    for bloco in blocos:\n",
    "        print(f\"üì¶ {bloco['titulo']} (C√©lula {bloco['celula']})\")\n",
    "\n",
    "\n",
    "    # OP√á√ÉO 4: Estat√≠sticas\n",
    "    # -----------------------------------------\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ESTAT√çSTICAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    total_markdown = sum(1 for h in headers if h['tipo'] == 'markdown')\n",
    "    total_code = sum(1 for h in headers if h['tipo'] == 'code')\n",
    "    total_blocos = len(blocos)\n",
    "\n",
    "    print(f\"üìä Headers Markdown: {total_markdown}\")\n",
    "    print(f\"üíª Headers Code: {total_code}\")\n",
    "    print(f\"üì¶ Blocos identificados: {total_blocos}\")\n",
    "    print(f\"üìù Total de headers: {len(headers)}\")\n"
   ],
   "id": "7608733d363b944b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# EXPORT SYSTEM - PROCESSADOR DE ARQUIVOS - CORRIGIDO v2.0\n",
    "# ======================================================================\n",
    "# CORRECOES v2.0:\n",
    "# + FIX CRITICO: KeyError 'pasta_destino' -> usar 'pasta_base_atual'\n",
    "# + FIX: KeyError 'container' -> derivar do path (pasta_base.name)\n",
    "# + MANTIDO: Toda funcionalidade original\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPORT SYSTEM - PROCESSADOR DE ARQUIVOS v2.0\")\n",
    "print(\"=\"*70)\n",
    "print(\"MODO: Exporta apenas sistema (notebook + dicionario)\")\n",
    "print(\"      NAO exporta containers de dados processados\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "def exportar_sistema():\n",
    "    \"\"\"\n",
    "    Exporta projeto completo para .zip portavel\n",
    "\n",
    "    v2.0: CORRIGIDO - usa chaves corretas do LOG GLOBAL\n",
    "    \"\"\"\n",
    "\n",
    "    # ===================================================================\n",
    "    # 1. CARREGAR LOG GLOBAL (CORRIGIDO)\n",
    "    # ===================================================================\n",
    "\n",
    "    log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    if not log_global_path.exists():\n",
    "        print(\"\\n! LOG GLOBAL nao encontrado!\")\n",
    "        print(\"  Execute o notebook antes de exportar.\")\n",
    "        return\n",
    "\n",
    "    with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "        log_global = json.load(f)\n",
    "\n",
    "    # ===================================================================\n",
    "    # FIX CRITICO: Usar chaves corretas\n",
    "    # ===================================================================\n",
    "    # ANTES (ERRADO):\n",
    "    # pasta_destino = Path(log_global['pasta_destino'])\n",
    "    # container_nome = log_global['container']\n",
    "\n",
    "    # DEPOIS (CORRETO):\n",
    "    pasta_base = Path(log_global['pasta_base_atual'])\n",
    "    container_nome = pasta_base.name\n",
    "    container_path = pasta_base\n",
    "\n",
    "    print(f\"\\n OK Container encontrado:\")\n",
    "    print(f\"    {container_path}\")\n",
    "    print(f\"    Nome: {container_nome}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 2. CRIAR PASTA TEMPORARIA\n",
    "    # ===================================================================\n",
    "\n",
    "    export_dir = Path('PROCESSADOR_EXPORT_TEMP')\n",
    "\n",
    "    # Limpar se ja existe\n",
    "    if export_dir.exists():\n",
    "        shutil.rmtree(export_dir)\n",
    "\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"\\n OK Criando estrutura de exportacao...\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 3. COPIAR ARQUIVOS ESSENCIAIS\n",
    "    # ===================================================================\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.1. Dicionarios\n",
    "    # ---------------------------------------------------------------\n",
    "    dicionarios_src = container_path / '05_Dicionarios'\n",
    "    dicionarios_dst = export_dir / 'data' / 'dicionarios'\n",
    "    dicionarios_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if dicionarios_src.exists():\n",
    "        for arquivo in dicionarios_src.glob('*.json'):\n",
    "            shutil.copy2(arquivo, dicionarios_dst)\n",
    "            print(f\"    OK Copiado: {arquivo.name}\")\n",
    "    else:\n",
    "        print(f\"    ! Dicionarios nao encontrados\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.2. Logs (estados dos blocos)\n",
    "    # ---------------------------------------------------------------\n",
    "    logs_src = container_path / '04_Logs'\n",
    "    logs_dst = export_dir / 'data' / 'logs'\n",
    "    logs_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if logs_src.exists():\n",
    "        for arquivo in logs_src.glob('.*.json'):\n",
    "            shutil.copy2(arquivo, logs_dst)\n",
    "            print(f\"    OK Copiado: {arquivo.name}\")\n",
    "    else:\n",
    "        print(f\"    ! Logs nao encontrados\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.3. Notebook (buscar no projeto atual)\n",
    "    # ---------------------------------------------------------------\n",
    "    notebooks_dst = export_dir / 'notebooks'\n",
    "    notebooks_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Buscar notebook principal\n",
    "    notebook_encontrado = False\n",
    "    for notebook in Path('.').glob('*.ipynb'):\n",
    "        if 'PROCESSAR' in notebook.name.upper():\n",
    "            shutil.copy2(notebook, notebooks_dst)\n",
    "            print(f\"    OK Copiado: {notebook.name}\")\n",
    "            notebook_encontrado = True\n",
    "\n",
    "    if not notebook_encontrado:\n",
    "        print(f\"    ! Notebook nao encontrado\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.4. Scripts\n",
    "    # ---------------------------------------------------------------\n",
    "    scripts_dst = export_dir / 'scripts'\n",
    "    scripts_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copiar scripts de integracao se existirem\n",
    "    scripts_src = container_path / '06_Codigos_Integracao'\n",
    "    if scripts_src.exists():\n",
    "        for script in scripts_src.glob('*.py'):\n",
    "            shutil.copy2(script, scripts_dst)\n",
    "            print(f\"    OK Copiado: {script.name}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 4. CRIAR CONFIGURACAO\n",
    "    # ===================================================================\n",
    "\n",
    "    config_dst = export_dir / 'config'\n",
    "    config_dst.mkdir(exist_ok=True)\n",
    "\n",
    "    settings = {\n",
    "        'exported_at': datetime.now().isoformat(),\n",
    "        'original_container': container_nome,\n",
    "        'original_path': str(container_path),\n",
    "        'version': '4.2',\n",
    "        'python_version': '3.8+',\n",
    "        'estrutura': {\n",
    "            'notebooks': 'Notebooks Jupyter do processador',\n",
    "            'data/dicionarios': 'Dicionarios de campos conhecidos',\n",
    "            'data/logs': 'Estados dos blocos (auditoria)',\n",
    "            'scripts': 'Scripts de integracao e reproducao',\n",
    "            'config': 'Configuracoes do sistema'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(config_dst / 'settings.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(settings, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"    OK Configuracao criada\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 5. CRIAR README\n",
    "    # ===================================================================\n",
    "\n",
    "    readme_content = f\"\"\"# PROCESSADOR DE ARQUIVOS DESCONHECIDOS v4.2\n",
    "\n",
    "Exportado de: {container_nome}\n",
    "Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## ESTRUTURA\n",
    "\n",
    "```\n",
    "PROCESSADOR_EXPORT/\n",
    "‚îú‚îÄ‚îÄ notebooks/          # Notebooks Jupyter\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ dicionarios/   # Campos conhecidos\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ logs/          # Estados dos blocos\n",
    "‚îú‚îÄ‚îÄ scripts/           # Scripts de integracao\n",
    "‚îú‚îÄ‚îÄ config/            # Configuracoes\n",
    "‚îî‚îÄ‚îÄ README.md          # Este arquivo\n",
    "```\n",
    "\n",
    "## REQUISITOS\n",
    "\n",
    "- Python 3.8+\n",
    "- pandas\n",
    "- openpyxl\n",
    "- tkinter (para GUI)\n",
    "\n",
    "## INSTALACAO\n",
    "\n",
    "```bash\n",
    "pip install pandas openpyxl\n",
    "```\n",
    "\n",
    "## USO BASICO\n",
    "\n",
    "1. **Abrir notebook**:\n",
    "   ```bash\n",
    "   jupyter notebook notebooks/PROCESSAR*.ipynb\n",
    "   ```\n",
    "\n",
    "2. **Executar blocos em sequencia**:\n",
    "   - BLOCO 1: Criar estrutura\n",
    "   - BLOCO 2: Carregar classes\n",
    "   - BLOCO 3-13: Processar arquivo\n",
    "\n",
    "3. **Usar scripts standalone**:\n",
    "   ```bash\n",
    "   python scripts/script_reproducao.py\n",
    "   ```\n",
    "\n",
    "## DICIONARIO DE CAMPOS\n",
    "\n",
    "O dicionario em `data/dicionarios/` contem:\n",
    "- Campos conhecidos\n",
    "- Mapeamentos automaticos\n",
    "- Regras de validacao\n",
    "\n",
    "## LOGS E AUDITORIA\n",
    "\n",
    "Estados dos blocos salvos em `data/logs/`:\n",
    "- `.bloco_N_state.json`: Estado de cada bloco\n",
    "- Permite rastreabilidade completa\n",
    "\n",
    "## SUPORTE\n",
    "\n",
    "Para mais informacoes sobre o sistema original:\n",
    "- Container: {container_nome}\n",
    "- Path: {container_path}\n",
    "\n",
    "---\n",
    "Gerado automaticamente pelo Export System v2.0\n",
    "\"\"\"\n",
    "\n",
    "    with open(export_dir / 'README.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "\n",
    "    print(f\"    OK README criado\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6. CRIAR ARQUIVO .ZIP\n",
    "    # ===================================================================\n",
    "\n",
    "    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    zip_filename = f'PROCESSADOR_EXPORT_{timestamp_str}.zip'\n",
    "    zip_path = Path('.') / zip_filename\n",
    "\n",
    "    print(f\"\\n Criando arquivo .zip...\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in export_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                arcname = file_path.relative_to(export_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 7. LIMPAR PASTA TEMPORARIA\n",
    "    # ===================================================================\n",
    "\n",
    "    shutil.rmtree(export_dir)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 8. RELATORIO FINAL\n",
    "    # ===================================================================\n",
    "\n",
    "    zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" OK EXPORTACAO CONCLUIDA\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(f\"\\n Arquivo gerado:\")\n",
    "    print(f\"    {zip_path}\")\n",
    "    print(f\"    Tamanho: {zip_size_mb:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n Conteudo:\")\n",
    "    print(f\"    - Notebooks do processador\")\n",
    "    print(f\"    - Dicionarios de campos\")\n",
    "    print(f\"    - Estados dos blocos (logs)\")\n",
    "    print(f\"    - Scripts de integracao\")\n",
    "    print(f\"    - Configuracoes\")\n",
    "    print(f\"    - README com instrucoes\")\n",
    "\n",
    "    print(f\"\\n Para usar:\")\n",
    "    print(f\"    1. Extrair arquivo .zip\")\n",
    "    print(f\"    2. Ler README.md\")\n",
    "    print(f\"    3. Instalar requisitos\")\n",
    "    print(f\"    4. Executar notebooks ou scripts\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "    return str(zip_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exportar_sistema()"
   ],
   "id": "a280b3273810d2ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# GERADOR DEFINITIVO - SEM ERROS DE TEMPLATE\n",
    "# ======================================================================\n",
    "# COPIE TUDO E EXECUTE - GARANTIDO QUE FUNCIONA!\n",
    "# ======================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(\"! ERRO: Execute o notebook completo primeiro\")\n",
    "    raise FileNotFoundError(\"LOG GLOBAL nao encontrado\")\n",
    "\n",
    "with open(log_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "# Extrair configuracao\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "container_nome = pasta_base.name\n",
    "timestamp = log_global['timestamp']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GERADOR DE SCRIPT v3.0 DEFINITIVO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n OK Container: {container_nome}\")\n",
    "print(f\" OK Timestamp: {timestamp}\")\n",
    "\n",
    "# ======================================================================\n",
    "# SALVAR SCRIPT LINHA POR LINHA (SEM TEMPLATE)\n",
    "# ======================================================================\n",
    "\n",
    "output_path = pasta_base / '06_Codigos_Integracao' / 'script_reproducao.py'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    # Cabecalho\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# SCRIPT DE REPRODUCAO - PROCESSADOR v4.2\\n')\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write(f'# Gerado: {datetime.now().isoformat()}\\n')\n",
    "    f.write(f'# Container: {container_nome}\\n')\n",
    "    f.write(f'# Timestamp: {timestamp}\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "\n",
    "    # Imports\n",
    "    f.write('from pathlib import Path\\n')\n",
    "    f.write('import json\\n')\n",
    "    f.write('import pandas as pd\\n')\n",
    "    f.write('from datetime import datetime\\n\\n')\n",
    "\n",
    "    # Configuracao\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# CONFIGURACAO\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('SCRIPT_DIR = Path(__file__).parent\\n')\n",
    "    f.write('BASE_DIR = SCRIPT_DIR.parent\\n')\n",
    "    f.write('PASTA_ENTRADA = Path(\"./entrada\")\\n\\n')\n",
    "\n",
    "    f.write('print(\"=\"*70)\\n')\n",
    "    f.write('print(\"SCRIPT DE REPRODUCAO - PROCESSADOR v4.2\")\\n')\n",
    "    f.write('print(\"=\"*70)\\n')\n",
    "    f.write(f'print(\"\\\\nContainer original: {container_nome}\")\\n')\n",
    "    f.write(f'print(\"Timestamp: {timestamp}\")\\n\\n')\n",
    "\n",
    "    # Carregar configuracoes\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# CARREGAR CONFIGURACOES\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('print(\"\\\\n\" + \"=\"*70)\\n')\n",
    "    f.write('print(\"CARREGANDO CONFIGURACOES\")\\n')\n",
    "    f.write('print(\"=\"*70)\\n\\n')\n",
    "\n",
    "    # Carregar dicionario\n",
    "    f.write('# Carregar dicionario\\n')\n",
    "    f.write('dicionario_file = BASE_DIR / \"data\" / \"dicionarios\" / \"DICT_Dicionario_Persistente.json\"\\n')\n",
    "    f.write('if dicionario_file.exists():\\n')\n",
    "    f.write('    with open(dicionario_file, \"r\", encoding=\"utf-8\") as f:\\n')\n",
    "    f.write('        DICIONARIO = json.load(f)\\n')\n",
    "    f.write('    print(f\"\\\\n OK Dicionario: {len(DICIONARIO.get(\\'campos_conhecidos\\', {}))} campos\")\\n')\n",
    "    f.write('else:\\n')\n",
    "    f.write('    DICIONARIO = {\"campos_conhecidos\": {}}\\n')\n",
    "    f.write('    print(\"\\\\n! Dicionario nao encontrado\")\\n\\n')\n",
    "\n",
    "    # Carregar estados\n",
    "    f.write('# Carregar estados dos blocos\\n')\n",
    "    f.write('estados_dir = BASE_DIR / \"data\" / \"logs\"\\n')\n",
    "    f.write('ESTADOS = {}\\n')\n",
    "    f.write('if estados_dir.exists():\\n')\n",
    "    f.write('    for arquivo in estados_dir.glob(\".bloco_*_state.json\"):\\n')\n",
    "    f.write('        bloco_nome = arquivo.stem.replace(\".\", \"\")\\n')\n",
    "    f.write('        with open(arquivo, \"r\", encoding=\"utf-8\") as f:\\n')\n",
    "    f.write('            ESTADOS[bloco_nome] = json.load(f)\\n')\n",
    "    f.write('    print(f\" OK Estados: {len(ESTADOS)} blocos carregados\")\\n')\n",
    "    f.write('else:\\n')\n",
    "    f.write('    print(\"! Pasta de estados nao encontrada\")\\n\\n')\n",
    "\n",
    "    # Funcao processar_arquivo\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# FUNCAO DE PROCESSAMENTO\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('def processar_arquivo(arquivo_path):\\n')\n",
    "    f.write('    \"\"\"Processa um arquivo conforme configuracoes originais\"\"\"\\n\\n')\n",
    "    f.write('    print(f\"\\\\n{\\'=\\'*70}\")\\n')\n",
    "    f.write('    print(f\"Processando: {arquivo_path.name}\")\\n')\n",
    "    f.write('    print(f\"{\\'=\\'*70}\")\\n\\n')\n",
    "\n",
    "    # Carregar arquivo\n",
    "    f.write('    # Carregar arquivo\\n')\n",
    "    f.write('    print(\"\\\\n[1/3] Carregando arquivo...\")\\n')\n",
    "    f.write('    try:\\n')\n",
    "    f.write('        if arquivo_path.suffix.lower() in [\\'.xlsx\\', \\'.xls\\', \\'.xlsm\\']:\\n')\n",
    "    f.write('            df = pd.read_excel(arquivo_path)\\n')\n",
    "    f.write('        elif arquivo_path.suffix.lower() == \\'.csv\\':\\n')\n",
    "    f.write('            df = pd.read_csv(arquivo_path, encoding=\\'utf-8\\')\\n')\n",
    "    f.write('        else:\\n')\n",
    "    f.write('            print(f\"  ! Formato nao suportado: {arquivo_path.suffix}\")\\n')\n",
    "    f.write('            return None\\n')\n",
    "    f.write('        print(f\"  OK Shape original: {df.shape}\")\\n')\n",
    "    f.write('    except Exception as e:\\n')\n",
    "    f.write('        print(f\"  ! ERRO ao carregar: {e}\")\\n')\n",
    "    f.write('        return None\\n\\n')\n",
    "\n",
    "    # Mapeamentos\n",
    "    f.write('    # Aplicar mapeamentos\\n')\n",
    "    f.write('    print(\"\\\\n[2/3] Aplicando mapeamentos...\")\\n')\n",
    "    f.write('    if \\'bloco_12_state\\' in ESTADOS:\\n')\n",
    "    f.write('        bloco12 = ESTADOS[\\'bloco_12_state\\']\\n')\n",
    "    f.write('        campos_mapeados = bloco12.get(\\'campos_mapeados\\', {})\\n')\n",
    "    f.write('        rename_dict = {}\\n')\n",
    "    f.write('        for col_orig, info in campos_mapeados.items():\\n')\n",
    "    f.write('            if col_orig in df.columns:\\n')\n",
    "    f.write('                tipo = info.get(\\'tipo\\', col_orig)\\n')\n",
    "    f.write('                if tipo != col_orig:\\n')\n",
    "    f.write('                    rename_dict[col_orig] = tipo\\n')\n",
    "    f.write('        if rename_dict:\\n')\n",
    "    f.write('            df.rename(columns=rename_dict, inplace=True)\\n')\n",
    "    f.write('            print(f\"  OK {len(rename_dict)} colunas renomeadas\")\\n')\n",
    "    f.write('        else:\\n')\n",
    "    f.write('            print(\"  -- Nenhum mapeamento necessario\")\\n')\n",
    "    f.write('    else:\\n')\n",
    "    f.write('        print(\"  -- BLOCO 12 nao disponivel\")\\n\\n')\n",
    "\n",
    "    # Limpeza\n",
    "    f.write('    # Limpeza basica\\n')\n",
    "    f.write('    print(\"\\\\n[3/3] Limpando dados...\")\\n')\n",
    "    f.write('    linhas_antes = len(df)\\n')\n",
    "    f.write('    df.dropna(how=\\'all\\', inplace=True)\\n')\n",
    "    f.write('    df.dropna(axis=1, how=\\'all\\', inplace=True)\\n')\n",
    "    f.write('    linhas_depois = len(df)\\n')\n",
    "    f.write('    if linhas_antes != linhas_depois:\\n')\n",
    "    f.write('        print(f\"  OK Removidas {linhas_antes - linhas_depois} linhas vazias\")\\n')\n",
    "    f.write('    print(f\"  OK Shape final: {df.shape}\")\\n')\n",
    "    f.write('    return df\\n\\n')\n",
    "\n",
    "    # Funcao main\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# MAIN\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('def main():\\n')\n",
    "    f.write('    \"\"\"Processa todos os arquivos da pasta entrada\"\"\"\\n\\n')\n",
    "\n",
    "    # Verificar entrada\n",
    "    f.write('    # Verificar pasta de entrada\\n')\n",
    "    f.write('    if not PASTA_ENTRADA.exists():\\n')\n",
    "    f.write('        print(f\"\\\\n! ERRO: Pasta de entrada nao encontrada\")\\n')\n",
    "    f.write('        print(f\"  Esperado: {PASTA_ENTRADA.absolute()}\")\\n')\n",
    "    f.write('        print(f\"\\\\n  COMO USAR:\")\\n')\n",
    "    f.write('        print(f\"  1. Criar pasta \\'entrada\\' no mesmo nivel do script\")\\n')\n",
    "    f.write('        print(f\"  2. Colocar arquivos .xlsx ou .csv na pasta\")\\n')\n",
    "    f.write('        print(f\"  3. Executar novamente\")\\n')\n",
    "    f.write('        return\\n\\n')\n",
    "\n",
    "    # Buscar arquivos\n",
    "    f.write('    # Buscar arquivos\\n')\n",
    "    f.write('    arquivos = (\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xlsx\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xls\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xlsm\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.csv\"))\\n')\n",
    "    f.write('    )\\n')\n",
    "    f.write('    if not arquivos:\\n')\n",
    "    f.write('        print(f\"\\\\n! Nenhum arquivo encontrado em {PASTA_ENTRADA}\")\\n')\n",
    "    f.write('        return\\n\\n')\n",
    "\n",
    "    f.write('    print(f\"\\\\n{\\'=\\'*70}\")\\n')\n",
    "    f.write('    print(f\"ARQUIVOS ENCONTRADOS: {len(arquivos)}\")\\n')\n",
    "    f.write('    print(f\"{\\'=\\'*70}\")\\n')\n",
    "    f.write('    for arq in arquivos:\\n')\n",
    "    f.write('        print(f\"  - {arq.name}\")\\n\\n')\n",
    "\n",
    "    # Criar saida\n",
    "    f.write('    # Criar pasta de saida\\n')\n",
    "    f.write('    timestamp_exec = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\\n')\n",
    "    f.write('    pasta_saida = Path(f\"./saida_{timestamp_exec}\")\\n')\n",
    "    f.write('    pasta_saida.mkdir(exist_ok=True, parents=True)\\n')\n",
    "    f.write('    print(f\"\\\\n OK Pasta de saida: {pasta_saida.absolute()}\")\\n\\n')\n",
    "\n",
    "    # Processar\n",
    "    f.write('    # Processar cada arquivo\\n')\n",
    "    f.write('    resultados = {}\\n')\n",
    "    f.write('    for arquivo in arquivos:\\n')\n",
    "    f.write('        try:\\n')\n",
    "    f.write('            df_processado = processar_arquivo(arquivo)\\n')\n",
    "    f.write('            if df_processado is not None:\\n')\n",
    "    f.write('                output_file = pasta_saida / f\"processado_{arquivo.stem}.xlsx\"\\n')\n",
    "    f.write('                df_processado.to_excel(output_file, index=False)\\n')\n",
    "    f.write('                resultados[arquivo.name] = {\\n')\n",
    "    f.write('                    \\'status\\': \\'OK\\',\\n')\n",
    "    f.write('                    \\'linhas\\': len(df_processado),\\n')\n",
    "    f.write('                    \\'colunas\\': len(df_processado.columns),\\n')\n",
    "    f.write('                    \\'arquivo_saida\\': output_file.name\\n')\n",
    "    f.write('                }\\n')\n",
    "    f.write('                print(f\"\\\\n OK SALVO: {output_file.name}\")\\n')\n",
    "    f.write('            else:\\n')\n",
    "    f.write('                resultados[arquivo.name] = {\\'status\\': \\'ERRO\\', \\'erro\\': \\'Processamento retornou None\\'}\\n')\n",
    "    f.write('        except Exception as e:\\n')\n",
    "    f.write('            print(f\"\\\\n! ERRO: {e}\")\\n')\n",
    "    f.write('            resultados[arquivo.name] = {\\'status\\': \\'ERRO\\', \\'erro\\': str(e)}\\n\\n')\n",
    "\n",
    "    # Relatorio\n",
    "    f.write('    # Salvar relatorio\\n')\n",
    "    f.write('    relatorio = {\\n')\n",
    "    f.write('        \\'timestamp\\': datetime.now().isoformat(),\\n')\n",
    "    f.write(f'        \\'configuracao_original\\': {{\"container\": \"{container_nome}\", \"timestamp\": \"{timestamp}\"}},\\n')\n",
    "    f.write('        \\'resultados\\': resultados,\\n')\n",
    "    f.write('        \\'resumo\\': {\\n')\n",
    "    f.write('            \\'total\\': len(resultados),\\n')\n",
    "    f.write('            \\'sucesso\\': sum(1 for r in resultados.values() if r[\\'status\\'] == \\'OK\\'),\\n')\n",
    "    f.write('            \\'erro\\': sum(1 for r in resultados.values() if r[\\'status\\'] == \\'ERRO\\')\\n')\n",
    "    f.write('        }\\n')\n",
    "    f.write('    }\\n')\n",
    "    f.write('    relatorio_file = pasta_saida / \\'RELATORIO.json\\'\\n')\n",
    "    f.write('    with open(relatorio_file, \\'w\\', encoding=\\'utf-8\\') as f:\\n')\n",
    "    f.write('        json.dump(relatorio, f, indent=2, ensure_ascii=False)\\n\\n')\n",
    "\n",
    "    # Resumo\n",
    "    f.write('    # Resumo final\\n')\n",
    "    f.write('    print(\"\\\\n\" + \"=\"*70)\\n')\n",
    "    f.write('    print(\"RESUMO FINAL\")\\n')\n",
    "    f.write('    print(\"=\"*70)\\n')\n",
    "    f.write('    print(f\"Total: {relatorio[\\'resumo\\'][\\'total\\']}\")\\n')\n",
    "    f.write('    print(f\"Sucesso: {relatorio[\\'resumo\\'][\\'sucesso\\']}\")\\n')\n",
    "    f.write('    print(f\"Erros: {relatorio[\\'resumo\\'][\\'erro\\']}\")\\n')\n",
    "    f.write('    print(f\"Pasta saida: {pasta_saida.absolute()}\")\\n')\n",
    "    f.write('    print(f\"Relatorio: {relatorio_file.name}\")\\n')\n",
    "    f.write('    print(\"=\"*70)\\n\\n')\n",
    "\n",
    "    # Executar\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# EXECUTAR\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('if __name__ == \"__main__\":\\n')\n",
    "    f.write('    try:\\n')\n",
    "    f.write('        main()\\n')\n",
    "    f.write('    except KeyboardInterrupt:\\n')\n",
    "    f.write('        print(\"\\\\n\\\\nProcessamento interrompido pelo usuario\")\\n')\n",
    "    f.write('    except Exception as e:\\n')\n",
    "    f.write('        print(f\"\\\\n\\\\nERRO FATAL: {e}\")\\n')\n",
    "    f.write('        import traceback\\n')\n",
    "    f.write('        traceback.print_exc()\\n')\n",
    "\n",
    "print(f\"\\n‚úÖ SCRIPT GERADO COM SUCESSO!\")\n",
    "print(f\"\\nüìÅ Local:\")\n",
    "print(f\"   {output_path}\")\n",
    "print(f\"\\nüìñ COMO USAR:\")\n",
    "print(f\"   1. cd \\\"{output_path.parent}\\\"\")\n",
    "print(f\"   2. mkdir entrada\")\n",
    "print(f\"   3. Colocar arquivos em entrada/\")\n",
    "print(f\"   4. python script_reproducao.py\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "id": "2b30f963334f0548",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "34cebe917d524e5a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
