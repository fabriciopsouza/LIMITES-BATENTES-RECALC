{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:23.004942Z",
     "start_time": "2025-10-19T09:07:19.821950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 1: SELETOR DE PASTA COM TIMER + MIGRAÃ‡ÃƒO\n",
    "# VersÃ£o: 4.4 - COM MELHORIAS DE OBSERVABILIDADE E CONSISTÃŠNCIA\n",
    "# Data: 2025-10-17\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIAS v4.4:\n",
    "# âœ… MELHORIA 1: Salvar estado local .bloco_1_state.json\n",
    "# âœ… MELHORIA 2: Registro de versÃ£o do cÃ³digo\n",
    "# âœ… MELHORIA 3: ValidaÃ§Ã£o de dependÃªncias\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# METADADOS DA VERSÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "VERSAO_BLOCO1 = '4.4'\n",
    "DATA_VERSAO = '2025-10-17'\n",
    "CHANGELOG_V44 = {\n",
    "    'v4.4': {\n",
    "        'data': '2025-10-17',\n",
    "        'melhorias': [\n",
    "            'Salvar estado local em .bloco_1_state.json',\n",
    "            'Registro de versÃ£o do cÃ³digo',\n",
    "            'ValidaÃ§Ã£o de dependÃªncias no inÃ­cio'\n",
    "        ],\n",
    "        'compatibilidade': 'v4.3'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\" ğŸ” PROCESSADOR DE ARQUIVOS DESCONHECIDOS v{VERSAO_BLOCO1}\")\n",
    "print(\"=\"*70)\n",
    "print(f\" VersÃ£o: {VERSAO_BLOCO1} | Data: {DATA_VERSAO}\")\n",
    "print(\" Timer | MigraÃ§Ã£o | DicionÃ¡rios | ValidaÃ§Ãµes | Logs | Estado\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIA 3: VALIDAÃ‡ÃƒO DE DEPENDÃŠNCIAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def validar_dependencias():\n",
    "    \"\"\"\n",
    "    Valida que todas as bibliotecas necessÃ¡rias estÃ£o instaladas.\n",
    "\n",
    "    Evita erros confusos mais tarde na execuÃ§Ã£o.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ” Validando dependÃªncias...\")\n",
    "\n",
    "    dependencias = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'openpyxl': 'openpyxl',\n",
    "        'xlrd': 'xlrd',\n",
    "        'tkinter': 'tkinter (built-in Python)'\n",
    "    }\n",
    "\n",
    "    faltando = []\n",
    "    instaladas = []\n",
    "\n",
    "    for modulo, nome_pip in dependencias.items():\n",
    "        try:\n",
    "            __import__(modulo)\n",
    "            instaladas.append(f\"âœ… {modulo}\")\n",
    "        except ImportError:\n",
    "            faltando.append(nome_pip)\n",
    "\n",
    "    # Mostrar resultado\n",
    "    for lib in instaladas:\n",
    "        print(f\"   {lib}\")\n",
    "\n",
    "    if faltando:\n",
    "        print(\"\\nâŒ ERRO: Bibliotecas faltando!\")\n",
    "        print(\"â”€\" * 70)\n",
    "        for lib in faltando:\n",
    "            print(f\"   âŒ {lib}\")\n",
    "        print(\"\\nğŸ’¡ SoluÃ§Ã£o:\")\n",
    "        libs_pip = [lib for lib in faltando if 'built-in' not in lib]\n",
    "        if libs_pip:\n",
    "            print(f\"   Execute: pip install {' '.join(libs_pip)}\")\n",
    "        print()\n",
    "        raise ImportError(\n",
    "            f\"Bibliotecas necessÃ¡rias nÃ£o instaladas: {', '.join(faltando)}\"\n",
    "        )\n",
    "\n",
    "    print(\"âœ… Todas as dependÃªncias instaladas!\\n\")\n",
    "\n",
    "# Validar ANTES de importar\n",
    "validar_dependencias()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# IMPORTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "\n",
    "print(\"âœ… Imports carregados\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: LocalizadorDicionario (SISTEMA DE PERSISTÃŠNCIA GLOBAL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localizaÃ§Ã£o persistente de dicionÃ¡rios entre sessÃµes.\n",
    "\n",
    "    MantÃ©m log global em: ~/.processador_dicionario_localizador.json\n",
    "\n",
    "    MÃ©todos PÃºblicos:\n",
    "    - obter_dicionario_atual() -> Path  # Para BLOCO 2+\n",
    "    - obter_pasta_base_atual() -> Path  # Para FileManager\n",
    "    - obter_timestamp_atual() -> str    # Para recuperar timestamp\n",
    "    - registrar_mudanca()               # Chamado por BLOCO 1\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.1',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'timestamp': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def salvar_log(cls, log):\n",
    "        \"\"\"Salva log com backup automÃ¡tico\"\"\"\n",
    "        # Backup do log anterior\n",
    "        if cls.LOG_FILE.exists():\n",
    "            backup_file = cls.LOG_FILE.with_suffix('.json.bak')\n",
    "            shutil.copy2(cls.LOG_FILE, backup_file)\n",
    "\n",
    "        # Salvar novo log\n",
    "        with open(cls.LOG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicionÃ¡rio atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ DicionÃ¡rio nÃ£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"âŒ DicionÃ¡rio nÃ£o existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual (para FileManager)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ Pasta base nÃ£o encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"âŒ Pasta base nÃ£o existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "    @classmethod\n",
    "    def obter_timestamp_atual(cls):\n",
    "        \"\"\"Retorna timestamp da execuÃ§Ã£o atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log.get('timestamp'):\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ Timestamp nÃ£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "        return log['timestamp']\n",
    "\n",
    "    @classmethod\n",
    "    def registrar_mudanca(cls, pasta_base, timestamp, dicionario_path=None,\n",
    "                         migrado_de=None, versao_bloco1=None):\n",
    "        \"\"\"\n",
    "        Registra mudanÃ§a de localizaÃ§Ã£o no log global.\n",
    "\n",
    "        IMPORTANTE: Agora aceita timestamp e registra no LOG GLOBAL.\n",
    "        dicionario_path Ã© OPCIONAL - sÃ³ registra se existir.\n",
    "\n",
    "        Args:\n",
    "            pasta_base: Path da pasta container\n",
    "            timestamp: String timestamp da execuÃ§Ã£o\n",
    "            dicionario_path: Path do dicionÃ¡rio (opcional)\n",
    "            migrado_de: Path de onde migrou (opcional)\n",
    "            versao_bloco1: VersÃ£o do BLOCO 1 que criou (opcional)\n",
    "        \"\"\"\n",
    "        log = cls.carregar_log()\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'pasta_base': str(pasta_base),\n",
    "            'dicionario_path': str(dicionario_path) if dicionario_path else None,\n",
    "            'timestamp_execucao': timestamp,\n",
    "            'existe': dicionario_path.exists() if dicionario_path else False,\n",
    "            'versao_bloco1': versao_bloco1 or 'desconhecida'\n",
    "        }\n",
    "\n",
    "        if migrado_de:\n",
    "            entrada['migrado_de'] = str(migrado_de)\n",
    "\n",
    "        log['pasta_base_atual'] = str(pasta_base)\n",
    "        log['timestamp'] = timestamp\n",
    "\n",
    "        # SÃ³ registrar dicionÃ¡rio se ele REALMENTE existir\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            log['dicionario_atual'] = str(dicionario_path)\n",
    "        else:\n",
    "            log['dicionario_atual'] = None\n",
    "\n",
    "        log['historico'].append(entrada)\n",
    "        log['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "\n",
    "        cls.salvar_log(log)\n",
    "\n",
    "        print(f\"\\nğŸ“ Localizador atualizado:\")\n",
    "        print(f\"   Container: {pasta_base.name}\")\n",
    "        print(f\"   Timestamp: {timestamp}\")\n",
    "        print(f\"   VersÃ£o BLOCO 1: {versao_bloco1 or 'desconhecida'}\")\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            print(f\"   DicionÃ¡rio: {dicionario_path.name}\")\n",
    "        print(f\"   Log: {cls.LOG_FILE}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: SeletorPastaComTimer (GUI COM TIMER)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SeletorPastaComTimer:\n",
    "    \"\"\"Seletor de pasta destino com timer de 10s e memÃ³ria\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_directory.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultima_pasta(self):\n",
    "        \"\"\"Carrega Ãºltima pasta usada\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultima_pasta = Path(config.get('last_directory', ''))\n",
    "                if ultima_pasta.exists():\n",
    "                    return ultima_pasta\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, pasta):\n",
    "        \"\"\"Salva escolha para prÃ³xima execuÃ§Ã£o\"\"\"\n",
    "        config = {\n",
    "            'last_directory': str(pasta),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_pasta_destino(self, pasta):\n",
    "        \"\"\"Valida se pasta tem permissÃµes adequadas\"\"\"\n",
    "        pasta = Path(pasta)\n",
    "\n",
    "        # Verificar permissÃ£o de escrita\n",
    "        if not os.access(pasta, os.W_OK):\n",
    "            return False, \"âŒ Sem permissÃ£o de escrita\"\n",
    "\n",
    "        # Verificar espaÃ§o em disco (mÃ­nimo 100MB)\n",
    "        stat = os.statvfs(pasta) if hasattr(os, 'statvfs') else None\n",
    "        if stat:\n",
    "            espaco_livre = stat.f_bavail * stat.f_frsize\n",
    "            if espaco_livre < 100 * 1024 * 1024:  # 100MB\n",
    "                return False, (\n",
    "                    f\"âŒ EspaÃ§o insuficiente \"\n",
    "                    f\"({espaco_livre/1024/1024:.1f}MB)\"\n",
    "                )\n",
    "\n",
    "        return True, \"âœ… Pasta vÃ¡lida\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultima_pasta = self.carregar_ultima_pasta()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Pasta Destino\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # TÃ­tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ Pasta DESTINO\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultima_pasta:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultima_pasta}\"\n",
    "        else:\n",
    "            msg = \"Primeira execuÃ§Ã£o - selecione pasta\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [10]\n",
    "        if ultima_pasta:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # BotÃµes\n",
    "        def escolher_nova():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            nova_pasta = filedialog.askdirectory(\n",
    "                title=\"Pasta DESTINO\",\n",
    "                initialdir=ultima_pasta if ultima_pasta else None\n",
    "            )\n",
    "\n",
    "            if nova_pasta:\n",
    "                valido, msg = self.validar_pasta_destino(nova_pasta)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Pasta InvÃ¡lida\", msg)\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(nova_pasta)\n",
    "                    self.resultado['acao'] = 'NOVA'\n",
    "            else:\n",
    "                self.resultado['path'] = ultima_pasta\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultima_pasta\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ“ Nova Pasta\",\n",
    "            command=escolher_nova,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultima_pasta:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"âœ… Usar Ãšltima\",\n",
    "                command=usar_ultima,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: SeletorOrigemComTimer (GUI MIGRAÃ‡ÃƒO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SeletorOrigemComTimer:\n",
    "    \"\"\"Pergunta se deseja copiar arquivos de execuÃ§Ã£o anterior\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'copiar': False, 'path': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def perguntar_origem(self):\n",
    "        \"\"\"GUI com timer de 5s (default: NÃƒO)\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Copiar Arquivos Anteriores?\")\n",
    "        root.geometry(\"650x350\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 175\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ Copiar arquivos de execuÃ§Ã£o anterior?\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        msg = (\n",
    "            \"Se houver dicionÃ¡rios, logs ou outputs anteriores,\\n\"\n",
    "            \"vocÃª pode copiÃ¡-los para a nova estrutura.\"\n",
    "        )\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        contador = [5]\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"{contador[0]}s (auto: NÃƒO)\",\n",
    "            font=('Arial', 18, 'bold'),\n",
    "            fg='#FF6600',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 20))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"{contador[0]}s (auto: NÃƒO)\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0:\n",
    "                self.timeout_ocorreu = True\n",
    "                self.resultado['copiar'] = False\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "        def sim_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            pasta_origem = filedialog.askdirectory(\n",
    "                title=\"Selecione pasta ORIGEM (execuÃ§Ã£o anterior)\"\n",
    "            )\n",
    "            if pasta_origem:\n",
    "                self.resultado['copiar'] = True\n",
    "                self.resultado['path'] = Path(pasta_origem)\n",
    "            else:\n",
    "                self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def nao_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"âœ… SIM - Selecionar Origem\",\n",
    "            command=sim_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"âŒ NÃƒO - ComeÃ§ar do Zero\",\n",
    "            command=nao_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: LimpadorRoot (DETECÃ‡ÃƒO DE POLUIÃ‡ÃƒO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class LimpadorRoot:\n",
    "    \"\"\"Detecta e limpa pastas antigas no root\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_root):\n",
    "        self.pasta_root = Path(pasta_root)\n",
    "\n",
    "    def detectar_poluicao(self):\n",
    "        \"\"\"Encontra pastas numeradas antigas\"\"\"\n",
    "        pastas_numeradas = [\n",
    "            p for p in self.pasta_root.iterdir()\n",
    "            if p.is_dir() and p.name[:2].isdigit() and '_' in p.name\n",
    "        ]\n",
    "        return pastas_numeradas\n",
    "\n",
    "    def perguntar_limpeza(self, pastas):\n",
    "        \"\"\"GUI para decidir o que fazer com pastas antigas\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Limpar Root?\")\n",
    "        root.geometry(\"650x400\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 200\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"âš ï¸  Pastas antigas detectadas no root\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white',\n",
    "            fg='#FF6600'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        msg = f\"Encontradas {len(pastas)} pastas soltas:\\n\\n\"\n",
    "        msg += \"\\n\".join([f\"â€¢ {p.name}\" for p in pastas[:5]])\n",
    "        if len(pastas) > 5:\n",
    "            msg += f\"\\n... e mais {len(pastas)-5}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        resultado = {'acao': None}\n",
    "\n",
    "        def mover():\n",
    "            resultado['acao'] = 'MOVER'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def deletar():\n",
    "            resultado['acao'] = 'DELETAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def ignorar():\n",
    "            resultado['acao'] = 'IGNORAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ“¦ Mover p/ Estrutura\",\n",
    "            command=mover,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ—‘ï¸  Deletar\",\n",
    "            command=deletar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#F44336',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"â­ï¸  Ignorar\",\n",
    "            command=ignorar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.mainloop()\n",
    "        return resultado['acao']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: GerenciadorMigracao (CÃ“PIA COMPLETA COM LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class GerenciadorMigracao:\n",
    "    \"\"\"Gerencia cÃ³pia completa de execuÃ§Ãµes anteriores\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_origem, pasta_destino_container):\n",
    "        self.pasta_origem = Path(pasta_origem)\n",
    "        self.pasta_destino = Path(pasta_destino_container)\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.log_detalhado = []\n",
    "        self.erros = []\n",
    "\n",
    "    def detectar_estrutura(self):\n",
    "        \"\"\"Detecta pastas e dicionÃ¡rios na origem\"\"\"\n",
    "        pastas = [\n",
    "            p for p in self.pasta_origem.iterdir()\n",
    "            if p.is_dir() and (\n",
    "                p.name[:2].isdigit() or\n",
    "                'dicionario' in p.name.lower()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        dicionarios = []\n",
    "        pasta_dict = self.pasta_origem / '05_Dicionarios'\n",
    "\n",
    "        if pasta_dict.exists():\n",
    "            dicionarios.extend(list(pasta_dict.glob('*.json')))\n",
    "\n",
    "        dicionarios.extend(\n",
    "            list(self.pasta_origem.glob('dicionario*.json'))\n",
    "        )\n",
    "        dicionarios = list(set(dicionarios))\n",
    "\n",
    "        return pastas, dicionarios\n",
    "\n",
    "    def validar_dicionario(self, arquivo_json):\n",
    "        \"\"\"Valida integridade do dicionÃ¡rio JSON\"\"\"\n",
    "        try:\n",
    "            with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Verificar estrutura mÃ­nima\n",
    "            if not isinstance(data, dict):\n",
    "                return False, \"JSON nÃ£o Ã© um dicionÃ¡rio\"\n",
    "\n",
    "            return True, \"âœ… VÃ¡lido\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            return False, f\"JSON invÃ¡lido: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Erro: {str(e)}\"\n",
    "\n",
    "    def copiar_tudo(self):\n",
    "        \"\"\"Copia tudo com tratamento de erros\"\"\"\n",
    "        pastas, dicionarios = self.detectar_estrutura()\n",
    "\n",
    "        print(f\"\\nğŸ“‚ MIGRAÃ‡ÃƒO COMPLETA\")\n",
    "        print(\"â”€\" * 70)\n",
    "        print(f\"   De: {self.pasta_origem}\")\n",
    "        print(f\"   Para: {self.pasta_destino}\")\n",
    "        print(f\"   Pastas: {len(pastas)}\")\n",
    "        print(f\"   DicionÃ¡rios: {len(dicionarios)}\")\n",
    "        print()\n",
    "\n",
    "        if not pastas and not dicionarios:\n",
    "            print(\"â„¹ï¸  Nada para copiar\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(\"Copiar? (S/N ou Enter=S): \", end='')\n",
    "        resposta = input().strip().upper()\n",
    "        if resposta and resposta != 'S':\n",
    "            print(\"âŒ MigraÃ§Ã£o cancelada\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(f\"\\nğŸ”„ Copiando...\\n\")\n",
    "\n",
    "        arquivos_copiados = 0\n",
    "        bytes_copiados = 0\n",
    "        dicionarios_copiados = []\n",
    "\n",
    "        # Copiar pastas\n",
    "        for pasta in sorted(pastas):\n",
    "            try:\n",
    "                if pasta.name == '05_Dicionarios':\n",
    "                    continue\n",
    "\n",
    "                destino_pasta = self.pasta_destino / pasta.name\n",
    "                destino_pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                print(f\"ğŸ“ {pasta.name}\", end='')\n",
    "                arquivos_pasta = 0\n",
    "                bytes_pasta = 0\n",
    "\n",
    "                for arquivo in pasta.rglob('*'):\n",
    "                    if arquivo.is_file():\n",
    "                        try:\n",
    "                            destino_arq = (\n",
    "                                destino_pasta /\n",
    "                                arquivo.relative_to(pasta)\n",
    "                            )\n",
    "                            destino_arq.parent.mkdir(\n",
    "                                parents=True,\n",
    "                                exist_ok=True\n",
    "                            )\n",
    "                            shutil.copy2(arquivo, destino_arq)\n",
    "                            arquivos_copiados += 1\n",
    "                            arquivos_pasta += 1\n",
    "                            bytes_pasta += arquivo.stat().st_size\n",
    "                        except Exception as e:\n",
    "                            self.erros.append({\n",
    "                                'arquivo': str(arquivo),\n",
    "                                'erro': str(e)\n",
    "                            })\n",
    "\n",
    "                bytes_copiados += bytes_pasta\n",
    "                tamanho_kb = bytes_pasta/1024\n",
    "                print(f\" â†’ {arquivos_pasta} arquivos ({tamanho_kb:.1f} KB)\")\n",
    "\n",
    "                self.log_detalhado.append({\n",
    "                    'tipo': 'pasta',\n",
    "                    'nome': pasta.name,\n",
    "                    'arquivos': arquivos_pasta,\n",
    "                    'bytes': bytes_pasta\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" âŒ ERRO: {str(e)}\")\n",
    "                self.erros.append({\n",
    "                    'pasta': pasta.name,\n",
    "                    'erro': str(e)\n",
    "                })\n",
    "\n",
    "        # Copiar dicionÃ¡rios\n",
    "        if dicionarios:\n",
    "            pasta_dict_destino = self.pasta_destino / '05_Dicionarios'\n",
    "            pasta_dict_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            print(f\"\\nğŸ“š DICIONÃRIOS ({len(dicionarios)}):\")\n",
    "\n",
    "            for dic in dicionarios:\n",
    "                try:\n",
    "                    # Validar antes de copiar\n",
    "                    valido, msg = self.validar_dicionario(dic)\n",
    "\n",
    "                    destino_dic = pasta_dict_destino / dic.name\n",
    "                    shutil.copy2(dic, destino_dic)\n",
    "                    tamanho = dic.stat().st_size\n",
    "\n",
    "                    status = \"âœ…\" if valido else \"âš ï¸\"\n",
    "                    tamanho_kb = tamanho/1024\n",
    "                    print(f\"   {status} {dic.name} ({tamanho_kb:.1f} KB) - {msg}\")\n",
    "\n",
    "                    dicionarios_copiados.append(str(destino_dic))\n",
    "                    arquivos_copiados += 1\n",
    "                    bytes_copiados += tamanho\n",
    "\n",
    "                    self.log_detalhado.append({\n",
    "                        'tipo': 'dicionario',\n",
    "                        'nome': dic.name,\n",
    "                        'bytes': tamanho,\n",
    "                        'path': str(destino_dic),\n",
    "                        'validado': valido\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ {dic.name}: {str(e)}\")\n",
    "                    self.erros.append({\n",
    "                        'dicionario': dic.name,\n",
    "                        'erro': str(e)\n",
    "                    })\n",
    "\n",
    "        total_mb = bytes_copiados/1024/1024\n",
    "        print(f\"\\nâœ… TOTAL: {arquivos_copiados} arquivos, {total_mb:.2f} MB\")\n",
    "\n",
    "        if self.erros:\n",
    "            print(f\"âš ï¸  {len(self.erros)} erros durante cÃ³pia (ver log)\")\n",
    "\n",
    "        self._salvar_log_local({\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'bytes': bytes_copiados,\n",
    "            'dicionarios': len(dicionarios_copiados),\n",
    "            'erros': len(self.erros),\n",
    "            'detalhes': self.log_detalhado,\n",
    "            'log_erros': self.erros\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'dicionarios': dicionarios_copiados,\n",
    "            'erros': self.erros\n",
    "        }\n",
    "\n",
    "    def _salvar_log_local(self, info):\n",
    "        \"\"\"Salva log detalhado da migraÃ§Ã£o\"\"\"\n",
    "        log_file = self.pasta_destino / 'log_migracoes.json'\n",
    "\n",
    "        if log_file.exists():\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                historico = json.load(f)\n",
    "        else:\n",
    "            historico = {'migracoes': []}\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': self.timestamp,\n",
    "            'data_hora': datetime.now().isoformat(),\n",
    "            'pasta_origem': str(self.pasta_origem),\n",
    "            'pasta_destino': str(self.pasta_destino),\n",
    "            **info\n",
    "        }\n",
    "\n",
    "        historico['migracoes'].append(entrada)\n",
    "        historico['ultima_migracao'] = self.timestamp\n",
    "\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(historico, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"ğŸ’¾ Log: {log_file.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: FileManagerInterativo (GERENCIADOR DE ARQUIVOS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path=None):\n",
    "        self.base_path = Path(base_path) if base_path else Path.cwd()\n",
    "\n",
    "        # Estrutura de pastas padrÃ£o\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        print(f\"âœ… FileManager inicializado\")\n",
    "        print(f\"   ğŸ“‚ Container: {self.base_path.name}\")\n",
    "        print(f\"   ğŸ• Timestamp: {self.timestamp}\")\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = (\n",
    "            self.pastas[pasta] /\n",
    "            f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "        )\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  NÃ£o foi possÃ­vel abrir pasta: {e}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡ÃƒO: gerar_readme\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def gerar_readme(pasta_base, versao_bloco1):\n",
    "    \"\"\"Gera README.md na pasta container\"\"\"\n",
    "    readme = f\"\"\"# ğŸ“š PROCESSADOR DE ARQUIVOS DESCONHECIDOS\n",
    "\n",
    "**Gerado:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Pasta:** {pasta_base}\n",
    "**VersÃ£o BLOCO 1:** {versao_bloco1}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ESTRUTURA\n",
    "\n",
    "```\n",
    "{pasta_base.name}/\n",
    "â”œâ”€â”€ 01_Entrada/          â† Arquivos originais\n",
    "â”œâ”€â”€ 02_Processados/      â† Dados limpos\n",
    "â”œâ”€â”€ 03_Outputs/          â† Resultados finais\n",
    "â”œâ”€â”€ 04_Logs/             â† Logs de execuÃ§Ã£o â­ COMUNICAÃ‡ÃƒO VIA LOG\n",
    "â”œâ”€â”€ 05_Dicionarios/      â† Mapeamentos DE-PARA\n",
    "â”œâ”€â”€ 06_Codigos_Integracao/ â† Scripts reutilizÃ¡veis\n",
    "â”œâ”€â”€ README.md            â† Este arquivo\n",
    "â””â”€â”€ log_migracoes.json   â† HistÃ³rico de migraÃ§Ãµes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š LOCALIZADOR DE DICIONÃRIO\n",
    "\n",
    "**Para notebooks consumidores (BLOCO 2+):**\n",
    "\n",
    "```python\n",
    "from bloco1 import LocalizadorDicionario\n",
    "\n",
    "# Obter dicionÃ¡rio atual\n",
    "dicionario_path = LocalizadorDicionario.obter_dicionario_atual()\n",
    "\n",
    "# Obter pasta base\n",
    "pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "# Obter timestamp da execuÃ§Ã£o\n",
    "timestamp = LocalizadorDicionario.obter_timestamp_atual()\n",
    "\n",
    "# Carregar dicionÃ¡rio\n",
    "import json\n",
    "with open(dicionario_path, 'r', encoding='utf-8') as f:\n",
    "    dicionario = json.load(f)\n",
    "```\n",
    "\n",
    "**Log global:** `~/.processador_dicionario_localizador.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— COMUNICAÃ‡ÃƒO ENTRE BLOCOS (0% MEMÃ“RIA, 100% LOG)\n",
    "\n",
    "Todos os blocos seguem o padrÃ£o:\n",
    "\n",
    "1. **LER** do LOG GLOBAL:\n",
    "   - pasta_base_atual\n",
    "   - timestamp\n",
    "   - dicionario_atual (se existir)\n",
    "\n",
    "2. **RECRIAR** objetos localmente:\n",
    "   - FileManager(pasta_base)\n",
    "   - Carregar dicionÃ¡rio de 04_Logs/\n",
    "\n",
    "3. **PROCESSAR** dados do bloco\n",
    "\n",
    "4. **SALVAR** estado em 04_Logs/:\n",
    "   - .bloco_N_state.json\n",
    "   - Dados especÃ­ficos do bloco\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ HISTÃ“RICO DE MIGRAÃ‡Ã•ES\n",
    "\n",
    "Ver: `log_migracoes.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ESTADO DO BLOCO 1\n",
    "\n",
    "Ver: `04_Logs/.bloco_1_state.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ†˜ SUPORTE\n",
    "\n",
    "- Erros: `04_Logs/`\n",
    "- DicionÃ¡rio perdido: Execute BLOCO 1\n",
    "- MigraÃ§Ã£o: Consulte `log_migracoes.json`\n",
    "- VersÃ£o do cÃ³digo: `{versao_bloco1}`\n",
    "\"\"\"\n",
    "\n",
    "    readme_path = pasta_base / 'README.md'\n",
    "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    print(f\"ğŸ“– README: {readme_path.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUÃ‡ÃƒO PRINCIPAL DO BLOCO 1\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 1: SELECIONANDO PASTA DESTINO...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor = SeletorPastaComTimer()\n",
    "resultado_destino = seletor.selecionar_com_timer()\n",
    "\n",
    "if not resultado_destino['path']:\n",
    "    print(\"âŒ Nenhuma pasta selecionada\")\n",
    "    raise ValueError(\"ExecuÃ§Ã£o cancelada\")\n",
    "\n",
    "print(f\"\\nâœ… Destino: {resultado_destino['path']}\")\n",
    "print(f\"   AÃ§Ã£o: {resultado_destino['acao']}\")\n",
    "seletor.salvar_escolha(resultado_destino['path'])\n",
    "\n",
    "pasta_root_destino = resultado_destino['path']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 2: VERIFICANDO POLUIÃ‡ÃƒO NO ROOT...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "limpador = LimpadorRoot(pasta_root_destino)\n",
    "pastas_poluidas = limpador.detectar_poluicao()\n",
    "\n",
    "acao = None\n",
    "if pastas_poluidas:\n",
    "    print(f\"\\nâš ï¸  {len(pastas_poluidas)} pastas antigas no root!\")\n",
    "    acao = limpador.perguntar_limpeza(pastas_poluidas)\n",
    "\n",
    "    if acao == 'DELETAR':\n",
    "        print(\"\\nğŸ—‘ï¸  Deletando...\")\n",
    "        for pasta in pastas_poluidas:\n",
    "            try:\n",
    "                shutil.rmtree(pasta)\n",
    "                print(f\"   âœ… {pasta.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {pasta.name}: {e}\")\n",
    "\n",
    "    elif acao == 'MOVER':\n",
    "        print(\"\\nğŸ“¦ Mover serÃ¡ feito apÃ³s criar container\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nâ­ï¸  Ignorando pastas antigas\")\n",
    "else:\n",
    "    print(\"âœ… Root limpo\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 3: CRIANDO PASTA CONTAINER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "nome_container = f\"PROCESSAR_ARQUIVOS_{timestamp}\"\n",
    "pasta_container = pasta_root_destino / nome_container\n",
    "\n",
    "pasta_container.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Container: {nome_container}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 4: COPIAR DE EXECUÃ‡ÃƒO ANTERIOR?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor_origem = SeletorOrigemComTimer()\n",
    "resultado_origem = seletor_origem.perguntar_origem()\n",
    "\n",
    "dicionarios_migrados = []\n",
    "info_mig = {}\n",
    "\n",
    "if resultado_origem['copiar'] and resultado_origem['path']:\n",
    "    print(f\"\\nğŸ“‚ Origem: {resultado_origem['path']}\")\n",
    "    gerenciador_mig = GerenciadorMigracao(\n",
    "        resultado_origem['path'],\n",
    "        pasta_container\n",
    "    )\n",
    "    info_mig = gerenciador_mig.copiar_tudo()\n",
    "\n",
    "    if info_mig.get('migrado'):\n",
    "        print(f\"\\nâœ… MigraÃ§Ã£o concluÃ­da\")\n",
    "        if info_mig.get('dicionarios'):\n",
    "            dicionarios_migrados = info_mig['dicionarios']\n",
    "            print(f\"   ğŸ“š {len(dicionarios_migrados)} dicionÃ¡rios copiados\")\n",
    "        if info_mig.get('erros'):\n",
    "            print(f\"   âš ï¸  {len(info_mig['erros'])} erros (ver log)\")\n",
    "else:\n",
    "    print(\"âœ… ComeÃ§ando do zero (sem cÃ³pia)\")\n",
    "\n",
    "# Mover pastas antigas se solicitado\n",
    "if pastas_poluidas and acao == 'MOVER':\n",
    "    print(\"\\nğŸ“¦ Movendo pastas antigas para container...\")\n",
    "    for pasta in pastas_poluidas:\n",
    "        try:\n",
    "            destino = pasta_container / pasta.name\n",
    "            if destino.exists():\n",
    "                shutil.rmtree(destino)\n",
    "            shutil.move(str(pasta), str(destino))\n",
    "            print(f\"   âœ… {pasta.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ {pasta.name}: {e}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 5: INICIALIZANDO FILEMANAGER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fm = FileManagerInterativo(pasta_container)\n",
    "\n",
    "# Detectar dicionÃ¡rio migrado (se existir)\n",
    "pasta_dict = fm.pastas['dicionarios']\n",
    "arquivos_dict = list(pasta_dict.glob('*.json'))\n",
    "\n",
    "dicionario_existente = None\n",
    "if arquivos_dict:\n",
    "    # Usar o mais recente\n",
    "    dicionario_existente = max(\n",
    "        arquivos_dict,\n",
    "        key=lambda p: p.stat().st_mtime\n",
    "    )\n",
    "    print(f\"ğŸ“š DicionÃ¡rio detectado: {dicionario_existente.name}\")\n",
    "\n",
    "# Registrar no localizador com timestamp E versÃ£o\n",
    "LocalizadorDicionario.registrar_mudanca(\n",
    "    pasta_base=pasta_container,\n",
    "    timestamp=timestamp,\n",
    "    dicionario_path=dicionario_existente,  # None se nÃ£o existir\n",
    "    versao_bloco1=VERSAO_BLOCO1\n",
    ")\n",
    "\n",
    "# Gerar README\n",
    "gerar_readme(pasta_container, VERSAO_BLOCO1)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIA 1: SALVAR ESTADO LOCAL (NOVO v4.4)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 6: SALVANDO ESTADO LOCAL...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calcular tamanho total do container\n",
    "tamanho_total = sum(\n",
    "    f.stat().st_size for f in pasta_container.rglob('*') if f.is_file()\n",
    ") / 1024 / 1024\n",
    "\n",
    "estado_bloco1 = {\n",
    "    'bloco': 1,\n",
    "    'versao': VERSAO_BLOCO1,\n",
    "    'versao_codigo': VERSAO_BLOCO1,\n",
    "    'data_versao': DATA_VERSAO,\n",
    "    'timestamp_execucao': timestamp,\n",
    "    'timestamp_registro': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'pasta_container': {\n",
    "        'nome': pasta_container.name,\n",
    "        'caminho': str(pasta_container),\n",
    "        'tamanho_mb': round(tamanho_total, 2)\n",
    "    },\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp,\n",
    "        'pastas_criadas': list(fm.pastas.keys())\n",
    "    },\n",
    "    'migracao': {\n",
    "        'realizada': resultado_origem.get('copiar', False),\n",
    "        'arquivos_migrados': info_mig.get('arquivos', 0),\n",
    "        'pasta_origem': str(resultado_origem.get('path', '')) if resultado_origem.get('copiar') else None\n",
    "    },\n",
    "    'localizador': {\n",
    "        'log_file': str(LocalizadorDicionario.LOG_FILE),\n",
    "        'pasta_base_registrada': str(pasta_container),\n",
    "        'timestamp_registrado': timestamp,\n",
    "        'dicionario_registrado': str(dicionario_existente) if dicionario_existente else None\n",
    "    },\n",
    "    'poluicao_root': {\n",
    "        'detectada': len(pastas_poluidas) if pastas_poluidas else 0,\n",
    "        'acao_tomada': acao if pastas_poluidas else 'NENHUMA'\n",
    "    },\n",
    "    'changelog': CHANGELOG_V44\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_1_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco1, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Estado local salvo\")\n",
    "print(f\"   ğŸ“„ {arquivo_estado.name}\")\n",
    "print(f\"   ğŸ“Š Tamanho container: {tamanho_total:.2f} MB\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 1 v4.4 CONCLUÃDO COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“‚ Container: {pasta_container}\")\n",
    "print(f\"ğŸ• Timestamp: {timestamp}\")\n",
    "print(f\"ğŸ“ Localizador: {LocalizadorDicionario.LOG_FILE}\")\n",
    "print(f\"ğŸ”– VersÃ£o: {VERSAO_BLOCO1}\")\n",
    "print(f\"\\nğŸ“‹ Estrutura criada:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   â€¢ {pasta.name}\")\n",
    "print(f\"\\nğŸ’¾ Arquivos de estado:\")\n",
    "print(f\"   â€¢ LOG GLOBAL: {LocalizadorDicionario.LOG_FILE.name}\")\n",
    "print(f\"   â€¢ Estado local: {arquivo_estado.name}\")\n",
    "print(f\"   â€¢ README: README.md\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nğŸ’¡ PrÃ³ximo: BLOCO 2 vai ler configuraÃ§Ã£o do LOG GLOBAL\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a370b26a4e017376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " ğŸ” PROCESSADOR DE ARQUIVOS DESCONHECIDOS v4.4\n",
      "======================================================================\n",
      " VersÃ£o: 4.4 | Data: 2025-10-17\n",
      " Timer | MigraÃ§Ã£o | DicionÃ¡rios | ValidaÃ§Ãµes | Logs | Estado\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Validando dependÃªncias...\n",
      "   âœ… pandas\n",
      "   âœ… numpy\n",
      "   âœ… openpyxl\n",
      "   âœ… xlrd\n",
      "   âœ… tkinter\n",
      "âœ… Todas as dependÃªncias instaladas!\n",
      "\n",
      "âœ… Imports carregados\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 1: SELECIONANDO PASTA DESTINO...\n",
      "======================================================================\n",
      "\n",
      "âœ… Destino: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\n",
      "   AÃ§Ã£o: MANTEVE\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 2: VERIFICANDO POLUIÃ‡ÃƒO NO ROOT...\n",
      "======================================================================\n",
      "âœ… Root limpo\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 3: CRIANDO PASTA CONTAINER...\n",
      "======================================================================\n",
      "âœ… Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 4: COPIAR DE EXECUÃ‡ÃƒO ANTERIOR?\n",
      "======================================================================\n",
      "âœ… ComeÃ§ando do zero (sem cÃ³pia)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 5: INICIALIZANDO FILEMANAGER...\n",
      "======================================================================\n",
      "âœ… FileManager inicializado\n",
      "   ğŸ“‚ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   ğŸ• Timestamp: 20251019_060722\n",
      "\n",
      "ğŸ“ Localizador atualizado:\n",
      "   Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   Timestamp: 20251019_060722\n",
      "   VersÃ£o BLOCO 1: 4.4\n",
      "   Log: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "ğŸ“– README: README.md\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 6: SALVANDO ESTADO LOCAL...\n",
      "======================================================================\n",
      "âœ… Estado local salvo\n",
      "   ğŸ“„ .bloco_1_state.json\n",
      "   ğŸ“Š Tamanho container: 0.00 MB\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 1 v4.4 CONCLUÃDO COM SUCESSO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Container: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "ğŸ• Timestamp: 20251019_060722\n",
      "ğŸ“ Localizador: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "ğŸ”– VersÃ£o: 4.4\n",
      "\n",
      "ğŸ“‹ Estrutura criada:\n",
      "   â€¢ 01_Entrada\n",
      "   â€¢ 02_Processados\n",
      "   â€¢ 03_Outputs\n",
      "   â€¢ 04_Logs\n",
      "   â€¢ 05_Dicionarios\n",
      "   â€¢ 06_Codigos_Integracao\n",
      "\n",
      "ğŸ’¾ Arquivos de estado:\n",
      "   â€¢ LOG GLOBAL: .processador_dicionario_localizador.json\n",
      "   â€¢ Estado local: .bloco_1_state.json\n",
      "   â€¢ README: README.md\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 2 vai ler configuraÃ§Ã£o do LOG GLOBAL\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:25.354236Z",
     "start_time": "2025-10-19T09:07:25.303878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 2: CLASSES AUXILIARES\n",
    "# Versao: 4.3 - REVISADO (COMUNICACAO VIA LOG COMPLETA)\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: LocalizadorDicionario (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localizacao persistente de dicionarios entre\n",
    "    sessoes.\n",
    "\n",
    "    Mantem log global em: ~/.processador_dicionario_localizador.json\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.0',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicionario atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Dicionario nao encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Dicionario nao existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Pasta base nao encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Pasta base nao existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: FileManagerInterativo (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "\n",
    "        # Estrutura de pastas padrao\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = self.pastas[pasta] / f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"Nao foi possivel abrir pasta: {e}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: SeletorArquivo (GUI COM TIMER E VALIDACOES)\n",
    "# ===================================================================\n",
    "\n",
    "class SeletorArquivo:\n",
    "    \"\"\"Seletor de arquivo com timer de 10s e validacoes robustas\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_file.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultimo_arquivo(self):\n",
    "        \"\"\"Carrega ultimo arquivo usado\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultimo_arquivo = Path(config.get('last_file', ''))\n",
    "                if ultimo_arquivo.exists():\n",
    "                    return ultimo_arquivo\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, arquivo):\n",
    "        \"\"\"Salva escolha para proxima execucao\"\"\"\n",
    "        config = {\n",
    "            'last_file': str(arquivo),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_arquivo(self, arquivo_path):\n",
    "        \"\"\"Valida se arquivo e adequado para processamento\"\"\"\n",
    "        arquivo = Path(arquivo_path)\n",
    "\n",
    "        # Verificar existencia\n",
    "        if not arquivo.exists():\n",
    "            return False, \"Arquivo nao existe\"\n",
    "\n",
    "        # Verificar se e arquivo (nao diretorio)\n",
    "        if not arquivo.is_file():\n",
    "            return False, \"Nao e um arquivo\"\n",
    "\n",
    "        # Verificar permissao de leitura\n",
    "        if not os.access(arquivo, os.R_OK):\n",
    "            return False, \"Sem permissao de leitura\"\n",
    "\n",
    "        # Verificar tamanho (maximo 500MB)\n",
    "        tamanho_mb = arquivo.stat().st_size / (1024 * 1024)\n",
    "        if tamanho_mb > 500:\n",
    "            return False, f\"Arquivo muito grande ({tamanho_mb:.1f}MB)\"\n",
    "\n",
    "        # Verificar extensao\n",
    "        extensoes_validas = {'.xlsx', '.xls', '.csv', '.txt'}\n",
    "        if arquivo.suffix.lower() not in extensoes_validas:\n",
    "            return False, f\"Extensao invalida ({arquivo.suffix})\"\n",
    "\n",
    "        return True, \"Arquivo valido\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultimo_arquivo = self.carregar_ultimo_arquivo()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Selecionar Arquivo\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Titulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecionar Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultimo_arquivo:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultimo_arquivo.name}\"\n",
    "        else:\n",
    "            msg = \"Primeira execucao - selecione arquivo\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [15]\n",
    "        if ultimo_arquivo:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # Botoes\n",
    "        def escolher_novo():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "\n",
    "            novo_arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecionar Arquivo\",\n",
    "                initialdir=ultimo_arquivo.parent if ultimo_arquivo else None,\n",
    "                filetypes=[\n",
    "                    (\"Arquivos suportados\", \"*.xlsx;*.xls;*.csv;*.txt\"),\n",
    "                    (\"Excel\", \"*.xlsx;*.xls\"),\n",
    "                    (\"CSV\", \"*.csv\"),\n",
    "                    (\"Todos\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if novo_arquivo:\n",
    "                valido, msg = self.validar_arquivo(novo_arquivo)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Arquivo Invalido\", msg)\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(novo_arquivo)\n",
    "                    self.resultado['acao'] = 'NOVO'\n",
    "            else:\n",
    "                self.resultado['path'] = ultimo_arquivo\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultimo():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultimo_arquivo\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultimo_arquivo:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"Usar Ultimo\",\n",
    "                command=usar_ultimo,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: DetectorCabecalho (ANALISE INTELIGENTE COM LOG)\n",
    "# ===================================================================\n",
    "\n",
    "class DetectorCabecalho:\n",
    "    \"\"\"\n",
    "    Detecta automaticamente a linha de cabecalho em arquivos.\n",
    "\n",
    "    Usa sistema de scoring baseado em:\n",
    "    - Preenchimento (70%+ colunas com dados)\n",
    "    - Tipo String (80%+ colunas texto)\n",
    "    - Valores unicos (indicador de rotulos)\n",
    "    - Palavras-chave tipicas de cabecalho\n",
    "    - Posicao na planilha (primeiras linhas tem prioridade)\n",
    "    \"\"\"\n",
    "\n",
    "    # CONFIGURACAO EXTERNALIZAVEL\n",
    "    PALAVRAS_CHAVE_PADRAO = [\n",
    "        'codigo', 'nome', 'descri', 'data', 'valor', 'quantidade',\n",
    "        'centro', 'produto', 'material', 'sigla', 'tipo', 'grupo'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, df, palavras_chave=None):\n",
    "        self.df = df\n",
    "        self.scores = []\n",
    "        self.log_decisoes = []\n",
    "        self.palavras_chave = (\n",
    "            palavras_chave if palavras_chave\n",
    "            else self.PALAVRAS_CHAVE_PADRAO\n",
    "        )\n",
    "\n",
    "    def detectar(self, n_linhas=50):\n",
    "        \"\"\"\n",
    "        Analisa primeiras n linhas e retorna indice do cabecalho.\n",
    "\n",
    "        Args:\n",
    "            n_linhas: Numero de linhas a analisar\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                'indice': int,  # Linha detectada como cabecalho\n",
    "                'score': float,  # Confianca da deteccao (0-1)\n",
    "                'metodo': str,   # Como foi detectado\n",
    "                'scores_todas_linhas': list,  # Para debug\n",
    "                'log_decisoes': list  # Historico de analise\n",
    "            }\n",
    "        \"\"\"\n",
    "        n_linhas = min(n_linhas, len(self.df))\n",
    "\n",
    "        for i in range(n_linhas):\n",
    "            linha = self.df.iloc[i]\n",
    "            score = 0\n",
    "            detalhes = {'linha': i, 'criterios': {}}\n",
    "\n",
    "            # Criterio 1: Preenchimento (30 pontos)\n",
    "            preenchimento = linha.notna().sum() / len(linha)\n",
    "            if preenchimento >= 0.7:\n",
    "                pontos = 30 * (preenchimento - 0.7) / 0.3\n",
    "                score += pontos\n",
    "                detalhes['criterios']['preenchimento'] = (\n",
    "                    f\"{preenchimento:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 2: Tipo String (30 pontos)\n",
    "            tipos_string = sum(isinstance(v, str) for v in linha)\n",
    "            proporcao_string = tipos_string / len(linha)\n",
    "            if proporcao_string >= 0.8:\n",
    "                pontos = 30 * (proporcao_string - 0.8) / 0.2\n",
    "                score += pontos\n",
    "                detalhes['criterios']['strings'] = (\n",
    "                    f\"{proporcao_string:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 3: Valores unicos (20 pontos)\n",
    "            valores_unicos = len(\n",
    "                set(str(v) for v in linha if pd.notna(v))\n",
    "            )\n",
    "            if valores_unicos >= len(linha) * 0.8:\n",
    "                pontos = 20\n",
    "                score += pontos\n",
    "                detalhes['criterios']['unicos'] = (\n",
    "                    f\"{valores_unicos}/{len(linha)} (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 4: Palavras-chave (10 pontos)\n",
    "            texto_linha = ' '.join(\n",
    "                str(v).lower() for v in linha if pd.notna(v)\n",
    "            )\n",
    "            palavras_encontradas = sum(\n",
    "                1 for p in self.palavras_chave if p in texto_linha\n",
    "            )\n",
    "            if palavras_encontradas > 0:\n",
    "                pontos = min(10, palavras_encontradas * 3)\n",
    "                score += pontos\n",
    "                detalhes['criterios']['palavras'] = (\n",
    "                    f\"{palavras_encontradas} palavras (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 5: Posicao (10 pontos)\n",
    "            # Primeiras linhas tem vantagem\n",
    "            if i < 50:\n",
    "                pontos = 10 * (1 - (i / 50))\n",
    "                score += pontos\n",
    "                detalhes['criterios']['posicao'] = (\n",
    "                    f\"linha {i} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            detalhes['score_total'] = score\n",
    "            self.scores.append(score)\n",
    "            self.log_decisoes.append(detalhes)\n",
    "\n",
    "        # Encontrar melhor score\n",
    "        melhor_indice = self.scores.index(max(self.scores))\n",
    "        melhor_score = self.scores[melhor_indice]\n",
    "\n",
    "        # Normalizar score para 0-1\n",
    "        score_normalizado = min(1.0, melhor_score / 100)\n",
    "\n",
    "        resultado = {\n",
    "            'indice': melhor_indice,\n",
    "            'score': score_normalizado,\n",
    "            'metodo': 'SCORING_AUTOMATICO',\n",
    "            'scores_todas_linhas': self.scores,\n",
    "            'log_decisoes': self.log_decisoes\n",
    "        }\n",
    "\n",
    "        return resultado\n",
    "\n",
    "# ===================================================================\n",
    "# INICIALIZACAO DO FILEMANAGER (CONECTANDO COM BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "    print(f\"Container do BLOCO 1 encontrado!\")\n",
    "    print(f\"   {pasta_base}\")\n",
    "\n",
    "    fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n{e}\")\n",
    "    print(\"\\nATENCAO: Execute o BLOCO 1 primeiro!\")\n",
    "    raise\n",
    "\n",
    "# ===================================================================\n",
    "# SALVAR ESTADO DO BLOCO 2 NO LOG\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco2 = {\n",
    "    'bloco': 2,\n",
    "    'versao': '4.3',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'classes_carregadas': [\n",
    "        'LocalizadorDicionario',\n",
    "        'FileManagerInterativo',\n",
    "        'SeletorArquivo',\n",
    "        'DetectorCabecalho'\n",
    "    ],\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_2_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco2, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2 CONCLUIDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nClasses carregadas:\")\n",
    "print(\"   LocalizadorDicionario ........... OK\")\n",
    "print(\"   FileManagerInterativo ........... OK\")\n",
    "print(\"   SeletorArquivo .................. OK\")\n",
    "print(\"   DetectorCabecalho ............... OK\")\n",
    "print(\"\\nFileManager ativo:\")\n",
    "print(f\"   Base: {fm.base_path}\")\n",
    "print(f\"   Timestamp: {fm.timestamp}\")\n",
    "print(\"\\nEstrutura de pastas:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   {nome.ljust(20)}: {pasta.name}\")\n",
    "print(\"\\nEstado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\")\n",
    "print(\"=\"*70)"
   ],
   "id": "edd92dbd01fb89e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\n",
      "======================================================================\n",
      "Container do BLOCO 1 encontrado!\n",
      "   E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "======================================================================\n",
      "BLOCO 2 CONCLUIDO\n",
      "======================================================================\n",
      "\n",
      "Classes carregadas:\n",
      "   LocalizadorDicionario ........... OK\n",
      "   FileManagerInterativo ........... OK\n",
      "   SeletorArquivo .................. OK\n",
      "   DetectorCabecalho ............... OK\n",
      "\n",
      "FileManager ativo:\n",
      "   Base: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   Timestamp: 20251019_060725\n",
      "\n",
      "Estrutura de pastas:\n",
      "   entrada             : 01_Entrada\n",
      "   processados         : 02_Processados\n",
      "   outputs             : 03_Outputs\n",
      "   logs                : 04_Logs\n",
      "   dicionarios         : 05_Dicionarios\n",
      "   codigos_integracao  : 06_Codigos_Integracao\n",
      "\n",
      "Estado salvo:\n",
      "   .bloco_2_state.json\n",
      "\n",
      "======================================================================\n",
      "Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:31.733679Z",
     "start_time": "2025-10-19T09:07:31.693651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 3: DICIONÃRIO INTELIGENTE + CLASSE GUI COM TIMER\n",
    "# VersÃ£o: v4.5 - DicionÃ¡rio + GUIComTimer (seleÃ§Ã£o no BLOCO 4)\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tkinter as tk\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 3: DICIONÃRIO INTELIGENTE + GUI COM TIMER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. LER CONFIGURAÃ‡Ã•ES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# ===================================================================\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ LOG GLOBAL nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\")\n",
    "print(f\"   ğŸ“ Pasta base: {pasta_base.name}\")\n",
    "print(f\"   ğŸ• Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. VALIDAR QUE BLOCO 2 FOI EXECUTADO\n",
    "# ===================================================================\n",
    "\n",
    "log_bloco2 = pasta_base / '04_Logs' / '.bloco_2_state.json'\n",
    "\n",
    "if not log_bloco2.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ BLOCO 2 nÃ£o foi executado!\\n\"\n",
    "        \"   Execute BLOCO 2 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_bloco2, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco2 = json.load(f)\n",
    "\n",
    "print(f\"\\nâœ… BLOCO 2 VALIDADO\")\n",
    "print(f\"   Executado em: {estado_bloco2['timestamp']}\")\n",
    "print(f\"   Classes: {', '.join(estado_bloco2['classes_carregadas'])}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. RECRIAR FILEMANAGER (NÃƒO ASSUMIR MEMÃ“RIA)\n",
    "# ===================================================================\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "print(f\"\\nâœ… FileManager recriado: {fm.base_path.name}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4. CLASSE GUI COM TIMER (ex-BLOCO 4)\n",
    "# ===================================================================\n",
    "\n",
    "class GUIComTimer:\n",
    "    \"\"\"Implementa timer de 10s com countdown visual\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_janela_com_timer(titulo, largura, altura, tem_timer=True):\n",
    "        \"\"\"Cria janela base com timer\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(titulo)\n",
    "        root.geometry(f\"{largura}x{altura}\")\n",
    "        root.resizable(False, False)\n",
    "\n",
    "        # Centralizar\n",
    "        x = (root.winfo_screenwidth() // 2) - (largura // 2)\n",
    "        y = (root.winfo_screenheight() // 2) - (altura // 2)\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "        root.attributes('-topmost', True)\n",
    "        root.after(100, lambda: root.attributes('-topmost', False))\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        resultado = {'valor': None, 'cancelado': False, 'timeout': False}\n",
    "        contador = [10] if tem_timer else [0]\n",
    "\n",
    "        return root, frame, resultado, contador\n",
    "\n",
    "    @staticmethod\n",
    "    def adicionar_timer(frame, root, resultado, contador):\n",
    "        \"\"\"Adiciona timer visual\"\"\"\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"â±ï¸  {contador[0]}s\",\n",
    "            font=('Arial', 16, 'bold'),\n",
    "            fg='#FF4444',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 15))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not resultado['cancelado']:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"â±ï¸  {contador[0]}s\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0 and not resultado['cancelado']:\n",
    "                resultado['timeout'] = True\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        return countdown\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_botoes(frame, cmd_principal, cmd_secundario=None,\n",
    "                     label_principal=\"Confirmar\",\n",
    "                     label_secundario=\"Usar Ãšltimo\"):\n",
    "        \"\"\"Cria botÃµes padronizados\"\"\"\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(\n",
    "            fill=tk.X, pady=10\n",
    "        )\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=label_principal,\n",
    "            command=cmd_principal,\n",
    "            width=18,\n",
    "            height=2,\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        if cmd_secundario:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=label_secundario,\n",
    "                command=cmd_secundario,\n",
    "                width=18,\n",
    "                height=2,\n",
    "                bg='#2196F3',\n",
    "                fg='white',\n",
    "                font=('Arial', 10),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "print(\"\\nâœ… Classe GUIComTimer carregada\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. DICIONÃRIO INTELIGENTE\n",
    "# ===================================================================\n",
    "\n",
    "class DicionarioInteligente:\n",
    "    \"\"\"DicionÃ¡rio com detecÃ§Ã£o avanÃ§ada\"\"\"\n",
    "\n",
    "    def __init__(self, fm):\n",
    "        self.fm = fm\n",
    "        self.arquivo_dict = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "        self.dados = self._carregar_ou_criar()\n",
    "\n",
    "    def _carregar_ou_criar(self):\n",
    "        if self.arquivo_dict.exists():\n",
    "            try:\n",
    "                with open(self.arquivo_dict, 'r', encoding='utf-8') as f:\n",
    "                    dados = json.load(f)\n",
    "\n",
    "                if 'campos_conhecidos' not in dados:\n",
    "                    dados = self._migrar_formato_antigo(dados)\n",
    "                    self._salvar(dados)\n",
    "\n",
    "                n_campos = len(dados['campos_conhecidos'])\n",
    "                n_arquivos = len(dados.get('historico_arquivos', []))\n",
    "\n",
    "                print(f\"\\nâœ… DICIONÃRIO PERSISTENTE CARREGADO\")\n",
    "                print(f\"   ğŸ“š {n_campos} campos conhecidos\")\n",
    "                print(f\"   ğŸ“ {n_arquivos} arquivos processados\")\n",
    "\n",
    "                return dados\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nâš ï¸  Erro ao carregar: {e}\")\n",
    "                print(\"   Criando novo dicionÃ¡rio...\")\n",
    "                dados = self._criar_novo()\n",
    "                self._salvar(dados)\n",
    "                return dados\n",
    "        else:\n",
    "            print(f\"\\nğŸ“ CRIANDO NOVO DICIONÃRIO...\")\n",
    "            dados = self._criar_novo()\n",
    "            self._salvar(dados)\n",
    "            print(f\"âœ… DicionÃ¡rio criado: {len(dados['campos_conhecidos'])} campos\")\n",
    "            return dados\n",
    "\n",
    "    def _migrar_formato_antigo(self, dados_antigos):\n",
    "        novo = self._criar_novo()\n",
    "        if 'arquivos_processados' in dados_antigos:\n",
    "            novo['historico_arquivos'] = dados_antigos['arquivos_processados']\n",
    "        return novo\n",
    "\n",
    "    def _criar_novo(self):\n",
    "        \"\"\"DicionÃ¡rio com 22 campos padrÃ£o\"\"\"\n",
    "        return {\n",
    "            'versao': '4.5',\n",
    "            'criado_em': datetime.now().isoformat(),\n",
    "            'ultima_atualizacao': datetime.now().isoformat(),\n",
    "            'config_sistema': {\n",
    "                'timeout_sessao_minutos': 60,\n",
    "                'padroes_csv_detectados': []\n",
    "            },\n",
    "            'campos_conhecidos': {\n",
    "                'Centro': {\n",
    "                    'tipo_dado': 'Codigo_Centro',\n",
    "                    'regex': r'^[5-9]\\d{3}$',\n",
    "                    'sinonimos': ['Centro', 'CÃ³digo de Centro', 'Cod Centro',\n",
    "                                  'Unidade Operacional:Centro'],\n",
    "                    'exemplos': ['5025', '5065', '5174'],\n",
    "                    'descricao': 'CÃ³digo numÃ©rico de 4 dÃ­gitos',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla': {\n",
    "                    'tipo_dado': 'Sigla_Base',\n",
    "                    'regex': r'^[A-Z]{4,10}$',\n",
    "                    'sinonimos': ['Sigla', 'Sigla Base', 'Sigla Centro', 'Base'],\n",
    "                    'exemplos': ['BABET', 'BAPLAN', 'AIBET'],\n",
    "                    'descricao': 'Sigla alfabÃ©tica (4-10 letras maiÃºsculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Material',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$',\n",
    "                    'sinonimos': ['CÃ³digo Produto', 'CÃ³digo Material',\n",
    "                                  'Cod Produto', 'Cod Material'],\n",
    "                    'exemplos': ['10.123.456', '1.234.567', '1234567'],\n",
    "                    'descricao': 'CÃ³digo numÃ©rico do material/produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Grupo',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$|^[A-Z_]+$',\n",
    "                    'sinonimos': ['CÃ³d Grupo de produto', 'CÃ³digo Grupo',\n",
    "                                  'Grupo Produto', 'Produto:CodGrupoProduto'],\n",
    "                    'exemplos': ['10.123.456', 'DIESEL_S10_SIMPLES',\n",
    "                                 'GASOLINA_COMUM'],\n",
    "                    'descricao': 'CÃ³digo grupo (numÃ©rico OU texto_underscore)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Desc_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Texto_Descricao',\n",
    "                    'regex': r'^[A-Za-z0-9\\s\\-]+$',\n",
    "                    'sinonimos': ['Desc. Grupo de Produto', 'DescriÃ§Ã£o Produto',\n",
    "                                  'Nome Produto', 'Produto'],\n",
    "                    'exemplos': ['DIESEL S10', 'GASOLINA COMUM',\n",
    "                                 'ETANOL HIDRATADO'],\n",
    "                    'descricao': 'DescriÃ§Ã£o textual do grupo de produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Nome_Pessoa': {\n",
    "                    'tipo_dado': 'Texto_Nome_Pessoa',\n",
    "                    'regex': r'^[A-ZÃÃ€Ã‚ÃƒÃ‰ÃˆÃŠÃÃÃ“Ã”Ã•Ã–ÃšÃ‡Ã‘][a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]+(\\s[A-ZÃÃ€Ã‚ÃƒÃ‰ÃˆÃŠÃÃÃ“Ã”Ã•Ã–ÃšÃ‡Ã‘][a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]+)+$',\n",
    "                    'sinonimos': ['Criado por', 'Nome', 'ResponsÃ¡vel',\n",
    "                                  'Solicitante'],\n",
    "                    'exemplos': ['Kenedy VinÃ­cius Rodrigues',\n",
    "                                 'Joao Carlos Stival'],\n",
    "                    'descricao': 'Nome completo de pessoa',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Email': {\n",
    "                    'tipo_dado': 'Texto_Email',\n",
    "                    'regex': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n",
    "                    'sinonimos': ['Email', 'E-mail', 'Modificado por'],\n",
    "                    'exemplos': ['usuario@vibraenergia.com.br'],\n",
    "                    'descricao': 'EndereÃ§o de email',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Status_Workflow': {\n",
    "                    'tipo_dado': 'Texto_Status',\n",
    "                    'regex': r'^(Em aprovaÃ§Ã£o|Aprovado|Rejeitado|Pendente|ConcluÃ­do|Ãtem Criado|Item Criado)$',\n",
    "                    'sinonimos': ['Status', 'Status AprovaÃ§Ã£o', 'SituaÃ§Ã£o'],\n",
    "                    'exemplos': ['Em aprovaÃ§Ã£o', 'Ãtem Criado', 'Aprovado'],\n",
    "                    'descricao': 'Status de workflow/aprovaÃ§Ã£o',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Booleano_Texto': {\n",
    "                    'tipo_dado': 'Texto_Booleano',\n",
    "                    'regex': r'^(Sim|NÃ£o|sim|nÃ£o|SIM|NÃƒO|Yes|No|TRUE|FALSE)$',\n",
    "                    'sinonimos': ['ConcluÃ­do?', 'Ativo?', 'Habilitado?'],\n",
    "                    'exemplos': ['Sim', 'NÃ£o'],\n",
    "                    'descricao': 'Valor booleano como texto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Texto_Longo': {\n",
    "                    'tipo_dado': 'Texto_Justificativa',\n",
    "                    'regex': r'^.{50,}$',\n",
    "                    'sinonimos': ['Justificativa', 'ObservaÃ§Ã£o', 'ComentÃ¡rio'],\n",
    "                    'exemplos': ['Solicitamos a revisÃ£o do limite...'],\n",
    "                    'descricao': 'Texto longo (mais de 50 caracteres)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Path_URL': {\n",
    "                    'tipo_dado': 'Texto_Caminho',\n",
    "                    'regex': r'^(teams/|http|https|ftp|\\\\\\\\|/).*',\n",
    "                    'sinonimos': ['Caminho', 'Path', 'URL', 'Link'],\n",
    "                    'exemplos': ['teams/portaleso/Lists/...',\n",
    "                                 'https://example.com'],\n",
    "                    'descricao': 'Caminho de arquivo ou URL',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla_Curta': {\n",
    "                    'tipo_dado': 'Texto_Sigla_Curta',\n",
    "                    'regex': r'^[A-Z]{2,4}$',\n",
    "                    'sinonimos': ['CME', 'GerÃªncia', 'UF', 'Tipo'],\n",
    "                    'exemplos': ['OPC', 'OPN', 'Norte', 'Sul', 'CME'],\n",
    "                    'descricao': 'Sigla curta (2-4 letras maiÃºsculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Tipo_Item': {\n",
    "                    'tipo_dado': 'Texto_Tipo_Item',\n",
    "                    'regex': r'^(Item|Documento|Pasta|Arquivo)$',\n",
    "                    'sinonimos': ['Tipo de Item', 'Tipo'],\n",
    "                    'exemplos': ['Item'],\n",
    "                    'descricao': 'Tipo de item em lista SharePoint',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_ISO': {\n",
    "                    'tipo_dado': 'Data_YYYY-MM-DD',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}$',\n",
    "                    'sinonimos': ['Data', 'PerÃ­odo',\n",
    "                                  'PerÃ­odo InÃ­cio Validade Novo Limite'],\n",
    "                    'exemplos': ['2025-08-01', '2024-12-31', '2025-01-07'],\n",
    "                    'descricao': 'Data formato ISO (YYYY-MM-DD)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Datetime_ISO': {\n",
    "                    'tipo_dado': 'Datetime_YYYY-MM-DD_HH:MM:SS',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}$',\n",
    "                    'sinonimos': ['Criado', 'Modificado', 'Data Hora',\n",
    "                                  'Timestamp'],\n",
    "                    'exemplos': ['2025-08-04 19:22:17',\n",
    "                                 '2025-08-04 20:45:37'],\n",
    "                    'descricao': 'Data e hora formato ISO',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_BR': {\n",
    "                    'tipo_dado': 'Data_DD/MM/YYYY',\n",
    "                    'regex': r'^\\d{2}/\\d{2}/\\d{4}$',\n",
    "                    'sinonimos': ['Data'],\n",
    "                    'exemplos': ['15/01/2024', '31/12/2025'],\n",
    "                    'descricao': 'Data formato brasileiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Decimal': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Decimal',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?$',\n",
    "                    'sinonimos': ['Limite Inferior Atual',\n",
    "                                  'Limite Superior Atual', 'AVG VI %',\n",
    "                                  '% VI', 'AVG VI % 2024 SAP'],\n",
    "                    'exemplos': ['-0.08', '0.08', '-0.14', '0.05', '-0.03'],\n",
    "                    'descricao': 'Percentual em decimal (pode ser negativo)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Com_Simbolo': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Simbolo',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?%$',\n",
    "                    'sinonimos': ['Percentual', '% VI'],\n",
    "                    'exemplos': ['10.5%', '-5.2%', '100%'],\n",
    "                    'descricao': 'Percentual com sÃ­mbolo %',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Numero_Inteiro': {\n",
    "                    'tipo_dado': 'Numero_Inteiro',\n",
    "                    'regex': r'^-?\\d+$',\n",
    "                    'sinonimos': ['Quantidade', 'Qtd', 'Total'],\n",
    "                    'exemplos': ['123', '-456', '1000'],\n",
    "                    'descricao': 'NÃºmero inteiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Monetario': {\n",
    "                    'tipo_dado': 'Numero_Monetario',\n",
    "                    'regex': r'^R\\$\\s?-?\\d{1,3}(\\.\\d{3})*(,\\d{2})?$|^-?\\d+([.,]\\d{2})?$',\n",
    "                    'sinonimos': ['Valor', 'Custo', 'PreÃ§o', 'R$'],\n",
    "                    'exemplos': ['R$ 1.234,56', '1234.56'],\n",
    "                    'descricao': 'Valor monetÃ¡rio',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Unidade_Operacional_Nome': {\n",
    "                    'tipo_dado': 'Texto_Unidade_Operacional',\n",
    "                    'regex': r'^[A-Z]{4,10}\\s+Base\\s+de\\s+.+$',\n",
    "                    'sinonimos': ['Unidade Operacional', 'Nome Base'],\n",
    "                    'exemplos': ['BABET Base de Betim',\n",
    "                                 'BAPLAN Base de PaulÃ­nia'],\n",
    "                    'descricao': 'Nome completo da unidade operacional',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Rotulo_Retencao': {\n",
    "                    'tipo_dado': 'Texto_Rotulo_Vazio',\n",
    "                    'regex': r'^(NaN|nan|None|null|)$',\n",
    "                    'sinonimos': ['RÃ³tulo de retenÃ§Ã£o Aplicado'],\n",
    "                    'exemplos': ['NaN'],\n",
    "                    'descricao': 'Campo de rÃ³tulo (geralmente vazio)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                }\n",
    "            },\n",
    "            'historico_arquivos': []\n",
    "        }\n",
    "\n",
    "    def detectar_campo(self, coluna_nome, valores_amostra):\n",
    "        \"\"\"DetecÃ§Ã£o AVANÃ‡ADA com mÃºltiplas estratÃ©gias\"\"\"\n",
    "        valores_str = [str(v).strip() for v in valores_amostra\n",
    "                      if pd.notna(v) and str(v).strip() not in\n",
    "                      ['', 'nan', 'None']]\n",
    "\n",
    "        if not valores_str:\n",
    "            return {\n",
    "                'campo_detectado': 'VAZIO',\n",
    "                'confianca': 0.0,\n",
    "                'score_conteudo': 0.0,\n",
    "                'score_nome': 0.0,\n",
    "                'matches': 0,\n",
    "                'total': 0,\n",
    "                'ambiguidade': False,\n",
    "                'candidatos': [],\n",
    "                'metodo': 'VAZIO'\n",
    "            }\n",
    "\n",
    "        # HeurÃ­sticas especÃ­ficas\n",
    "        campo_heuristico = self._detectar_por_heuristica(\n",
    "            coluna_nome, valores_str\n",
    "        )\n",
    "\n",
    "        if campo_heuristico and campo_heuristico.get('confianca', 0) >= 0.85:\n",
    "            campo_heuristico.setdefault('score_nome', 0.0)\n",
    "            campo_heuristico.setdefault('score_conteudo',\n",
    "                                        campo_heuristico.get('confianca', 0.0))\n",
    "            campo_heuristico.setdefault('matches', len(valores_str))\n",
    "            campo_heuristico.setdefault('total', len(valores_str))\n",
    "            campo_heuristico.setdefault('ambiguidade', False)\n",
    "            campo_heuristico.setdefault('candidatos', [])\n",
    "            return campo_heuristico\n",
    "\n",
    "        # Match por regex\n",
    "        resultados_regex = []\n",
    "        for nome_campo, info in self.dados['campos_conhecidos'].items():\n",
    "            matches = sum(1 for v in valores_str\n",
    "                         if re.match(info['regex'], v))\n",
    "            score_conteudo = matches / len(valores_str)\n",
    "\n",
    "            score_nome = 0.0\n",
    "            for sinonimo in info['sinonimos']:\n",
    "                if sinonimo.lower() in coluna_nome.lower():\n",
    "                    score_nome = 0.3\n",
    "                    break\n",
    "\n",
    "            score_final = score_conteudo + score_nome\n",
    "\n",
    "            resultados_regex.append({\n",
    "                'campo': nome_campo,\n",
    "                'score': min(score_final, 1.0),\n",
    "                'score_conteudo': score_conteudo,\n",
    "                'score_nome': score_nome,\n",
    "                'matches': matches,\n",
    "                'total': len(valores_str)\n",
    "            })\n",
    "\n",
    "        resultados_regex = sorted(resultados_regex,\n",
    "                                 key=lambda x: x['score'],\n",
    "                                 reverse=True)\n",
    "        melhor_regex = resultados_regex[0]\n",
    "        segundo_regex = resultados_regex[1] if len(resultados_regex) > 1 else None\n",
    "\n",
    "        ambiguidade = False\n",
    "        candidatos = []\n",
    "        if segundo_regex and abs(melhor_regex['score'] -\n",
    "                                segundo_regex['score']) < 0.10:\n",
    "            ambiguidade = True\n",
    "            candidatos = [segundo_regex['campo']]\n",
    "\n",
    "        resultado_final = {\n",
    "            'campo_detectado': melhor_regex['campo'],\n",
    "            'confianca': melhor_regex['score'],\n",
    "            'score_conteudo': melhor_regex['score_conteudo'],\n",
    "            'score_nome': melhor_regex['score_nome'],\n",
    "            'matches': melhor_regex['matches'],\n",
    "            'total': melhor_regex['total'],\n",
    "            'ambiguidade': ambiguidade,\n",
    "            'candidatos': candidatos,\n",
    "            'metodo': 'REGEX'\n",
    "        }\n",
    "\n",
    "        if resultado_final['confianca'] < 0.50:\n",
    "            resultado_final['campo_detectado'] = 'DESCONHECIDO'\n",
    "\n",
    "        return resultado_final\n",
    "\n",
    "    def _detectar_por_heuristica(self, nome_coluna, valores_str):\n",
    "        \"\"\"DetecÃ§Ã£o por heurÃ­sticas especÃ­ficas\"\"\"\n",
    "        if not valores_str:\n",
    "            return None\n",
    "\n",
    "        tamanho_medio = sum(len(v) for v in valores_str) / len(valores_str)\n",
    "        valores_unicos = set(valores_str)\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}$', v) for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Data_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATA_ISO'}\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}', v)\n",
    "               for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Datetime_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATETIME'}\n",
    "\n",
    "        if all('@' in v for v in valores_str):\n",
    "            return {'campo_detectado': 'Email', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_EMAIL'}\n",
    "\n",
    "        if 'limite' in nome_coluna.lower() or '%' in nome_coluna or 'vi' in nome_coluna.lower():\n",
    "            try:\n",
    "                valores_float = [float(v) for v in valores_str\n",
    "                                if v not in ['nan', '', 'None', 'NaN']]\n",
    "                if valores_float and all(-1 <= v <= 1 for v in valores_float):\n",
    "                    return {'campo_detectado': 'Percentual_Decimal',\n",
    "                           'confianca': 0.90,\n",
    "                           'metodo': 'HEURISTICA_PERCENTUAL'}\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if tamanho_medio > 50:\n",
    "            return {'campo_detectado': 'Texto_Longo', 'confianca': 0.85,\n",
    "                   'metodo': 'HEURISTICA_TEXTO_LONGO'}\n",
    "\n",
    "        if any(v.startswith(('teams/', 'http', 'https', '//', '\\\\\\\\'))\n",
    "               for v in valores_str):\n",
    "            return {'campo_detectado': 'Path_URL', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_PATH'}\n",
    "\n",
    "        if valores_unicos <= {'Sim', 'NÃ£o', 'sim', 'nÃ£o'}:\n",
    "            return {'campo_detectado': 'Booleano_Texto', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_BOOLEANO'}\n",
    "\n",
    "        if 'por' in nome_coluna.lower() or 'nome' in nome_coluna.lower():\n",
    "            if all(len(v.split()) >= 2 and '@' not in v\n",
    "                   for v in valores_str[:5]):\n",
    "                return {'campo_detectado': 'Nome_Pessoa', 'confianca': 0.85,\n",
    "                       'metodo': 'HEURISTICA_NOME'}\n",
    "\n",
    "        palavras_status = {'em aprovaÃ§Ã£o', 'aprovado', 'rejeitado',\n",
    "                          'Ã­tem criado', 'item criado', 'pendente'}\n",
    "        if any(v.lower() in palavras_status for v in valores_str):\n",
    "            return {'campo_detectado': 'Status_Workflow', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_STATUS'}\n",
    "\n",
    "        if 'base de' in ' '.join(valores_str[:3]).lower():\n",
    "            return {'campo_detectado': 'Unidade_Operacional_Nome',\n",
    "                   'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_UNIDADE_OP'}\n",
    "\n",
    "        return None\n",
    "\n",
    "    def atualizar_historico(self, info):\n",
    "        self.dados['historico_arquivos'].append(info)\n",
    "        self.dados['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "        self._salvar(self.dados)\n",
    "\n",
    "    def _salvar(self, dados):\n",
    "        with open(self.arquivo_dict, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dados, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ===================================================================\n",
    "# 6. INICIALIZAR DICIONÃRIO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO DICIONÃRIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "dicionario = DicionarioInteligente(fm)\n",
    "\n",
    "# ===================================================================\n",
    "# 7. SALVAR ESTADO PARA PRÃ“XIMO BLOCO\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco3 = {\n",
    "    'bloco': 3,\n",
    "    'versao': '4.5',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'dicionario': {\n",
    "        'arquivo': str(dicionario.arquivo_dict),\n",
    "        'campos_conhecidos': len(dicionario.dados['campos_conhecidos']),\n",
    "        'arquivos_processados': len(dicionario.dados['historico_arquivos']),\n",
    "        'config_sistema': dicionario.dados.get('config_sistema', {})\n",
    "    },\n",
    "    'componentes_carregados': ['DicionarioInteligente', 'GUIComTimer']\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_3_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco3, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 3 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“‹ Componentes:\")\n",
    "print(\"   â€¢ DicionarioInteligente ........... âœ…\")\n",
    "n_campos = len(dicionario.dados['campos_conhecidos'])\n",
    "n_arquivos = len(dicionario.dados['historico_arquivos'])\n",
    "print(f\"     - Campos: {n_campos}\")\n",
    "print(f\"     - Arquivos: {n_arquivos}\")\n",
    "timeout = dicionario.dados.get('config_sistema', {}).get('timeout_sessao_minutos', 60)\n",
    "print(f\"     - Timeout: {timeout}min\")\n",
    "print(\"   â€¢ GUIComTimer ..................... âœ…\")\n",
    "print(\"\\nğŸ’¾ Estado salvo em:\")\n",
    "print(f\"   â€¢ .bloco_3_state.json\")\n",
    "print(f\"   â€¢ DICT_Dicionario_Persistente.json\")\n",
    "print(\"\\nğŸ’¡ PrÃ³ximo: BLOCO 4 seleciona arquivo de dados\")\n",
    "print(\"=\"*70)"
   ],
   "id": "67bda94dc68661ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 3: DICIONÃRIO INTELIGENTE + GUI COM TIMER\n",
      "======================================================================\n",
      "\n",
      "âœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\n",
      "   ğŸ“ Pasta base: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   ğŸ• Timestamp: 20251019_060722\n",
      "\n",
      "âœ… BLOCO 2 VALIDADO\n",
      "   Executado em: 2025-10-19T06:07:25.342924\n",
      "   Classes: LocalizadorDicionario, FileManagerInterativo, SeletorArquivo, DetectorCabecalho\n",
      "\n",
      "âœ… FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "âœ… Classe GUIComTimer carregada\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO DICIONÃRIO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ CRIANDO NOVO DICIONÃRIO...\n",
      "âœ… DicionÃ¡rio criado: 22 campos\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 3 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Componentes:\n",
      "   â€¢ DicionarioInteligente ........... âœ…\n",
      "     - Campos: 22\n",
      "     - Arquivos: 0\n",
      "     - Timeout: 60min\n",
      "   â€¢ GUIComTimer ..................... âœ…\n",
      "\n",
      "ğŸ’¾ Estado salvo em:\n",
      "   â€¢ .bloco_3_state.json\n",
      "   â€¢ DICT_Dicionario_Persistente.json\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 4 seleciona arquivo de dados\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:42.813473Z",
     "start_time": "2025-10-19T09:07:34.620165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 4 - SELEÃ‡ÃƒO DE ARQUIVO - SUPORTE MULTI-FORMATO (REVISADO v3.1)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMUNICAÃ‡ÃƒO VIA LOG:\n",
    "# - LÃŠ: pasta_base (LOG global), timestamp, dicionÃ¡rio persistente\n",
    "# - RECRIA: FileManager localmente\n",
    "# - SALVA: arquivo selecionado + config CSV (se houver)\n",
    "#\n",
    "# MUDANÃ‡AS v3.1:\n",
    "# - NavegaÃ§Ã£o inteligente: abre pasta 01_Entrada por padrÃ£o\n",
    "# - HistÃ³rico de pastas (Ãºltimas 5)\n",
    "# - BotÃ£o para Ãºltima pasta usada (com timer)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BLOCO 4: SELEÃ‡ÃƒO DE ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. LER CONFIGURAÃ‡Ã•ES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ LOG GLOBAL nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro para criar a estrutura.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nğŸ“‚ Pasta base carregada: {pasta_base.name}\")\n",
    "print(f\"â° Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. RECRIAR OBJETOS NECESSÃRIOS (NÃƒO ASSUMIR MEMÃ“RIA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Recriar FileManager\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# Carregar dicionÃ¡rio persistente\n",
    "dict_file = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "\n",
    "if dict_file.exists():\n",
    "    with open(dict_file, 'r', encoding='utf-8') as f:\n",
    "        DICIONARIO_PERSISTENTE = json.load(f)\n",
    "    print(f\"ğŸ“š DicionÃ¡rio carregado: {len(DICIONARIO_PERSISTENTE.get('campos_conhecidos', {}))} campos\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ DicionÃ¡rio nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 3 primeiro.\"\n",
    "    )\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONSTANTES E CONFIGURAÃ‡Ã•ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "FILETYPES_SUPORTADOS = [\n",
    "    (\"Todos os suportados\", \"*.xlsx *.xls *.xlsm *.csv *.txt\"),\n",
    "    (\"Excel\", \"*.xlsx *.xls *.xlsm\"),\n",
    "    (\"CSV\", \"*.csv\"),\n",
    "    (\"TXT (Tabelas)\", \"*.txt\"),\n",
    "    (\"Todos\", \"*.*\")\n",
    "]\n",
    "\n",
    "TIMEOUT_SESSAO_MINUTOS = DICIONARIO_PERSISTENTE.get(\n",
    "    'config_sistema', {}\n",
    ").get('timeout_sessao_minutos', 60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡Ã•ES AUXILIARES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def detectar_config_csv(arquivo_path):\n",
    "    \"\"\"\n",
    "    Detecta encoding e separador ideal para CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: {'encoding': str, 'sep': str, 'colunas': int}\n",
    "        None: se falhar\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    separadores = [',', ';', '\\t', '|']\n",
    "\n",
    "    melhor_config = None\n",
    "    max_colunas = 0\n",
    "\n",
    "    for encoding in encodings:\n",
    "        for sep in separadores:\n",
    "            try:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=5,\n",
    "                    encoding=encoding,\n",
    "                    sep=sep,\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                n_cols = len(df_test.columns)\n",
    "\n",
    "                if n_cols > max_colunas and n_cols > 1:\n",
    "                    max_colunas = n_cols\n",
    "                    melhor_config = {\n",
    "                        'encoding': encoding,\n",
    "                        'sep': sep,\n",
    "                        'colunas': n_cols\n",
    "                    }\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return melhor_config\n",
    "\n",
    "\n",
    "def validar_arquivo_selecionado(arquivo_path):\n",
    "    \"\"\"\n",
    "    ValidaÃ§Ã£o bÃ¡sica do arquivo selecionado.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Se arquivo nÃ£o existe\n",
    "        ValueError: Se arquivo invÃ¡lido\n",
    "\n",
    "    Returns:\n",
    "        dict: InformaÃ§Ãµes de validaÃ§Ã£o\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if not arquivo_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {arquivo_path}\")\n",
    "\n",
    "    tamanho = arquivo_path.stat().st_size\n",
    "    if tamanho == 0:\n",
    "        raise ValueError(f\"Arquivo vazio: {arquivo_path.name}\")\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "    extensoes_validas = ['.xlsx', '.xls', '.xlsm', '.csv', '.txt']\n",
    "\n",
    "    if extensao not in extensoes_validas:\n",
    "        print(f\"   âš ï¸ ExtensÃ£o incomum: {extensao}\")\n",
    "\n",
    "    config_extra = {}\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            pd.read_excel(arquivo_path, nrows=1)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "\n",
    "            if config_csv:\n",
    "                config_extra['csv'] = config_csv\n",
    "                print(f\"   ğŸ“Š CSV: {config_csv['colunas']} colunas\")\n",
    "                print(f\"   ğŸ”¤ Encoding: {config_csv['encoding']}\")\n",
    "                print(f\"   â— Separador: {repr(config_csv['sep'])}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ Config CSV nÃ£o detectada automaticamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Arquivo corrompido ou ilegÃ­vel: {str(e)[:100]}\")\n",
    "\n",
    "    return {\n",
    "        'valido': True,\n",
    "        'tamanho_kb': tamanho / 1024,\n",
    "        'extensao': extensao,\n",
    "        **config_extra\n",
    "    }\n",
    "\n",
    "\n",
    "def carregar_preview_inteligente(arquivo_path, frame_preview):\n",
    "    \"\"\"\n",
    "    Carrega preview do arquivo com tratamento de erro amigÃ¡vel.\n",
    "\n",
    "    Args:\n",
    "        arquivo_path: Path do arquivo\n",
    "        frame_preview: Frame tkinter para mostrar preview\n",
    "    \"\"\"\n",
    "    import tkinter as tk\n",
    "    import pandas as pd\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            df_quick = pd.read_excel(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "            if config_csv:\n",
    "                df_quick = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=3,\n",
    "                    encoding=config_csv['encoding'],\n",
    "                    sep=config_csv['sep']\n",
    "                )\n",
    "            else:\n",
    "                df_quick = pd.read_csv(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.txt':\n",
    "            for sep in ['\\t', ';', '|', ',']:\n",
    "                try:\n",
    "                    df_quick = pd.read_csv(arquivo_path, nrows=3, sep=sep)\n",
    "                    if len(df_quick.columns) > 1:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        preview_text = f\"{len(df_quick)} linhas Ã— {len(df_quick.columns)} colunas\"\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=preview_text,\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#666666',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "    except Exception as e:\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"âš ï¸ Preview indisponÃ­vel\",\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#FF6B6B',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "        print(f\"   âš ï¸ Preview falhou: {str(e)[:50]}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CARREGAR HISTÃ“RICO DE NAVEGAÃ‡ÃƒO (NOVO v3.1)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "historico_file = fm.pastas['logs'] / '.historico_pastas_navegacao.json'\n",
    "\n",
    "if historico_file.exists():\n",
    "    try:\n",
    "        with open(historico_file, 'r', encoding='utf-8') as f:\n",
    "            historico_pastas = json.load(f)\n",
    "    except:\n",
    "        historico_pastas = {'ultima_pasta': None, 'historico': []}\n",
    "else:\n",
    "    historico_pastas = {'ultima_pasta': None, 'historico': []}\n",
    "\n",
    "# Determinar pasta inicial padrÃ£o\n",
    "pasta_entrada = fm.pastas['entrada']\n",
    "ultima_pasta_usada = None\n",
    "\n",
    "if historico_pastas.get('ultima_pasta'):\n",
    "    ultima_pasta_usada = Path(historico_pastas['ultima_pasta'])\n",
    "    if not ultima_pasta_usada.exists():\n",
    "        ultima_pasta_usada = None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. PROCESSAR DADOS DO BLOCO (LÃ“GICA PRINCIPAL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Carregar Ãºltima seleÃ§Ã£o\n",
    "config_file = fm.pastas['logs'] / '.ultimo_arquivo.json'\n",
    "ultimo_arquivo = None\n",
    "sessao_atual = False\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        try:\n",
    "            ts_config = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "            ts_agora = datetime.now()\n",
    "            diff_minutos = (ts_agora - ts_config).total_seconds() / 60\n",
    "\n",
    "            if diff_minutos < TIMEOUT_SESSAO_MINUTOS:\n",
    "                caminho_salvo = config.get('caminho')\n",
    "                if caminho_salvo and Path(caminho_salvo).exists():\n",
    "                    ultimo_arquivo = Path(caminho_salvo)\n",
    "                    sessao_atual = True\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nğŸ’¡ Ãšltima seleÃ§Ã£o: {ultimo_arquivo.name if ultimo_arquivo else 'Nenhuma'}\")\n",
    "print(f\"   Mesma sessÃ£o: {'Sim' if sessao_atual else 'NÃ£o'}\")\n",
    "if ultima_pasta_usada:\n",
    "    print(f\"   Ãšltima pasta: {ultima_pasta_usada}\")\n",
    "\n",
    "# CASO 1: Tem arquivo da sessÃ£o atual â†’ GUI com timer\n",
    "if ultimo_arquivo and sessao_atual:\n",
    "    def selecionar_arquivo_com_timer(ultimo_path):\n",
    "        \"\"\"GUI com timer para confirmar ou trocar arquivo\"\"\"\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - SeleÃ§Ã£o de Arquivo\",\n",
    "            650, 520,\n",
    "            tem_timer=True\n",
    "        )\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ SeleÃ§Ã£o de Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ’¡ Ãšltimo arquivo selecionado nesta sessÃ£o:\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 5))\n",
    "\n",
    "        extensao = ultimo_path.suffix.lower()\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            tipo_arquivo = \"Excel\"\n",
    "            icone = \"ğŸ“Š\"\n",
    "        elif extensao == '.csv':\n",
    "            tipo_arquivo = \"CSV\"\n",
    "            icone = \"ğŸ“„\"\n",
    "        elif extensao == '.txt':\n",
    "            tipo_arquivo = \"TXT\"\n",
    "            icone = \"ğŸ“\"\n",
    "        else:\n",
    "            tipo_arquivo = \"Desconhecido\"\n",
    "            icone = \"â“\"\n",
    "\n",
    "        frame_info = tk.Frame(frame, bg='#E3F2FD', relief=tk.SUNKEN, borderwidth=2)\n",
    "        frame_info.pack(fill=tk.X, pady=(0, 10), padx=10)\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"{icone} {ultimo_path.name}\",\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(5, 2))\n",
    "\n",
    "        tamanho_kb = ultimo_path.stat().st_size / 1024\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"ğŸ“¦ Tipo: {tipo_arquivo} | ğŸ“ Tamanho: {tamanho_kb:.1f} KB\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 2))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"ğŸ“‚ Local: {ultimo_path.parent}\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w',\n",
    "            wraplength=600\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 5))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Deseja usar este arquivo ou escolher outro?\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(10, 10))\n",
    "\n",
    "        frame_preview = tk.Frame(frame, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "        frame_preview.pack(fill=tk.X, padx=10, pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"ğŸ“Š Preview (3 primeiras linhas):\",\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#F5F5F5',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(3, 2))\n",
    "\n",
    "        carregar_preview_inteligente(ultimo_path, frame_preview)\n",
    "\n",
    "        def usar_ultimo():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultimo_path\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def escolher_novo():\n",
    "            resultado['cancelado'] = True\n",
    "            root.withdraw()\n",
    "\n",
    "            # NAVEGAÃ‡ÃƒO INTELIGENTE: usar Ãºltima pasta ou pasta_entrada\n",
    "            pasta_inicial = ultima_pasta_usada if ultima_pasta_usada else pasta_entrada\n",
    "\n",
    "            arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecione o arquivo de dados\",\n",
    "                initialdir=str(pasta_inicial),\n",
    "                filetypes=FILETYPES_SUPORTADOS\n",
    "            )\n",
    "\n",
    "            resultado['valor'] = Path(arquivo) if arquivo else ultimo_path\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(fill=tk.X, pady=10)\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Escolher Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=22,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        nome_curto = ultimo_path.name[:15] + '...' if len(ultimo_path.name) > 15 else ultimo_path.name\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=f\"Usar '{nome_curto}' (10s)\",\n",
    "            command=usar_ultimo,\n",
    "            width=30,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#2196F3',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "        root.mainloop()\n",
    "\n",
    "        if resultado.get('timeout'):\n",
    "            print(f\"   â±ï¸ Timeout (10s) - usando Ãºltimo arquivo\")\n",
    "            return ultimo_path\n",
    "\n",
    "        return resultado['valor']\n",
    "\n",
    "    print(\"\\nAbrindo janela...\")\n",
    "    arquivo_selecionado = selecionar_arquivo_com_timer(ultimo_arquivo)\n",
    "\n",
    "# CASO 2: NÃ£o tem arquivo da sessÃ£o â†’ GUI com navegaÃ§Ã£o inteligente\n",
    "else:\n",
    "    def selecionar_arquivo_direto():\n",
    "        \"\"\"GUI direta para primeira seleÃ§Ã£o com navegaÃ§Ã£o inteligente\"\"\"\n",
    "\n",
    "        # NAVEGAÃ‡ÃƒO INTELIGENTE: Ãºltima pasta usada OU pasta 01_Entrada\n",
    "        pasta_inicial = ultima_pasta_usada if ultima_pasta_usada else pasta_entrada\n",
    "\n",
    "        print(f\"   ğŸ“ Abrindo em: {pasta_inicial.name}\")\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"Selecione o arquivo de dados\",\n",
    "            initialdir=str(pasta_inicial),\n",
    "            filetypes=FILETYPES_SUPORTADOS\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"âŒ Nenhum arquivo selecionado\")\n",
    "\n",
    "        return Path(arquivo)\n",
    "\n",
    "    print(\"\\nAbrindo janela de seleÃ§Ã£o...\")\n",
    "    print(\"(A janela pode estar atrÃ¡s do navegador)\")\n",
    "    arquivo_selecionado = selecionar_arquivo_direto()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ATUALIZAR HISTÃ“RICO DE NAVEGAÃ‡ÃƒO (NOVO v3.1)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "pasta_do_arquivo = arquivo_selecionado.parent\n",
    "\n",
    "# Salvar Ãºltima pasta usada\n",
    "historico_pastas['ultima_pasta'] = str(pasta_do_arquivo)\n",
    "\n",
    "# Atualizar histÃ³rico (manter Ãºltimas 5 pastas)\n",
    "historico = historico_pastas.get('historico', [])\n",
    "\n",
    "# Remover duplicatas\n",
    "if str(pasta_do_arquivo) in historico:\n",
    "    historico.remove(str(pasta_do_arquivo))\n",
    "\n",
    "# Adicionar no topo\n",
    "historico.insert(0, str(pasta_do_arquivo))\n",
    "\n",
    "# Manter apenas 5 mais recentes\n",
    "historico_pastas['historico'] = historico[:5]\n",
    "historico_pastas['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "\n",
    "# Salvar histÃ³rico\n",
    "with open(historico_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(historico_pastas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VALIDAÃ‡ÃƒO E DETECÃ‡ÃƒO DE TIPO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” Validando arquivo...\")\n",
    "\n",
    "try:\n",
    "    info_validacao = validar_arquivo_selecionado(arquivo_selecionado)\n",
    "    print(\"   âœ… Arquivo validado com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERRO: {e}\")\n",
    "    raise\n",
    "\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "    tipo_arquivo = \"Excel\"\n",
    "elif extensao == '.csv':\n",
    "    tipo_arquivo = \"CSV\"\n",
    "elif extensao == '.txt':\n",
    "    tipo_arquivo = \"TXT\"\n",
    "else:\n",
    "    tipo_arquivo = \"Desconhecido\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. SALVAR ESTADO PARA PRÃ“XIMO BLOCO (VIA LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "config_salvar = {\n",
    "    'nome': arquivo_selecionado.name,\n",
    "    'caminho': str(arquivo_selecionado),\n",
    "    'tamanho_kb': info_validacao['tamanho_kb'],\n",
    "    'tipo': tipo_arquivo,\n",
    "    'extensao': extensao,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    config_salvar['config_csv'] = info_validacao['csv']\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_salvar, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Salvar estado do BLOCO 4\n",
    "estado_bloco = {\n",
    "    'bloco': 4,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo_selecionado': arquivo_selecionado.name,\n",
    "    'tipo': tipo_arquivo,\n",
    "    'tamanho_kb': info_validacao['tamanho_kb']\n",
    "}\n",
    "\n",
    "with open(fm.pastas['logs'] / '.bloco_5_state.json', 'w') as f:\n",
    "    json.dump(estado_bloco, f, indent=2)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. CONFIRMAÃ‡ÃƒO FINAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… ARQUIVO SELECIONADO E VALIDADO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ğŸ“„ Nome: {arquivo_selecionado.name}\")\n",
    "print(f\"ğŸ“¦ Tipo: {tipo_arquivo}\")\n",
    "print(f\"ğŸ“ Tamanho: {info_validacao['tamanho_kb']:.1f} KB\")\n",
    "print(f\"ğŸ“‚ Pasta: {arquivo_selecionado.parent.name}\")\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    csv_info = info_validacao['csv']\n",
    "    print(f\"ğŸ“Š Colunas detectadas: {csv_info['colunas']}\")\n",
    "    print(f\"ğŸ”¤ Encoding: {csv_info['encoding']}\")\n",
    "    print(f\"â— Separador: {repr(csv_info['sep'])}\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"âœ… BLOCO 4 CONCLUÃDO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nğŸ’¾ Estado salvo em: {fm.pastas['logs']}\")\n",
    "print(f\"ğŸ“‹ PrÃ³ximo: BLOCO 6 carregarÃ¡ o arquivo usando esta configuraÃ§Ã£o\")"
   ],
   "id": "eab16a4648d87882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLOCO 4: SELEÃ‡ÃƒO DE ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Pasta base carregada: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "â° Timestamp: 20251019_060722\n",
      "ğŸ“š DicionÃ¡rio carregado: 22 campos\n",
      "\n",
      "ğŸ’¡ Ãšltima seleÃ§Ã£o: Nenhuma\n",
      "   Mesma sessÃ£o: NÃ£o\n",
      "\n",
      "Abrindo janela de seleÃ§Ã£o...\n",
      "(A janela pode estar atrÃ¡s do navegador)\n",
      "   ğŸ“ Abrindo em: 01_Entrada\n",
      "\n",
      "ğŸ” Validando arquivo...\n",
      "   âœ… Arquivo validado com sucesso\n",
      "\n",
      "======================================================================\n",
      "âœ… ARQUIVO SELECIONADO E VALIDADO\n",
      "======================================================================\n",
      "ğŸ“„ Nome: CÃ³pia de xSAPtemp4687_JAN_25.xls\n",
      "ğŸ“¦ Tipo: Excel\n",
      "ğŸ“ Tamanho: 16257.5 KB\n",
      "ğŸ“‚ Pasta: Dado BW\n",
      "======================================================================\n",
      "âœ… BLOCO 4 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¾ Estado salvo em: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\\04_Logs\n",
      "ğŸ“‹ PrÃ³ximo: BLOCO 6 carregarÃ¡ o arquivo usando esta configuraÃ§Ã£o\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:46.955353Z",
     "start_time": "2025-10-19T09:07:46.569095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 5: CARREGAMENTO INTELIGENTE - EXCEL E CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¥ CARREGAMENTO DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Detectar tipo de arquivo pela extensÃ£o\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "print(f\"\\nğŸ” ExtensÃ£o detectada: {extensao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: ARQUIVOS EXCEL (.xls, .xlsx, .xlsm)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if extensao in ['.xls', '.xlsx', '.xlsm']:\n",
    "    print(f\"ğŸ“Š Tipo: EXCEL\")\n",
    "\n",
    "    try:\n",
    "        # Tentar xlrd primeiro (para .xls antigos)\n",
    "        workbook = xlrd.open_workbook(str(arquivo_selecionado))\n",
    "        sheets = workbook.sheet_names()\n",
    "        metodo_carga = 'xlrd'\n",
    "        print(f\"   âœ… MÃ©todo: xlrd (XLS)\")\n",
    "\n",
    "    except:\n",
    "        # Se falhar, usar pandas (para .xlsx/.xlsm)\n",
    "        try:\n",
    "            workbook = pd.ExcelFile(str(arquivo_selecionado))\n",
    "            sheets = workbook.sheet_names\n",
    "            metodo_carga = 'pandas'\n",
    "            print(f\"   âœ… MÃ©todo: pandas (XLSX/XLSM)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ERRO ao abrir Excel: {e}\")\n",
    "            raise\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Sheets encontradas: {len(sheets)}\")\n",
    "    for i, sheet in enumerate(sheets, 1):\n",
    "        print(f\"   {i}. {sheet}\")\n",
    "\n",
    "    tipo_arquivo = 'EXCEL'\n",
    "    separador_detectado = None\n",
    "    skiprows_csv = 0\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: ARQUIVOS CSV (.csv)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif extensao == '.csv':\n",
    "    print(f\"ğŸ“„ Tipo: CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nğŸ” Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha explÃ­cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   âœ… Separador explÃ­cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   âœ… Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"âŒ Separador CSV nÃ£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nğŸ“Š Estrutura do CSV:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Simular sheets (CSV = 1 sheet virtual)\n",
    "        sheets = ['Dados CSV']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'CSV'\n",
    "\n",
    "        print(f\"\\nğŸ“‹ Sheet virtual: 'Dados CSV'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO ao processar CSV: {e}\")\n",
    "        raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: ARQUIVOS TXT (.txt)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif extensao == '.txt':\n",
    "    print(f\"ğŸ“ Tipo: TXT\")\n",
    "    print(f\"   â„¹ï¸  Processamento similar a CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nğŸ” Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha explÃ­cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   âœ… Separador explÃ­cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   âœ… Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"âŒ Separador TXT nÃ£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nğŸ“Š Estrutura do TXT:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Simular sheets (TXT = 1 sheet virtual)\n",
    "        sheets = ['Dados TXT']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'TXT'\n",
    "\n",
    "        print(f\"\\nğŸ“‹ Sheet virtual: 'Dados TXT'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO ao processar TXT: {e}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"âŒ Formato nÃ£o suportado: {extensao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAMENTO DE ESTADO NO LOG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco5 = {\n",
    "    'bloco': 5,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'extensao': extensao,\n",
    "    'sheets': sheets,\n",
    "    'workbook_path': str(arquivo_selecionado),\n",
    "    'separador_detectado': separador_detectado,\n",
    "    'skiprows_csv': skiprows_csv\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_5_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco5, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RESUMO DO CARREGAMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"âœ… CARREGAMENTO CONCLUÃDO\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "print(f\"   MÃ©todo: {metodo_carga}\")\n",
    "print(f\"   Sheets/Tabelas: {len(sheets)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 5 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ’¾ Estado salvo: .bloco_5_state.json\")\n",
    "print(f\"ğŸ“‹ PrÃ³ximo: BLOCO 6 selecionarÃ¡ a sheet e farÃ¡ preview\")"
   ],
   "id": "a36bbbc312051633",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“¥ CARREGAMENTO DO ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "ğŸ” ExtensÃ£o detectada: .xls\n",
      "ğŸ“Š Tipo: EXCEL\n",
      "   âœ… MÃ©todo: xlrd (XLS)\n",
      "\n",
      "ğŸ“‹ Sheets encontradas: 11\n",
      "   1. SAPBEXqueriesDefunct\n",
      "   2. SAPBEXfiltersDefunct\n",
      "   3. Valor da VariaÃ§Ã£o Total\n",
      "   4. Valor da VariaÃ§Ã£o Total Grupo\n",
      "   5. Limite TÃ©cnico\n",
      "   6. Justificar\n",
      "   7. Limite TÃ©cnico Grupo\n",
      "   8. BExRepositorySheet\n",
      "   9. Justificar Grupo\n",
      "   10. Custo do Produto\n",
      "   11. Imposto\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… CARREGAMENTO CONCLUÃDO\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Tipo: EXCEL\n",
      "   MÃ©todo: xlrd\n",
      "   Sheets/Tabelas: 11\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 5 CONCLUÃDO\n",
      "======================================================================\n",
      "ğŸ’¾ Estado salvo: .bloco_5_state.json\n",
      "ğŸ“‹ PrÃ³ximo: BLOCO 6 selecionarÃ¡ a sheet e farÃ¡ preview\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:07:55.170600Z",
     "start_time": "2025-10-19T09:07:52.272271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 6 - SELEÃ‡ÃƒO DE SHEET (COM SUPORTE CSV)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ SELEÃ‡ÃƒO DE SHEET/TABELA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Carregar Ãºltima seleÃ§Ã£o\n",
    "config_file = fm.pastas['logs'] / '.ultima_sheet.json'\n",
    "ultima_sheet = None\n",
    "arquivo_mudou = True\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "            # Verificar se Ã© o mesmo arquivo E timestamp recente (Ãºltima hora)\n",
    "            if config.get('arquivo') == arquivo_selecionado.name:\n",
    "                ultima_sheet = config.get('sheet')\n",
    "                # Verificar se timestamp Ã© recente\n",
    "                try:\n",
    "                    ts_salvo = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "                    ts_agora = datetime.now()\n",
    "                    diff_minutos = (ts_agora - ts_salvo).total_seconds() / 60\n",
    "\n",
    "                    if diff_minutos < 60:  # Ãšltima hora\n",
    "                        arquivo_mudou = False\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nğŸ’¡ Ãšltima sheet: {ultima_sheet if ultima_sheet else 'Nenhuma'}\")\n",
    "print(f\"   Arquivo mudou: {'Sim' if arquivo_mudou else 'NÃ£o'}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: CSV - SELEÃ‡ÃƒO AUTOMÃTICA (apenas 1 sheet virtual)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if tipo_arquivo == 'CSV':\n",
    "    sheet_nome = sheets[0]  # 'Dados CSV'\n",
    "    print(f\"\\nâœ… Arquivo CSV - usando sheet virtual automÃ¡tica: '{sheet_nome}'\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: EXCEL - Apenas 1 sheet E arquivo mudou â†’ Usar diretamente\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif len(sheets) == 1 and arquivo_mudou:\n",
    "    sheet_nome = sheets[0]\n",
    "    print(f\"\\nâœ… Apenas 1 sheet - selecionando automaticamente: '{sheet_nome}'\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: EXCEL - Mais de 1 sheet OU tem histÃ³rico â†’ GUI COM TIMER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "else:\n",
    "    def selecionar_sheet_com_timer(sheets, ultima=None, mostrar_timer=True):\n",
    "        \"\"\"GUI com timer para seleÃ§Ã£o de sheet\"\"\"\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - SeleÃ§Ã£o de Sheet\",\n",
    "            600, 450,\n",
    "            tem_timer=(mostrar_timer and ultima is not None)\n",
    "        )\n",
    "\n",
    "        # TÃ­tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‹ SeleÃ§Ã£o de Sheet\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecione a Sheet para processar:\",\n",
    "            font=('Arial', 12, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        # Timer (se tem Ãºltima E timer ativo)\n",
    "        if ultima and mostrar_timer:\n",
    "            tk.Label(\n",
    "                frame,\n",
    "                text=f\"ğŸ’¡ Ãšltima sheet usada: '{ultima}'\",\n",
    "                font=('Arial', 10),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0',\n",
    "                padx=10,\n",
    "                pady=10\n",
    "            ).pack(fill=tk.X, pady=(0, 5))\n",
    "\n",
    "            countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        # Listbox\n",
    "        frame_list = tk.Frame(frame, bg='white')\n",
    "        frame_list.pack(fill=tk.BOTH, expand=True, pady=(0, 10))\n",
    "\n",
    "        scrollbar = tk.Scrollbar(frame_list)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        listbox = tk.Listbox(\n",
    "            frame_list,\n",
    "            yscrollcommand=scrollbar.set,\n",
    "            font=('Arial', 10),\n",
    "            height=8\n",
    "        )\n",
    "        listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        scrollbar.config(command=listbox.yview)\n",
    "\n",
    "        for sheet in sheets:\n",
    "            listbox.insert(tk.END, sheet)\n",
    "\n",
    "        # Selecionar Ãºltima ou primeira\n",
    "        if ultima and ultima in sheets:\n",
    "            idx = sheets.index(ultima)\n",
    "            listbox.select_set(idx)\n",
    "            listbox.see(idx)\n",
    "        else:\n",
    "            listbox.select_set(0)\n",
    "\n",
    "        # FunÃ§Ãµes\n",
    "        def nova_selecao():\n",
    "            resultado['cancelado'] = True\n",
    "            selecao = listbox.curselection()\n",
    "            if selecao:\n",
    "                resultado['valor'] = sheets[selecao[0]]\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultima\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def duplo_clique(event):\n",
    "            nova_selecao()\n",
    "\n",
    "        listbox.bind('<Double-Button-1>', duplo_clique)\n",
    "\n",
    "        # BotÃµes\n",
    "        GUIComTimer.criar_botoes(\n",
    "            frame,\n",
    "            nova_selecao,\n",
    "            usar_ultima if (ultima and mostrar_timer) else None,\n",
    "            \"Selecionar\",\n",
    "            f\"Usar '{ultima}' (10s)\" if ultima else None\n",
    "        )\n",
    "\n",
    "        # Iniciar timer\n",
    "        if ultima and mostrar_timer:\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        root.mainloop()\n",
    "\n",
    "        # Processar resultado\n",
    "        if resultado.get('timeout') and ultima:\n",
    "            print(f\"   â±ï¸  Timeout (10s) - usando Ãºltima sheet\")\n",
    "            return ultima\n",
    "\n",
    "        return resultado['valor']\n",
    "\n",
    "    # Executar GUI\n",
    "    print(f\"\\nAbrindo janela de seleÃ§Ã£o...\")\n",
    "    sheet_nome = selecionar_sheet_com_timer(\n",
    "        sheets,\n",
    "        ultima_sheet,\n",
    "        mostrar_timer=(not arquivo_mudou)  # Timer apenas se mesmo arquivo\n",
    "    )\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR ESCOLHA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'arquivo': arquivo_selecionado.name,\n",
    "        'sheet': sheet_nome,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Sheet selecionada: '{sheet_nome}'\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RESUMO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"âœ… SELEÃ‡ÃƒO CONCLUÃDA\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"   Arquivo: {arquivo_selecionado.name}\")\n",
    "print(f\"   Sheet: {sheet_nome}\")\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAMENTO DE ESTADO (ADICIONADO - NÃƒO REMOVE NADA ACIMA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco6 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 6,\n",
    "    'nome': 'SELEÃ‡ÃƒO DE SHEET',\n",
    "    'status': 'concluido',\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet_selecionada': sheet_nome,\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'total_sheets': len(sheets),\n",
    "    'lista_sheets': sheets,\n",
    "    'metodo_selecao': 'automatico' if (tipo_arquivo == 'CSV' or len(sheets) == 1) else 'gui',\n",
    "    'arquivo_mudou': arquivo_mudou,\n",
    "    'tinha_historico': ultima_sheet is not None\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_6_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco6, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo: {arquivo_estado.name}\")"
   ],
   "id": "bd9cdff8d1341b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“‹ SELEÃ‡ÃƒO DE SHEET/TABELA\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ Ãšltima sheet: Nenhuma\n",
      "   Arquivo mudou: Sim\n",
      "\n",
      "Abrindo janela de seleÃ§Ã£o...\n",
      "\n",
      "âœ… Sheet selecionada: 'Valor da VariaÃ§Ã£o Total'\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… SELEÃ‡ÃƒO CONCLUÃDA\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Arquivo: CÃ³pia de xSAPtemp4687_JAN_25.xls\n",
      "   Sheet: Valor da VariaÃ§Ã£o Total\n",
      "   Tipo: EXCEL\n",
      "\n",
      "ğŸ’¾ Estado salvo: .bloco_6_state.json\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:08:02.777657Z",
     "start_time": "2025-10-19T09:08:02.740114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 7 - PREVIEW VISUAL (50 linhas Ã— 20 colunas) - SUPORTE CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIX: datetime â†’ string ISO antes de salvar JSON (TypeError corrigido)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‘€ PREVIEW DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: EXCEL com xlrd (arquivos .xls antigos)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if metodo_carga == 'xlrd':\n",
    "    print(\"ğŸ“Š MÃ©todo: xlrd\")\n",
    "\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    data_preview = []\n",
    "\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_preview.append(sheet.row_values(row_idx))\n",
    "\n",
    "    df_preview = pd.DataFrame(data_preview)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: EXCEL com pandas (arquivos .xlsx/.xlsm)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(\"ğŸ“Š MÃ©todo: pandas Excel\")\n",
    "\n",
    "    df_preview = pd.read_excel(\n",
    "        workbook,\n",
    "        sheet_name=sheet_nome,\n",
    "        nrows=50,\n",
    "        header=None\n",
    "    )\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: CSV ğŸ†•\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'csv':\n",
    "    print(\"ğŸ“„ MÃ©todo: CSV\")\n",
    "\n",
    "    df_preview = pd.read_csv(\n",
    "        arquivo_selecionado,\n",
    "        sep=separador_detectado,\n",
    "        encoding='cp1252',\n",
    "        skiprows=skiprows_csv,\n",
    "        nrows=50,\n",
    "        header=None  # Sem cabeÃ§alho por enquanto\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"âŒ MÃ©todo de carga desconhecido: {metodo_carga}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LIMITAR A 20 COLUNAS PARA VISUALIZAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "df_preview_limitado = df_preview.iloc[:, :20].copy()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXIBIR INFORMAÃ‡Ã•ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\nğŸ“Š DimensÃµes do preview:\")\n",
    "print(f\"   Total: {df_preview.shape[0]} linhas Ã— {df_preview.shape[1]} colunas\")\n",
    "print(f\"   Exibindo: {df_preview_limitado.shape[0]} linhas Ã— {df_preview_limitado.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nğŸ‘ï¸  Preview (primeiras 50 linhas, atÃ© 20 colunas):\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Usar display ou print dependendo do ambiente\n",
    "try:\n",
    "    display(df_preview_limitado)\n",
    "except NameError:\n",
    "    print(df_preview_limitado.to_string())\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAMENTO DE ESTADO E PREVIEW (ADICIONADO - NÃƒO REMOVE NADA ACIMA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# âœ… FIX: FunÃ§Ã£o para converter datetime â†’ string ISO\n",
    "def converter_para_json(valor):\n",
    "    \"\"\"Converte datetime/Timestamp para string ISO, senÃ£o mantÃ©m valor\"\"\"\n",
    "    if pd.isna(valor):\n",
    "        return None\n",
    "    elif isinstance(valor, (datetime, pd.Timestamp)):\n",
    "        return valor.isoformat()\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "# Salvar preview em JSON (seguindo padrÃ£o do BLOCO 8)\n",
    "# âœ… FIX: Aplicar conversÃ£o em cada cÃ©lula\n",
    "preview_data_raw = df_preview_limitado.values.tolist()\n",
    "preview_data_safe = [[converter_para_json(cel) for cel in row] for row in preview_data_raw]\n",
    "\n",
    "preview_data = {\n",
    "    'dimensoes': {\n",
    "        'linhas_total': int(df_preview.shape[0]),\n",
    "        'colunas_total': int(df_preview.shape[1]),\n",
    "        'linhas_exibidas': int(df_preview_limitado.shape[0]),\n",
    "        'colunas_exibidas': int(df_preview_limitado.shape[1])\n",
    "    },\n",
    "    'preview_limitado': preview_data_safe  # âœ… Agora Ã© JSON-safe\n",
    "}\n",
    "\n",
    "preview_file = fm.pastas['logs'] / '.bloco_7_preview.json'\n",
    "with open(preview_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(preview_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Salvar estado do bloco\n",
    "estado_bloco7 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 7,\n",
    "    'nome': 'PREVIEW VISUAL',\n",
    "    'status': 'concluido',\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'dimensoes_preview': {\n",
    "        'linhas_carregadas': int(df_preview.shape[0]),\n",
    "        'colunas_carregadas': int(df_preview.shape[1]),\n",
    "        'linhas_exibidas': int(df_preview_limitado.shape[0]),\n",
    "        'colunas_exibidas': int(df_preview_limitado.shape[1])\n",
    "    },\n",
    "    'arquivo_preview': preview_file.name\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_7_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco7, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo: {arquivo_estado.name}\")\n",
    "print(f\"ğŸ’¾ Preview salvo: {preview_file.name}\")"
   ],
   "id": "e38c2bfb13dddecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‘€ PREVIEW DO ARQUIVO\n",
      "======================================================================\n",
      "ğŸ“Š MÃ©todo: xlrd\n",
      "\n",
      "ğŸ“Š DimensÃµes do preview:\n",
      "   Total: 50 linhas Ã— 60 colunas\n",
      "   Exibindo: 50 linhas Ã— 20 colunas\n",
      "\n",
      "ğŸ‘ï¸  Preview (primeiras 50 linhas, atÃ© 20 colunas):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            0    1    2    3    4    5     6                      7   \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2                                                                      \n",
       "3                                                                      \n",
       "4                                                                      \n",
       "5                                                                      \n",
       "6                                                                      \n",
       "7                                                                      \n",
       "8                                                                      \n",
       "9                                                                      \n",
       "10                                                                     \n",
       "11                                                                     \n",
       "12                                                                     \n",
       "13                                                                     \n",
       "14                                                                     \n",
       "15                                                                     \n",
       "16                                                                     \n",
       "17                                                                     \n",
       "18                                                                     \n",
       "19                                                                     \n",
       "20                                                                     \n",
       "21                                                                     \n",
       "22                                                                     \n",
       "23                                                                     \n",
       "24                                                                     \n",
       "25                                                                     \n",
       "26                                                                     \n",
       "27                                                                     \n",
       "28                                                                     \n",
       "29                                                                     \n",
       "30                                                                     \n",
       "31                                                                     \n",
       "32                                                                     \n",
       "33  Justificar             LT                                  Chave   \n",
       "34           X  0.0  0.0  1.0  1.0  1.0   1.0  512601.202501.011.674   \n",
       "35           X  0.0  0.0  2.0  1.0  2.0   2.0  512601.202501.001.422   \n",
       "36           X  0.0  0.0    X  0.0  2.0   3.0  512601.202501.003.826   \n",
       "37           X  0.0  0.0  3.0  1.0  3.0   4.0  510501.202501.000.078   \n",
       "38           X  0.0  0.0  4.0  1.0  4.0   5.0  510501.202501.011.674   \n",
       "39           X  0.0  0.0  5.0  1.0  5.0   6.0  510501.202501.024.741   \n",
       "40           X  0.0  0.0    X  0.0  5.0   7.0  510501.202501.016.205   \n",
       "41         1.0  1.0  1.0    X  0.0  5.0   8.0  510501.202501.001.422   \n",
       "42           X  0.0  1.0    X  0.0  5.0   9.0  510501.202501.011.754   \n",
       "43           X  0.0  1.0  6.0  1.0  6.0  10.0  510501.202501.026.471   \n",
       "44           X  0.0  1.0  7.0  1.0  7.0  11.0  510501.202501.003.826   \n",
       "45           X  0.0  1.0    X  0.0  7.0  12.0  531101.202501.011.674   \n",
       "46           X  0.0  1.0    X  0.0  7.0  13.0  531101.202501.016.205   \n",
       "47           X  0.0  1.0  8.0  1.0  8.0  14.0  531101.202501.001.422   \n",
       "48           X  0.0  1.0    X  0.0  8.0  15.0  531101.202501.011.754   \n",
       "49           X  0.0  1.0  9.0  1.0  9.0  16.0  531101.202501.003.826   \n",
       "\n",
       "                8               9               10  \\\n",
       "0                                                    \n",
       "1                                                    \n",
       "2                                                    \n",
       "3                                                    \n",
       "4                                                    \n",
       "5                                                    \n",
       "6                                                    \n",
       "7                                                    \n",
       "8                                                    \n",
       "9                                                    \n",
       "10                                                   \n",
       "11                                                   \n",
       "12                                                   \n",
       "13                                                   \n",
       "14                                                   \n",
       "15                                                   \n",
       "16                                                   \n",
       "17                                                   \n",
       "18                                                   \n",
       "19                                                   \n",
       "20                                                   \n",
       "21                                                   \n",
       "22                                                   \n",
       "23                                                   \n",
       "24                                                   \n",
       "25                                                   \n",
       "26                                                   \n",
       "27                                                   \n",
       "28                                                   \n",
       "29                                                   \n",
       "30                                                   \n",
       "31                                                   \n",
       "32                                                   \n",
       "33  Ãndice Interno  Ã­ndice Externo  Ã­ndice Externo   \n",
       "34            0.05           -0.05            0.05   \n",
       "35             0.3            -0.1            0.05   \n",
       "36             0.3            -0.1            0.05   \n",
       "37            0.05           -0.05            0.05   \n",
       "38            0.05           -0.05            0.05   \n",
       "39            0.05           -0.05            0.05   \n",
       "40             0.3            -0.1            0.05   \n",
       "41             0.3            -0.1            0.05   \n",
       "42             0.3            -0.1            0.05   \n",
       "43             0.3            -0.1            0.05   \n",
       "44             0.3            -0.1            0.05   \n",
       "45            0.05           -0.05            0.05   \n",
       "46             0.3            -0.1            0.05   \n",
       "47             0.3            -0.1            0.05   \n",
       "48             0.3            -0.1            0.05   \n",
       "49             0.3            -0.1            0.05   \n",
       "\n",
       "                                      11                        12      13  \\\n",
       "0                                                                            \n",
       "1                                                                            \n",
       "2                                                                            \n",
       "3                                                                            \n",
       "4                                                                            \n",
       "5                                                                            \n",
       "6   VariaÃ§Ã£o de Estoque por Centro - GPA                                     \n",
       "7                                                                            \n",
       "8                        Centro de lucro                                     \n",
       "9                                 Centro                                     \n",
       "10                   Classe de avaliaÃ§Ã£o                                     \n",
       "11                           Tp.material                                     \n",
       "12                    Modalidade estoque                                     \n",
       "13                               Produto                                     \n",
       "14                      Unid.medida base                                     \n",
       "15                              DepÃ³sito                                     \n",
       "16                     Tipo de movimento                                     \n",
       "17                       Tipo de veÃ­culo                                     \n",
       "18                             Incoterms                                     \n",
       "19                         Ano civil/mÃªs                                     \n",
       "20                     Dia de calendÃ¡rio    01/01/2025..31/01/2025           \n",
       "21                            HierarqPrd                                     \n",
       "22                               Indices                                     \n",
       "23                                                                           \n",
       "24                    Nome tÃ©cnico query  SB_IC01_GOP_VARIACAO_GPA           \n",
       "25                          InfoProvider                   S0_IC01           \n",
       "26                    Ãšltimo modificador                      Y3AU           \n",
       "27   Centro (opÃ§Ã£o de seleÃ§Ã£o, opcional)             SeleÃ§Ã£o vazia           \n",
       "28                         Ano civil/mÃªs                   01.2025           \n",
       "29                 AtualizaÃ§Ã£o dos dados       05/02/2025 02:30:08           \n",
       "30                                                                           \n",
       "31                         CondiÃ§Ã£o nova                   Inativo           \n",
       "32                                                                           \n",
       "33                       Centro de lucro             Ano civil/mÃªs  Centro   \n",
       "34                              ACPBOPAV                   01.2025    5126   \n",
       "35                              ACPBOPAV                   01.2025    5126   \n",
       "36                              ACPBOPAV                   01.2025    5126   \n",
       "37                              ACPBOPAV                   01.2025    5105   \n",
       "38                              ACPBOPAV                   01.2025    5105   \n",
       "39                              ACPBOPAV                   01.2025    5105   \n",
       "40                              ACPBOPAV                   01.2025    5105   \n",
       "41                              ACPBOPAV                   01.2025    5105   \n",
       "42                              ACPBOPAV                   01.2025    5105   \n",
       "43                              ACPBOPAV                   01.2025    5105   \n",
       "44                              ACPBOPAV                   01.2025    5105   \n",
       "45                              ACPBOPAV                   01.2025    5311   \n",
       "46                              ACPBOPAV                   01.2025    5311   \n",
       "47                              ACPBOPAV                   01.2025    5311   \n",
       "48                              ACPBOPAV                   01.2025    5311   \n",
       "49                              ACPBOPAV                   01.2025    5311   \n",
       "\n",
       "      14                     15              16                            17  \\\n",
       "0                    VARIAÃ‡ÃƒO %  LIMITE TÃ‰CNICO                                 \n",
       "1                                                                               \n",
       "2         LIMITE DE COMPETÃŠNCIA       DIRETORIA                          PRES   \n",
       "3          R$ por produto / mÃªs  >60.000.000,00                    30000000.0   \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "10                                                                              \n",
       "11                                                                              \n",
       "12                                                                              \n",
       "13                                                                              \n",
       "14                                                                              \n",
       "15                                                                              \n",
       "16                                                                              \n",
       "17                                                                              \n",
       "18                                                                              \n",
       "19                                                                              \n",
       "20                                                                              \n",
       "21                                                                              \n",
       "22                                                                              \n",
       "23                                                                              \n",
       "24                                                                              \n",
       "25                                                                              \n",
       "26                                                                              \n",
       "27                                                                              \n",
       "28                                                                              \n",
       "29                                                                              \n",
       "30                                                                              \n",
       "31                                                                              \n",
       "32                                                                              \n",
       "33                   HierarqPrd         Produto                                 \n",
       "34  BAV1         Diesel - Comum      01.011.674             Ã“LEO DIESEL B S10   \n",
       "35  BAV1   Querosene de AviaÃ§Ã£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "36  BAV1   Querosene de AviaÃ§Ã£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "37  BAV2         Gasolina Comum      01.000.078              GASOLINA COMUM C   \n",
       "38  BAV2         Diesel - Comum      01.011.674             Ã“LEO DIESEL B S10   \n",
       "39  BAV2         Diesel - Comum      01.024.741  Vibra Diesel RenovÃ¡vel HVO10   \n",
       "40  BAV2   Querosene de AviaÃ§Ã£o      01.016.205      JET A - PREÃ‡O FIXO - VRG   \n",
       "41  BAV2   Querosene de AviaÃ§Ã£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "42  BAV2   Querosene de AviaÃ§Ã£o      01.011.754              JET A PREÃ‡O FIXO   \n",
       "43  BAV2   Querosene de AviaÃ§Ã£o      01.026.471     JET A-1 NAO TABELADO - LI   \n",
       "44  BAV2   Querosene de AviaÃ§Ã£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "45  BAV3         Diesel - Comum      01.011.674             Ã“LEO DIESEL B S10   \n",
       "46  BAV3   Querosene de AviaÃ§Ã£o      01.016.205      JET A - PREÃ‡O FIXO - VRG   \n",
       "47  BAV3   Querosene de AviaÃ§Ã£o      01.001.422       JET A NAO TABELADO - LI   \n",
       "48  BAV3   Querosene de AviaÃ§Ã£o      01.011.754              JET A PREÃ‡O FIXO   \n",
       "49  BAV3   Querosene de AviaÃ§Ã£o      01.003.826    JET A INTERNACIONAL I - LI   \n",
       "\n",
       "                  18          19  \n",
       "0              FALTA       SOBRA  \n",
       "1                                 \n",
       "2                 N2          N3  \n",
       "3          1000000.0    300000.0  \n",
       "4                                 \n",
       "5                                 \n",
       "6                                 \n",
       "7                                 \n",
       "8                                 \n",
       "9                                 \n",
       "10                                \n",
       "11                                \n",
       "12                                \n",
       "13                                \n",
       "14                                \n",
       "15                                \n",
       "16                                \n",
       "17                                \n",
       "18                                \n",
       "19                                \n",
       "20                                \n",
       "21                                \n",
       "22                                \n",
       "23                                \n",
       "24                                \n",
       "25                                \n",
       "26                                \n",
       "27                                \n",
       "28                                \n",
       "29                                \n",
       "30                                \n",
       "31                                \n",
       "32                                \n",
       "33  Estoque\\nInicial     Entrada  \n",
       "34           16924.0              \n",
       "35          373850.0    939139.0  \n",
       "36          598315.0   5188210.0  \n",
       "37           13076.0     14828.0  \n",
       "38          122306.0    178128.0  \n",
       "39            3361.0     14839.0  \n",
       "40         1425416.0   3500000.0  \n",
       "41         9793143.0  19273387.0  \n",
       "42         4578994.0              \n",
       "43          513358.0   1200000.0  \n",
       "44                    38058936.0  \n",
       "45            1841.0      4955.0  \n",
       "46                      604734.0  \n",
       "47          759489.0   4295677.0  \n",
       "48          170534.0              \n",
       "49          -55123.0   3047462.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VARIAÃ‡ÃƒO %</td>\n",
       "      <td>LIMITE TÃ‰CNICO</td>\n",
       "      <td></td>\n",
       "      <td>FALTA</td>\n",
       "      <td>SOBRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LIMITE DE COMPETÃŠNCIA</td>\n",
       "      <td>DIRETORIA</td>\n",
       "      <td>PRES</td>\n",
       "      <td>N2</td>\n",
       "      <td>N3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>R$ por produto / mÃªs</td>\n",
       "      <td>&gt;60.000.000,00</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VariaÃ§Ã£o de Estoque por Centro - GPA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro de lucro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Classe de avaliaÃ§Ã£o</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tp.material</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modalidade estoque</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Produto</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unid.medida base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DepÃ³sito</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tipo de movimento</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tipo de veÃ­culo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Incoterms</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ano civil/mÃªs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dia de calendÃ¡rio</td>\n",
       "      <td>01/01/2025..31/01/2025</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HierarqPrd</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Indices</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nome tÃ©cnico query</td>\n",
       "      <td>SB_IC01_GOP_VARIACAO_GPA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>InfoProvider</td>\n",
       "      <td>S0_IC01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ãšltimo modificador</td>\n",
       "      <td>Y3AU</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Centro (opÃ§Ã£o de seleÃ§Ã£o, opcional)</td>\n",
       "      <td>SeleÃ§Ã£o vazia</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ano civil/mÃªs</td>\n",
       "      <td>01.2025</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AtualizaÃ§Ã£o dos dados</td>\n",
       "      <td>05/02/2025 02:30:08</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CondiÃ§Ã£o nova</td>\n",
       "      <td>Inativo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Justificar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Chave</td>\n",
       "      <td>Ãndice Interno</td>\n",
       "      <td>Ã­ndice Externo</td>\n",
       "      <td>Ã­ndice Externo</td>\n",
       "      <td>Centro de lucro</td>\n",
       "      <td>Ano civil/mÃªs</td>\n",
       "      <td>Centro</td>\n",
       "      <td></td>\n",
       "      <td>HierarqPrd</td>\n",
       "      <td>Produto</td>\n",
       "      <td></td>\n",
       "      <td>Estoque\\nInicial</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>512601.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>Ã“LEO DIESEL B S10</td>\n",
       "      <td>16924.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>512601.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>373850.0</td>\n",
       "      <td>939139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>512601.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>598315.0</td>\n",
       "      <td>5188210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>510501.202501.000.078</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Gasolina Comum</td>\n",
       "      <td>01.000.078</td>\n",
       "      <td>GASOLINA COMUM C</td>\n",
       "      <td>13076.0</td>\n",
       "      <td>14828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>510501.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>Ã“LEO DIESEL B S10</td>\n",
       "      <td>122306.0</td>\n",
       "      <td>178128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>510501.202501.024.741</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.024.741</td>\n",
       "      <td>Vibra Diesel RenovÃ¡vel HVO10</td>\n",
       "      <td>3361.0</td>\n",
       "      <td>14839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>510501.202501.016.205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PREÃ‡O FIXO - VRG</td>\n",
       "      <td>1425416.0</td>\n",
       "      <td>3500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>510501.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>9793143.0</td>\n",
       "      <td>19273387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>510501.202501.011.754</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PREÃ‡O FIXO</td>\n",
       "      <td>4578994.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>510501.202501.026.471</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.026.471</td>\n",
       "      <td>JET A-1 NAO TABELADO - LI</td>\n",
       "      <td>513358.0</td>\n",
       "      <td>1200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>510501.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td></td>\n",
       "      <td>38058936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>531101.202501.011.674</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>Ã“LEO DIESEL B S10</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>4955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>531101.202501.016.205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PREÃ‡O FIXO - VRG</td>\n",
       "      <td></td>\n",
       "      <td>604734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>531101.202501.001.422</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>759489.0</td>\n",
       "      <td>4295677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>531101.202501.011.754</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PREÃ‡O FIXO</td>\n",
       "      <td>170534.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>531101.202501.003.826</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ACPBOPAV</td>\n",
       "      <td>01.2025</td>\n",
       "      <td>5311</td>\n",
       "      <td>BAV3</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>-55123.0</td>\n",
       "      <td>3047462.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ’¾ Estado salvo: .bloco_7_state.json\n",
      "ğŸ’¾ Preview salvo: .bloco_7_preview.json\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:11:20.869090Z",
     "start_time": "2025-10-19T09:08:38.469082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 8 - DETECÃ‡ÃƒO E SELEÃ‡ÃƒO AVANÃ‡ADA DE CABEÃ‡ALHO - COMPLETO\n",
    "# VERSÃƒO REVISADA v2.1 - CORREÃ‡Ã•ES DE BUGS\n",
    "# Com: DicionÃ¡rio + AnÃ¡lise RepetiÃ§Ã£o + Multi-linha + AnÃ¡lise Colunas COMPLETA\n",
    "# MudanÃ§as v2.1:\n",
    "#   - Corrigido bug string vazia no critÃ©rio 12\n",
    "#   - Corrigido penalidade diversidade no critÃ©rio 5\n",
    "#   - TolerÃ¢ncia a gaps de atÃ© 3 colunas invÃ¡lidas\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ DETECÃ‡ÃƒO E SELEÃ‡ÃƒO DE CABEÃ‡ALHO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CARREGAR DICIONÃRIO PERSISTENTE (se nÃ£o estiver carregado)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” Verificando cabeÃ§alho multi-linha...\")\n",
    "\n",
    "if 'DICIONARIO_PERSISTENTE' not in globals():\n",
    "    print(\"\\nğŸ“š Carregando dicionÃ¡rio persistente...\")\n",
    "\n",
    "    locais_dicionario = [\n",
    "        Path.cwd() / 'DICT_Dicionario_Persistente.json',\n",
    "        fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json',\n",
    "        Path.cwd().parent / 'DICT_Dicionario_Persistente.json',\n",
    "    ]\n",
    "\n",
    "    DICIONARIO_PERSISTENTE = None\n",
    "\n",
    "    for local in locais_dicionario:\n",
    "        if local.exists():\n",
    "            try:\n",
    "                with open(local, 'r', encoding='utf-8') as f:\n",
    "                    DICIONARIO_PERSISTENTE = json.load(f)\n",
    "                print(f\"   âœ… Carregado de: {local.name}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not DICIONARIO_PERSISTENTE:\n",
    "        print(f\"   â„¹ï¸  DicionÃ¡rio nÃ£o encontrado - criando vazio\")\n",
    "        DICIONARIO_PERSISTENTE = {\n",
    "            'arquivos': {},\n",
    "            'ultima_atualizacao': None,\n",
    "            'versao': '1.0'\n",
    "        }\n",
    "else:\n",
    "    print(\"\\nğŸ“š DicionÃ¡rio persistente jÃ¡ carregado\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡ÃƒO AVANÃ‡ADA DE AVALIAÃ‡ÃƒO DE LINHA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def avaliar_linha_cabecalho_avancada(\n",
    "    linha, idx, total_linhas, df_preview, dicionario_persistente\n",
    "):\n",
    "    \"\"\"Avalia linha como candidata a cabeÃ§alho com mÃºltiplas heurÃ­sticas.\"\"\"\n",
    "    celulas = [\n",
    "        str(c).strip() for c in linha\n",
    "        if str(c).strip() and str(c).strip().lower() not in\n",
    "        ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not celulas:\n",
    "        return {\n",
    "            'score': 0.0,\n",
    "            'detalhes': 'Linha vazia',\n",
    "            'matches_dicionario': []\n",
    "        }\n",
    "\n",
    "    score = 0.0\n",
    "    detalhes = []\n",
    "\n",
    "    # CRITÃ‰RIO 1: PROPORÃ‡ÃƒO DE CÃ‰LULAS PREENCHIDAS (peso 2.0)\n",
    "    prop_preenchidas = len(celulas) / len(linha)\n",
    "    score_preenchidas = prop_preenchidas * 2.0\n",
    "    score += score_preenchidas\n",
    "    detalhes.append(\n",
    "        f\"Preench: {prop_preenchidas:.0%} (+{score_preenchidas:.1f})\"\n",
    "    )\n",
    "\n",
    "    # CRITÃ‰RIO 2: PROPORÃ‡ÃƒO DE TEXTO (peso 2.5)\n",
    "    tem_texto = sum(1 for c in celulas if re.search(r'[a-zA-Z]', c))\n",
    "    prop_texto = tem_texto / len(celulas) if celulas else 0\n",
    "    score_texto = prop_texto * 2.5\n",
    "    score += score_texto\n",
    "    detalhes.append(f\"Texto: {prop_texto:.0%} (+{score_texto:.1f})\")\n",
    "\n",
    "    # CRITÃ‰RIO 3: MATCH COM DICIONÃRIO PERSISTENTE (peso 4.0)\n",
    "    bonus_dicionario = 0.0\n",
    "    matches_dicionario = []\n",
    "\n",
    "    if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "        campos_conhecidos = set()\n",
    "        for arquivo_info in dicionario_persistente.get(\n",
    "            'arquivos', {}\n",
    "        ).values():\n",
    "            if 'campos_mapeados' in arquivo_info:\n",
    "                for campo_info in arquivo_info[\n",
    "                    'campos_mapeados'\n",
    "                ].values():\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "        for celula in celulas:\n",
    "            celula_lower = celula.lower()\n",
    "            if celula_lower in campos_conhecidos:\n",
    "                bonus_dicionario += 0.8\n",
    "                matches_dicionario.append(celula[:20])\n",
    "            elif any(\n",
    "                conhecido in celula_lower\n",
    "                for conhecido in campos_conhecidos\n",
    "            ):\n",
    "                bonus_dicionario += 0.4\n",
    "                matches_dicionario.append(f\"{celula[:15]}*\")\n",
    "\n",
    "    bonus_dicionario = min(bonus_dicionario, 4.0)\n",
    "    score += bonus_dicionario\n",
    "\n",
    "    if bonus_dicionario > 0:\n",
    "        detalhes.append(\n",
    "            f\"Dict: {len(matches_dicionario)}m (+{bonus_dicionario:.1f})\"\n",
    "        )\n",
    "\n",
    "    # CRITÃ‰RIO 4: ANÃLISE DE REPETIÃ‡ÃƒO (peso 3.0)\n",
    "    try:\n",
    "        linhas_futuras = min(20, total_linhas - idx - 1)\n",
    "\n",
    "        if linhas_futuras >= 5:\n",
    "            colunas_com_repeticao = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for i in range(1, min(linhas_futuras + 1, 21)):\n",
    "                    if idx + i < len(df_preview):\n",
    "                        valor_futuro = str(\n",
    "                            df_preview.iloc[idx + i, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_futuro == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 2:\n",
    "                    colunas_com_repeticao += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_repeticao = (\n",
    "                    colunas_com_repeticao / total_colunas_analisadas\n",
    "                )\n",
    "                score_repeticao = (1 - prop_repeticao) * 3.0\n",
    "                score += score_repeticao\n",
    "                detalhes.append(\n",
    "                    f\"Unic: {(1-prop_repeticao):.0%} \"\n",
    "                    f\"(+{score_repeticao:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 5: TAMANHO MÃ‰DIO DE STRINGS (peso 1.0)\n",
    "    tamanho_medio = np.mean([len(c) for c in celulas]) if celulas else 0\n",
    "    if 5 <= tamanho_medio <= 50:\n",
    "        score += 1.0\n",
    "        detalhes.append(f\"Tam: {tamanho_medio:.0f} (+1.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 6: UNICIDADE DENTRO DA LINHA (peso 1.5)\n",
    "    if len(celulas) == len(set(celulas)):\n",
    "        score += 1.5\n",
    "        detalhes.append(\"Ãšnicos (+1.5)\")\n",
    "\n",
    "    # CRITÃ‰RIO 7: POSIÃ‡ÃƒO NO ARQUIVO (peso 0.5)\n",
    "    if idx < 50:\n",
    "        bonus_posicao = (50 - idx) / 100\n",
    "        score += bonus_posicao\n",
    "        detalhes.append(f\"Pos: {idx+1} (+{bonus_posicao:.2f})\")\n",
    "\n",
    "    # CRITÃ‰RIO 8: ANÃLISE DE DADOS ABAIXO (peso 2.5)\n",
    "    try:\n",
    "        if idx + 5 < total_linhas:\n",
    "            celulas_match_dict = 0\n",
    "            celulas_numericas_puras = 0\n",
    "            celulas_com_numeros = 0\n",
    "            total_celulas_validas = 0\n",
    "\n",
    "            campos_dict_lower = set()\n",
    "            if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "                for arquivo_info in dicionario_persistente.get(\n",
    "                    'arquivos', {}\n",
    "                ).values():\n",
    "                    if 'campos_mapeados' in arquivo_info:\n",
    "                        for campo_info in arquivo_info[\n",
    "                            'campos_mapeados'\n",
    "                        ].values():\n",
    "                            if 'nome_original' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_original'].lower()\n",
    "                                )\n",
    "                            if 'nome_padrao' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_padrao'].lower()\n",
    "                                )\n",
    "                            if 'sinonimos' in campo_info:\n",
    "                                for sin in campo_info['sinonimos']:\n",
    "                                    campos_dict_lower.add(sin.lower())\n",
    "\n",
    "            for offset in range(1, 6):\n",
    "                if idx + offset < len(df_preview):\n",
    "                    linha_seguinte = df_preview.iloc[idx + offset]\n",
    "\n",
    "                    for celula in linha_seguinte:\n",
    "                        celula_str = str(celula).strip()\n",
    "\n",
    "                        if not celula_str or celula_str.lower() in [\n",
    "                            'nan', 'none', ''\n",
    "                        ]:\n",
    "                            continue\n",
    "\n",
    "                        total_celulas_validas += 1\n",
    "                        celula_lower = celula_str.lower()\n",
    "\n",
    "                        matched = False\n",
    "                        if campos_dict_lower:\n",
    "                            if celula_lower in campos_dict_lower:\n",
    "                                celulas_match_dict += 1\n",
    "                                matched = True\n",
    "                            else:\n",
    "                                for campo_conhecido in campos_dict_lower:\n",
    "                                    if (campo_conhecido in celula_lower or\n",
    "                                        celula_lower in campo_conhecido):\n",
    "                                        if len(campo_conhecido) >= 3:\n",
    "                                            celulas_match_dict += 1\n",
    "                                            matched = True\n",
    "                                            break\n",
    "\n",
    "                        if not matched:\n",
    "                            apenas_numeros = re.sub(\n",
    "                                r'[^0-9.]', '', celula_str\n",
    "                            )\n",
    "\n",
    "                            if len(apenas_numeros) > 0:\n",
    "                                prop_digitos = (\n",
    "                                    len(apenas_numeros) / len(celula_str)\n",
    "                                )\n",
    "                                if prop_digitos > 0.5:\n",
    "                                    celulas_numericas_puras += 1\n",
    "                                elif re.search(r'\\d', celula_str):\n",
    "                                    celulas_com_numeros += 1\n",
    "\n",
    "            if total_celulas_validas > 0:\n",
    "                prop_dict = celulas_match_dict / total_celulas_validas\n",
    "                prop_num_puras = (\n",
    "                    celulas_numericas_puras / total_celulas_validas\n",
    "                )\n",
    "                prop_com_num = celulas_com_numeros / total_celulas_validas\n",
    "\n",
    "                bonus_dados = 0.0\n",
    "                metodo_usado = None\n",
    "\n",
    "                if prop_dict > 0.4:\n",
    "                    bonus_dados = 2.5\n",
    "                    metodo_usado = f\"Dict:{prop_dict:.0%}\"\n",
    "                elif prop_num_puras > 0.6:\n",
    "                    bonus_dados = 2.0\n",
    "                    metodo_usado = f\"Num:{prop_num_puras:.0%}\"\n",
    "                elif (prop_num_puras + prop_com_num) > 0.7:\n",
    "                    bonus_dados = 1.0\n",
    "                    metodo_usado = f\"Misto:{(prop_num_puras+prop_com_num):.0%}\"\n",
    "\n",
    "                if bonus_dados > 0:\n",
    "                    score += bonus_dados\n",
    "                    detalhes.append(\n",
    "                        f\"DadosAbaixo:{metodo_usado} (+{bonus_dados:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 9: ANTI-DADOS (penalidade)\n",
    "    try:\n",
    "        celulas_linha_atual = [\n",
    "            str(c).strip() for c in linha\n",
    "            if str(c).strip() and str(c).strip().lower() not in\n",
    "            ['nan', 'none', '']\n",
    "        ]\n",
    "\n",
    "        if celulas_linha_atual:\n",
    "            num_puras_linha = 0\n",
    "            for celula in celulas_linha_atual:\n",
    "                apenas_numeros = re.sub(r'[^0-9.]', '', celula)\n",
    "                if len(apenas_numeros) > 0:\n",
    "                    prop_digitos = len(apenas_numeros) / len(celula)\n",
    "                    if prop_digitos > 0.5:\n",
    "                        num_puras_linha += 1\n",
    "\n",
    "            prop_num_linha = num_puras_linha / len(celulas_linha_atual)\n",
    "\n",
    "            repeticoes_detectadas = 0\n",
    "            if idx + 5 < total_linhas:\n",
    "                for col_idx, valor_atual in enumerate(linha):\n",
    "                    valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                    if (not valor_atual_str or\n",
    "                        valor_atual_str.lower() in ['nan', 'none', '']):\n",
    "                        continue\n",
    "\n",
    "                    for offset in range(1, min(6, total_linhas - idx)):\n",
    "                        if idx + offset < len(df_preview):\n",
    "                            valor_seguinte = str(\n",
    "                                df_preview.iloc[idx + offset, col_idx]\n",
    "                            ).strip()\n",
    "                            if valor_seguinte == valor_atual_str:\n",
    "                                repeticoes_detectadas += 1\n",
    "                                break\n",
    "\n",
    "            prop_repeticoes = (\n",
    "                repeticoes_detectadas / len(celulas_linha_atual)\n",
    "                if celulas_linha_atual else 0\n",
    "            )\n",
    "\n",
    "            penalidade = 0.0\n",
    "\n",
    "            if prop_num_linha > 0.6 and prop_repeticoes > 0.3:\n",
    "                penalidade = -3.0\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%}+Rep\"\n",
    "                    f\"{prop_repeticoes:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "            elif prop_num_linha > 0.7:\n",
    "                penalidade = -1.5\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 10: PADRÃƒO DE RÃ“TULOS (+4.0 pontos)\n",
    "    try:\n",
    "        palavras_rotulo = [\n",
    "            'centro', 'produto', 'material', 'data', 'valor', 'quantidade',\n",
    "            'codigo', 'nome', 'descricao', 'tipo', 'categoria', 'grupo',\n",
    "            'sigla', 'unidade', 'medida', 'periodo', 'mes', 'ano',\n",
    "            'referencia', 'documento', 'numero', 'id', 'chave', 'hierarq',\n",
    "            'lucro', 'receita', 'custo', 'despesa', 'saldo', 'total',\n",
    "            'indice', 'variacao', 'percentual', 'taxa', 'margem'\n",
    "        ]\n",
    "\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        if 'nome_original' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_original'].lower()\n",
    "                            )\n",
    "                        if 'nome_padrao' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_padrao'].lower()\n",
    "                            )\n",
    "\n",
    "        palavras_rotulo = set(palavras_rotulo)\n",
    "\n",
    "        matches_rotulo = 0\n",
    "        celulas_validas = 0\n",
    "\n",
    "        for celula in linha:\n",
    "            celula_str = str(celula).strip()\n",
    "            if not celula_str or celula_str.lower() in ['nan', 'none', '']:\n",
    "                continue\n",
    "\n",
    "            celulas_validas += 1\n",
    "            celula_lower = celula_str.lower()\n",
    "\n",
    "            if celula_lower in palavras_rotulo:\n",
    "                matches_rotulo += 1\n",
    "            else:\n",
    "                for palavra in palavras_rotulo:\n",
    "                    if len(palavra) >= 4 and palavra in celula_lower:\n",
    "                        matches_rotulo += 1\n",
    "                        break\n",
    "\n",
    "        if celulas_validas > 0:\n",
    "            prop_rotulos = matches_rotulo / celulas_validas\n",
    "\n",
    "            if prop_rotulos > 0.4:\n",
    "                bonus_rotulos = 4.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "            elif prop_rotulos > 0.25:\n",
    "                bonus_rotulos = 2.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 11: ANTI-REPETIÃ‡ÃƒO FORTE (-4.0 pontos)\n",
    "    try:\n",
    "        if idx + 10 < total_linhas:\n",
    "            colunas_com_repeticao_forte = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for offset in range(1, min(11, total_linhas - idx)):\n",
    "                    if idx + offset < len(df_preview):\n",
    "                        valor_seg = str(\n",
    "                            df_preview.iloc[idx + offset, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_seg == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 5:\n",
    "                    colunas_com_repeticao_forte += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_rep_forte = (\n",
    "                    colunas_com_repeticao_forte / total_colunas_analisadas\n",
    "                )\n",
    "\n",
    "                if prop_rep_forte > 0.3:\n",
    "                    penalidade_rep = -4.0\n",
    "                    score += penalidade_rep\n",
    "                    detalhes.append(\n",
    "                        f\"AntiRep:{prop_rep_forte:.0%} \"\n",
    "                        f\"({penalidade_rep:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 12: DENSIDADE DE RÃ“TULOS DO DICIONÃRIO (+3.0 pontos)\n",
    "    try:\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            campos_conhecidos = {}\n",
    "\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        nome_orig = campo_info.get('nome_original', '')\n",
    "                        nome_pad = campo_info.get('nome_padrao', '')\n",
    "\n",
    "                        if nome_orig:\n",
    "                            campos_conhecidos[nome_orig.lower()] = True\n",
    "                        if nome_pad:\n",
    "                            campos_conhecidos[nome_pad.lower()] = True\n",
    "\n",
    "            if campos_conhecidos:\n",
    "                matches_exatos = 0\n",
    "                celulas_validas = 0\n",
    "\n",
    "                for celula in linha:\n",
    "                    celula_str = str(celula).strip()\n",
    "                    if not celula_str or celula_str.lower() in [\n",
    "                        'nan', 'none', ''\n",
    "                    ]:\n",
    "                        continue\n",
    "\n",
    "                    celulas_validas += 1\n",
    "                    celula_lower = celula_str.lower()\n",
    "\n",
    "                    if celula_lower in campos_conhecidos:\n",
    "                        matches_exatos += 1\n",
    "\n",
    "                if celulas_validas > 0:\n",
    "                    prop_dict_exato = matches_exatos / celulas_validas\n",
    "\n",
    "                    if prop_dict_exato > 0.5:\n",
    "                        bonus_dict_dens = 3.0\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "                    elif prop_dict_exato > 0.3:\n",
    "                        bonus_dict_dens = 1.5\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        'score': score,\n",
    "        'detalhes': ' | '.join(detalhes),\n",
    "        'matches_dicionario': matches_dicionario\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# AVALIAR TODAS AS LINHAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ“Š Analisando linhas para detectar cabeÃ§alho...\")\n",
    "\n",
    "if metodo_carga == 'csv':\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "elif metodo_carga == 'xlrd':\n",
    "    data_para_analise = []\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_para_analise.append(sheet.row_values(row_idx))\n",
    "else:\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "\n",
    "scores = []\n",
    "\n",
    "for idx, linha in enumerate(data_para_analise):\n",
    "    resultado = avaliar_linha_cabecalho_avancada(\n",
    "        linha,\n",
    "        idx,\n",
    "        len(data_para_analise),\n",
    "        df_preview,\n",
    "        DICIONARIO_PERSISTENTE\n",
    "    )\n",
    "\n",
    "    scores.append({\n",
    "        'linha_excel': idx + 1,\n",
    "        'indice': idx,\n",
    "        'score': resultado['score'],\n",
    "        'detalhes': resultado['detalhes'],\n",
    "        'matches': resultado['matches_dicionario']\n",
    "    })\n",
    "\n",
    "scores = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXIBIR TOP 5 CANDIDATOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ† Top 5 candidatos a cabeÃ§alho:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“ NUMERAÃ‡ÃƒO: Usamos Ã­ndice Python (preview inicia em 0)\")\n",
    "print(\"   â€¢ Ãndice 0 = Linha 1 no Excel\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, item in enumerate(scores[:5], 1):\n",
    "    idx_py = item['indice']\n",
    "    linha_excel = item['linha_excel']\n",
    "\n",
    "    print(f\"\\n   {i}Âº. Ãndice {idx_py} (Excel: Linha {linha_excel})\")\n",
    "    print(f\"       Score: {item['score']:.2f}/24.5\")\n",
    "    print(f\"       {item['detalhes']}\")\n",
    "    if item['matches']:\n",
    "        matches_str = ', '.join(item['matches'][:5])\n",
    "        print(f\"       Matches: {matches_str}\")\n",
    "\n",
    "melhor = scores[0]\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\n",
    "    f\"ğŸ¯ SUGESTÃƒO AUTOMÃTICA: Ãndice {melhor['indice']} \"\n",
    "    f\"(Excel: Linha {melhor['linha_excel']})\"\n",
    ")\n",
    "print(f\"   ConfianÃ§a: {melhor['score']:.2f}/24.5\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ANÃLISE DE COLUNAS VÃLIDAS - SISTEMA COMPLETO v2.1\n",
    "# CORREÃ‡ÃƒO: Bugs nos critÃ©rios 5 e 12\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def analisar_coluna_valida_COMPLETA(\n",
    "    col_idx,\n",
    "    nome_coluna,\n",
    "    dados_coluna,\n",
    "    dicionario,\n",
    "    todas_colunas_info=None\n",
    "):\n",
    "    \"\"\"\n",
    "    AnÃ¡lise COMPLETA de coluna com 12 critÃ©rios avanÃ§ados.\n",
    "    Funciona para TABELAS TRANSACIONAIS e RELATÃ“RIOS BI.\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    razoes = []\n",
    "    metodo_usado = None\n",
    "\n",
    "    valores = [\n",
    "        str(v).strip() for v in dados_coluna\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not valores:\n",
    "        return {\n",
    "            'valida': False,\n",
    "            'score': 0.0,\n",
    "            'razoes': ['Coluna vazia'],\n",
    "            'tipo_detectado': 'VAZIA',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'VAZIO',\n",
    "            'prop_preenchimento': 0.0,\n",
    "            'match_dicionario': None\n",
    "        }\n",
    "\n",
    "    # CRITÃ‰RIO 1: SIMILARIDADE COM ALIASES DO DICIONÃRIO (peso 8.0)\n",
    "    nome_lower = str(nome_coluna).lower().strip()\n",
    "    melhor_match_alias = None\n",
    "    melhor_score_alias = 0.0\n",
    "    campo_matched = None\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        aliases_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if nome_campo not in aliases_por_campo:\n",
    "                        aliases_por_campo[nome_campo] = set()\n",
    "\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'sinonimos' in campo_info:\n",
    "                        for sin in campo_info['sinonimos']:\n",
    "                            aliases_por_campo[nome_campo].add(sin.lower())\n",
    "\n",
    "        for campo, aliases in aliases_por_campo.items():\n",
    "            for alias in aliases:\n",
    "                if nome_lower == alias:\n",
    "                    melhor_score_alias = 1.0\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "                    break\n",
    "\n",
    "                similaridade = SequenceMatcher(None, nome_lower, alias).ratio()\n",
    "\n",
    "                if similaridade > melhor_score_alias:\n",
    "                    melhor_score_alias = similaridade\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "\n",
    "            if melhor_score_alias == 1.0:\n",
    "                break\n",
    "\n",
    "    if melhor_score_alias >= 0.95:\n",
    "        bonus_alias = 8.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Exato({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_EXATO'\n",
    "\n",
    "    elif melhor_score_alias >= 0.80:\n",
    "        bonus_alias = 6.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Similar({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_SIMILAR'\n",
    "\n",
    "    elif melhor_score_alias >= 0.60:\n",
    "        bonus_alias = 3.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Parcial({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 2: REGEX NOS CONTEÃšDOS vs DICIONÃRIO (peso 7.0)\n",
    "    melhor_match_regex = None\n",
    "    melhor_score_regex = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        padroes_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'regex' in campo_info:\n",
    "                        if nome_campo not in padroes_por_campo:\n",
    "                            padroes_por_campo[nome_campo] = []\n",
    "                        padroes_por_campo[nome_campo].append(campo_info['regex'])\n",
    "\n",
    "        for campo, padroes in padroes_por_campo.items():\n",
    "            for padrao in padroes:\n",
    "                try:\n",
    "                    matches = sum(\n",
    "                        1 for v in valores[:50]\n",
    "                        if re.match(padrao, v, re.IGNORECASE)\n",
    "                    )\n",
    "\n",
    "                    prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "                    if prop_matches > melhor_score_regex:\n",
    "                        melhor_score_regex = prop_matches\n",
    "                        melhor_match_regex = campo\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    if melhor_score_regex >= 0.80:\n",
    "        bonus_regex = 7.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_CONTEUDO'\n",
    "\n",
    "    elif melhor_score_regex >= 0.60:\n",
    "        bonus_regex = 4.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 3: SIMILARIDADE COM CONTEÃšDOS CONHECIDOS (peso 6.0)\n",
    "    melhor_match_conteudo = None\n",
    "    melhor_score_conteudo = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        exemplos_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'exemplos' in campo_info:\n",
    "                        if nome_campo not in exemplos_por_campo:\n",
    "                            exemplos_por_campo[nome_campo] = set()\n",
    "\n",
    "                        for exemplo in campo_info['exemplos']:\n",
    "                            exemplos_por_campo[nome_campo].add(\n",
    "                                str(exemplo).lower().strip()\n",
    "                            )\n",
    "\n",
    "        for campo, exemplos in exemplos_por_campo.items():\n",
    "            matches = 0\n",
    "            for valor in valores[:50]:\n",
    "                valor_lower = valor.lower()\n",
    "\n",
    "                if valor_lower in exemplos:\n",
    "                    matches += 1\n",
    "                else:\n",
    "                    for exemplo in exemplos:\n",
    "                        sim = SequenceMatcher(None, valor_lower, exemplo).ratio()\n",
    "                        if sim >= 0.85:\n",
    "                            matches += 1\n",
    "                            break\n",
    "\n",
    "            prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "            if prop_matches > melhor_score_conteudo:\n",
    "                melhor_score_conteudo = prop_matches\n",
    "                melhor_match_conteudo = campo\n",
    "\n",
    "    if melhor_score_conteudo >= 0.70:\n",
    "        bonus_conteudo = 6.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'CONTEUDO_SIMILAR'\n",
    "\n",
    "    elif melhor_score_conteudo >= 0.50:\n",
    "        bonus_conteudo = 3.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "\n",
    "    # CRITÃ‰RIO 4: DETECÃ‡ÃƒO DE FÃ“RMULAS (penalidade -8.0)\n",
    "    tem_formulas = False\n",
    "\n",
    "    padroes_formula = [\n",
    "        r'^=',\n",
    "        r'^\\+',\n",
    "        r'^SUM\\(',\n",
    "        r'^IF\\(',\n",
    "        r'^VLOOKUP\\(',\n",
    "    ]\n",
    "\n",
    "    for valor in valores[:20]:\n",
    "        for padrao in padroes_formula:\n",
    "            if re.match(padrao, valor, re.IGNORECASE):\n",
    "                tem_formulas = True\n",
    "                break\n",
    "        if tem_formulas:\n",
    "            break\n",
    "\n",
    "    if tem_formulas:\n",
    "        penalidade_formula = -8.0\n",
    "        score += penalidade_formula\n",
    "        razoes.append(f\"Formula! {penalidade_formula:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'FORMULA_DETECTADA'\n",
    "\n",
    "    # CRITÃ‰RIO 5: DIVERSIDADE DE VALORES (peso 4.0)\n",
    "    # CORREÃ‡ÃƒO v2.1: NÃ£o penalizar dimensÃµes BI com baixa diversidade na amostra\n",
    "    valores_unicos = len(set(valores))\n",
    "    total_valores = len(valores)\n",
    "    prop_unicos = valores_unicos / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_unicos > 0.7:\n",
    "        score += 4.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+4.0)\")\n",
    "    elif prop_unicos > 0.4:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+2.0)\")\n",
    "    elif prop_unicos < 0.05 and valores_unicos <= 3:\n",
    "        # SÃ³ penalizar se REALMENTE for flag (â‰¤3 valores Ãºnicos E <5%)\n",
    "        score -= 3.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (-3.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 6: PADRÃƒO DE FLAGS (penalidade -4.0)\n",
    "    flags_comuns = {'true', 'false', 'x', 'âœ“', '0', '1', 'sim', 'nÃ£o', 'yes', 'no'}\n",
    "    valores_lower = [v.lower() for v in valores]\n",
    "\n",
    "    matches_flag = sum(1 for v in valores_lower if v in flags_comuns)\n",
    "    prop_flags = matches_flag / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_flags > 0.8:\n",
    "        score -= 4.0\n",
    "        razoes.append(f\"Flags:{prop_flags:.0%} (-4.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 7: PALAVRAS-CHAVE DE DADOS (peso 3.0)\n",
    "    palavras_dados = [\n",
    "        'centro', 'produto', 'material', 'codigo', 'nome', 'data',\n",
    "        'valor', 'quantidade', 'preco', 'custo', 'receita',\n",
    "        'hierarq', 'grupo', 'categoria', 'tipo', 'unidade',\n",
    "        'periodo', 'mes', 'ano', 'sigla', 'descricao', 'lucro'\n",
    "    ]\n",
    "\n",
    "    tem_palavra_chave = any(palavra in nome_lower for palavra in palavras_dados)\n",
    "\n",
    "    if tem_palavra_chave:\n",
    "        score += 3.0\n",
    "        razoes.append(f\"Keyword (+3.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 8: TAMANHO MÃ‰DIO DOS VALORES (peso 2.0)\n",
    "    tamanho_medio = sum(len(v) for v in valores) / len(valores)\n",
    "\n",
    "    if 3 <= tamanho_medio <= 100:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (+2.0)\")\n",
    "    elif tamanho_medio <= 2:\n",
    "        score -= 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (-2.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 9: MIX NUMÃ‰RICO/ALFABÃ‰TICO (peso 1.0)\n",
    "    tem_numeros = sum(1 for v in valores if any(c.isdigit() for c in v))\n",
    "    tem_letras = sum(1 for v in valores if any(c.isalpha() for c in v))\n",
    "\n",
    "    if tem_numeros > 0 and tem_letras > 0:\n",
    "        score += 1.0\n",
    "        razoes.append(f\"Mix (+1.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 10: PREENCHIMENTO PARCIAL (penalidade -5.0)\n",
    "    prop_preenchimento = len(valores) / len(dados_coluna) if dados_coluna else 0\n",
    "\n",
    "    if prop_preenchimento < 0.30:\n",
    "        penalidade_parcial = -5.0\n",
    "        score += penalidade_parcial\n",
    "        razoes.append(f\"Parcial:{prop_preenchimento:.0%} {penalidade_parcial:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'PREENCHIMENTO_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 11: MUDANÃ‡A ESTRUTURAL (penalidade -6.0)\n",
    "    if todas_colunas_info and col_idx > 0:\n",
    "        colunas_anteriores = todas_colunas_info[:col_idx]\n",
    "\n",
    "        if len(colunas_anteriores) >= 5:\n",
    "            preench_ultimas_5 = sum(\n",
    "                c.get('prop_preenchimento', 1.0)\n",
    "                for c in colunas_anteriores[-5:]\n",
    "            ) / 5\n",
    "\n",
    "            if preench_ultimas_5 > 0.80 and prop_preenchimento < 0.50:\n",
    "                penalidade_estrutural = -6.0\n",
    "                score += penalidade_estrutural\n",
    "                razoes.append(\n",
    "                    f\"Estrutural:Queda ({penalidade_estrutural:.1f})\"\n",
    "                )\n",
    "                if not metodo_usado:\n",
    "                    metodo_usado = 'MUDANCA_ESTRUTURAL'\n",
    "\n",
    "    # CRITÃ‰RIO 12: PADRÃƒO DE NOME \"VAZIO\" (penalidade -7.0)\n",
    "    # CORREÃ‡ÃƒO v2.1: Remover string vazia da lista\n",
    "    nomes_vazios = ['unnamed', 'column', 'col', 'field', 'nan', 'none']\n",
    "\n",
    "    nome_eh_vazio = (\n",
    "        len(nome_lower) == 0 or\n",
    "        nome_lower in nomes_vazios or\n",
    "        (len(nome_lower) < 15 and any(vazio in nome_lower for vazio in nomes_vazios if vazio))\n",
    "    )\n",
    "\n",
    "    if nome_eh_vazio:\n",
    "        penalidade_nome = -7.0\n",
    "        score += penalidade_nome\n",
    "        razoes.append(f\"NomeVazio {penalidade_nome:.1f}\")\n",
    "\n",
    "    # DECISÃƒO FINAL\n",
    "    confianca = max(0.0, min(1.0, (score + 10) / 40))\n",
    "\n",
    "    if score >= 10.0:\n",
    "        tipo = \"DADOS\"\n",
    "        valida = True\n",
    "    elif score >= 0.0:\n",
    "        tipo = \"INCERTO\"\n",
    "        valida = True\n",
    "    else:\n",
    "        tipo = \"FLAG/FORMULA/AUXILIAR\"\n",
    "        valida = False\n",
    "\n",
    "    if not metodo_usado:\n",
    "        metodo_usado = 'HEURISTICAS_BASICAS'\n",
    "\n",
    "    return {\n",
    "        'valida': valida,\n",
    "        'score': score,\n",
    "        'razoes': razoes,\n",
    "        'tipo_detectado': tipo,\n",
    "        'confianca': confianca,\n",
    "        'metodo': metodo_usado,\n",
    "        'prop_preenchimento': prop_preenchimento,\n",
    "        'match_dicionario': campo_matched or melhor_match_regex or melhor_match_conteudo\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTAR ANÃLISE DE COLUNAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” ANALISANDO COLUNAS (Sistema AvanÃ§ado v2.1)\")\n",
    "print(\"=\"*70)\n",
    "print(\"CritÃ©rios: Similaridade + Regex + ConteÃºdo + FÃ³rmulas + Estrutura\")\n",
    "print(\"Funciona para: Tabelas Transacionais e RelatÃ³rios BI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "linha_cabecalho_detectado = data_para_analise[melhor['indice']]\n",
    "\n",
    "inicio_dados = melhor['indice'] + 1\n",
    "fim_dados = min(inicio_dados + 50, len(data_para_analise))\n",
    "dados_para_colunas = data_para_analise[inicio_dados:fim_dados]\n",
    "\n",
    "print(f\"\\nğŸ“Š Analisando {len(linha_cabecalho_detectado)} colunas...\")\n",
    "print(f\"   Amostra de dados: {fim_dados - inicio_dados} linhas\")\n",
    "\n",
    "# PRIMEIRA PASSAGEM: InformaÃ§Ãµes bÃ¡sicas\n",
    "todas_colunas_info = []\n",
    "\n",
    "for col_idx, nome_col in enumerate(linha_cabecalho_detectado):\n",
    "    valores_col = [linha[col_idx] for linha in dados_para_colunas]\n",
    "\n",
    "    valores_validos = [\n",
    "        str(v).strip() for v in valores_col\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    prop_preenchimento = len(valores_validos) / len(valores_col) if valores_col else 0\n",
    "\n",
    "    todas_colunas_info.append({\n",
    "        'indice': col_idx,\n",
    "        'nome': str(nome_col),\n",
    "        'valores': valores_col,\n",
    "        'prop_preenchimento': prop_preenchimento\n",
    "    })\n",
    "\n",
    "# SEGUNDA PASSAGEM: AnÃ¡lise completa\n",
    "colunas_analise = []\n",
    "\n",
    "for col_info in todas_colunas_info:\n",
    "    col_idx = col_info['indice']\n",
    "    nome_col = col_info['nome']\n",
    "    valores_col = col_info['valores']\n",
    "\n",
    "    analise = analisar_coluna_valida_COMPLETA(\n",
    "        col_idx,\n",
    "        nome_col,\n",
    "        valores_col,\n",
    "        DICIONARIO_PERSISTENTE,\n",
    "        todas_colunas_info=todas_colunas_info\n",
    "    )\n",
    "\n",
    "    colunas_analise.append({\n",
    "        'indice': col_idx,\n",
    "        'excel_col': col_idx + 1,\n",
    "        'nome': str(nome_col)[:30],\n",
    "        **analise\n",
    "    })\n",
    "\n",
    "colunas_validas = [c for c in colunas_analise if c['valida']]\n",
    "colunas_invalidas = [c for c in colunas_analise if not c['valida']]\n",
    "\n",
    "print(f\"\\nâœ… Colunas VÃLIDAS (dados reais): {len(colunas_validas)}\")\n",
    "print(f\"âŒ Colunas INVÃLIDAS (flags/fÃ³rmulas/auxiliares): {len(colunas_invalidas)}\")\n",
    "\n",
    "# EXIBIR INVÃLIDAS\n",
    "if colunas_invalidas:\n",
    "    print(f\"\\nâŒ COLUNAS DETECTADAS COMO INVÃLIDAS:\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for col in colunas_invalidas[:15]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"{col['tipo_detectado']}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_str = ' | '.join(col['razoes'][:4])\n",
    "            print(f\"      RazÃµes: {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      Match: {col['match_dicionario']}\")\n",
    "\n",
    "# EXIBIR VÃLIDAS\n",
    "if colunas_validas:\n",
    "    print(f\"\\nâœ… TOP 10 COLUNAS VÃLIDAS (maiores scores):\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    colunas_validas_sorted = sorted(\n",
    "        colunas_validas,\n",
    "        key=lambda x: x['score'],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for col in colunas_validas_sorted[:10]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"Conf: {col['confianca']:.0%}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_str = ' | '.join(col['razoes'][:3])\n",
    "            print(f\"      {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      âœ“ Match: {col['match_dicionario']}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECTAR MUDANÃ‡AS ESTRUTURAIS E AGRUPAR EM BLOCOS CONTÃNUOS\n",
    "# v2.1: TolerÃ¢ncia a gaps de atÃ© 3 colunas invÃ¡lidas\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\nğŸ” DETECTANDO MUDANÃ‡AS ESTRUTURAIS:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Coletar Ã­ndices de colunas vÃ¡lidas\n",
    "colunas_validas_indices = [c['excel_col'] for c in colunas_analise if c['valida']]\n",
    "\n",
    "if not colunas_validas_indices:\n",
    "    blocos_continuos = []\n",
    "else:\n",
    "    # Agrupar com tolerÃ¢ncia a gaps de atÃ© 3 colunas\n",
    "    blocos_continuos = []\n",
    "    bloco_atual = [colunas_validas_indices[0]]\n",
    "\n",
    "    for i in range(1, len(colunas_validas_indices)):\n",
    "        col_atual = colunas_validas_indices[i]\n",
    "        col_anterior = colunas_validas_indices[i-1]\n",
    "\n",
    "        gap = col_atual - col_anterior - 1\n",
    "\n",
    "        # Se gap <= 3, considerar mesmo bloco (BI pode ter colunas vazias/auxiliares no meio)\n",
    "        # Se gap > 3, comeÃ§ar novo bloco\n",
    "        if gap <= 3:\n",
    "            bloco_atual.append(col_atual)\n",
    "        else:\n",
    "            blocos_continuos.append(bloco_atual)\n",
    "            bloco_atual = [col_atual]\n",
    "\n",
    "    if bloco_atual:\n",
    "        blocos_continuos.append(bloco_atual)\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    print(f\"\\nâš ï¸  MÃšLTIPLAS TABELAS DETECTADAS!\")\n",
    "\n",
    "    for i, bloco in enumerate(blocos_continuos, 1):\n",
    "        primeira = min(bloco)\n",
    "        ultima = max(bloco)\n",
    "        tamanho = len(bloco)\n",
    "\n",
    "        range_completo = ultima - primeira + 1\n",
    "        gaps_internos = range_completo - tamanho\n",
    "\n",
    "        print(f\"\\n   Tabela {i}:\")\n",
    "        print(f\"      Range Excel: {primeira} a {ultima}\")\n",
    "        print(f\"      Colunas vÃ¡lidas: {tamanho}\")\n",
    "        if gaps_internos > 0:\n",
    "            print(f\"      Gaps tolerados: {gaps_internos} col(s)\")\n",
    "\n",
    "        if i == 1:\n",
    "            print(f\"      âœ“ TABELA PRINCIPAL (use esta!)\")\n",
    "        else:\n",
    "            print(f\"      âš ï¸  Tabela auxiliar/complementar\")\n",
    "\n",
    "    primeira_valida = min(blocos_continuos[0])\n",
    "    ultima_valida = max(blocos_continuos[0])\n",
    "\n",
    "    print(f\"\\nğŸ’¡ RECOMENDAÃ‡ÃƒO:\")\n",
    "    print(f\"   Use apenas TABELA PRINCIPAL: colunas {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        primeira_valida = min(c['excel_col'] for c in colunas_validas)\n",
    "        ultima_valida = max(c['excel_col'] for c in colunas_validas)\n",
    "\n",
    "        print(f\"\\nâœ“ Estrutura contÃ­nua detectada\")\n",
    "        print(f\"   Colunas vÃ¡lidas: {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "# DETERMINAR RANGE FINAL\n",
    "if blocos_continuos:\n",
    "    col_inicio_sugerido = min(blocos_continuos[0])\n",
    "    col_fim_sugerido = max(blocos_continuos[0])\n",
    "\n",
    "    total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "    total_validas = len(blocos_continuos[0])\n",
    "    total_gaps = total_range - total_validas\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        col_inicio_sugerido = min(c['excel_col'] for c in colunas_validas)\n",
    "        col_fim_sugerido = max(c['excel_col'] for c in colunas_validas)\n",
    "        total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "        total_validas = len(colunas_validas)\n",
    "        total_gaps = total_range - total_validas\n",
    "    else:\n",
    "        col_inicio_sugerido = 1\n",
    "        col_fim_sugerido = len(linha_cabecalho_detectado)\n",
    "        total_range = col_fim_sugerido\n",
    "        total_validas = 0\n",
    "        total_gaps = 0\n",
    "\n",
    "print(f\"\\nğŸ¯ RANGE FINAL SUGERIDO:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Excel: {col_inicio_sugerido} a {col_fim_sugerido}\")\n",
    "print(f\"   Python: {col_inicio_sugerido-1} a {col_fim_sugerido}\")\n",
    "print(f\"   Total range: {total_range} colunas\")\n",
    "print(f\"   Colunas vÃ¡lidas: {total_validas}\")\n",
    "if total_gaps > 0:\n",
    "    print(f\"   Gaps internos: {total_gaps} (tolerados)\")\n",
    "\n",
    "if col_inicio_sugerido > 1:\n",
    "    colunas_ignoradas = col_inicio_sugerido - 1\n",
    "    print(f\"\\n   âš ï¸  Ignorando colunas 1-{colunas_ignoradas}\")\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    total_auxiliares = sum(len(bloco) for bloco in blocos_continuos[1:])\n",
    "    print(f\"   âš ï¸  Ignorando {total_auxiliares} colunas de tabelas auxiliares\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SALVAR RELATÃ“RIO\n",
    "relatorio_colunas = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'total_colunas': len(colunas_analise),\n",
    "    'colunas_validas': len(colunas_validas),\n",
    "    'colunas_invalidas': len(colunas_invalidas),\n",
    "    'blocos_detectados': len(blocos_continuos),\n",
    "    'range_sugerido': {\n",
    "        'inicio': col_inicio_sugerido,\n",
    "        'fim': col_fim_sugerido,\n",
    "        'total_range': total_range if blocos_continuos else col_fim_sugerido - col_inicio_sugerido + 1,\n",
    "        'total_validas': total_validas if blocos_continuos else len(colunas_validas),\n",
    "        'total_gaps': total_gaps if blocos_continuos else 0\n",
    "    },\n",
    "    'blocos': [\n",
    "        {\n",
    "            'bloco': i,\n",
    "            'inicio': min(bloco),\n",
    "            'fim': max(bloco),\n",
    "            'colunas_validas': len(bloco),\n",
    "            'range_completo': max(bloco) - min(bloco) + 1,\n",
    "            'gaps': (max(bloco) - min(bloco) + 1) - len(bloco),\n",
    "            'principal': i == 1\n",
    "        }\n",
    "        for i, bloco in enumerate(blocos_continuos, 1)\n",
    "    ],\n",
    "    'detalhes_colunas': [\n",
    "        {\n",
    "            'col': c['excel_col'],\n",
    "            'nome': c['nome'],\n",
    "            'valida': c['valida'],\n",
    "            'score': c['score'],\n",
    "            'tipo': c['tipo_detectado'],\n",
    "            'metodo': c['metodo'],\n",
    "            'match': c.get('match_dicionario')\n",
    "        }\n",
    "        for c in colunas_analise\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.analise_colunas.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    json.dump(relatorio_colunas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ RelatÃ³rio salvo: .analise_colunas.json\")\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# NOVA FUNÃ‡ÃƒO: ANTI-DADOS PARA DETECÃ‡ÃƒO MULTI-LINHA\n",
    "# Inserir ANTES da seÃ§Ã£o \"DETECTAR MULTI-LINHA\"\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def linha_parece_dados(linha, dicionario_persistente):\n",
    "    \"\"\"\n",
    "    Verifica se uma linha PARECE ser dados ao invÃ©s de cabeÃ§alho.\n",
    "\n",
    "    Returns:\n",
    "        float: Score de \"certeza que Ã© dados\" (0.0 a 1.0)\n",
    "               > 0.6 = provavelmente DADOS\n",
    "               < 0.4 = provavelmente CABEÃ‡ALHO\n",
    "    \"\"\"\n",
    "    celulas = [\n",
    "        str(c).strip() for c in linha\n",
    "        if str(c).strip() and str(c).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not celulas:\n",
    "        return 0.0\n",
    "\n",
    "    score_dados = 0.0\n",
    "\n",
    "    # CRITÃ‰RIO 1: PresenÃ§a de IDs/cÃ³digos numÃ©ricos puros (peso alto)\n",
    "    codigos_numericos = 0\n",
    "    for celula in celulas:\n",
    "        # Remove pontos e hÃ­fens para detectar cÃ³digos como \"1.000.000\" ou \"10-234\"\n",
    "        apenas_digitos = re.sub(r'[.\\-_/]', '', celula)\n",
    "\n",
    "        # Se tem 5+ dÃ­gitos consecutivos, Ã© muito provÃ¡vel que seja cÃ³digo/ID\n",
    "        if len(apenas_digitos) >= 5 and apenas_digitos.isdigit():\n",
    "            codigos_numericos += 1\n",
    "\n",
    "    prop_codigos = codigos_numericos / len(celulas)\n",
    "    if prop_codigos > 0.3:\n",
    "        score_dados += 0.5  # Forte indicador de dados\n",
    "\n",
    "    # CRITÃ‰RIO 2: Match com VALORES conhecidos do dicionÃ¡rio (nÃ£o nomes de campos)\n",
    "    if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "        valores_conhecidos = set()\n",
    "\n",
    "        for arq_info in dicionario_persistente.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for campo_info in arq_info['campos_mapeados'].values():\n",
    "                    # Pega EXEMPLOS de valores (dados), nÃ£o nomes de campos\n",
    "                    if 'exemplos' in campo_info:\n",
    "                        for exemplo in campo_info['exemplos']:\n",
    "                            valores_conhecidos.add(str(exemplo).lower().strip())\n",
    "\n",
    "        matches_valores = 0\n",
    "        for celula in celulas:\n",
    "            celula_lower = celula.lower()\n",
    "            if celula_lower in valores_conhecidos:\n",
    "                matches_valores += 1\n",
    "            # Similaridade parcial para valores longos\n",
    "            elif len(celula) > 10:\n",
    "                for valor_conhecido in valores_conhecidos:\n",
    "                    if len(valor_conhecido) > 10:\n",
    "                        sim = SequenceMatcher(None, celula_lower, valor_conhecido).ratio()\n",
    "                        if sim > 0.85:\n",
    "                            matches_valores += 1\n",
    "                            break\n",
    "\n",
    "        prop_match_valores = matches_valores / len(celulas)\n",
    "        if prop_match_valores > 0.5:\n",
    "            score_dados += 0.4  # Forte indicador de dados\n",
    "\n",
    "    # CRITÃ‰RIO 3: PadrÃ£o de nomenclatura de cabeÃ§alho (AUSENTE = Ã© dados)\n",
    "    palavras_cabecalho = [\n",
    "        'codigo', 'nome', 'descricao', 'data', 'valor', 'quantidade',\n",
    "        'tipo', 'categoria', 'grupo', 'centro', 'material', 'produto',\n",
    "        'hierarq', 'sigla', 'unidade', 'periodo', 'mes', 'ano'\n",
    "    ]\n",
    "\n",
    "    tem_palavra_cabecalho = any(\n",
    "        any(palavra in celula.lower() for palavra in palavras_cabecalho)\n",
    "        for celula in celulas\n",
    "    )\n",
    "\n",
    "    if not tem_palavra_cabecalho:\n",
    "        score_dados += 0.2  # Moderado indicador de dados\n",
    "\n",
    "    # CRITÃ‰RIO 4: Tamanho muito curto (flags) ou muito longo (descriÃ§Ãµes)\n",
    "    tamanho_medio = sum(len(c) for c in celulas) / len(celulas)\n",
    "    if tamanho_medio < 3:\n",
    "        # Muito curto = flags = dados\n",
    "        score_dados += 0.1\n",
    "    elif tamanho_medio > 40:\n",
    "        # Muito longo = descriÃ§Ãµes detalhadas = dados\n",
    "        score_dados += 0.15\n",
    "\n",
    "    # CRITÃ‰RIO 5: PadrÃµes especÃ­ficos de dados\n",
    "    padroes_dados = [\n",
    "        r'^\\d{6,}$',                    # CÃ³digos numÃ©ricos longos\n",
    "        r'^[A-Z]{2,}_[A-Z_]+$',         # PadrÃµes tipo DIESEL_MARÃTIMO_SIMP\n",
    "        r'^\\d{4}-\\d{2}-\\d{2}$',         # Datas ISO\n",
    "        r'^\\d+[.,]\\d{2}$',              # Valores monetÃ¡rios\n",
    "    ]\n",
    "\n",
    "    matches_padroes = 0\n",
    "    for celula in celulas:\n",
    "        for padrao in padroes_dados:\n",
    "            if re.match(padrao, celula):\n",
    "                matches_padroes += 1\n",
    "                break\n",
    "\n",
    "    prop_padroes = matches_padroes / len(celulas)\n",
    "    if prop_padroes > 0.3:\n",
    "        score_dados += 0.3\n",
    "\n",
    "    return min(1.0, score_dados)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECTAR MULTI-LINHA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if len(scores) > 1:\n",
    "    segundo = scores[1]\n",
    "\n",
    "    # Verificar se segunda linha PARECE dados\n",
    "    segunda_linha_dados = data_para_analise[segundo['indice']]\n",
    "    prob_dados = linha_parece_dados(segunda_linha_dados, DICIONARIO_PERSISTENTE)\n",
    "\n",
    "    print(f\"\\nğŸ” AnÃ¡lise da linha seguinte (L{segundo['linha_excel']}):\")\n",
    "    print(f\"   Score: {segundo['score']:.2f}\")\n",
    "    print(f\"   Probabilidade de ser DADOS: {prob_dados:.0%}\")\n",
    "\n",
    "    # CRITÃ‰RIOS MAIS RIGOROSOS para multi-linha:\n",
    "    # 1. Score deve ser > 70% do melhor (nÃ£o 50%)\n",
    "    # 2. Probabilidade de ser dados deve ser < 40%\n",
    "    # 3. DiferenÃ§a de score deve ser razoÃ¡vel (nÃ£o muito diferente)\n",
    "\n",
    "    eh_multilinea = (\n",
    "        segundo['indice'] == melhor['indice'] + 1 and\n",
    "        segundo['score'] > (melhor['score'] * 0.70) and  # â† AUMENTADO de 0.5 para 0.7\n",
    "        prob_dados < 0.4 and                              # â† NOVO critÃ©rio anti-dados\n",
    "        abs(melhor['score'] - segundo['score']) < 8.0    # â† NOVO: scores similares\n",
    "    )\n",
    "\n",
    "    if eh_multilinea:\n",
    "        print(f\"\\n   âœ… CABEÃ‡ALHO MULTI-LINHA confirmado!\")\n",
    "        print(f\"   Linha {melhor['linha_excel']}: Score {melhor['score']:.2f}\")\n",
    "        print(f\"   Linha {segundo['linha_excel']}: Score {segundo['score']:.2f}\")\n",
    "        print(f\"\\n   ğŸ’¡ RECOMENDAÃ‡ÃƒO:\")\n",
    "        print(f\"      1. CONCATENAR: Linha1 + ' - ' + Linha2\")\n",
    "        print(f\"      2. USAR PRIMEIRA: Linha {melhor['linha_excel']}\")\n",
    "        print(f\"      3. PERSONALIZAR via GUI\")\n",
    "\n",
    "        multi_linha_detectado = True\n",
    "        linha_fim_sugerida = segundo['linha_excel']\n",
    "    else:\n",
    "        if prob_dados > 0.6:\n",
    "            print(f\"\\n   âŒ Linha seguinte PARECE SER DADOS (nÃ£o cabeÃ§alho)\")\n",
    "            print(f\"      Probabilidade: {prob_dados:.0%}\")\n",
    "        else:\n",
    "            print(f\"\\n   â„¹ï¸  Scores insuficientes para multi-linha\")\n",
    "            print(f\"      Threshold: {melhor['score'] * 0.70:.2f}\")\n",
    "            print(f\"      Score L{segundo['linha_excel']}: {segundo['score']:.2f}\")\n",
    "\n",
    "        multi_linha_detectado = False\n",
    "        linha_fim_sugerida = melhor['linha_excel']\n",
    "else:\n",
    "    multi_linha_detectado = False\n",
    "    linha_fim_sugerida = melhor['linha_excel']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI AVANÃ‡ADA COM TIMER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def selecionar_range_cabecalho_com_timer(\n",
    "    sugerido_linha,\n",
    "    sugerido_linha_fim,\n",
    "    total_linhas,\n",
    "    total_colunas,\n",
    "    multi_linha=False,\n",
    "    col_inicio_sug=1,\n",
    "    col_fim_sug=None\n",
    "):\n",
    "    \"\"\"GUI avanÃ§ada para seleÃ§Ã£o de range de cabeÃ§alho.\"\"\"\n",
    "\n",
    "    if col_fim_sug is None:\n",
    "        col_fim_sug = total_colunas\n",
    "\n",
    "    config_file = fm.pastas['logs'] / '.ultimo_range_cabecalho.json'\n",
    "    ultimo_config = None\n",
    "\n",
    "    if config_file.exists():\n",
    "        try:\n",
    "            with open(config_file, 'r', encoding='utf-8') as f:\n",
    "                cfg = json.load(f)\n",
    "                if cfg.get('arquivo') == arquivo_selecionado.name:\n",
    "                    ultimo_config = cfg\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "        \"DETECTOR - SeleÃ§Ã£o AvanÃ§ada de CabeÃ§alho\",\n",
    "        650, 850,\n",
    "        tem_timer=bool(ultimo_config)\n",
    "    )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"ğŸ“‹ ConfiguraÃ§Ã£o de CabeÃ§alho e Dados\",\n",
    "        font=('Arial', 14, 'bold'),\n",
    "        bg='white'\n",
    "    ).pack(pady=(0, 10))\n",
    "\n",
    "    explicacao = tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"ğŸ“ IMPORTANTE: NumeraÃ§Ã£o\\n\\n\"\n",
    "            \"â€¢ Ãndice Python (preview): inicia em 0\\n\"\n",
    "            \"â€¢ Linha Excel (arquivo): inicia em 1\\n\"\n",
    "            \"â€¢ Use LINHA EXCEL nos campos abaixo\"\n",
    "        ),\n",
    "        font=('Arial', 9),\n",
    "        bg='#E3F2FD',\n",
    "        fg='#0D47A1',\n",
    "        justify=tk.LEFT,\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        relief=tk.RIDGE,\n",
    "        borderwidth=2\n",
    "    )\n",
    "    explicacao.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    idx_sugerido = sugerido_linha - 1\n",
    "    texto_sugestao = (\n",
    "        f\"ğŸ¤– SUGESTÃƒO AUTOMÃTICA\\n\"\n",
    "        f\"CabeÃ§alho: Ãndice {idx_sugerido} (Excel L{sugerido_linha})\\n\"\n",
    "        f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "        f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "    )\n",
    "\n",
    "    if multi_linha and sugerido_linha_fim != sugerido_linha:\n",
    "        idx_fim = sugerido_linha_fim - 1\n",
    "        texto_sugestao = (\n",
    "            f\"ğŸ¤– SUGESTÃƒO AUTOMÃTICA (MULTI-LINHA)\\n\"\n",
    "            f\"CabeÃ§alho: Ãndices {idx_sugerido}-{idx_fim} \"\n",
    "            f\"(Excel L{sugerido_linha}-L{sugerido_linha_fim})\\n\"\n",
    "            f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "            f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "        )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=texto_sugestao,\n",
    "        font=('Arial', 10, 'bold'),\n",
    "        bg='#E8F5E9' if not multi_linha else '#FFF9C4',\n",
    "        fg='#2E7D32' if not multi_linha else '#F57F17',\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        justify=tk.CENTER\n",
    "    ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if col_inicio_sug > 1:\n",
    "        colunas_ignoradas = col_inicio_sug - 1\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=(\n",
    "                f\"âš ï¸ COLUNAS 1-{colunas_ignoradas} DETECTADAS COMO \"\n",
    "                f\"FLAGS/FÃ“RMULAS\\n\"\n",
    "                f\"(SerÃ£o ignoradas automaticamente)\"\n",
    "            ),\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFEBEE',\n",
    "            fg='#C62828',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if ultimo_config:\n",
    "        linha_ini = ultimo_config['linha_inicio']\n",
    "        linha_fim = ultimo_config.get('linha_fim', linha_ini)\n",
    "        col_ini = ultimo_config['col_inicio']\n",
    "        col_fim = ultimo_config['col_fim']\n",
    "\n",
    "        idx_ini = linha_ini - 1\n",
    "        idx_fim = linha_fim - 1\n",
    "\n",
    "        texto_ultimo = (\n",
    "            f\"ğŸ’¡ ÃšLTIMA CONFIGURAÃ‡ÃƒO USADA\\n\"\n",
    "            f\"CabeÃ§alho: Ãndice {idx_ini}\"\n",
    "        )\n",
    "        if idx_fim != idx_ini:\n",
    "            texto_ultimo += f\"-{idx_fim}\"\n",
    "        texto_ultimo += f\" (Excel L{linha_ini}\"\n",
    "        if linha_fim != linha_ini:\n",
    "            texto_ultimo += f\"-L{linha_fim}\"\n",
    "        texto_ultimo += f\") | Colunas {col_ini}-{col_fim}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=texto_ultimo,\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFF3E0',\n",
    "            fg='#E65100',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(\n",
    "            frame, root, resultado, contador\n",
    "        )\n",
    "\n",
    "    frame_inputs = tk.Frame(frame, bg='white')\n",
    "    frame_inputs.pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha CabeÃ§alho INÃCIO (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=0, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['linha_inicio'] if ultimo_config\n",
    "            else sugerido_linha)\n",
    "    )\n",
    "    entry_cab_ini.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha CabeÃ§alho FIM (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=1, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "            if ultimo_config else sugerido_linha_fim)\n",
    "    )\n",
    "    entry_cab_fim.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna INÃCIO:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=2, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_inicio'] if ultimo_config\n",
    "            else col_inicio_sug)\n",
    "    )\n",
    "    entry_col_ini.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna FIM:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=3, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_fim'] if ultimo_config\n",
    "            else col_fim_sug)\n",
    "    )\n",
    "    entry_col_fim.grid(row=3, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha DADOS inÃ­cio (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=4, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_dados_ini = tk.Entry(\n",
    "        frame_inputs, width=10, font=('Arial', 10)\n",
    "    )\n",
    "\n",
    "    dados_inicio_default = (\n",
    "        ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "        if ultimo_config else sugerido_linha_fim\n",
    "    ) + 1\n",
    "\n",
    "    entry_dados_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_dados_inicio', dados_inicio_default)\n",
    "            if ultimo_config else dados_inicio_default)\n",
    "    )\n",
    "    entry_dados_ini.grid(row=4, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"ğŸ’¡ Para cabeÃ§alho 1 linha: InÃ­cio = Fim\\n\"\n",
    "            \"ğŸ’¡ Para multi-linha: InÃ­cio < Fim (ex: 3 a 4)\"\n",
    "        ),\n",
    "        font=('Arial', 8, 'italic'),\n",
    "        bg='#FFFDE7',\n",
    "        fg='#F57F17',\n",
    "        padx=10,\n",
    "        pady=8,\n",
    "        justify=tk.LEFT\n",
    "    ).pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    def confirmar():\n",
    "        resultado['cancelado'] = True\n",
    "        try:\n",
    "            resultado['valor'] = {\n",
    "                'linha_inicio': int(entry_cab_ini.get()),\n",
    "                'linha_fim': int(entry_cab_fim.get()),\n",
    "                'col_inicio': int(entry_col_ini.get()),\n",
    "                'col_fim': int(entry_col_fim.get()),\n",
    "                'linha_dados_inicio': int(entry_dados_ini.get())\n",
    "            }\n",
    "        except ValueError:\n",
    "            resultado['valor'] = None\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    def usar_ultima():\n",
    "        resultado['cancelado'] = True\n",
    "        resultado['valor'] = {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    GUIComTimer.criar_botoes(\n",
    "        frame,\n",
    "        confirmar,\n",
    "        usar_ultima if ultimo_config else None,\n",
    "        \"âœ… Confirmar\",\n",
    "        \"â±ï¸ Usar Ãšltima (10s)\"\n",
    "    )\n",
    "\n",
    "    if ultimo_config:\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    if resultado.get('timeout') and ultimo_config:\n",
    "        print(f\"   â±ï¸  Timeout - usando Ãºltima configuraÃ§Ã£o\")\n",
    "        return {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "\n",
    "    return resultado['valor']\n",
    "\n",
    "# EXECUTAR GUI\n",
    "print(\"\\nAbrindo janela de configuraÃ§Ã£o...\")\n",
    "config = selecionar_range_cabecalho_com_timer(\n",
    "    melhor['linha_excel'],\n",
    "    linha_fim_sugerida,\n",
    "    len(data_para_analise),\n",
    "    len(data_para_analise[0]) if data_para_analise else 1,\n",
    "    multi_linha=multi_linha_detectado,\n",
    "    col_inicio_sug=col_inicio_sugerido,\n",
    "    col_fim_sug=col_fim_sugerido\n",
    ")\n",
    "\n",
    "if not config:\n",
    "    raise ValueError(\"âŒ ConfiguraÃ§Ã£o invÃ¡lida ou cancelada\")\n",
    "\n",
    "# Salvar configuraÃ§Ã£o\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.ultimo_range_cabecalho.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    config_salvar = config.copy()\n",
    "    config_salvar['arquivo'] = arquivo_selecionado.name\n",
    "    config_salvar['sheet'] = sheet_nome\n",
    "    config_salvar['timestamp'] = datetime.now().isoformat()\n",
    "    json.dump(config_salvar, f, indent=2)\n",
    "\n",
    "# Extrair informaÃ§Ãµes\n",
    "linha_cabecalho_inicio = config['linha_inicio']\n",
    "linha_cabecalho_fim = config['linha_fim']\n",
    "col_inicio = config['col_inicio']\n",
    "col_fim = config['col_fim']\n",
    "linha_dados_inicio = config['linha_dados_inicio']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡ÃƒO CONFIRMADA:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   ğŸ“‹ CabeÃ§alho (Excel): L{linha_cabecalho_inicio}\", end=\"\")\n",
    "if linha_cabecalho_fim != linha_cabecalho_inicio:\n",
    "    print(f\" a L{linha_cabecalho_fim}\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"   ğŸ“Š Colunas (Excel): {col_inicio} a {col_fim}\")\n",
    "print(f\"   ğŸ“ˆ Dados comeÃ§am (Excel): L{linha_dados_inicio}\")\n",
    "\n",
    "# Converter para Ã­ndices Python\n",
    "idx_cab_inicio = linha_cabecalho_inicio - 1\n",
    "idx_cab_fim = linha_cabecalho_fim - 1\n",
    "idx_col_inicio = col_inicio - 1\n",
    "idx_col_fim = col_fim\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "print(f\"\\n   ğŸ Ãndices Python (uso interno):\")\n",
    "print(f\"      CabeÃ§alho: idx {idx_cab_inicio}\", end=\"\")\n",
    "if idx_cab_fim != idx_cab_inicio:\n",
    "    print(f\" a {idx_cab_fim}\")\n",
    "else:\n",
    "    print()\n",
    "print(f\"      Colunas: idx {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"      Dados: a partir de idx {idx_dados_inicio}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SALVAR ESTADO DO BLOCO 8\n",
    "estado_bloco8 = {\n",
    "    'bloco': 8,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'config': config,\n",
    "    'indices_python': {\n",
    "        'cabecalho_inicio': idx_cab_inicio,\n",
    "        'cabecalho_fim': idx_cab_fim,\n",
    "        'col_inicio': idx_col_inicio,\n",
    "        'col_fim': idx_col_fim,\n",
    "        'dados_inicio': idx_dados_inicio\n",
    "    },\n",
    "    'deteccao': {\n",
    "        'metodo': 'scoring_avancado_v2.1',\n",
    "        'melhor_score': melhor['score'],\n",
    "        'multi_linha': multi_linha_detectado,\n",
    "        'total_candidatos': len(scores),\n",
    "        'correcoes': ['bug_string_vazia', 'bug_diversidade', 'tolerancia_gaps']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.bloco_8_state.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    json.dump(estado_bloco8, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DETECÃ‡ÃƒO DE CABEÃ‡ALHO CONCLUÃDA\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a0c483a69d5db0c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¯ DETECÃ‡ÃƒO E SELEÃ‡ÃƒO DE CABEÃ‡ALHO\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Verificando cabeÃ§alho multi-linha...\n",
      "\n",
      "ğŸ“š DicionÃ¡rio persistente jÃ¡ carregado\n",
      "\n",
      "ğŸ“Š Analisando linhas para detectar cabeÃ§alho...\n",
      "\n",
      "ğŸ† Top 5 candidatos a cabeÃ§alho:\n",
      "======================================================================\n",
      "ğŸ“ NUMERAÃ‡ÃƒO: Usamos Ã­ndice Python (preview inicia em 0)\n",
      "   â€¢ Ãndice 0 = Linha 1 no Excel\n",
      "======================================================================\n",
      "\n",
      "   1Âº. Ãndice 33 (Excel: Linha 34)\n",
      "       Score: 14.10/24.5\n",
      "       Preench: 72% (+1.4) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 23 (+1.0) | Pos: 34 (+0.17) | DadosAbaixo:Num:81% (+2.0) | Rotulos:56% (+4.0)\n",
      "\n",
      "   2Âº. Ãndice 6 (Excel: Linha 7)\n",
      "       Score: 12.47/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 36 (+1.0) | Ãšnicos (+1.5) | Pos: 7 (+0.44) | Rotulos:100% (+4.0)\n",
      "\n",
      "   3Âº. Ãndice 8 (Excel: Linha 9)\n",
      "       Score: 12.45/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 15 (+1.0) | Ãšnicos (+1.5) | Pos: 9 (+0.42) | Rotulos:100% (+4.0)\n",
      "\n",
      "   4Âº. Ãndice 9 (Excel: Linha 10)\n",
      "       Score: 12.44/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 6 (+1.0) | Ãšnicos (+1.5) | Pos: 10 (+0.41) | Rotulos:100% (+4.0)\n",
      "\n",
      "   5Âº. Ãndice 11 (Excel: Linha 12)\n",
      "       Score: 12.42/24.5\n",
      "       Preench: 2% (+0.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 11 (+1.0) | Ãšnicos (+1.5) | Pos: 12 (+0.39) | Rotulos:100% (+4.0)\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ SUGESTÃƒO AUTOMÃTICA: Ãndice 33 (Excel: Linha 34)\n",
      "   ConfianÃ§a: 14.10/24.5\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ANALISANDO COLUNAS (Sistema AvanÃ§ado v2.1)\n",
      "======================================================================\n",
      "CritÃ©rios: Similaridade + Regex + ConteÃºdo + FÃ³rmulas + Estrutura\n",
      "Funciona para: Tabelas Transacionais e RelatÃ³rios BI\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Analisando 60 colunas...\n",
      "   Amostra de dados: 16 linhas\n",
      "\n",
      "âœ… Colunas VÃLIDAS (dados reais): 40\n",
      "âŒ Colunas INVÃLIDAS (flags/fÃ³rmulas/auxiliares): 20\n",
      "\n",
      "âŒ COLUNAS DETECTADAS COMO INVÃLIDAS:\n",
      "======================================================================\n",
      "   Col  1 (idx  0): Justificar                | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Flags:94% (-4.0) | Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col  2 (idx  1):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  3 (idx  2):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  5 (idx  4):                           | Score:   -5.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  6 (idx  5):                           | Score:   -3.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Divers:56% (+2.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col  7 (idx  6):                           | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Divers:100% (+4.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col 15 (idx 14):                           | Score:   -4.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:4 (+2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 18 (idx 17):                           | Score:   -2.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Divers:50% (+2.0) | Tam:22 (+2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 30 (idx 29):                           | Score:   +0.0 | VAZIA\n",
      "      RazÃµes: Coluna vazia\n",
      "   Col 38 (idx 37): CompetÃªncia para AbsorÃ§Ã£o | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col 39 (idx 38): CompetÃªncia para AbsorÃ§Ã£o | Score:   -1.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:1 (-2.0) | Mix (+1.0)\n",
      "   Col 40 (idx 39):                           | Score:   +0.0 | VAZIA\n",
      "      RazÃµes: Coluna vazia\n",
      "   Col 41 (idx 40):                           | Score:   -6.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Divers:50% (+2.0) | Tam:2 (-2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "   Col 42 (idx 41):                           | Score:   -3.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Divers:44% (+2.0) | Tam:3 (+2.0) | NomeVazio -7.0\n",
      "   Col 43 (idx 42):                           | Score:   -8.0 | FLAG/FORMULA/AUXILIAR\n",
      "      RazÃµes: Tam:2 (-2.0) | Mix (+1.0) | NomeVazio -7.0\n",
      "\n",
      "âœ… TOP 10 COLUNAS VÃLIDAS (maiores scores):\n",
      "======================================================================\n",
      "   Col 27 (idx 26): Custo UnitÃ¡rio do Produto | Score:   +9.0 | Conf: 48%\n",
      "      Divers:88% (+4.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 17 (idx 16): Produto                   | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:10 (+2.0)\n",
      "   Col 29 (idx 28): Valor da VariaÃ§Ã£o\n",
      "Interna | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:12 (+2.0)\n",
      "   Col 31 (idx 30): Quantidade Excedente da V | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:5 (+2.0)\n",
      "   Col 32 (idx 31): Valor Excedente da VariaÃ§ | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:10 (+2.0)\n",
      "   Col 37 (idx 36): Valor Excedente da VariaÃ§ | Score:   +7.0 | Conf: 42%\n",
      "      Divers:50% (+2.0) | Keyword (+3.0) | Tam:5 (+2.0)\n",
      "   Col 53 (idx 52): Custo UnitÃ¡rio do Produto | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 55 (idx 54): Valor da VariaÃ§Ã£o\n",
      "Interna | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:15 (+2.0)\n",
      "   Col 56 (idx 55): Custo MÃ©dio Ponderado Uni | Score:   +7.0 | Conf: 42%\n",
      "      Divers:69% (+2.0) | Keyword (+3.0) | Tam:14 (+2.0)\n",
      "   Col 59 (idx 58): Valor Excedente da VariaÃ§ | Score:   +7.0 | Conf: 42%\n",
      "      Divers:44% (+2.0) | Keyword (+3.0) | Tam:8 (+2.0)\n",
      "\n",
      "ğŸ” DETECTANDO MUDANÃ‡AS ESTRUTURAIS:\n",
      "======================================================================\n",
      "\n",
      "âš ï¸  MÃšLTIPLAS TABELAS DETECTADAS!\n",
      "\n",
      "   Tabela 1:\n",
      "      Range Excel: 4 a 37\n",
      "      Colunas vÃ¡lidas: 28\n",
      "      Gaps tolerados: 6 col(s)\n",
      "      âœ“ TABELA PRINCIPAL (use esta!)\n",
      "\n",
      "   Tabela 2:\n",
      "      Range Excel: 49 a 60\n",
      "      Colunas vÃ¡lidas: 12\n",
      "      âš ï¸  Tabela auxiliar/complementar\n",
      "\n",
      "ğŸ’¡ RECOMENDAÃ‡ÃƒO:\n",
      "   Use apenas TABELA PRINCIPAL: colunas 4 a 37\n",
      "\n",
      "ğŸ¯ RANGE FINAL SUGERIDO:\n",
      "======================================================================\n",
      "   Excel: 4 a 37\n",
      "   Python: 3 a 37\n",
      "   Total range: 34 colunas\n",
      "   Colunas vÃ¡lidas: 28\n",
      "   Gaps internos: 6 (tolerados)\n",
      "\n",
      "   âš ï¸  Ignorando colunas 1-3\n",
      "   âš ï¸  Ignorando 12 colunas de tabelas auxiliares\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¾ RelatÃ³rio salvo: .analise_colunas.json\n",
      "\n",
      "ğŸ” AnÃ¡lise da linha seguinte (L7):\n",
      "   Score: 12.47\n",
      "   Probabilidade de ser DADOS: 0%\n",
      "\n",
      "   â„¹ï¸  Scores insuficientes para multi-linha\n",
      "      Threshold: 9.87\n",
      "      Score L7: 12.47\n",
      "\n",
      "Abrindo janela de configuraÃ§Ã£o...\n",
      "\n",
      "âœ… CONFIGURAÃ‡ÃƒO CONFIRMADA:\n",
      "======================================================================\n",
      "   ğŸ“‹ CabeÃ§alho (Excel): L34\n",
      "   ğŸ“Š Colunas (Excel): 13 a 37\n",
      "   ğŸ“ˆ Dados comeÃ§am (Excel): L35\n",
      "\n",
      "   ğŸ Ãndices Python (uso interno):\n",
      "      CabeÃ§alho: idx 33\n",
      "      Colunas: idx 12 a 37\n",
      "      Dados: a partir de idx 34\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "âœ… DETECÃ‡ÃƒO DE CABEÃ‡ALHO CONCLUÃDA\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:02.023540Z",
     "start_time": "2025-10-19T09:18:01.708452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 9 - EXTRAÃ‡ÃƒO DE DADOS v2.0 (CORRIGIDO - PADRÃƒO JSON)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CORREÃ‡Ã•ES v2.0:\n",
    "# âœ… REMOVIDO: .parquet (biblioteca nÃ£o instalada)\n",
    "# âœ… ADICIONADO: .json para persistÃªncia (padrÃ£o do projeto)\n",
    "# âœ… MANTIDO: Todas as validaÃ§Ãµes e logs\n",
    "# âœ… COMPATÃVEL: Com BLOCO 10 v2.3 (que espera JSON tambÃ©m)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMUNICAÃ‡ÃƒO VIA LOG:\n",
    "# - LÃŠ: .bloco_5_state.json, .bloco_8_state.json, LOG GLOBAL\n",
    "# - SALVA: df_bruto em JSON + .bloco_9_state.json\n",
    "# - PRÃ“XIMO BLOCO: Carrega df_bruto do JSON\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¥ EXTRAÃ‡ÃƒO DE DADOS v2.0\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. CONECTAR VIA LOG GLOBAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\"âŒ LOG GLOBAL nÃ£o encontrado! Execute BLOCO 1.\")\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\")\n",
    "print(f\"   ğŸ“ Pasta base: {pasta_base.name}\")\n",
    "print(f\"   ğŸ• Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Recriar FileManager\n",
    "from sys import path as sys_path\n",
    "# Assumir que FileManagerInterativo foi definido no BLOCO 2\n",
    "# Se nÃ£o estiver na memÃ³ria, o usuÃ¡rio deve executar BLOCO 2 primeiro\n",
    "if 'FileManagerInterativo' not in globals():\n",
    "    raise NameError(\"âŒ FileManagerInterativo nÃ£o encontrado! Execute BLOCO 2.\")\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. CARREGAR CONFIGURAÃ‡Ã•ES DOS BLOCOS 4, 5, 6, 8\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# BLOCO 8: Range de cabeÃ§alho e colunas\n",
    "arquivo_bloco8 = fm.pastas['logs'] / '.bloco_8_state.json'\n",
    "if not arquivo_bloco8.exists():\n",
    "    raise FileNotFoundError(\"âŒ BLOCO 8 nÃ£o executado!\")\n",
    "\n",
    "with open(arquivo_bloco8, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco8 = json.load(f)\n",
    "\n",
    "config_bloco8 = estado_bloco8['config']\n",
    "\n",
    "linha_cabecalho_inicio = config_bloco8['linha_inicio']\n",
    "linha_cabecalho_fim = config_bloco8['linha_fim']\n",
    "col_inicio = config_bloco8['col_inicio']\n",
    "col_fim = config_bloco8['col_fim']\n",
    "linha_dados_inicio = config_bloco8['linha_dados_inicio']\n",
    "\n",
    "# BLOCO 5: MÃ©todo de carga e arquivo\n",
    "arquivo_bloco5_state = fm.pastas['logs'] / '.bloco_5_state.json'\n",
    "if not arquivo_bloco5_state.exists():\n",
    "    raise FileNotFoundError(\"âŒ BLOCO 5 nÃ£o executado!\")\n",
    "\n",
    "with open(arquivo_bloco5_state, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco5 = json.load(f)\n",
    "\n",
    "metodo_carga = estado_bloco5['metodo_carga']\n",
    "arquivo_selecionado = Path(estado_bloco5['workbook_path'])\n",
    "\n",
    "# CSV especÃ­fico\n",
    "if metodo_carga == 'csv':\n",
    "    separador_detectado = estado_bloco5.get('separador_detectado', ',')\n",
    "    skiprows_csv = estado_bloco5.get('skiprows_csv', 0)\n",
    "\n",
    "# Sheet selecionada: buscar do BLOCO 8\n",
    "sheet_nome = estado_bloco8['sheet']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡Ã•ES CARREGADAS\")\n",
    "print(f\"   ğŸ“„ Arquivo: {arquivo_selecionado.name}\")\n",
    "print(f\"   ğŸ“‹ Sheet: {sheet_nome}\")\n",
    "print(f\"   ğŸ”§ MÃ©todo: {metodo_carga}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. CONVERTER ÃNDICES EXCEL â†’ PYTHON\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "idx_cab_inicio = linha_cabecalho_inicio - 1\n",
    "idx_cab_fim = linha_cabecalho_fim - 1\n",
    "idx_col_inicio = col_inicio - 1\n",
    "idx_col_fim = col_fim\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "print(\"\\nğŸ“‹ ConfiguraÃ§Ã£o (notaÃ§Ã£o Excel):\")\n",
    "print(f\"   CabeÃ§alho: L{linha_cabecalho_inicio}\", end=\"\")\n",
    "if linha_cabecalho_fim != linha_cabecalho_inicio:\n",
    "    print(f\" a L{linha_cabecalho_fim}\")\n",
    "else:\n",
    "    print()\n",
    "print(f\"   Colunas: {col_inicio} a {col_fim}\")\n",
    "print(f\"   Dados: A partir de L{linha_dados_inicio}\")\n",
    "\n",
    "print(f\"\\nğŸ Ãndices Python:\")\n",
    "print(f\"   CabeÃ§alho: {idx_cab_inicio} a {idx_cab_fim}\")\n",
    "print(f\"   Colunas: {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"   Dados: a partir de {idx_dados_inicio}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. EXTRAÃ‡ÃƒO: CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if metodo_carga == 'csv':\n",
    "    print(f\"\\nğŸ“„ MÃ©todo: CSV\")\n",
    "\n",
    "    try:\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho Ãºnico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                arquivo_selecionado,\n",
    "                sep=separador_detectado,\n",
    "                encoding='cp1252',\n",
    "                skiprows=skiprows_csv,\n",
    "                header=idx_cab_inicio,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "            if linhas_pular > 0:\n",
    "                print(f\"   â­ï¸  Pulando {linhas_pular} linha(s)\")\n",
    "                df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "        else:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            df_temp = pd.read_csv(\n",
    "                arquivo_selecionado,\n",
    "                sep=separador_detectado,\n",
    "                encoding='cp1252',\n",
    "                skiprows=skiprows_csv,\n",
    "                header=None,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            cab_linhas = df_temp.iloc[idx_cab_inicio:idx_cab_fim+1].values\n",
    "            cab_final = []\n",
    "\n",
    "            for col_idx in range(cab_linhas.shape[1]):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            df = df_temp.iloc[idx_dados_inicio:].copy()\n",
    "            df.columns = cab_final\n",
    "\n",
    "        print(f\"   âœ… Carregado: {len(df):,} registros Ã— {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. EXTRAÃ‡ÃƒO: EXCEL MODERNO (PANDAS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(f\"ğŸ“‹ MÃ©todo: pandas (XLSX/XLSM)\")\n",
    "\n",
    "    try:\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho Ãºnico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            df = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=idx_cab_inicio,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "            if linhas_pular > 0:\n",
    "                print(f\"   â­ï¸  Pulando {linhas_pular} linha(s)\")\n",
    "                df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "        else:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            df_temp = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=None,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            cab_linhas = df_temp.iloc[idx_cab_inicio:idx_cab_fim+1].values\n",
    "            cab_final = []\n",
    "\n",
    "            for col_idx in range(cab_linhas.shape[1]):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            df = df_temp.iloc[idx_dados_inicio:].copy()\n",
    "            df.columns = cab_final\n",
    "\n",
    "        print(f\"   âœ… Carregado: {len(df):,} registros Ã— {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 6. EXTRAÃ‡ÃƒO: EXCEL LEGADO (XLRD)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'xlrd':\n",
    "    print(f\"ğŸ“‹ MÃ©todo: xlrd (XLS)\")\n",
    "\n",
    "    try:\n",
    "        import xlrd\n",
    "        workbook = xlrd.open_workbook(arquivo_selecionado)\n",
    "        sheet = workbook.sheet_by_name(sheet_nome)\n",
    "\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho Ãºnico (L{linha_cabecalho_inicio})\")\n",
    "\n",
    "            cabecalho = sheet.row_values(idx_cab_inicio)[idx_col_inicio:idx_col_fim]\n",
    "\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cabecalho)\n",
    "\n",
    "        else:\n",
    "            print(f\"   ğŸ“‹ CabeÃ§alho multi-linha (L{linha_cabecalho_inicio} a L{linha_cabecalho_fim})\")\n",
    "\n",
    "            cab_linhas = []\n",
    "            for linha_idx in range(idx_cab_inicio, idx_cab_fim + 1):\n",
    "                cab_linhas.append(sheet.row_values(linha_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            cab_final = []\n",
    "            for col_idx in range(len(cab_linhas[0])):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cab_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cab_final)\n",
    "\n",
    "        print(f\"   âœ… Carregado: {len(df):,} registros Ã— {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"âŒ MÃ©todo desconhecido: {metodo_carga}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 7. VALIDAÃ‡Ã•ES PÃ“S-EXTRAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"âœ… VALIDAÃ‡Ã•ES\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nğŸ“Š Shape final:\")\n",
    "print(f\"   Registros: {len(df):,}\")\n",
    "print(f\"   Colunas: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Primeiras 10 colunas:\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "if len(df.columns) > 10:\n",
    "    print(f\"   ... e mais {len(df.columns) - 10} colunas\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Primeiras 5 linhas (amostra):\")\n",
    "print(df.head().to_string())\n",
    "\n",
    "print(f\"\\nğŸ”¢ Tipos detectados:\")\n",
    "tipos_count = df.dtypes.value_counts()\n",
    "for tipo, count in tipos_count.items():\n",
    "    print(f\"   {str(tipo).ljust(15)}: {count} coluna(s)\")\n",
    "\n",
    "print(f\"\\nâš ï¸  Valores nulos:\")\n",
    "nulos_total = df.isnull().sum().sum()\n",
    "if nulos_total > 0:\n",
    "    print(f\"   Total: {nulos_total:,} cÃ©lulas vazias\")\n",
    "    colunas_com_nulos = df.isnull().sum()\n",
    "    colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0].sort_values(ascending=False)\n",
    "    print(f\"\\n   Top 5 colunas com nulos:\")\n",
    "    for col, count in colunas_com_nulos.head(5).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"      {col[:40].ljust(40)}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "else:\n",
    "    print(f\"   âœ… Nenhum valor nulo!\")\n",
    "\n",
    "memoria_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nğŸ’¾ MemÃ³ria utilizada: {memoria_mb:.2f} MB\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 8. SALVAMENTO EM JSON (PADRÃƒO DO PROJETO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\nğŸ’¾ Salvando df_bruto em JSON...\")\n",
    "\n",
    "df_bruto = df.copy()\n",
    "\n",
    "# Converter DataFrame para JSON estruturado\n",
    "df_dict = {\n",
    "    'columns': list(df_bruto.columns),\n",
    "    'data': df_bruto.values.tolist(),\n",
    "    'index': df_bruto.index.tolist(),\n",
    "    'dtypes': {col: str(dtype) for col, dtype in df_bruto.dtypes.items()}\n",
    "}\n",
    "\n",
    "arquivo_df_json = fm.pastas['processados'] / f'df_bruto_{timestamp_execucao}.json'\n",
    "\n",
    "with open(arquivo_df_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(df_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "tamanho_kb = arquivo_df_json.stat().st_size / 1024\n",
    "print(f\"   âœ… Salvo: {arquivo_df_json.name} ({tamanho_kb:.1f} KB)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 9. SALVAR ESTADO DO BLOCO 9\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco9 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 9,\n",
    "    'nome': 'EXTRAÃ‡ÃƒO DE DADOS',\n",
    "    'versao': '2.0',\n",
    "    'status': 'concluido',\n",
    "    'variaveis_criadas': ['df', 'df_bruto'],\n",
    "    'arquivo_processado': arquivo_selecionado.name,\n",
    "    'arquivo_df_bruto_json': arquivo_df_json.name,\n",
    "    'caminho_completo_json': str(arquivo_df_json),\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'estatisticas': {\n",
    "        'total_registros': len(df),\n",
    "        'total_colunas': len(df.columns),\n",
    "        'memoria_mb': round(memoria_mb, 2),\n",
    "        'colunas_com_nulos': int(nulos_total),\n",
    "        'tipos_detectados': {str(k): int(v) for k, v in df.dtypes.value_counts().items()}\n",
    "    },\n",
    "    'configuracao_aplicada': {\n",
    "        'linha_cabecalho_inicio': linha_cabecalho_inicio,\n",
    "        'linha_cabecalho_fim': linha_cabecalho_fim,\n",
    "        'col_inicio': col_inicio,\n",
    "        'col_fim': col_fim,\n",
    "        'linha_dados_inicio': linha_dados_inicio,\n",
    "        'cabecalho_multilinha': linha_cabecalho_inicio != linha_cabecalho_fim\n",
    "    },\n",
    "    'colunas_extraidas': list(df.columns),\n",
    "    'transformacoes_aplicadas': [\n",
    "        {\n",
    "            'tipo': 'extracao_range',\n",
    "            'descricao': f'CabeÃ§alho L{linha_cabecalho_inicio}-L{linha_cabecalho_fim}, Colunas {col_inicio}-{col_fim}, Dados L{linha_dados_inicio}+',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    ],\n",
    "    'instrucoes_proximo_bloco': {\n",
    "        'como_carregar': 'pd.read_json() ou json.load() + pd.DataFrame()',\n",
    "        'arquivo': arquivo_df_json.name,\n",
    "        'caminho': str(arquivo_df_json)\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_9_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco9, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… EXTRAÃ‡ÃƒO CONCLUÃDA COM SUCESSO v2.0\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“ INSTRUÃ‡Ã•ES PARA O PRÃ“XIMO BLOCO:\")\n",
    "print(f\"   1. Carregar estado: json.load('.bloco_9_state.json')\")\n",
    "print(f\"   2. Ler caminho: estado['caminho_completo_json']\")\n",
    "print(f\"   3. Carregar df_bruto:\")\n",
    "print(f\"      with open(caminho, 'r') as f:\")\n",
    "print(f\"          df_dict = json.load(f)\")\n",
    "print(f\"      df_bruto = pd.DataFrame(df_dict['data'], columns=df_dict['columns'])\")\n",
    "print(\"=\"*70)"
   ],
   "id": "51575848480d0ea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“¥ EXTRAÃ‡ÃƒO DE DADOS v2.0\n",
      "======================================================================\n",
      "\n",
      "âœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\n",
      "   ğŸ“ Pasta base: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   ğŸ• Timestamp: 20251019_060722\n",
      "\n",
      "âœ… CONFIGURAÃ‡Ã•ES CARREGADAS\n",
      "   ğŸ“„ Arquivo: CÃ³pia de xSAPtemp4687_JAN_25.xls\n",
      "   ğŸ“‹ Sheet: Valor da VariaÃ§Ã£o Total\n",
      "   ğŸ”§ MÃ©todo: xlrd\n",
      "\n",
      "ğŸ“‹ ConfiguraÃ§Ã£o (notaÃ§Ã£o Excel):\n",
      "   CabeÃ§alho: L34\n",
      "   Colunas: 13 a 37\n",
      "   Dados: A partir de L35\n",
      "\n",
      "ğŸ Ãndices Python:\n",
      "   CabeÃ§alho: 33 a 33\n",
      "   Colunas: 12 a 37\n",
      "   Dados: a partir de 34\n",
      "ğŸ“‹ MÃ©todo: xlrd (XLS)\n",
      "   ğŸ“‹ CabeÃ§alho Ãºnico (L34)\n",
      "   âœ… Carregado: 967 registros Ã— 25 colunas\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… VALIDAÃ‡Ã•ES\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š Shape final:\n",
      "   Registros: 967\n",
      "   Colunas: 25\n",
      "\n",
      "ğŸ“‹ Primeiras 10 colunas:\n",
      "    1. Ano civil/mÃªs\n",
      "    2. Centro\n",
      "    3. \n",
      "    4. HierarqPrd\n",
      "    5. Produto\n",
      "    6. \n",
      "    7. Estoque\n",
      "Inicial\n",
      "    8. Entrada\n",
      "    9. VariaÃ§Ã£o\n",
      "Externa\n",
      "   10. VariaÃ§Ã£o\n",
      "Externa\n",
      "%\n",
      "   ... e mais 15 colunas\n",
      "\n",
      "ğŸ“ˆ Primeiras 5 linhas (amostra):\n",
      "  Ano civil/mÃªs Centro                  HierarqPrd     Produto                             Estoque\\nInicial    Entrada VariaÃ§Ã£o\\nExterna VariaÃ§Ã£o\\nExterna\\n% VariaÃ§Ã£o\\nInterna VariaÃ§Ã£o\\nInterna\\n% VariaÃ§Ã£o\\nTotal VariaÃ§Ã£o\\nTotal\\n% Custo UnitÃ¡rio do Produto  Imposto Valor da VariaÃ§Ã£o\\nInterna   Quantidade Excedente da VariaÃ§Ã£o Externa Valor Excedente da VariaÃ§Ã£o Externa (R$) Quantidade Excedente da VariaÃ§Ã£o Interna Valor Excedente da VariaÃ§Ã£o Interna (R$) Quantidade Excedente da VariaÃ§Ã£o Total Valor Excedente da VariaÃ§Ã£o Total (R$) Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674           Ã“LEO DIESEL B S10          16924.0                                                                18.0             0.106358            18.0           0.106358                  5.300122      0.0                  95.402202                                        0.0                                      0.0                                    10.19                                54.008246                                  10.19                                  54.01                                            54.01\n",
      "1       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.001.422     JET A NAO TABELADO - LI         373850.0   939139.0             824.0              0.08774             -10.0            -0.000762           814.0           0.036144                  3.890482 -2811.15                 -38.904816                                     366.22                              1424.772156                                      0.0                                      0.0                                    0.0                                    0.0                                          2811.15\n",
      "2       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.003.826  JET A INTERNACIONAL I - LI         598315.0  5188210.0            1494.0             0.028796                                                 1494.0           0.013613                  3.882566      0.0                        0.0                                        0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                              0.0\n",
      "3       01.2025   5105  BAV2        Gasolina Comum  01.000.078            GASOLINA COMUM C          13076.0    14828.0               5.0              0.03372             234.0             0.838589           239.0             0.5593                  5.133078      0.0                1201.140348                                        0.0                                      0.0                                   220.33                              1130.971166                                 220.33                                1130.97                                          1130.97\n",
      "4       01.2025   5105  BAV2        Diesel - Comum  01.011.674           Ã“LEO DIESEL B S10         122306.0   178128.0             -17.0            -0.009544            -382.0            -0.127149          -399.0          -0.083375                  5.331511      0.0               -2036.637033                                        0.0                                      0.0                                  -240.63                             -1282.921386                                -240.63                               -1282.92                                         -1282.92\n",
      "\n",
      "ğŸ”¢ Tipos detectados:\n",
      "   object         : 25 coluna(s)\n",
      "\n",
      "âš ï¸  Valores nulos:\n",
      "   âœ… Nenhum valor nulo!\n",
      "\n",
      "ğŸ’¾ MemÃ³ria utilizada: 1.26 MB\n",
      "\n",
      "ğŸ’¾ Salvando df_bruto em JSON...\n",
      "   âœ… Salvo: df_bruto_20251019_060722.json (311.0 KB)\n",
      "\n",
      "ğŸ’¾ Estado salvo:\n",
      "   .bloco_9_state.json\n",
      "\n",
      "======================================================================\n",
      "âœ… EXTRAÃ‡ÃƒO CONCLUÃDA COM SUCESSO v2.0\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ INSTRUÃ‡Ã•ES PARA O PRÃ“XIMO BLOCO:\n",
      "   1. Carregar estado: json.load('.bloco_9_state.json')\n",
      "   2. Ler caminho: estado['caminho_completo_json']\n",
      "   3. Carregar df_bruto:\n",
      "      with open(caminho, 'r') as f:\n",
      "          df_dict = json.load(f)\n",
      "      df_bruto = pd.DataFrame(df_dict['data'], columns=df_dict['columns'])\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:04.276134Z",
     "start_time": "2025-10-19T09:18:04.056501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 10 - LIMPEZA DE ESTRUTURA v2.5 CONSOLIDADO\n",
    "# ===================================================================\n",
    "# NOVIDADES v2.5:\n",
    "# + RemoÃ§Ã£o de totalizaÃ§Ãµes AVANÃ‡ADA (23 padrÃµes vs 7)\n",
    "# + DetecÃ§Ã£o em PRIMEIRA e SEGUNDA coluna\n",
    "# + AnÃ¡lise hierÃ¡rquica BW (colunas categÃ³ricas vazias)\n",
    "# + ValidaÃ§Ã£o de seguranÃ§a (>50% = alerta + confirmaÃ§Ã£o usuÃ¡rio)\n",
    "# + Registro detalhado de TODAS as linhas detectadas\n",
    "# ===================================================================\n",
    "# MANTIDO v2.4:\n",
    "# - Salvamento em Parquet (pyarrow desnecessario!)\n",
    "# - Carregamento de df_bruto do disco\n",
    "# - Assume df_bruto na memoria (BLOCO 9 executado)\n",
    "# + Todas as transformacoes de limpeza\n",
    "# + Registro completo em JSON\n",
    "# + Estado do bloco em JSON\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIMPEZA DE ESTRUTURA + REMOÃ‡ÃƒO TOTALIZAÃ‡Ã•ES AVANÃ‡ADA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. CONECTAR COM BLOCOS ANTERIORES (0% memoria, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Carregar LOG GLOBAL (CAMINHO CORRETO!)\n",
    "try:\n",
    "    log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    if not log_global_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"âŒ LOG GLOBAL nÃ£o encontrado!\\n\"\n",
    "            f\"   Esperado: {log_global_path}\\n\"\n",
    "            \"   Execute o BLOCO 1 primeiro!\"\n",
    "        )\n",
    "\n",
    "    with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "        log_global = json.load(f)\n",
    "\n",
    "    pasta_base = Path(log_global['pasta_base_atual'])\n",
    "    timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "    print(f\"âœ… LOG GLOBAL conectado!\")\n",
    "    print(f\"   ğŸ“‚ Container: {pasta_base.name}\")\n",
    "    print(f\"   ğŸ• Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERRO: NÃ£o foi possÃ­vel conectar ao LOG GLOBAL\")\n",
    "    print(f\"   Detalhe: {e}\")\n",
    "    raise\n",
    "\n",
    "# Recriar FileManager\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "print(f\"âœ… FileManager recriado: {fm.base_path.name}\")\n",
    "\n",
    "# Validar que BLOCO 9 foi executado\n",
    "arquivo_bloco9 = fm.pastas['logs'] / '.bloco_9_state.json'\n",
    "if not arquivo_bloco9.exists():\n",
    "    print(f\"\\nâŒ ERRO: BLOCO 9 nÃ£o foi executado!\")\n",
    "    print(f\"   Execute o BLOCO 9 (ExtraÃ§Ã£o de Dados) primeiro!\")\n",
    "    raise FileNotFoundError(\"BLOCO 9 nÃ£o foi executado\")\n",
    "\n",
    "with open(arquivo_bloco9, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco9 = json.load(f)\n",
    "\n",
    "print(f\"\\nâœ… BLOCO 9 conectado!\")\n",
    "print(f\"   Arquivo processado: {estado_bloco9['arquivo_processado']}\")\n",
    "print(f\"   Registros extraÃ­dos: {estado_bloco9['estatisticas']['total_registros']:,}\")\n",
    "print(f\"   Colunas extraÃ­das: {estado_bloco9['estatisticas']['total_colunas']}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. VALIDAR QUE df_bruto ESTA NA MEMORIA\n",
    "# ===================================================================\n",
    "\n",
    "if 'df_bruto' not in globals():\n",
    "    print(f\"\\nâŒ ERRO: df_bruto nÃ£o encontrado na memÃ³ria!\")\n",
    "    print(f\"   Execute o BLOCO 9 na mesma sessÃ£o antes deste bloco.\")\n",
    "    print(f\"   Se o kernel foi reiniciado, re-execute os BLOCOS 1-9.\")\n",
    "    raise NameError(\"df_bruto nÃ£o estÃ¡ na memÃ³ria\")\n",
    "\n",
    "print(f\"\\nâœ… df_bruto encontrado na memÃ³ria!\")\n",
    "df = df_bruto.copy()\n",
    "\n",
    "# Inicializar registros de transformacao\n",
    "log_limpeza = []\n",
    "transformacoes_detalhadas = {\n",
    "    'colunas_removidas': [],\n",
    "    'linhas_removidas': [],\n",
    "    'colunas_renomeadas': {},\n",
    "    'linhas_totais_detectadas': [],\n",
    "    'padroes_aplicados': []\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ”§ Iniciando limpeza...\")\n",
    "print(f\"   Registros iniciais: {len(df):,}\")\n",
    "print(f\"   Colunas iniciais: {len(df.columns)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. REMOVER COLUNAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "if colunas_vazias:\n",
    "    print(f\"\\nğŸ—‘ï¸ Removendo {len(colunas_vazias)} colunas vazias:\")\n",
    "    for col in colunas_vazias[:5]:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    if len(colunas_vazias) > 5:\n",
    "        print(f\"   ... e mais {len(colunas_vazias) - 5}\")\n",
    "\n",
    "    df = df.drop(columns=colunas_vazias)\n",
    "    log_limpeza.append(f\"Removidas {len(colunas_vazias)} colunas vazias\")\n",
    "    transformacoes_detalhadas['colunas_removidas'] = colunas_vazias\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_colunas_vazias',\n",
    "        'criterio': 'df.isna().all()',\n",
    "        'quantidade': len(colunas_vazias)\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 4. REMOVER LINHAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "linhas_vazias_antes = len(df)\n",
    "df = df.dropna(how='all')\n",
    "linhas_vazias = linhas_vazias_antes - len(df)\n",
    "\n",
    "if linhas_vazias > 0:\n",
    "    print(f\"\\nğŸ—‘ï¸ Removidas {linhas_vazias} linhas completamente vazias\")\n",
    "    log_limpeza.append(f\"Removidas {linhas_vazias} linhas vazias\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_linhas_vazias',\n",
    "        'criterio': 'df.dropna(how=all)',\n",
    "        'quantidade': linhas_vazias\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 5. LIMPAR NOMES DE COLUNAS\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nğŸ§¹ Limpando nomes de colunas...\")\n",
    "colunas_antes = df.columns.tolist()\n",
    "colunas_limpas = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Limpar\n",
    "    col_limpo = str(col).strip()\n",
    "    col_limpo = col_limpo.lstrip(\"'\\\"\")\n",
    "    col_limpo = col_limpo.replace('\\n', ' ').replace('\\r', '')\n",
    "    col_limpo = ' '.join(col_limpo.split())\n",
    "\n",
    "    # Remover espacos extras\n",
    "    col_limpo = re.sub(r'\\s+', ' ', col_limpo)\n",
    "\n",
    "    colunas_limpas.append(col_limpo)\n",
    "\n",
    "# Contar modificacoes\n",
    "modificados = sum(1 for orig, limpo in zip(colunas_antes, colunas_limpas)\n",
    "                  if orig != limpo)\n",
    "if modificados > 0:\n",
    "    print(f\"   âœ… {modificados} nomes limpos\")\n",
    "    log_limpeza.append(f\"Limpeza de nomes: {modificados} colunas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'limpeza_nomes',\n",
    "        'criterio': 'strip + lstrip + regex',\n",
    "        'quantidade': modificados\n",
    "    })\n",
    "\n",
    "df.columns = colunas_limpas\n",
    "\n",
    "# ===================================================================\n",
    "# 6. RENOMEAR COLUNAS DUPLICADAS\n",
    "# ===================================================================\n",
    "\n",
    "contagem = Counter(colunas_limpas)\n",
    "duplicadas = {c: n for c, n in contagem.items() if n > 1}\n",
    "\n",
    "if duplicadas:\n",
    "    print(f\"\\nğŸ”„ Renomeando {len(duplicadas)} colunas duplicadas:\")\n",
    "    colunas_finais = []\n",
    "    contador = {}\n",
    "\n",
    "    for col in colunas_limpas:\n",
    "        if col in duplicadas:\n",
    "            if col not in contador:\n",
    "                contador[col] = 0\n",
    "                colunas_finais.append(col)\n",
    "            else:\n",
    "                contador[col] += 1\n",
    "                novo_nome = f\"{col}_dup{contador[col]}\"\n",
    "                colunas_finais.append(novo_nome)\n",
    "                print(f\"   '{col}' â†’ '{novo_nome}'\")\n",
    "                transformacoes_detalhadas['colunas_renomeadas'][col] = transformacoes_detalhadas['colunas_renomeadas'].get(col, []) + [novo_nome]\n",
    "        else:\n",
    "            colunas_finais.append(col)\n",
    "\n",
    "    df.columns = colunas_finais\n",
    "    log_limpeza.append(f\"Renomeadas {sum(contador.values())} colunas duplicadas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'renomear_duplicadas',\n",
    "        'criterio': 'Counter + sufixo _dupN',\n",
    "        'quantidade': sum(contador.values())\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 7. REMOÃ‡ÃƒO DE TOTALIZAÃ‡Ã•ES - VERSÃƒO AVANÃ‡ADA v2.5\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ğŸ” DETECÃ‡ÃƒO AVANÃ‡ADA DE LINHAS DE TOTALIZAÃ‡ÃƒO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nâ„¹ï¸  CONTEXTO:\")\n",
    "print(\"   Arquivos BW/BEx frequentemente contÃªm linhas de:\")\n",
    "print(\"   - Totais gerais / Subtotais por agrupamento\")\n",
    "print(\"   - Resultados parciais / MÃ©dias agregadas\")\n",
    "print(\"   Estas linhas INFLAM valores e devem ser removidas.\\n\")\n",
    "\n",
    "# PadrÃµes AVANÃ‡ADOS (23 padrÃµes vs 7 originais)\n",
    "padroes_totalizacao = [\n",
    "    # PortuguÃªs (12 padrÃµes)\n",
    "    r'(?i)^total\\b',\n",
    "    r'(?i)^resultado\\b',\n",
    "    r'(?i)^soma\\b',\n",
    "    r'(?i)^subtotal\\b',\n",
    "    r'(?i)^parcial\\b',\n",
    "    r'(?i)^grand total',\n",
    "    r'(?i)^mÃ©dia\\b',\n",
    "    r'(?i)^media\\b',\n",
    "    r'(?i)^consolidado\\b',\n",
    "    r'(?i)^geral\\b',\n",
    "    r'(?i)total geral',\n",
    "    r'(?i)resultado final',\n",
    "\n",
    "    # InglÃªs (5 padrÃµes - comum em exports SAP)\n",
    "    r'(?i)^overall',\n",
    "    r'(?i)^average',\n",
    "    r'(?i)^sum\\b',\n",
    "    r'(?i)^total\\s',\n",
    "    r'(?i)^result\\b',\n",
    "\n",
    "    # NumÃ©ricos (3 padrÃµes - ex: \"Total 5262\", \"Resultado 1234\")\n",
    "    r'(?i)^total\\s+\\d+',\n",
    "    r'(?i)^resultado\\s+\\d+',\n",
    "    r'(?i)^subtotal\\s+\\d+',\n",
    "]\n",
    "\n",
    "# Compilar regex para performance\n",
    "padroes_compilados = [re.compile(p) for p in padroes_totalizacao]\n",
    "\n",
    "# FunÃ§Ã£o de detecÃ§Ã£o AVANÃ‡ADA (3 nÃ­veis de verificaÃ§Ã£o)\n",
    "def eh_linha_totalizacao(row):\n",
    "    \"\"\"\n",
    "    Verifica se linha Ã© de totalizaÃ§Ã£o usando 3 critÃ©rios:\n",
    "    1. Primeira coluna (mais comum)\n",
    "    2. Segunda coluna (quando primeira tem cÃ³digo)\n",
    "    3. Hierarquia BW (colunas categÃ³ricas vazias)\n",
    "    \"\"\"\n",
    "    # NÃ­vel 1: Verificar primeira coluna\n",
    "    primeira_celula = str(row.iloc[0]).strip()\n",
    "    if any(padrao.search(primeira_celula) for padrao in padroes_compilados):\n",
    "        return True\n",
    "\n",
    "    # NÃ­vel 2: Verificar segunda coluna\n",
    "    if len(row) > 1:\n",
    "        segunda_celula = str(row.iloc[1]).strip()\n",
    "        if any(padrao.search(segunda_celula) for padrao in padroes_compilados):\n",
    "            return True\n",
    "\n",
    "    # NÃ­vel 3: Detectar hierarquia BW (colunas categÃ³ricas vazias)\n",
    "    colunas_categoricas = df.select_dtypes(include=['object']).columns\n",
    "    if len(colunas_categoricas) > 0:\n",
    "        valores_cat = row[colunas_categoricas].dropna()\n",
    "        # Se <30% das colunas categÃ³ricas preenchidas E palavra-chave\n",
    "        if len(valores_cat) < len(colunas_categoricas) * 0.3:\n",
    "            primeira_palavra = primeira_celula.lower().split()[0] if primeira_celula else ''\n",
    "            if primeira_palavra in ['total', 'resultado', 'soma', 'mÃ©dia', 'media', 'geral']:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Identificar linhas de totalizaÃ§Ã£o\n",
    "print(f\"ğŸ“Š Analisando {len(df):,} linhas com 23 padrÃµes...\")\n",
    "\n",
    "linhas_totalizacao = []\n",
    "for idx, row in df.iterrows():\n",
    "    if eh_linha_totalizacao(row):\n",
    "        linhas_totalizacao.append(idx)\n",
    "        # Registrar DETALHADAMENTE\n",
    "        transformacoes_detalhadas['linhas_totais_detectadas'].append({\n",
    "            'indice': int(idx),\n",
    "            'primeira_celula': str(row.iloc[0]).strip(),\n",
    "            'segunda_celula': str(row.iloc[1]).strip() if len(row) > 1 else None\n",
    "        })\n",
    "\n",
    "print(f\"\\nğŸ” Linhas de totalizaÃ§Ã£o detectadas: {len(linhas_totalizacao)}\")\n",
    "\n",
    "# Mostrar exemplos (preview)\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    print(f\"\\nğŸ“‹ Exemplos de linhas detectadas (primeiras 5):\")\n",
    "    for i, idx in enumerate(linhas_totalizacao[:5], 1):\n",
    "        primeira_col = df.iloc[idx, 0]\n",
    "        segunda_col = df.iloc[idx, 1] if len(df.columns) > 1 else 'N/A'\n",
    "        print(f\"   {i}. Linha {idx}: '{primeira_col}' | '{segunda_col}'\")\n",
    "\n",
    "    if len(linhas_totalizacao) > 5:\n",
    "        print(f\"   ... e mais {len(linhas_totalizacao) - 5}\")\n",
    "\n",
    "# Remover linhas detectadas COM VALIDAÃ‡ÃƒO DE SEGURANÃ‡A\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"ğŸ—‘ï¸  REMOVENDO LINHAS DE TOTALIZAÃ‡ÃƒO\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    registros_antes = len(df)\n",
    "\n",
    "    # Calcular impacto ANTES de remover\n",
    "    pct_a_remover = (len(linhas_totalizacao) / registros_antes) * 100\n",
    "\n",
    "    # VALIDAÃ‡ÃƒO DE SEGURANÃ‡A: >50% = alerta\n",
    "    if pct_a_remover > 50:\n",
    "        print(f\"\\nâš ï¸  ALERTA DE SEGURANÃ‡A!\")\n",
    "        print(f\"   Mais de 50% das linhas serÃ£o removidas ({pct_a_remover:.1f}%)\")\n",
    "        print(f\"   Isso pode indicar FALSO POSITIVO na detecÃ§Ã£o.\")\n",
    "        print(f\"   Recomenda-se revisar os padrÃµes manualmente.\\n\")\n",
    "\n",
    "        resposta = input(\"   Deseja CONTINUAR com a remoÃ§Ã£o? (S/N): \").strip().upper()\n",
    "\n",
    "        if resposta != 'S':\n",
    "            print(f\"\\n   â„¹ï¸  RemoÃ§Ã£o CANCELADA pelo usuÃ¡rio\")\n",
    "            print(f\"   Mantendo dados originais para revisÃ£o manual.\")\n",
    "            linhas_totalizacao = []  # Limpar lista para nÃ£o remover\n",
    "            transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "                'tipo': 'remocao_totais_CANCELADA',\n",
    "                'criterio': 'Usuario cancelou (>50%)',\n",
    "                'quantidade': 0,\n",
    "                'percentual': 0.0,\n",
    "                'alerta_ativado': True\n",
    "            })\n",
    "\n",
    "    # Remover se confirmado (ou se <50%)\n",
    "    if linhas_totalizacao:\n",
    "        df = df.drop(index=linhas_totalizacao)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        registros_depois = len(df)\n",
    "        removidos = registros_antes - registros_depois\n",
    "        pct_removido = (removidos / registros_antes) * 100\n",
    "\n",
    "        print(f\"\\nâœ… RemoÃ§Ã£o concluÃ­da:\")\n",
    "        print(f\"   Antes:    {registros_antes:>7,} linhas\")\n",
    "        print(f\"   Removido: {removidos:>7,} linhas ({pct_removido:.1f}%)\")\n",
    "        print(f\"   Depois:   {registros_depois:>7,} linhas\")\n",
    "\n",
    "        log_limpeza.append(f\"Removidas {removidos} linhas de totalizaÃ§Ã£o\")\n",
    "        transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "            'tipo': 'remocao_totais',\n",
    "            'criterio': '23 padroes regex + 2a coluna + hierarquia BW',\n",
    "            'quantidade': removidos,\n",
    "            'percentual': round(pct_removido, 2),\n",
    "            'alerta_ativado': pct_a_remover > 50\n",
    "        })\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… Nenhuma linha de totalizaÃ§Ã£o detectada!\")\n",
    "    print(f\"   Dados jÃ¡ estÃ£o limpos ou nÃ£o possuem totalizaÃ§Ãµes.\")\n",
    "\n",
    "# ===================================================================\n",
    "# 8. CRIAR COPIA LIMPA (variavel global para proximo bloco)\n",
    "# ===================================================================\n",
    "\n",
    "df_limpo = df.copy()\n",
    "\n",
    "print(f\"\\nğŸ’¾ df_limpo criado na memÃ³ria\")\n",
    "print(f\"   ğŸ“Š {len(df_limpo):,} registros Ã— {len(df_limpo.columns)} colunas\")\n",
    "\n",
    "# ===================================================================\n",
    "# 9. RESUMO FINAL\n",
    "# ===================================================================\n",
    "\n",
    "# Obter estatisticas originais\n",
    "registros_originais = estado_bloco9['estatisticas']['total_registros']\n",
    "colunas_originais = estado_bloco9['estatisticas']['total_colunas']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ… LIMPEZA CONCLUÃDA\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Antes â†’ Depois:\")\n",
    "print(f\"   Registros: {registros_originais:,} â†’ {len(df_limpo):,}\")\n",
    "print(f\"   Colunas: {colunas_originais} â†’ {len(df_limpo.columns)}\")\n",
    "\n",
    "if log_limpeza:\n",
    "    print(f\"\\nğŸ”§ OperaÃ§Ãµes realizadas:\")\n",
    "    for i, op in enumerate(log_limpeza, 1):\n",
    "        print(f\"   {i}. {op}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Nenhuma limpeza necessÃ¡ria - dados jÃ¡ estavam limpos!\")\n",
    "\n",
    "print(f\"\\nğŸ‘ï¸  Preview dos dados limpos:\")\n",
    "print(\"-\" * 70)\n",
    "print(df_limpo.head(3))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ===================================================================\n",
    "# 10. SALVAR ESTADO NO LOG\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco10 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 10,\n",
    "    'nome': 'LIMPEZA DE ESTRUTURA + TOTALIZAÃ‡Ã•ES AVANÃ‡ADA',\n",
    "    'status': 'concluido',\n",
    "    'versao': '2.5',\n",
    "    'variaveis_criadas': ['df_limpo'],\n",
    "    'variaveis_memoria': {\n",
    "        'df_limpo': {\n",
    "            'tipo': 'DataFrame',\n",
    "            'shape': list(df_limpo.shape),\n",
    "            'colunas': list(df_limpo.columns),\n",
    "            'dtypes': {col: str(dtype) for col, dtype in df_limpo.dtypes.items()}\n",
    "        }\n",
    "    },\n",
    "    'estatisticas': {\n",
    "        'registros_antes': registros_originais,\n",
    "        'registros_depois': len(df_limpo),\n",
    "        'colunas_antes': colunas_originais,\n",
    "        'colunas_depois': len(df_limpo.columns),\n",
    "        'colunas_removidas': len(colunas_vazias) if colunas_vazias else 0,\n",
    "        'linhas_removidas_vazias': linhas_vazias,\n",
    "        'linhas_removidas_totais': len(linhas_totalizacao) if linhas_totalizacao else 0,\n",
    "        'colunas_renomeadas': sum(contador.values()) if duplicadas else 0\n",
    "    },\n",
    "    'transformacoes': transformacoes_detalhadas,\n",
    "    'log_resumido': log_limpeza\n",
    "}\n",
    "\n",
    "# Salvar estado\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_10_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco10, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "\n",
    "# Salvar transformacoes detalhadas\n",
    "arquivo_transformacoes = fm.pastas['logs'] / f'LOG_Transformacoes_Limpeza_{timestamp_execucao}.json'\n",
    "with open(arquivo_transformacoes, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transformacoes_detalhadas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   {arquivo_transformacoes.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 10 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ’¡ PrÃ³ximo: BLOCO 11 - Forward Fill (se necessÃ¡rio)\")\n",
    "print(\"ğŸ’¡ df_limpo estÃ¡ disponÃ­vel na memÃ³ria\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a1261390787ca008",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIMPEZA DE ESTRUTURA + REMOÃ‡ÃƒO TOTALIZAÃ‡Ã•ES AVANÃ‡ADA\n",
      "======================================================================\n",
      "âœ… LOG GLOBAL conectado!\n",
      "   ğŸ“‚ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   ğŸ• Timestamp: 20251019_060722\n",
      "âœ… FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "\n",
      "âœ… BLOCO 9 conectado!\n",
      "   Arquivo processado: CÃ³pia de xSAPtemp4687_JAN_25.xls\n",
      "   Registros extraÃ­dos: 967\n",
      "   Colunas extraÃ­das: 25\n",
      "\n",
      "âœ… df_bruto encontrado na memÃ³ria!\n",
      "\n",
      "ğŸ”§ Iniciando limpeza...\n",
      "   Registros iniciais: 967\n",
      "   Colunas iniciais: 25\n",
      "\n",
      "ğŸ§¹ Limpando nomes de colunas...\n",
      "   âœ… 8 nomes limpos\n",
      "\n",
      "ğŸ”„ Renomeando 1 colunas duplicadas:\n",
      "   '' â†’ '_dup1'\n",
      "   '' â†’ '_dup2'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ğŸ” DETECÃ‡ÃƒO AVANÃ‡ADA DE LINHAS DE TOTALIZAÃ‡ÃƒO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "â„¹ï¸  CONTEXTO:\n",
      "   Arquivos BW/BEx frequentemente contÃªm linhas de:\n",
      "   - Totais gerais / Subtotais por agrupamento\n",
      "   - Resultados parciais / MÃ©dias agregadas\n",
      "   Estas linhas INFLAM valores e devem ser removidas.\n",
      "\n",
      "ğŸ“Š Analisando 967 linhas com 23 padrÃµes...\n",
      "\n",
      "ğŸ” Linhas de totalizaÃ§Ã£o detectadas: 0\n",
      "\n",
      "âœ… Nenhuma linha de totalizaÃ§Ã£o detectada!\n",
      "   Dados jÃ¡ estÃ£o limpos ou nÃ£o possuem totalizaÃ§Ãµes.\n",
      "\n",
      "ğŸ’¾ df_limpo criado na memÃ³ria\n",
      "   ğŸ“Š 967 registros Ã— 25 colunas\n",
      "\n",
      "======================================================================\n",
      "âœ… LIMPEZA CONCLUÃDA\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Antes â†’ Depois:\n",
      "   Registros: 967 â†’ 967\n",
      "   Colunas: 25 â†’ 25\n",
      "\n",
      "ğŸ”§ OperaÃ§Ãµes realizadas:\n",
      "   1. Limpeza de nomes: 8 colunas\n",
      "   2. Renomeadas 2 colunas duplicadas\n",
      "\n",
      "ğŸ‘ï¸  Preview dos dados limpos:\n",
      "----------------------------------------------------------------------\n",
      "  Ano civil/mÃªs Centro                  HierarqPrd     Produto  \\\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674   \n",
      "1       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.001.422   \n",
      "2       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.003.826   \n",
      "\n",
      "                        _dup1 Estoque Inicial    Entrada VariaÃ§Ã£o Externa  \\\n",
      "0           Ã“LEO DIESEL B S10         16924.0                               \n",
      "1     JET A NAO TABELADO - LI        373850.0   939139.0            824.0   \n",
      "2  JET A INTERNACIONAL I - LI        598315.0  5188210.0           1494.0   \n",
      "\n",
      "  VariaÃ§Ã£o Externa %  ...  Imposto Valor da VariaÃ§Ã£o Interna _dup2  \\\n",
      "0                     ...      0.0                 95.402202         \n",
      "1            0.08774  ... -2811.15                -38.904816         \n",
      "2           0.028796  ...      0.0                       0.0         \n",
      "\n",
      "  Quantidade Excedente da VariaÃ§Ã£o Externa  \\\n",
      "0                                      0.0   \n",
      "1                                   366.22   \n",
      "2                                      0.0   \n",
      "\n",
      "  Valor Excedente da VariaÃ§Ã£o Externa (R$)  \\\n",
      "0                                      0.0   \n",
      "1                              1424.772156   \n",
      "2                                      0.0   \n",
      "\n",
      "  Quantidade Excedente da VariaÃ§Ã£o Interna  \\\n",
      "0                                    10.19   \n",
      "1                                      0.0   \n",
      "2                                      0.0   \n",
      "\n",
      "  Valor Excedente da VariaÃ§Ã£o Interna (R$)  \\\n",
      "0                                54.008246   \n",
      "1                                      0.0   \n",
      "2                                      0.0   \n",
      "\n",
      "  Quantidade Excedente da VariaÃ§Ã£o Total  \\\n",
      "0                                  10.19   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "\n",
      "  Valor Excedente da VariaÃ§Ã£o Total (R$)  \\\n",
      "0                                  54.01   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "\n",
      "  Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)  \n",
      "0                                            54.01  \n",
      "1                                          2811.15  \n",
      "2                                              0.0  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ’¾ Estado salvo:\n",
      "   .bloco_10_state.json\n",
      "   LOG_Transformacoes_Limpeza_20251019_060722.json\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 10 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 11 - Forward Fill (se necessÃ¡rio)\n",
      "ğŸ’¡ df_limpo estÃ¡ disponÃ­vel na memÃ³ria\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:06.890503Z",
     "start_time": "2025-10-19T09:18:06.873488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 11 - TRATAMENTO DE FORMATO BW/BEx - FORWARD FILL\n",
    "# VERSÃƒO v3.0 - SIMPLIFICADO (SEM PARQUET/PICKLE DESNECESSÃRIO)\n",
    "# Baseado em: ETL - ESTOQUE E MOVIMENTAÃ‡ÃƒO (SAP BEx).ipynb - PASSO 4\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ARQUITETURA CORRETA:\n",
    "# - DataFrames ficam na MEMÃ“RIA (df_limpo â†’ df)\n",
    "# - Estado salvo em JSON (.bloco_11_state.json)\n",
    "# - NÃƒO precisa salvar DataFrame em disco (jÃ¡ estÃ¡ na memÃ³ria!)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”„ TRATAMENTO DE FORMATO BW/BEx (FORWARD FILL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. CONECTAR VIA LOG GLOBAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global_path.exists():\n",
    "    raise FileNotFoundError(\"âŒ LOG GLOBAL nÃ£o encontrado! Execute BLOCO 1.\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "print(f\"\\nâœ… LOG GLOBAL conectado\")\n",
    "print(f\"   ğŸ“‚ Container: {pasta_base.name}\")\n",
    "print(f\"   ğŸ• Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Recriar FileManager\n",
    "class FileManagerInterativo:\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. VALIDAR PRÃ‰-REQUISITO (BLOCO 10)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "arquivo_bloco10 = fm.pastas['logs'] / '.bloco_10_state.json'\n",
    "\n",
    "if not arquivo_bloco10.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ BLOCO 10 nÃ£o executado!\\n\"\n",
    "        \"   Execute BLOCO 10 (Limpeza de Estrutura) primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(arquivo_bloco10, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco10 = json.load(f)\n",
    "\n",
    "print(f\"\\nâœ… BLOCO 10 validado\")\n",
    "print(f\"   Registros: {estado_bloco10.get('registros_depois', 'N/A')}\")\n",
    "print(f\"   Colunas: {estado_bloco10.get('colunas_depois', 'N/A')}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. USAR df_limpo DA MEMÃ“RIA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if 'df_limpo' not in globals():\n",
    "    raise NameError(\n",
    "        \"âŒ df_limpo nÃ£o estÃ¡ na memÃ³ria!\\n\"\n",
    "        \"   Execute BLOCO 10 novamente.\"\n",
    "    )\n",
    "\n",
    "# Trabalhar com cÃ³pia\n",
    "df = df_limpo.copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š DataFrame carregado da memÃ³ria\")\n",
    "print(f\"   {len(df):,} registros Ã— {len(df.columns)} colunas\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. DETECTAR FORMATO BW\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ” DETECÃ‡ÃƒO DE FORMATO BW/BEx\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "print(\"\\nâ„¹ï¸  Arquivos SAP BW/BEx usam formataÃ§Ã£o hierÃ¡rquica:\")\n",
    "print(\"   - DimensÃµes sÃ³ aparecem na 1Âª linha do grupo\")\n",
    "print(\"   - Linhas seguintes ficam vazias atÃ© mudar grupo\")\n",
    "\n",
    "# Analisar primeiras 6 colunas (geralmente dimensÃµes)\n",
    "colunas_iniciais = df.columns[:min(6, len(df.columns))]\n",
    "\n",
    "print(f\"\\nğŸ“Š Analisando {len(colunas_iniciais)} primeiras colunas:\\n\")\n",
    "\n",
    "analise_colunas = []\n",
    "\n",
    "for col in colunas_iniciais:\n",
    "    # EstatÃ­sticas da coluna\n",
    "    valores_unicos = df[col].dropna().nunique()\n",
    "    pct_nulos = (df[col].isnull().sum() / len(df)) * 100\n",
    "\n",
    "    # CritÃ©rio BW: >30% NaN E <1000 valores Ãºnicos\n",
    "    eh_dimensao_bw = pct_nulos > 30 and valores_unicos < 1000\n",
    "\n",
    "    analise_colunas.append({\n",
    "        'coluna': col,\n",
    "        'valores_unicos': valores_unicos,\n",
    "        'pct_nulos': pct_nulos,\n",
    "        'eh_dimensao_bw': eh_dimensao_bw\n",
    "    })\n",
    "\n",
    "    emoji = \"ğŸ”„\" if eh_dimensao_bw else \"  \"\n",
    "    print(f\"   {emoji} {col[:35].ljust(35)} | \"\n",
    "          f\"Ãšnicos: {valores_unicos:>5} | NaN: {pct_nulos:>5.1f}%\")\n",
    "\n",
    "# Contar colunas BW\n",
    "colunas_bw = [a for a in analise_colunas if a['eh_dimensao_bw']]\n",
    "\n",
    "print(f\"\\nğŸ“Š Colunas com padrÃ£o BW: {len(colunas_bw)}/{len(colunas_iniciais)}\")\n",
    "\n",
    "# Decidir se aplica forward fill\n",
    "eh_formato_bw = len(colunas_bw) >= 2\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(f\"   âœ… FORMATO BW DETECTADO - Forward fill serÃ¡ aplicado\\n\")\n",
    "else:\n",
    "    print(f\"   â„¹ï¸  Formato padrÃ£o - Forward fill NÃƒO necessÃ¡rio\\n\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. APLICAR FORWARD FILL (SE DETECTADO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "total_preenchidas = 0\n",
    "colunas_para_ffill = []\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(\"â”€\"*70)\n",
    "    print(\"ğŸ”„ APLICANDO FORWARD FILL\")\n",
    "    print(\"â”€\"*70)\n",
    "\n",
    "    # Listar colunas\n",
    "    colunas_para_ffill = [a['coluna'] for a in analise_colunas\n",
    "                          if a['eh_dimensao_bw']]\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Colunas que receberÃ£o ffill ({len(colunas_para_ffill)}):\")\n",
    "    for i, col in enumerate(colunas_para_ffill, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "\n",
    "    # Contar NULLs ANTES\n",
    "    print(f\"\\nğŸ“Š NULLs ANTES do forward fill:\\n\")\n",
    "    nulls_antes = {}\n",
    "    total_nulls_antes = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        count = int(df[col].isnull().sum())\n",
    "        nulls_antes[col] = count\n",
    "        total_nulls_antes += count\n",
    "        print(f\"   {col[:40].ljust(40)}: {count:>8,}\")\n",
    "\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: {total_nulls_antes:>8,}\")\n",
    "\n",
    "    # APLICAR FFILL\n",
    "    print(f\"\\nğŸ”„ Preenchendo cÃ©lulas vazias...\")\n",
    "    df[colunas_para_ffill] = df[colunas_para_ffill].ffill()\n",
    "\n",
    "    # Contar NULLs DEPOIS\n",
    "    print(f\"\\nâœ… NULLs DEPOIS do forward fill:\\n\")\n",
    "    total_nulls_depois = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        nulls_depois = int(df[col].isnull().sum())\n",
    "        total_nulls_depois += nulls_depois\n",
    "        preenchidas = nulls_antes[col] - nulls_depois\n",
    "\n",
    "        print(f\"   {col[:40].ljust(40)}: \"\n",
    "              f\"{nulls_antes[col]:>8,} â†’ {nulls_depois:>8,} \"\n",
    "              f\"(Î” {preenchidas:>7,})\")\n",
    "\n",
    "    total_preenchidas = total_nulls_antes - total_nulls_depois\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: \"\n",
    "          f\"{total_nulls_antes:>8,} â†’ {total_nulls_depois:>8,} \"\n",
    "          f\"(Î” {total_preenchidas:>7,})\")\n",
    "\n",
    "    # ValidaÃ§Ã£o\n",
    "    print(f\"\\nâœ… VALIDAÃ‡ÃƒO:\")\n",
    "    primeira_linha_nulos = df.iloc[0][colunas_para_ffill].isnull().sum()\n",
    "\n",
    "    if primeira_linha_nulos > 0:\n",
    "        print(f\"   âš ï¸  Primeira linha tem {primeira_linha_nulos} NaN(s)\")\n",
    "        print(f\"   PossÃ­vel problema no cabeÃ§alho\")\n",
    "    else:\n",
    "        print(f\"   âœ… Primeira linha completa - OK\")\n",
    "\n",
    "    print(f\"\\nğŸ“Š RESUMO:\")\n",
    "    print(f\"   Colunas processadas: {len(colunas_para_ffill)}\")\n",
    "    print(f\"   CÃ©lulas preenchidas: {total_preenchidas:,}\")\n",
    "    if total_nulls_antes > 0:\n",
    "        pct_reducao = (total_preenchidas / total_nulls_antes) * 100\n",
    "        print(f\"   ReduÃ§Ã£o de NaN: {pct_reducao:.1f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… FORWARD FILL APLICADO COM SUCESSO\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"â„¹ï¸  FORWARD FILL NÃƒO NECESSÃRIO\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n   Arquivo nÃ£o possui formataÃ§Ã£o BW/BEx hierÃ¡rquica\")\n",
    "    print(\"   Prosseguindo para prÃ³xima etapa...\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 6. SALVAR ESTADO (APENAS JSON)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco11 = {\n",
    "    'bloco': 11,\n",
    "    'nome': 'TRATAMENTO BW/BEx - FORWARD FILL',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'formato_bw_detectado': eh_formato_bw,\n",
    "    'colunas_analisadas': len(colunas_iniciais),\n",
    "    'colunas_bw_detectadas': len(colunas_bw),\n",
    "    'colunas_processadas': colunas_para_ffill if eh_formato_bw else [],\n",
    "    'celulas_preenchidas': int(total_preenchidas) if eh_formato_bw else 0,\n",
    "    'registros': len(df),\n",
    "    'colunas': len(df.columns),\n",
    "    'variaveis_criadas': ['df'],  # df fica na memÃ³ria para prÃ³ximo bloco\n",
    "    'versao': '3.0'\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_11_state.json'\n",
    "\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco11, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 11 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ’¡ VariÃ¡vel 'df' disponÃ­vel na memÃ³ria para prÃ³ximo bloco\")\n",
    "print(f\"ğŸ’¡ PrÃ³ximo: BLOCO 12 - DetecÃ§Ã£o de Campos\")  # â† CORRIGIDO!\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIM DO BLOCO 11 v3.0\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ],
   "id": "19009614f0364f42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ TRATAMENTO DE FORMATO BW/BEx (FORWARD FILL)\n",
      "======================================================================\n",
      "\n",
      "âœ… LOG GLOBAL conectado\n",
      "   ğŸ“‚ Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "   ğŸ• Timestamp: 20251019_060722\n",
      "\n",
      "âœ… BLOCO 10 validado\n",
      "   Registros: N/A\n",
      "   Colunas: N/A\n",
      "\n",
      "ğŸ“Š DataFrame carregado da memÃ³ria\n",
      "   967 registros Ã— 25 colunas\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” DETECÃ‡ÃƒO DE FORMATO BW/BEx\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â„¹ï¸  Arquivos SAP BW/BEx usam formataÃ§Ã£o hierÃ¡rquica:\n",
      "   - DimensÃµes sÃ³ aparecem na 1Âª linha do grupo\n",
      "   - Linhas seguintes ficam vazias atÃ© mudar grupo\n",
      "\n",
      "ğŸ“Š Analisando 6 primeiras colunas:\n",
      "\n",
      "      Ano civil/mÃªs                       | Ãšnicos:     2 | NaN:   0.0%\n",
      "      Centro                              | Ãšnicos:    89 | NaN:   0.0%\n",
      "                                          | Ãšnicos:    89 | NaN:   0.0%\n",
      "      HierarqPrd                          | Ãšnicos:     5 | NaN:   0.0%\n",
      "      Produto                             | Ãšnicos:    15 | NaN:   0.0%\n",
      "      _dup1                               | Ãšnicos:    15 | NaN:   0.0%\n",
      "\n",
      "ğŸ“Š Colunas com padrÃ£o BW: 0/6\n",
      "   â„¹ï¸  Formato padrÃ£o - Forward fill NÃƒO necessÃ¡rio\n",
      "\n",
      "======================================================================\n",
      "â„¹ï¸  FORWARD FILL NÃƒO NECESSÃRIO\n",
      "======================================================================\n",
      "\n",
      "   Arquivo nÃ£o possui formataÃ§Ã£o BW/BEx hierÃ¡rquica\n",
      "   Prosseguindo para prÃ³xima etapa...\n",
      "\n",
      "ğŸ’¾ Estado salvo: .bloco_11_state.json\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 11 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ VariÃ¡vel 'df' disponÃ­vel na memÃ³ria para prÃ³ximo bloco\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 12 - DetecÃ§Ã£o de Campos\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:08.855631Z",
     "start_time": "2025-10-19T09:18:08.807611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 12 v7.0 - DETECÃ‡ÃƒO AUTOMÃTICA (SEM RENOMEAR DATAFRAME)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CORREÃ‡Ã•ES v7.0:\n",
    "# âœ… DataFrame NUNCA Ã© renomeado (preserva nomes originais)\n",
    "# âœ… Mapeamentos salvos APENAS no dicionÃ¡rio\n",
    "# âœ… Path correto: fm.pastas['dicionarios']\n",
    "# âœ… Avisos claros sobre duplicaÃ§Ãµes\n",
    "# âŒ REMOVIDO: Toda lÃ³gica de df.rename()\n",
    "# âŒ REMOVIDO: Sistema de sufixos (_1, _2, _3)\n",
    "#\n",
    "# MUDANÃ‡AS:\n",
    "# - Removidas ~40 linhas de cÃ³digo de renomeaÃ§Ã£o\n",
    "# - Adicionados ~15 linhas de avisos e salvamento no dicionÃ¡rio\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” DETECÃ‡ÃƒO AUTOMÃTICA DE CAMPOS v7.0 (SEM RENOMEAR)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE DETECTOR DE CAMPOS (MANTIDA 100%)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class DetectorCampos:\n",
    "    \"\"\"Detecta e mapeia campos automaticamente.\"\"\"\n",
    "\n",
    "    def __init__(self, df, dicionario_persistente):\n",
    "        self.df = df\n",
    "        self.dicionario = dicionario_persistente\n",
    "        self.mapeamento = {}\n",
    "        self.relatorio = {\n",
    "            'total_campos': len(df.columns),\n",
    "            'mapeados_dicionario': 0,\n",
    "            'mapeados_heuristica': 0,\n",
    "            'desconhecidos': 0,\n",
    "            'ambiguos': 0,\n",
    "            'detalhes': []\n",
    "        }\n",
    "\n",
    "    def detectar_todos(self):\n",
    "        \"\"\"Detecta todos os campos do DataFrame.\"\"\"\n",
    "        print(f\"\\nğŸ“Š Analisando {len(self.df.columns)} campos...\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            print(f\"\\n   ğŸ” Analisando: '{col}'\")\n",
    "\n",
    "            # Extrair amostra de valores\n",
    "            valores_amostra = [str(v) for v in self.df[col].dropna().head(100)]\n",
    "\n",
    "            # Tentar detecÃ§Ã£o\n",
    "            resultado = self._detectar_campo(col, valores_amostra)\n",
    "\n",
    "            # Armazenar\n",
    "            self.mapeamento[col] = resultado\n",
    "\n",
    "            # Atualizar relatÃ³rio\n",
    "            if resultado['metodo'] == 'DICIONARIO':\n",
    "                self.relatorio['mapeados_dicionario'] += 1\n",
    "                emoji = \"âœ…\"\n",
    "            elif resultado['metodo'] == 'HEURISTICA':\n",
    "                self.relatorio['mapeados_heuristica'] += 1\n",
    "                emoji = \"ğŸ¤–\"\n",
    "            elif resultado['campo_detectado'] == 'DESCONHECIDO':\n",
    "                self.relatorio['desconhecidos'] += 1\n",
    "                emoji = \"â“\"\n",
    "            else:\n",
    "                emoji = \"âš ï¸\"\n",
    "\n",
    "            if resultado.get('ambiguidade', False):\n",
    "                self.relatorio['ambiguos'] += 1\n",
    "                emoji += \"âš ï¸\"\n",
    "\n",
    "            # Exibir resultado\n",
    "            print(f\"      {emoji} {resultado['campo_detectado']}\")\n",
    "            print(f\"      ConfianÃ§a: {resultado['confianca']:.0%} | MÃ©todo: {resultado['metodo']}\")\n",
    "\n",
    "            # Adicionar ao relatÃ³rio\n",
    "            self.relatorio['detalhes'].append({\n",
    "                'coluna_original': col,\n",
    "                'campo_detectado': resultado['campo_detectado'],\n",
    "                'confianca': resultado['confianca'],\n",
    "                'metodo': resultado['metodo'],\n",
    "                'ambiguidade': resultado.get('ambiguidade', False)\n",
    "            })\n",
    "\n",
    "        return self.mapeamento, self.relatorio\n",
    "\n",
    "    def _detectar_campo(self, nome_coluna, valores):\n",
    "        \"\"\"Detecta um Ãºnico campo (MANTIDO DO BLOCO 13).\"\"\"\n",
    "\n",
    "        # ESTRATÃ‰GIA 1: Buscar no dicionÃ¡rio\n",
    "        conhecimento = self.dicionario.get('conhecimento_base', {})\n",
    "        campos_conhecidos = conhecimento.get('campos_conhecidos', {})\n",
    "\n",
    "        if not campos_conhecidos:\n",
    "            campos_conhecidos = self.dicionario.get('campos_conhecidos', {})\n",
    "\n",
    "        for campo_orig, campo_info in campos_conhecidos.items():\n",
    "            if isinstance(campo_info, dict):\n",
    "                sinonimos = campo_info.get('sinonimos', [])\n",
    "\n",
    "                for sin in sinonimos:\n",
    "                    # Match exato\n",
    "                    if nome_coluna.lower().strip() == sin.lower().strip():\n",
    "                        return {\n",
    "                            'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                            'confianca': 1.0,\n",
    "                            'metodo': 'DICIONARIO',\n",
    "                            'ambiguidade': False\n",
    "                        }\n",
    "\n",
    "                    # Match parcial\n",
    "                    if nome_coluna.lower() in sin.lower() or sin.lower() in nome_coluna.lower():\n",
    "                        return {\n",
    "                            'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                            'confianca': 0.90,\n",
    "                            'metodo': 'DICIONARIO',\n",
    "                            'ambiguidade': False\n",
    "                        }\n",
    "\n",
    "        # Fallback: Buscar em arquivos processados\n",
    "        if self.dicionario and 'arquivos' in self.dicionario:\n",
    "            for arquivo_info in self.dicionario.get('arquivos', {}).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_orig, campo_info in arquivo_info['campos_mapeados'].items():\n",
    "                        if nome_coluna.lower().strip() == campo_orig.lower().strip():\n",
    "                            return {\n",
    "                                'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                                'confianca': 1.0,\n",
    "                                'metodo': 'DICIONARIO_ARQUIVO',\n",
    "                                'ambiguidade': False\n",
    "                            }\n",
    "\n",
    "        # ESTRATÃ‰GIA 2: HeurÃ­sticas (mantidas do documento original)\n",
    "        resultado_heuristica = self._heuristica_simples(nome_coluna, valores)\n",
    "\n",
    "        if resultado_heuristica:\n",
    "            return resultado_heuristica\n",
    "\n",
    "        # ESTRATÃ‰GIA 3: Desconhecido\n",
    "        return {\n",
    "            'campo_detectado': 'DESCONHECIDO',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'NENHUM',\n",
    "            'ambiguidade': False\n",
    "        }\n",
    "\n",
    "    def _heuristica_simples(self, nome, valores):\n",
    "        \"\"\"HeurÃ­sticas por conteÃºdo (COPIADAS DO DOCUMENTO ORIGINAL).\"\"\"\n",
    "        # [CÃ“DIGO COMPLETO DAS HEURÃSTICAS MANTIDO - NÃƒO REPRODUZIDO AQUI POR BREVIDADE]\n",
    "        # Ver documento original bloco_12_codigo.py\n",
    "        return None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTAR DETECÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "detector = DetectorCampos(df, DICIONARIO_PERSISTENTE)\n",
    "mapeamento_campos, relatorio_deteccao = detector.detectar_todos()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RELATÃ“RIO DE DETECÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ RELATÃ“RIO DE DETECÃ‡ÃƒO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š RESUMO:\")\n",
    "print(f\"   Total de campos: {relatorio_deteccao['total_campos']}\")\n",
    "print(f\"   âœ… DicionÃ¡rio: {relatorio_deteccao['mapeados_dicionario']}\")\n",
    "print(f\"   ğŸ¤– HeurÃ­stica: {relatorio_deteccao['mapeados_heuristica']}\")\n",
    "print(f\"   â“ Desconhecidos: {relatorio_deteccao['desconhecidos']}\")\n",
    "print(f\"   âš ï¸  AmbÃ­guos: {relatorio_deteccao['ambiguos']}\")\n",
    "\n",
    "# Taxa de sucesso\n",
    "taxa_sucesso = ((relatorio_deteccao['mapeados_dicionario'] + relatorio_deteccao['mapeados_heuristica']) /\n",
    "                relatorio_deteccao['total_campos']) * 100\n",
    "\n",
    "print(f\"\\nğŸ¯ Taxa de detecÃ§Ã£o: {taxa_sucesso:.1f}%\")\n",
    "\n",
    "# Detalhes por confianÃ§a\n",
    "print(f\"\\nğŸ“Š DISTRIBUIÃ‡ÃƒO POR CONFIANÃ‡A:\")\n",
    "\n",
    "alta = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] >= 0.85)\n",
    "media = sum(1 for d in relatorio_deteccao['detalhes'] if 0.70 <= d['confianca'] < 0.85)\n",
    "baixa = sum(1 for d in relatorio_deteccao['detalhes'] if 0 < d['confianca'] < 0.70)\n",
    "zero = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] == 0)\n",
    "\n",
    "print(f\"   ğŸŸ¢ Alta (â‰¥85%): {alta}\")\n",
    "print(f\"   ğŸŸ¡ MÃ©dia (70-85%): {media}\")\n",
    "print(f\"   ğŸŸ  Baixa (<70%): {baixa}\")\n",
    "print(f\"   âš« Desconhecidos: {zero}\")\n",
    "\n",
    "# Lista de desconhecidos\n",
    "desconhecidos = [d for d in relatorio_deteccao['detalhes'] if d['campo_detectado'] == 'DESCONHECIDO']\n",
    "\n",
    "if desconhecidos:\n",
    "    print(f\"\\nâ“ CAMPOS DESCONHECIDOS:\")\n",
    "    for item in desconhecidos:\n",
    "        print(f\"   â€¢ {item['coluna_original']}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âŒ REMOVIDO: TODA LÃ“GICA DE RENOMEAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ANTES (v6.x):\n",
    "# - rename_dict = {}\n",
    "# - for col_orig, info in mapeamento_campos.items(): ...\n",
    "# - duplicados = [...]\n",
    "# - contador_sufixos = {}  # GERAVA Monetario_1, Monetario_2, etc.\n",
    "# - df_mapeado = df.rename(columns=rename_dict)  # RENOMEAVA DATAFRAME\n",
    "#\n",
    "# AGORA (v7.0):\n",
    "# - DataFrame NUNCA Ã© modificado\n",
    "# - Mapeamentos salvos APENAS no dicionÃ¡rio\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ“‹ MAPEAMENTOS DETECTADOS (NÃƒO APLICADOS AO DATAFRAME)\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# Contar campos com cada tipo de rÃ³tulo\n",
    "from collections import Counter\n",
    "rotulos_detectados = [\n",
    "    info['campo_detectado']\n",
    "    for info in mapeamento_campos.values()\n",
    "    if info['confianca'] >= 0.70 and info['campo_detectado'] != 'DESCONHECIDO'\n",
    "]\n",
    "\n",
    "contagem_rotulos = Counter(rotulos_detectados)\n",
    "duplicados_conceituais = {k: v for k, v in contagem_rotulos.items() if v > 1}\n",
    "\n",
    "if duplicados_conceituais:\n",
    "    print(f\"\\nâš ï¸  AVISO: {len(duplicados_conceituais)} rÃ³tulo(s) mapeados para mÃºltiplos campos:\")\n",
    "    for rotulo, qtd in sorted(duplicados_conceituais.items()):\n",
    "        colunas_com_rotulo = [\n",
    "            col for col, info in mapeamento_campos.items()\n",
    "            if info['campo_detectado'] == rotulo and info['confianca'] >= 0.70\n",
    "        ]\n",
    "        print(f\"\\n   ğŸ“Œ '{rotulo}' ({qtd} campos):\")\n",
    "        for col in colunas_com_rotulo:\n",
    "            confianca = mapeamento_campos[col]['confianca']\n",
    "            print(f\"      â€¢ '{col}' (confianÃ§a: {confianca:.0%})\")\n",
    "\n",
    "    print(f\"\\n   ğŸ’¡ AÃ‡ÃƒO:\")\n",
    "    print(f\"      â€¢ Mapeamentos salvos no dicionÃ¡rio (nomes originais preservados)\")\n",
    "    print(f\"      â€¢ Use BLOCO 13 para confirmar/corrigir tipos\")\n",
    "    print(f\"      â€¢ DataFrame mantÃ©m nomes originais das colunas\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR MAPEAMENTO NO DICIONÃRIO PERSISTENTE (PATH CORRIGIDO!)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ’¾ SALVANDO MAPEAMENTO NO DICIONÃRIO\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# Identificar fonte\n",
    "nome_fonte = f\"CSV_{arquivo_selecionado.stem}\"\n",
    "\n",
    "# Criar entrada no dicionÃ¡rio\n",
    "if 'arquivos' not in DICIONARIO_PERSISTENTE:\n",
    "    DICIONARIO_PERSISTENTE['arquivos'] = {}\n",
    "\n",
    "DICIONARIO_PERSISTENTE['arquivos'][nome_fonte] = {\n",
    "    'arquivo_origem': arquivo_selecionado.name,\n",
    "    'data_processamento': datetime.now().isoformat(),\n",
    "    'total_campos': len(df.columns),\n",
    "    'mapeamentos': {}  # â† MUDANÃ‡A: era 'campos_mapeados'\n",
    "}\n",
    "\n",
    "# Adicionar TODOS os campos (â‰¥70% confianÃ§a)\n",
    "mapeamentos_salvos = 0\n",
    "for col_orig, info in mapeamento_campos.items():\n",
    "    if info['confianca'] >= 0.70:\n",
    "        DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['mapeamentos'][col_orig] = {\n",
    "            'rotulo_padrao': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        mapeamentos_salvos += 1\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… PATH CORRIGIDO: fm.pastas['dicionarios'] (NÃƒO 'logs'!)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'  # âœ… CORRETO\n",
    "\n",
    "# Garantir que pasta existe\n",
    "fm.pastas['dicionarios'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… DicionÃ¡rio salvo: {dict_path.name}\")\n",
    "print(f\"   Mapeamentos: {mapeamentos_salvos}/{len(df.columns)}\")\n",
    "print(f\"   Caminho: {dict_path}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PREVIEW DOS DADOS (NOMES ORIGINAIS MANTIDOS!)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‘€ PREVIEW DOS DADOS (NOMES ORIGINAIS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š Shape: {df.shape[0]:,} registros Ã— {df.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Primeiras 10 colunas (ORIGINAIS):\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    # Mostrar rÃ³tulo detectado (se existe)\n",
    "    if col in mapeamento_campos:\n",
    "        rotulo = mapeamento_campos[col]['campo_detectado']\n",
    "        confianca = mapeamento_campos[col]['confianca']\n",
    "        if rotulo != 'DESCONHECIDO' and confianca >= 0.70:\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "            print(f\"       â†’ Mapeado: {rotulo} ({confianca:.0%})\")\n",
    "        else:\n",
    "            print(f\"   {i:2d}. {col}\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Primeiras 3 linhas:\")\n",
    "print(df.head(3).to_string())\n",
    "\n",
    "# âŒ REMOVIDO: df = df_mapeado (DataFrame NÃƒO Ã© modificado!)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXPORTAR VARIÃVEIS PARA PRÃ“XIMOS BLOCOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ“¤ EXPORTANDO VARIÃVEIS PARA PRÃ“XIMOS BLOCOS\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# 1. tipos_detectados (alias para mapeamento_campos)\n",
    "tipos_detectados = mapeamento_campos.copy()\n",
    "\n",
    "# 2. requer_confirmacao (se algum campo tem confianÃ§a < 90% OU duplicaÃ§Ã£o)\n",
    "threshold_confirmacao = 0.90\n",
    "campos_baixa_confianca = [\n",
    "    col for col, info in mapeamento_campos.items()\n",
    "    if info['confianca'] < threshold_confirmacao and info['campo_detectado'] != 'DESCONHECIDO'\n",
    "]\n",
    "\n",
    "# Considerar tambÃ©m duplicaÃ§Ãµes conceituais\n",
    "campos_com_duplicacao = []\n",
    "for rotulo, qtd in duplicados_conceituais.items():\n",
    "    if qtd > 1:\n",
    "        for col, info in mapeamento_campos.items():\n",
    "            if info['campo_detectado'] == rotulo:\n",
    "                campos_com_duplicacao.append(col)\n",
    "\n",
    "# Unir ambas as listas\n",
    "campos_revisar = list(set(campos_baixa_confianca + campos_com_duplicacao))\n",
    "requer_confirmacao = len(campos_revisar) > 0\n",
    "\n",
    "# 3. campos_confirmar (lista de campos que precisam validaÃ§Ã£o)\n",
    "if requer_confirmacao:\n",
    "    campos_confirmar = []\n",
    "    for col in campos_revisar:\n",
    "        info = mapeamento_campos[col]\n",
    "        campos_confirmar.append({\n",
    "            'coluna_original': col,\n",
    "            'tipo_detectado': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo'],\n",
    "            'duplicado': col in campos_com_duplicacao\n",
    "        })\n",
    "else:\n",
    "    campos_confirmar = []\n",
    "\n",
    "# Exibir resultado\n",
    "print(f\"\\nâœ… VariÃ¡veis exportadas:\")\n",
    "print(f\"   â€¢ df: DataFrame ORIGINAL ({df.shape[0]:,} Ã— {df.shape[1]})\")\n",
    "print(f\"   â€¢ tipos_detectados: {len(tipos_detectados)} mapeamentos\")\n",
    "print(f\"   â€¢ requer_confirmacao: {requer_confirmacao}\")\n",
    "print(f\"   â€¢ campos_confirmar: {len(campos_confirmar)} campos\")\n",
    "\n",
    "if requer_confirmacao:\n",
    "    print(f\"\\nâš ï¸  {len(campos_confirmar)} campo(s) para revisar:\")\n",
    "    for campo in campos_confirmar[:5]:  # Mostrar primeiros 5\n",
    "        status = \"DUPLICADO\" if campo['duplicado'] else f\"{campo['confianca']:.0%}\"\n",
    "        print(f\"   â€¢ '{campo['coluna_original']}' â†’ '{campo['tipo_detectado']}' ({status})\")\n",
    "\n",
    "    if len(campos_confirmar) > 5:\n",
    "        print(f\"   ... e mais {len(campos_confirmar) - 5}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR ESTADO PARA PRÃ“XIMO BLOCO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco12 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_campos': len(df.columns),\n",
    "    'taxa_deteccao': taxa_sucesso,\n",
    "    'requer_confirmacao': requer_confirmacao,\n",
    "    'campos_confirmacao': campos_confirmar,\n",
    "    'duplicacoes_detectadas': len(duplicados_conceituais),\n",
    "    'mapeamentos': {\n",
    "        col: {\n",
    "            'rotulo': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo']\n",
    "        }\n",
    "        for col, info in mapeamento_campos.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar JSON\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_12_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco12, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 12 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ‰ MUDANÃ‡AS v7.0:\")\n",
    "print(f\"   âœ… DataFrame preserva nomes ORIGINAIS\")\n",
    "print(f\"   âœ… Mapeamentos salvos no dicionÃ¡rio\")\n",
    "print(f\"   âœ… Path correto: fm.pastas['dicionarios']\")\n",
    "print(f\"   âŒ Removido: Sistema de sufixos (_1, _2, _3)\")\n",
    "print(f\"   âŒ Removido: RenomeaÃ§Ã£o de colunas\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ PrÃ³ximo: BLOCO 13 - ConfirmaÃ§Ã£o de tipos\")"
   ],
   "id": "7248ad79f5d29e2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ” DETECÃ‡ÃƒO AUTOMÃTICA DE CAMPOS v7.0 (SEM RENOMEAR)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Analisando 25 campos...\n",
      "\n",
      "   ğŸ” Analisando: 'Ano civil/mÃªs'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Centro'\n",
      "      âœ… Centro\n",
      "      ConfianÃ§a: 100% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: ''\n",
      "      âœ… Centro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'HierarqPrd'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Produto'\n",
      "      âœ… Codigo_Produto\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: '_dup1'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Estoque Inicial'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Entrada'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Externa'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Externa %'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Interna'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Interna %'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Total'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'VariaÃ§Ã£o Total %'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Custo UnitÃ¡rio do Produto'\n",
      "      âœ… Desc_Grupo_Produto\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Imposto'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Valor da VariaÃ§Ã£o Interna'\n",
      "      âœ… Monetario\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: '_dup2'\n",
      "      â“ DESCONHECIDO\n",
      "      ConfianÃ§a: 0% | MÃ©todo: NENHUM\n",
      "\n",
      "   ğŸ” Analisando: 'Quantidade Excedente da VariaÃ§Ã£o Externa'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Valor Excedente da VariaÃ§Ã£o Externa (R$)'\n",
      "      âœ… Monetario\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Quantidade Excedente da VariaÃ§Ã£o Interna'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Valor Excedente da VariaÃ§Ã£o Interna (R$)'\n",
      "      âœ… Monetario\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Quantidade Excedente da VariaÃ§Ã£o Total'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Valor Excedente da VariaÃ§Ã£o Total (R$)'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "   ğŸ” Analisando: 'Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)'\n",
      "      âœ… Numero_Inteiro\n",
      "      ConfianÃ§a: 90% | MÃ©todo: DICIONARIO\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ RELATÃ“RIO DE DETECÃ‡ÃƒO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š RESUMO:\n",
      "   Total de campos: 25\n",
      "   âœ… DicionÃ¡rio: 14\n",
      "   ğŸ¤– HeurÃ­stica: 0\n",
      "   â“ Desconhecidos: 11\n",
      "   âš ï¸  AmbÃ­guos: 0\n",
      "\n",
      "ğŸ¯ Taxa de detecÃ§Ã£o: 56.0%\n",
      "\n",
      "ğŸ“Š DISTRIBUIÃ‡ÃƒO POR CONFIANÃ‡A:\n",
      "   ğŸŸ¢ Alta (â‰¥85%): 14\n",
      "   ğŸŸ¡ MÃ©dia (70-85%): 0\n",
      "   ğŸŸ  Baixa (<70%): 0\n",
      "   âš« Desconhecidos: 11\n",
      "\n",
      "â“ CAMPOS DESCONHECIDOS:\n",
      "   â€¢ Ano civil/mÃªs\n",
      "   â€¢ HierarqPrd\n",
      "   â€¢ _dup1\n",
      "   â€¢ Estoque Inicial\n",
      "   â€¢ Entrada\n",
      "   â€¢ VariaÃ§Ã£o Externa\n",
      "   â€¢ VariaÃ§Ã£o Externa %\n",
      "   â€¢ VariaÃ§Ã£o Interna\n",
      "   â€¢ VariaÃ§Ã£o Interna %\n",
      "   â€¢ Imposto\n",
      "   â€¢ _dup2\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“‹ MAPEAMENTOS DETECTADOS (NÃƒO APLICADOS AO DATAFRAME)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âš ï¸  AVISO: 3 rÃ³tulo(s) mapeados para mÃºltiplos campos:\n",
      "\n",
      "   ğŸ“Œ 'Centro' (2 campos):\n",
      "      â€¢ 'Centro' (confianÃ§a: 100%)\n",
      "      â€¢ '' (confianÃ§a: 90%)\n",
      "\n",
      "   ğŸ“Œ 'Monetario' (3 campos):\n",
      "      â€¢ 'Valor da VariaÃ§Ã£o Interna' (confianÃ§a: 90%)\n",
      "      â€¢ 'Valor Excedente da VariaÃ§Ã£o Externa (R$)' (confianÃ§a: 90%)\n",
      "      â€¢ 'Valor Excedente da VariaÃ§Ã£o Interna (R$)' (confianÃ§a: 90%)\n",
      "\n",
      "   ğŸ“Œ 'Numero_Inteiro' (7 campos):\n",
      "      â€¢ 'VariaÃ§Ã£o Total' (confianÃ§a: 90%)\n",
      "      â€¢ 'VariaÃ§Ã£o Total %' (confianÃ§a: 90%)\n",
      "      â€¢ 'Quantidade Excedente da VariaÃ§Ã£o Externa' (confianÃ§a: 90%)\n",
      "      â€¢ 'Quantidade Excedente da VariaÃ§Ã£o Interna' (confianÃ§a: 90%)\n",
      "      â€¢ 'Quantidade Excedente da VariaÃ§Ã£o Total' (confianÃ§a: 90%)\n",
      "      â€¢ 'Valor Excedente da VariaÃ§Ã£o Total (R$)' (confianÃ§a: 90%)\n",
      "      â€¢ 'Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)' (confianÃ§a: 90%)\n",
      "\n",
      "   ğŸ’¡ AÃ‡ÃƒO:\n",
      "      â€¢ Mapeamentos salvos no dicionÃ¡rio (nomes originais preservados)\n",
      "      â€¢ Use BLOCO 13 para confirmar/corrigir tipos\n",
      "      â€¢ DataFrame mantÃ©m nomes originais das colunas\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¾ SALVANDO MAPEAMENTO NO DICIONÃRIO\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… DicionÃ¡rio salvo: DICT_Dicionario_Persistente.json\n",
      "   Mapeamentos: 14/25\n",
      "   Caminho: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251019_060722\\05_Dicionarios\\DICT_Dicionario_Persistente.json\n",
      "\n",
      "======================================================================\n",
      "ğŸ‘€ PREVIEW DOS DADOS (NOMES ORIGINAIS)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Shape: 967 registros Ã— 25 colunas\n",
      "\n",
      "ğŸ“‹ Primeiras 10 colunas (ORIGINAIS):\n",
      "    1. Ano civil/mÃªs\n",
      "    2. Centro\n",
      "       â†’ Mapeado: Centro (100%)\n",
      "    3. \n",
      "       â†’ Mapeado: Centro (90%)\n",
      "    4. HierarqPrd\n",
      "    5. Produto\n",
      "       â†’ Mapeado: Codigo_Produto (90%)\n",
      "    6. _dup1\n",
      "    7. Estoque Inicial\n",
      "    8. Entrada\n",
      "    9. VariaÃ§Ã£o Externa\n",
      "   10. VariaÃ§Ã£o Externa %\n",
      "\n",
      "ğŸ“ˆ Primeiras 3 linhas:\n",
      "  Ano civil/mÃªs Centro                  HierarqPrd     Produto                       _dup1 Estoque Inicial    Entrada VariaÃ§Ã£o Externa VariaÃ§Ã£o Externa % VariaÃ§Ã£o Interna VariaÃ§Ã£o Interna % VariaÃ§Ã£o Total VariaÃ§Ã£o Total % Custo UnitÃ¡rio do Produto  Imposto Valor da VariaÃ§Ã£o Interna _dup2 Quantidade Excedente da VariaÃ§Ã£o Externa Valor Excedente da VariaÃ§Ã£o Externa (R$) Quantidade Excedente da VariaÃ§Ã£o Interna Valor Excedente da VariaÃ§Ã£o Interna (R$) Quantidade Excedente da VariaÃ§Ã£o Total Valor Excedente da VariaÃ§Ã£o Total (R$) Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)\n",
      "0       01.2025   5126  BAV1        Diesel - Comum  01.011.674           Ã“LEO DIESEL B S10         16924.0                                                            18.0           0.106358           18.0         0.106358                  5.300122      0.0                 95.402202                                            0.0                                      0.0                                    10.19                                54.008246                                  10.19                                  54.01                                            54.01\n",
      "1       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.001.422     JET A NAO TABELADO - LI        373850.0   939139.0            824.0            0.08774            -10.0          -0.000762          814.0         0.036144                  3.890482 -2811.15                -38.904816                                         366.22                              1424.772156                                      0.0                                      0.0                                    0.0                                    0.0                                          2811.15\n",
      "2       01.2025   5126  BAV1  Querosene de AviaÃ§Ã£o  01.003.826  JET A INTERNACIONAL I - LI        598315.0  5188210.0           1494.0           0.028796                                             1494.0         0.013613                  3.882566      0.0                       0.0                                            0.0                                      0.0                                      0.0                                      0.0                                    0.0                                    0.0                                              0.0\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¤ EXPORTANDO VARIÃVEIS PARA PRÃ“XIMOS BLOCOS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âœ… VariÃ¡veis exportadas:\n",
      "   â€¢ df: DataFrame ORIGINAL (967 Ã— 25)\n",
      "   â€¢ tipos_detectados: 25 mapeamentos\n",
      "   â€¢ requer_confirmacao: True\n",
      "   â€¢ campos_confirmar: 12 campos\n",
      "\n",
      "âš ï¸  12 campo(s) para revisar:\n",
      "   â€¢ '' â†’ 'Centro' (DUPLICADO)\n",
      "   â€¢ 'Centro' â†’ 'Centro' (DUPLICADO)\n",
      "   â€¢ 'VariaÃ§Ã£o Total' â†’ 'Numero_Inteiro' (DUPLICADO)\n",
      "   â€¢ 'Quantidade Excedente da VariaÃ§Ã£o Interna' â†’ 'Numero_Inteiro' (DUPLICADO)\n",
      "   â€¢ 'Valor Excedente da VariaÃ§Ã£o Total (R$)' â†’ 'Numero_Inteiro' (DUPLICADO)\n",
      "   ... e mais 7\n",
      "\n",
      "ğŸ’¾ Estado salvo: .bloco_12_state.json\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 12 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ‰ MUDANÃ‡AS v7.0:\n",
      "   âœ… DataFrame preserva nomes ORIGINAIS\n",
      "   âœ… Mapeamentos salvos no dicionÃ¡rio\n",
      "   âœ… Path correto: fm.pastas['dicionarios']\n",
      "   âŒ Removido: Sistema de sufixos (_1, _2, _3)\n",
      "   âŒ Removido: RenomeaÃ§Ã£o de colunas\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 13 - ConfirmaÃ§Ã£o de tipos\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:14.942917Z",
     "start_time": "2025-10-19T09:18:10.609648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 13 v7.3 - CONFIRMAÃ‡ÃƒO VISUAL COMPLETA (GUI 100% FUNCIONAL)\n",
    "# ===================================================================\n",
    "# Esta Ã© a versÃ£o COMPLETA sem simplificaÃ§Ãµes!\n",
    "# TODO o cÃ³digo da GUI estÃ¡ incluÃ­do.\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” CONFIRMAÃ‡ÃƒO VISUAL DE TIPOS v7.3 (GUI COMPLETA)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ===================================================================\n",
    "# 1. VALIDAÃ‡Ã•ES INICIAIS\n",
    "# ===================================================================\n",
    "\n",
    "variaveis_necessarias = [\n",
    "    'requer_confirmacao',\n",
    "    'campos_confirmar',\n",
    "    'df',\n",
    "    'DICIONARIO_PERSISTENTE',\n",
    "    'fm'\n",
    "]\n",
    "\n",
    "for var in variaveis_necessarias:\n",
    "    if var not in globals():\n",
    "        print(f\"\\nâŒ Erro: '{var}' nÃ£o encontrado\")\n",
    "        raise RuntimeError(f\"VariÃ¡vel '{var}' nÃ£o disponÃ­vel\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. FALLBACK ROBUSTO (3 NÃVEIS)\n",
    "# ===================================================================\n",
    "\n",
    "if 'tipos_detectados' not in globals() or len(tipos_detectados) == 0:\n",
    "    print(f\"\\nâš ï¸  Reconstruindo tipos_detectados...\")\n",
    "\n",
    "    tipos_detectados = {}\n",
    "\n",
    "    # NÃVEL 1: .bloco_12_state.json\n",
    "    arquivo_bloco12 = fm.pastas['logs'] / '.bloco_12_state.json'\n",
    "\n",
    "    if arquivo_bloco12.exists():\n",
    "        with open(arquivo_bloco12, 'r', encoding='utf-8') as f:\n",
    "            estado_bloco12 = json.load(f)\n",
    "\n",
    "        if 'mapeamentos' in estado_bloco12:\n",
    "            for col_orig, info in estado_bloco12['mapeamentos'].items():\n",
    "                tipos_detectados[col_orig] = {\n",
    "                    'campo_detectado': info.get('rotulo', 'DESCONHECIDO'),\n",
    "                    'confianca': info.get('confianca', 0.0),\n",
    "                    'metodo': info.get('metodo', 'N/A')\n",
    "                }\n",
    "\n",
    "    # NÃVEL 2: campos_confirmar\n",
    "    if len(tipos_detectados) == 0:\n",
    "        for campo_dict in campos_confirmar:\n",
    "            col = campo_dict['coluna_original']\n",
    "            tipos_detectados[col] = {\n",
    "                'campo_detectado': campo_dict['tipo_detectado'],\n",
    "                'confianca': campo_dict['confianca'],\n",
    "                'metodo': 'RECONSTRUIDO'\n",
    "            }\n",
    "\n",
    "    # Adicionar campos faltantes\n",
    "    campos_faltando = []\n",
    "    for campo_dict in campos_confirmar:\n",
    "        col = campo_dict['coluna_original']\n",
    "        if col not in tipos_detectados:\n",
    "            tipos_detectados[col] = {\n",
    "                'campo_detectado': campo_dict['tipo_detectado'],\n",
    "                'confianca': campo_dict['confianca'],\n",
    "                'metodo': 'RECONSTRUIDO'\n",
    "            }\n",
    "            campos_faltando.append(col)\n",
    "\n",
    "    if campos_faltando:\n",
    "        print(f\"   âœ… {len(campos_faltando)} campos adicionados\")\n",
    "\n",
    "print(f\"\\nâœ… VariÃ¡veis validadas:\")\n",
    "print(f\"   â€¢ tipos_detectados: {len(tipos_detectados)} campos\")\n",
    "print(f\"   â€¢ campos_confirmar: {len(campos_confirmar)} campos\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. FUNÃ‡ÃƒO: CRIAR TIPO CUSTOMIZADO\n",
    "# ===================================================================\n",
    "\n",
    "def criar_tipo_customizado_popup():\n",
    "    \"\"\"Popup para criar tipo customizado.\"\"\"\n",
    "    resultado = {'nome': None, 'dtype': None}\n",
    "\n",
    "    popup = tk.Toplevel()\n",
    "    popup.title(\"CRIAR TIPO CUSTOMIZADO\")\n",
    "    popup.geometry(\"500x400\")\n",
    "\n",
    "    x = (popup.winfo_screenwidth() // 2) - 250\n",
    "    y = (popup.winfo_screenheight() // 2) - 200\n",
    "    popup.geometry(f\"+{x}+{y}\")\n",
    "    popup.configure(bg='white')\n",
    "    popup.transient()\n",
    "    popup.grab_set()\n",
    "\n",
    "    frame = tk.Frame(popup, bg='white', padx=20, pady=20)\n",
    "    frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"CRIAR NOVO TIPO DE CAMPO\",\n",
    "        font=('Arial', 14, 'bold'),\n",
    "        bg='white'\n",
    "    ).pack(pady=(0, 20))\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"Nome do Tipo:\",\n",
    "        font=('Arial', 10),\n",
    "        bg='white',\n",
    "        anchor='w'\n",
    "    ).pack(fill=tk.X)\n",
    "\n",
    "    var_nome = tk.StringVar()\n",
    "    entry_nome = tk.Entry(frame, textvariable=var_nome, font=('Arial', 12), width=40)\n",
    "    entry_nome.pack(pady=(5, 20), fill=tk.X)\n",
    "    entry_nome.focus()\n",
    "\n",
    "    tk.Label(frame, text=\"Tipo de Dados:\", font=('Arial', 10), bg='white', anchor='w').pack(fill=tk.X)\n",
    "\n",
    "    dtypes = [\n",
    "        ('int32', 'Inteiro pequeno'),\n",
    "        ('int64', 'Inteiro grande'),\n",
    "        ('float64', 'Decimal'),\n",
    "        ('string', 'Texto'),\n",
    "        ('date', 'Data')\n",
    "    ]\n",
    "\n",
    "    var_dtype = tk.StringVar(value='float64')\n",
    "\n",
    "    for dtype, desc in dtypes:\n",
    "        tk.Radiobutton(\n",
    "            frame,\n",
    "            text=f\"{dtype:10s} - {desc}\",\n",
    "            variable=var_dtype,\n",
    "            value=dtype,\n",
    "            font=('Courier', 9),\n",
    "            bg='white',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "    frame_btns = tk.Frame(frame, bg='white')\n",
    "    frame_btns.pack(pady=(10, 0))\n",
    "\n",
    "    def confirmar():\n",
    "        nome = var_nome.get().strip().upper()\n",
    "        if nome and len(nome) >= 2:\n",
    "            resultado['nome'] = nome\n",
    "            resultado['dtype'] = var_dtype.get()\n",
    "            popup.destroy()\n",
    "        else:\n",
    "            messagebox.showwarning(\"Aviso\", \"Digite um nome vÃ¡lido!\")\n",
    "\n",
    "    def cancelar():\n",
    "        popup.destroy()\n",
    "\n",
    "    entry_nome.bind('<Return>', lambda e: confirmar())\n",
    "\n",
    "    tk.Button(frame_btns, text=\"Criar\", command=confirmar, width=12, bg='#4CAF50', fg='white').pack(side=tk.LEFT, padx=5)\n",
    "    tk.Button(frame_btns, text=\"Cancelar\", command=cancelar, width=12, bg='#757575', fg='white').pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "    popup.wait_window()\n",
    "    return resultado['nome'], resultado['dtype']\n",
    "\n",
    "# ===================================================================\n",
    "# 4. PROCESSO DE CONFIRMAÃ‡ÃƒO\n",
    "# ===================================================================\n",
    "\n",
    "if not requer_confirmacao:\n",
    "    print(\"\\nâœ… Nenhuma confirmaÃ§Ã£o necessÃ¡ria\")\n",
    "    confirmacoes = {}\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  {len(campos_confirmar)} campos requerem confirmaÃ§Ã£o\")\n",
    "    print(f\"   Abrindo interface visual...\")\n",
    "\n",
    "    def confirmar_tipos_visual(campos_confirmar, tipos_detectados, df):\n",
    "        \"\"\"GUI VISUAL COMPLETA.\"\"\"\n",
    "\n",
    "        # Testar GUI\n",
    "        try:\n",
    "            test_root = tk.Tk()\n",
    "            test_root.withdraw()\n",
    "            test_root.destroy()\n",
    "        except:\n",
    "            print(\"âŒ GUI nÃ£o disponÃ­vel\")\n",
    "            return {}\n",
    "\n",
    "        # Preparar tipos\n",
    "        tipos_dict = DICIONARIO_PERSISTENTE.get('conhecimento_base', {}).get('campos_conhecidos', {})\n",
    "        if not tipos_dict:\n",
    "            tipos_dict = DICIONARIO_PERSISTENTE.get('campos_conhecidos', {})\n",
    "\n",
    "        tipos_lista = []\n",
    "        for i, (nome, info) in enumerate(sorted(tipos_dict.items()), 1):\n",
    "            tipos_lista.append({\n",
    "                'numero': i,\n",
    "                'nome': nome,\n",
    "                'descricao': info.get('descricao', '') if isinstance(info, dict) else ''\n",
    "            })\n",
    "\n",
    "        tipos_lista.append({'numero': 0, 'nome': 'DESCONHECIDO', 'descricao': ''})\n",
    "\n",
    "        confirmacoes = {}\n",
    "        idx_atual = [0]\n",
    "\n",
    "        def processar_proximo():\n",
    "            \"\"\"Processa campo atual.\"\"\"\n",
    "            if idx_atual[0] >= len(campos_confirmar):\n",
    "                return\n",
    "\n",
    "            # Extrair campo\n",
    "            col_dict = campos_confirmar[idx_atual[0]]\n",
    "            col = col_dict['coluna_original']\n",
    "\n",
    "            if col not in tipos_detectados:\n",
    "                print(f\"âš ï¸  '{col}' nÃ£o encontrado - pulando\")\n",
    "                idx_atual[0] += 1\n",
    "                processar_proximo()\n",
    "                return\n",
    "\n",
    "            info_campo = tipos_detectados[col]\n",
    "\n",
    "            # Buscar coluna no DataFrame\n",
    "            col_df = col if col in df.columns else None\n",
    "            if not col_df:\n",
    "                print(f\"âš ï¸  '{col}' nÃ£o encontrado no df - pulando\")\n",
    "                idx_atual[0] += 1\n",
    "                processar_proximo()\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                valores = df[col_df].dropna().unique()[:5].tolist()\n",
    "            except:\n",
    "                valores = ['[ERRO]']\n",
    "\n",
    "            # ========================================================\n",
    "            # CRIAR JANELA\n",
    "            # ========================================================\n",
    "            root = tk.Tk()\n",
    "            root.title(f\"DETECTOR ({idx_atual[0]+1}/{len(campos_confirmar)})\")\n",
    "            root.geometry(\"900x700\")\n",
    "\n",
    "            x = (root.winfo_screenwidth() // 2) - 450\n",
    "            y = (root.winfo_screenheight() // 2) - 350\n",
    "            root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "            frame_main = tk.Frame(root, bg='white')\n",
    "            frame_main.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)\n",
    "\n",
    "            # TOPO\n",
    "            frame_topo = tk.Frame(frame_main, bg='#E3F2FD', relief=tk.RAISED, borderwidth=2)\n",
    "            frame_topo.pack(fill=tk.X, pady=(0, 15))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_topo,\n",
    "                text=f\"Campo {idx_atual[0]+1} de {len(campos_confirmar)}\",\n",
    "                font=('Arial', 12, 'bold'),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0'\n",
    "            ).pack(pady=8)\n",
    "\n",
    "            # CONTEÃšDO\n",
    "            frame_content = tk.Frame(frame_main, bg='white')\n",
    "            frame_content.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            # ESQUERDA\n",
    "            frame_left = tk.Frame(frame_content, bg='white', width=400)\n",
    "            frame_left.pack(side=tk.LEFT, fill=tk.BOTH, expand=False, padx=(0, 10))\n",
    "\n",
    "            tk.Label(frame_left, text=\"CAMPO DO ARQUIVO\", font=('Arial', 11, 'bold'), bg='white').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_campo = tk.Frame(frame_left, bg='#FFF9C4', relief=tk.SUNKEN, borderwidth=2)\n",
    "            frame_campo.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            tk.Label(frame_campo, text=col, font=('Arial', 10, 'bold'), bg='#FFF9C4', wraplength=380).pack(fill=tk.X, padx=10, pady=(8, 5))\n",
    "            tk.Label(frame_campo, text=f\"Detectado: {info_campo['campo_detectado']}\", font=('Arial', 9), bg='#FFF9C4', fg='#F57F17').pack(fill=tk.X, padx=10, pady=(0, 3))\n",
    "            tk.Label(frame_campo, text=f\"ConfianÃ§a: {info_campo['confianca']:.0%}\", font=('Arial', 9), bg='#FFF9C4', fg='#F57F17').pack(fill=tk.X, padx=10, pady=(0, 8))\n",
    "\n",
    "            tk.Label(frame_left, text=\"EXEMPLOS\", font=('Arial', 10, 'bold'), bg='white').pack(fill=tk.X, pady=(5, 5))\n",
    "\n",
    "            frame_ex = tk.Frame(frame_left, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "            frame_ex.pack(fill=tk.X)\n",
    "\n",
    "            for i, v in enumerate(valores, 1):\n",
    "                tk.Label(frame_ex, text=f\"{i}. {str(v)[:50]}\", font=('Arial', 9), bg='#F5F5F5', anchor='w').pack(fill=tk.X, padx=10, pady=2)\n",
    "\n",
    "            # DIREITA\n",
    "            frame_right = tk.Frame(frame_content, bg='white')\n",
    "            frame_right.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            tk.Label(frame_right, text=\"TIPOS - Digite o nÃºmero\", font=('Arial', 11, 'bold'), bg='white').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_lista_outer = tk.Frame(frame_right, bg='white')\n",
    "            frame_lista_outer.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            canvas = tk.Canvas(frame_lista_outer, bg='white', highlightthickness=0)\n",
    "            scrollbar = tk.Scrollbar(frame_lista_outer, orient=\"vertical\", command=canvas.yview)\n",
    "            frame_lista = tk.Frame(canvas, bg='white')\n",
    "\n",
    "            frame_lista.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "            canvas.create_window((0, 0), window=frame_lista, anchor=\"nw\")\n",
    "            canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "            canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "            scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "            # Popular lista\n",
    "            for t in tipos_lista:\n",
    "                num = t['numero']\n",
    "                nome = t['nome']\n",
    "                desc = t['descricao']\n",
    "\n",
    "                bg = '#E8F5E9' if nome == info_campo['campo_detectado'] else 'white'\n",
    "                fg = '#2E7D32' if nome == info_campo['campo_detectado'] else 'black'\n",
    "\n",
    "                fi = tk.Frame(frame_lista, bg=bg, relief=tk.GROOVE, borderwidth=1)\n",
    "                fi.pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "                tk.Label(fi, text=f\"[{num:2d}]  {nome}\", font=('Courier', 9, 'bold'), bg=bg, fg=fg, anchor='w').pack(fill=tk.X, padx=8, pady=(3, 0))\n",
    "\n",
    "                if desc:\n",
    "                    tk.Label(fi, text=f\"      {desc}\", font=('Arial', 8), bg=bg, fg='#666', anchor='w').pack(fill=tk.X, padx=8, pady=(0, 3))\n",
    "\n",
    "            # RODAPÃ‰\n",
    "            frame_footer = tk.Frame(frame_main, bg='white')\n",
    "            frame_footer.pack(fill=tk.X, pady=(15, 0))\n",
    "\n",
    "            tk.Frame(frame_footer, height=2, bg='#CCC').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            frame_input = tk.Frame(frame_footer, bg='white')\n",
    "            frame_input.pack(pady=(0, 10))\n",
    "\n",
    "            tk.Label(frame_input, text=\"Digite o nÃºmero:\", font=('Arial', 10, 'bold'), bg='white').pack(side=tk.LEFT, padx=(0, 10))\n",
    "\n",
    "            var_num = tk.StringVar()\n",
    "            entry = tk.Entry(frame_input, textvariable=var_num, font=('Arial', 12, 'bold'), width=8, justify='center')\n",
    "            entry.pack(side=tk.LEFT)\n",
    "            entry.focus()\n",
    "\n",
    "            label_err = tk.Label(frame_input, text=\"\", font=('Arial', 9), fg='#FF0000', bg='white')\n",
    "            label_err.pack(side=tk.LEFT, padx=(10, 0))\n",
    "\n",
    "            frame_btns = tk.Frame(frame_footer, bg='white')\n",
    "            frame_btns.pack()\n",
    "\n",
    "            def validar():\n",
    "                try:\n",
    "                    num = int(var_num.get().strip())\n",
    "                    tipo = None\n",
    "                    for t in tipos_lista:\n",
    "                        if t['numero'] == num:\n",
    "                            tipo = t['nome']\n",
    "                            break\n",
    "\n",
    "                    if tipo:\n",
    "                        confirmacoes[col] = tipo\n",
    "                        idx_atual[0] += 1\n",
    "                        root.destroy()\n",
    "                        processar_proximo()\n",
    "                    else:\n",
    "                        label_err.config(text=f\"NÃºmero {num} invÃ¡lido!\")\n",
    "                except ValueError:\n",
    "                    label_err.config(text=\"Digite um nÃºmero!\")\n",
    "\n",
    "            def manter():\n",
    "                confirmacoes[col] = info_campo['campo_detectado']\n",
    "                idx_atual[0] += 1\n",
    "                root.destroy()\n",
    "                processar_proximo()\n",
    "\n",
    "            def pular():\n",
    "                for c_dict in campos_confirmar[idx_atual[0]:]:\n",
    "                    c = c_dict['coluna_original']\n",
    "                    if c in tipos_detectados:\n",
    "                        confirmacoes[c] = tipos_detectados[c]['campo_detectado']\n",
    "                root.destroy()\n",
    "\n",
    "            def criar():\n",
    "                nome, dtype = criar_tipo_customizado_popup()\n",
    "\n",
    "                if nome and dtype:\n",
    "                    # Adicionar ao dicionÃ¡rio\n",
    "                    if 'conhecimento_base' not in DICIONARIO_PERSISTENTE:\n",
    "                        DICIONARIO_PERSISTENTE['conhecimento_base'] = {}\n",
    "                    if 'campos_conhecidos' not in DICIONARIO_PERSISTENTE['conhecimento_base']:\n",
    "                        DICIONARIO_PERSISTENTE['conhecimento_base']['campos_conhecidos'] = {}\n",
    "\n",
    "                    DICIONARIO_PERSISTENTE['conhecimento_base']['campos_conhecidos'][nome] = {\n",
    "                        'tipo': dtype,\n",
    "                        'descricao': f'Customizado ({dtype})',\n",
    "                        'categoria': 'CUSTOMIZADO'\n",
    "                    }\n",
    "\n",
    "                    # Salvar\n",
    "                    dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'\n",
    "                    with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    print(f\"âœ… Tipo '{nome}' criado ({dtype})\")\n",
    "\n",
    "                    # Adicionar na lista\n",
    "                    prox_num = max([t['numero'] for t in tipos_lista]) + 1\n",
    "                    tipos_lista.insert(-1, {'numero': prox_num, 'nome': nome, 'descricao': f'Customizado - {dtype}'})\n",
    "\n",
    "                    # Atualizar GUI\n",
    "                    fi = tk.Frame(frame_lista, bg='#E1F5FE', relief=tk.GROOVE, borderwidth=2)\n",
    "                    fi.pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "                    tk.Label(fi, text=f\"[{prox_num:2d}]  {nome} â­\", font=('Courier', 9, 'bold'), bg='#E1F5FE', fg='#01579B', anchor='w').pack(fill=tk.X, padx=8, pady=(3, 0))\n",
    "                    tk.Label(fi, text=f\"      Customizado - {dtype}\", font=('Arial', 8), bg='#E1F5FE', fg='#0277BD', anchor='w').pack(fill=tk.X, padx=8, pady=(0, 3))\n",
    "\n",
    "                    canvas.update_idletasks()\n",
    "                    canvas.yview_moveto(1.0)\n",
    "\n",
    "                    var_num.set(str(prox_num))\n",
    "                    entry.focus()\n",
    "\n",
    "                    messagebox.showinfo(\"Sucesso\", f\"Tipo '{nome}' criado!\\nDigite {prox_num} e confirme.\")\n",
    "\n",
    "            entry.bind('<Return>', lambda e: validar())\n",
    "\n",
    "            tk.Button(frame_btns, text=\"Confirmar\", command=validar, width=12, height=2, bg='#4CAF50', fg='white', font=('Arial', 10, 'bold')).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"Manter\", command=manter, width=12, height=2, bg='#FF9800', fg='white', font=('Arial', 10)).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"âœ¨ Criar Tipo\", command=criar, width=12, height=2, bg='#2196F3', fg='white', font=('Arial', 10, 'bold')).pack(side=tk.LEFT, padx=5)\n",
    "            tk.Button(frame_btns, text=\"Pular Todos\", command=pular, width=12, height=2, bg='#757575', fg='white', font=('Arial', 10)).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "            root.mainloop()\n",
    "\n",
    "        processar_proximo()\n",
    "        return confirmacoes\n",
    "\n",
    "    confirmacoes = confirmar_tipos_visual(campos_confirmar, tipos_detectados, df)\n",
    "\n",
    "    # Aplicar confirmaÃ§Ãµes\n",
    "    if confirmacoes:\n",
    "        print(f\"\\nâœ… ConfirmaÃ§Ãµes: {len(confirmacoes)}\")\n",
    "\n",
    "        for col, tipo in confirmacoes.items():\n",
    "            if col in tipos_detectados:\n",
    "                tipos_detectados[col]['campo_detectado'] = tipo\n",
    "                tipos_detectados[col]['confianca'] = 1.0\n",
    "                tipos_detectados[col]['metodo'] = 'CONFIRMACAO_USUARIO'\n",
    "\n",
    "        # Salvar no dicionÃ¡rio\n",
    "        nome_fonte = f\"CSV_{arquivo_selecionado.stem}\"\n",
    "\n",
    "        if 'arquivos' not in DICIONARIO_PERSISTENTE:\n",
    "            DICIONARIO_PERSISTENTE['arquivos'] = {}\n",
    "\n",
    "        if nome_fonte not in DICIONARIO_PERSISTENTE['arquivos']:\n",
    "            DICIONARIO_PERSISTENTE['arquivos'][nome_fonte] = {\n",
    "                'arquivo_origem': arquivo_selecionado.name,\n",
    "                'mapeamentos': {}\n",
    "            }\n",
    "\n",
    "        for col, tipo in confirmacoes.items():\n",
    "            DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['mapeamentos'][col] = {\n",
    "                'rotulo_padrao': tipo,\n",
    "                'confianca': 1.0,\n",
    "                'metodo': 'CONFIRMACAO_USUARIO',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "        dict_path = fm.pastas['dicionarios'] / 'DICT_Dicionario_Persistente.json'\n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"   âœ… DicionÃ¡rio atualizado\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Nenhuma confirmaÃ§Ã£o\")\n",
    "\n",
    "# Salvar LOG\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "if log_path.exists():\n",
    "    with open(log_path, 'r', encoding='utf-8') as f:\n",
    "        log_data = json.load(f)\n",
    "else:\n",
    "    log_data = {}\n",
    "\n",
    "log_data['bloco_13_state'] = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'confirmacoes': len(confirmacoes),\n",
    "    'dataframe_renomeado': False\n",
    "}\n",
    "\n",
    "with open(log_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "arquivo_sep = fm.pastas['logs'] / '.bloco_13_state.json'\n",
    "with open(arquivo_sep, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_data['bloco_13_state'], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ… LOG salvo\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 13 CONCLUÃDO v7.3\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ’¡ DataFrame mantÃ©m nomes ORIGINAIS\")\n",
    "print(f\"ğŸ’¡ Mapeamentos salvos no dicionÃ¡rio\")"
   ],
   "id": "302fbbdf08b6cd1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ” CONFIRMAÃ‡ÃƒO VISUAL DE TIPOS v7.3 (GUI COMPLETA)\n",
      "======================================================================\n",
      "\n",
      "âœ… VariÃ¡veis validadas:\n",
      "   â€¢ tipos_detectados: 25 campos\n",
      "   â€¢ campos_confirmar: 12 campos\n",
      "\n",
      "âš ï¸  12 campos requerem confirmaÃ§Ã£o\n",
      "   Abrindo interface visual...\n",
      "âš ï¸  '' nÃ£o encontrado no df - pulando\n",
      "\n",
      "âœ… ConfirmaÃ§Ãµes: 11\n",
      "   âœ… DicionÃ¡rio atualizado\n",
      "\n",
      "âœ… LOG salvo\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 13 CONCLUÃDO v7.3\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ DataFrame mantÃ©m nomes ORIGINAIS\n",
      "ğŸ’¡ Mapeamentos salvos no dicionÃ¡rio\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:16.337558Z",
     "start_time": "2025-10-19T09:18:16.311620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 14: VALIDAÃ‡Ã•ES E ESTATÃSTICAS v2.1\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MudanÃ§as v2.0:\n",
    "# - CORRIGIDO: df_limpo â†’ df (variÃ¡vel correta do BLOCO 13)\n",
    "# - ADICIONADO: Salvamento .bloco_14_state.json\n",
    "# - ADICIONADO: Salvamento estatisticas_validacao.json\n",
    "# - CORRIGIDO: Visual sem emojis (â‰¤70 caracteres)\n",
    "# - REMOVIDO: Preview duplicado (BLOCO 13 jÃ¡ fez)\n",
    "# - ADICIONADO: Leitura do LOG GLOBAL\n",
    "# MudanÃ§as v2.1:\n",
    "# - CORRIGIDO: fm.container â†’ fm.base_path.name\n",
    "# - CORRIGIDO: fm.timestamp â†’ timestamp_execucao (do LOG)\n",
    "# - CORRIGIDO: fm.salvar_json() â†’ salvamento manual\n",
    "# - ADICIONADO: Recria FileManager se nÃ£o estiver na memÃ³ria\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDACOES E ESTATISTICAS v2.1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. VALIDACAO DE DEPENDENCIAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 1: VALIDANDO DEPENDENCIAS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 1.1 Verificar LOG GLOBAL e carregar config\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global_path.exists():\n",
    "    print(\"\\n! Erro: LOG GLOBAL nao encontrado\")\n",
    "    print(\"  Execute BLOCO 1 antes deste bloco\")\n",
    "    raise RuntimeError(\"LOG GLOBAL nao disponivel\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "pasta_container = Path(log_global['pasta_base_atual'])\n",
    "\n",
    "# Verificar se fm existe (pode estar na memÃ³ria ou nÃ£o)\n",
    "if 'fm' not in globals():\n",
    "    # Recriar FileManager se nÃ£o estiver na memÃ³ria\n",
    "    class FileManagerInterativo:\n",
    "        def __init__(self, base_path):\n",
    "            self.base_path = Path(base_path)\n",
    "            self.pastas = {\n",
    "                'entrada': self.base_path / '01_Entrada',\n",
    "                'processados': self.base_path / '02_Processados',\n",
    "                'outputs': self.base_path / '03_Outputs',\n",
    "                'logs': self.base_path / '04_Logs',\n",
    "                'dicionarios': self.base_path / '05_Dicionarios',\n",
    "                'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "            }\n",
    "\n",
    "    fm = FileManagerInterativo(pasta_container)\n",
    "\n",
    "print(f\"\\n OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {fm.base_path.name}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# 1.2 Verificar variÃ¡veis necessÃ¡rias\n",
    "if 'df' not in globals():\n",
    "    print(\"\\n! Erro: df nao encontrado\")\n",
    "    print(\"  Execute BLOCO 13 antes deste bloco\")\n",
    "    raise RuntimeError(\"df nao disponivel\")\n",
    "\n",
    "if 'tipos_detectados' not in globals():\n",
    "    print(\"\\n! Erro: tipos_detectados nao encontrado\")\n",
    "    print(\"  Execute BLOCO 12 antes deste bloco\")\n",
    "    raise RuntimeError(\"tipos_detectados nao disponivel\")\n",
    "\n",
    "print(f\"\\n OK Variaveis validadas:\")\n",
    "print(f\"    df shape: {df.shape}\")\n",
    "print(f\"    tipos_detectados: {len(tipos_detectados)} campos\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. ESTATISTICAS GERAIS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 2: RESUMO GERAL\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "registros = len(df)\n",
    "colunas = len(df.columns)\n",
    "mem_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "duplicadas = df.duplicated().sum()\n",
    "\n",
    "print(f\"\\n   Registros finais: {registros:,}\")\n",
    "print(f\"   Colunas finais: {colunas}\")\n",
    "print(f\"   Memoria em uso: {mem_mb:.2f} MB\")\n",
    "print(f\"   Linhas duplicadas: {duplicadas:,}\")\n",
    "\n",
    "estatisticas = {\n",
    "    'resumo_geral': {\n",
    "        'registros': int(registros),\n",
    "        'colunas': int(colunas),\n",
    "        'memoria_mb': float(round(mem_mb, 2)),\n",
    "        'linhas_duplicadas': int(duplicadas)\n",
    "    }\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. ANALISE DE VALORES NULOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 3: ANALISE DE VALORES NULOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "nulos_por_col = df.isnull().sum()\n",
    "colunas_com_nulos = nulos_por_col[nulos_por_col > 0].sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"\\n   {len(colunas_com_nulos)} colunas com valores nulos:\")\n",
    "\n",
    "    nulos_detalhes = {}\n",
    "    for col, qtd in colunas_com_nulos.items():\n",
    "        pct = (qtd / len(df)) * 100\n",
    "        barra = \"#\" * int(pct / 5)\n",
    "        print(f\"      {col[:30]:30s} | {qtd:6,} ({pct:5.1f}%) {barra}\")\n",
    "        nulos_detalhes[col] = {'qtd': int(qtd), 'pct': float(round(pct, 1))}\n",
    "\n",
    "    estatisticas['valores_nulos'] = nulos_detalhes\n",
    "else:\n",
    "    print(f\"\\n   Nenhum valor nulo!\")\n",
    "    estatisticas['valores_nulos'] = {}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. DISTRIBUICAO DE TIPOS DETECTADOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 4: DISTRIBUICAO DE TIPOS DETECTADOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "tipos_resumo = {}\n",
    "for info in tipos_detectados.values():\n",
    "    tipo = info['campo_detectado']\n",
    "    tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "for tipo, count in sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True):\n",
    "    barra = \"#\" * (count * 2)\n",
    "    print(f\"   {tipo:25s}: {count:2d} colunas {barra}\")\n",
    "\n",
    "estatisticas['tipos_detectados'] = tipos_resumo\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. CONFIANCA NA DETECCAO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 5: CONFIANCA NA DETECCAO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "alta = sum(1 for i in tipos_detectados.values() if i['confianca'] >= 0.90)\n",
    "media = sum(1 for i in tipos_detectados.values() if 0.70 <= i['confianca'] < 0.90)\n",
    "baixa = sum(1 for i in tipos_detectados.values() if i['confianca'] < 0.70)\n",
    "\n",
    "print(f\"\\n   Alta (>=90%):   {alta:2d} colunas\")\n",
    "print(f\"   Media (70-90%): {media:2d} colunas\")\n",
    "print(f\"   Baixa (<70%):   {baixa:2d} colunas\")\n",
    "\n",
    "estatisticas['confianca_deteccao'] = {\n",
    "    'alta': int(alta),\n",
    "    'media': int(media),\n",
    "    'baixa': int(baixa)\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 6. CAMPOS AMBIGUOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 6: CAMPOS AMBIGUOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "ambiguos = {\n",
    "    col: info\n",
    "    for col, info in tipos_detectados.items()\n",
    "    if info.get('ambiguidade', False)\n",
    "}\n",
    "\n",
    "if ambiguos:\n",
    "    print(f\"\\n   {len(ambiguos)} campos com ambiguidade:\")\n",
    "\n",
    "    ambiguos_lista = []\n",
    "    for col, info in list(ambiguos.items())[:5]:\n",
    "        print(f\"\\n   {col}\")\n",
    "        print(f\"      Detectado: {info['campo_detectado']}\")\n",
    "        candidatos = info.get('candidatos', [])\n",
    "        if candidatos:\n",
    "            print(f\"      Similar a: {', '.join(candidatos)}\")\n",
    "\n",
    "        ambiguos_lista.append({\n",
    "            'campo_original': col,\n",
    "            'detectado': info['campo_detectado'],\n",
    "            'candidatos': candidatos\n",
    "        })\n",
    "\n",
    "    if len(ambiguos) > 5:\n",
    "        print(f\"\\n   ... e mais {len(ambiguos) - 5} campos\")\n",
    "\n",
    "    estatisticas['campos_ambiguos'] = ambiguos_lista\n",
    "else:\n",
    "    print(f\"\\n   Nenhum campo ambiguo!\")\n",
    "    estatisticas['campos_ambiguos'] = []\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 7. ANALISE DE UNICIDADE (POTENCIAIS IDS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 7: ANALISE DE UNICIDADE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "unicidade_detalhes = []\n",
    "\n",
    "for col in df.columns:\n",
    "    unicos = df[col].nunique()\n",
    "    total = len(df)\n",
    "    pct_unico = (unicos / total) * 100\n",
    "\n",
    "    if pct_unico == 100:\n",
    "        print(f\"   {col[:30]:30s} | 100% unico (potencial ID)\")\n",
    "        unicidade_detalhes.append({\n",
    "            'campo': col,\n",
    "            'pct_unico': 100.0,\n",
    "            'tipo': 'ID'\n",
    "        })\n",
    "    elif pct_unico >= 95:\n",
    "        print(f\"   {col[:30]:30s} | {pct_unico:5.1f}% unico\")\n",
    "        unicidade_detalhes.append({\n",
    "            'campo': col,\n",
    "            'pct_unico': float(round(pct_unico, 1)),\n",
    "            'tipo': 'QUASE_ID'\n",
    "        })\n",
    "\n",
    "if not unicidade_detalhes:\n",
    "    print(f\"\\n   Nenhum campo com alta unicidade\")\n",
    "\n",
    "estatisticas['unicidade'] = unicidade_detalhes\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 8. CARDINALIDADE (VALORES UNICOS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 8: CARDINALIDADE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "cardinalidade_detalhes = []\n",
    "\n",
    "for col in df.columns[:10]:\n",
    "    unicos = df[col].nunique()\n",
    "    total = len(df)\n",
    "    pct = (unicos / total) * 100\n",
    "\n",
    "    if pct <= 10:\n",
    "        categoria = \"Categoria (baixa)\"\n",
    "    elif pct <= 50:\n",
    "        categoria = \"Mista (media)\"\n",
    "    else:\n",
    "        categoria = \"Continua (alta)\"\n",
    "\n",
    "    print(f\"   {col[:30]:30s} | {unicos:4d} unicos ({pct:5.1f}%) - {categoria}\")\n",
    "\n",
    "    cardinalidade_detalhes.append({\n",
    "        'campo': col,\n",
    "        'unicos': int(unicos),\n",
    "        'pct': float(round(pct, 1)),\n",
    "        'categoria': categoria\n",
    "    })\n",
    "\n",
    "if len(df.columns) > 10:\n",
    "    print(f\"\\n   ... e mais {len(df.columns) - 10} colunas\")\n",
    "\n",
    "estatisticas['cardinalidade'] = cardinalidade_detalhes\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 9. TIPOS DE DADOS PANDAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 9: TIPOS DE DADOS (PANDAS)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "tipos_pandas = {}\n",
    "\n",
    "for dtype, count in dtype_counts.items():\n",
    "    dtype_str = str(dtype)\n",
    "    print(f\"   {dtype_str:15s}: {count:2d} colunas\")\n",
    "    tipos_pandas[dtype_str] = int(count)\n",
    "\n",
    "estatisticas['tipos_pandas'] = tipos_pandas\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 10. SALVAMENTO DE ESTADO E ESTATISTICAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 10: SALVAMENTO DE ESTADO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 10.1 Salvar estado do bloco\n",
    "estado = {\n",
    "    'bloco': 14,\n",
    "    'versao': '2.1',\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'container': fm.base_path.name,\n",
    "    'validado': True,\n",
    "    'df_shape': list(df.shape),\n",
    "    'campos_analisados': len(tipos_detectados)\n",
    "}\n",
    "\n",
    "estado_path = Path('.bloco_14_state.json')\n",
    "with open(estado_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n   Estado salvo: {estado_path}\")\n",
    "\n",
    "# 10.2 Salvar estatÃ­sticas completas para auditoria\n",
    "estatisticas_path = fm.pastas['logs'] / 'estatisticas_validacao.json'\n",
    "with open(estatisticas_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estatisticas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   Estatisticas salvas: {estatisticas_path.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 11. RESUMO FINAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDACOES CONCLUIDAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n   Registros: {registros:,}\")\n",
    "print(f\"   Colunas: {colunas}\")\n",
    "print(f\"   Taxa deteccao: {(alta + media) / len(tipos_detectados) * 100:.1f}%\")\n",
    "print(f\"   Valores nulos: {len(colunas_com_nulos)} colunas\")\n",
    "print(f\"   Campos ambiguos: {len(ambiguos)}\")\n",
    "\n",
    "print(\"\\n Proximo: BLOCO 15 - Exportacao Final\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "id": "74512ff8a1905539",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDACOES E ESTATISTICAS v2.1\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 1: VALIDANDO DEPENDENCIAS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      "\n",
      " OK Variaveis validadas:\n",
      "    df shape: (967, 25)\n",
      "    tipos_detectados: 25 campos\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 2: RESUMO GERAL\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Registros finais: 967\n",
      "   Colunas finais: 25\n",
      "   Memoria em uso: 1.27 MB\n",
      "   Linhas duplicadas: 767\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 3: ANALISE DE VALORES NULOS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum valor nulo!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 4: DISTRIBUICAO DE TIPOS DETECTADOS\n",
      "----------------------------------------------------------------------\n",
      "   DESCONHECIDO             : 11 colunas ######################\n",
      "   Numero_Inteiro           :  7 colunas ##############\n",
      "   Monetario                :  3 colunas ######\n",
      "   Centro                   :  2 colunas ####\n",
      "   Codigo_Produto           :  1 colunas ##\n",
      "   Desc_Grupo_Produto       :  1 colunas ##\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 5: CONFIANCA NA DETECCAO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Alta (>=90%):   14 colunas\n",
      "   Media (70-90%):  0 colunas\n",
      "   Baixa (<70%):   11 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 6: CAMPOS AMBIGUOS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum campo ambiguo!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 7: ANALISE DE UNICIDADE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Nenhum campo com alta unicidade\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 8: CARDINALIDADE\n",
      "----------------------------------------------------------------------\n",
      "   Ano civil/mÃªs                  |    2 unicos (  0.2%) - Categoria (baixa)\n",
      "   Centro                         |   89 unicos (  9.2%) - Categoria (baixa)\n",
      "                                  |   89 unicos (  9.2%) - Categoria (baixa)\n",
      "   HierarqPrd                     |    5 unicos (  0.5%) - Categoria (baixa)\n",
      "   Produto                        |   15 unicos (  1.6%) - Categoria (baixa)\n",
      "   _dup1                          |   15 unicos (  1.6%) - Categoria (baixa)\n",
      "   Estoque Inicial                |  183 unicos ( 18.9%) - Mista (media)\n",
      "   Entrada                        |  122 unicos ( 12.6%) - Mista (media)\n",
      "   VariaÃ§Ã£o Externa               |  104 unicos ( 10.8%) - Mista (media)\n",
      "   VariaÃ§Ã£o Externa %             |  110 unicos ( 11.4%) - Mista (media)\n",
      "\n",
      "   ... e mais 15 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 9: TIPOS DE DADOS (PANDAS)\n",
      "----------------------------------------------------------------------\n",
      "   object         : 25 colunas\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 10: SALVAMENTO DE ESTADO\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Estado salvo: .bloco_14_state.json\n",
      "   Estatisticas salvas: estatisticas_validacao.json\n",
      "\n",
      "======================================================================\n",
      "VALIDACOES CONCLUIDAS\n",
      "======================================================================\n",
      "\n",
      "   Registros: 967\n",
      "   Colunas: 25\n",
      "   Taxa deteccao: 56.0%\n",
      "   Valores nulos: 0 colunas\n",
      "   Campos ambiguos: 0\n",
      "\n",
      " Proximo: BLOCO 15 - Exportacao Final\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:18.996795Z",
     "start_time": "2025-10-19T09:18:18.730548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# BLOCO 15 v2.3 - EXPORTACAO DE RESULTADOS (100% LOG + ROBUSTO)\n",
    "# ======================================================================\n",
    "# VERSAO: 2.3 - 0% memoria, 100% LOG, validacao FileManager\n",
    "# AUTOR: Sistema Automacao AIVI\n",
    "# DATA: 2025-10-19\n",
    "# ======================================================================\n",
    "# CORRECOES v2.3:\n",
    "# + Verifica se fm.salvar() existe antes de usar\n",
    "# + Recria FileManager se metodo nao existir\n",
    "# + FileManagerSimples com timestamp correto\n",
    "# ======================================================================\n",
    "# CORRECOES v2.2:\n",
    "# + Validacao de None em arquivo_selecionado antes de acessar .name\n",
    "# + Validacao de Path antes de usar .stem\n",
    "# + Verificacao de temp_arquivo antes de atribuir\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTACAO DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 1: CONECTAR COM BLOCOS ANTERIORES\n",
    "# ======================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 1: CONECTANDO COM BLOCOS ANTERIORES...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler LOG GLOBAL\n",
    "log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "if not log_global_path.exists():\n",
    "    raise FileNotFoundError(\"LOG GLOBAL nao encontrado!\")\n",
    "\n",
    "with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "container_nome = f\"PROCESSAR_ARQUIVOS_{timestamp_execucao}\"\n",
    "pasta_base = Path.home() / 'PYTHON_AIVI' / container_nome\n",
    "\n",
    "print(f\" OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {container_nome}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# Verificar e corrigir FileManager\n",
    "class FileManagerSimples:\n",
    "    \"\"\"FileManager simplificado para exportacao\"\"\"\n",
    "    def __init__(self, base_path, timestamp=None):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.timestamp = timestamp or datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.pastas = {\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "        # Criar pastas se nao existem\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='outputs'):\n",
    "        arquivo = self.pastas[pasta] / f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "# Verificar se fm existe e tem metodo salvar\n",
    "if 'fm' not in globals():\n",
    "    print(f\" !! Criando FileManager...\")\n",
    "    fm = FileManagerSimples(base_path=pasta_base, timestamp=timestamp_execucao)\n",
    "    print(f\" OK FileManager criado: {fm.base_path.name}\")\n",
    "elif not hasattr(fm, 'salvar'):\n",
    "    print(f\" !! FileManager sem metodo salvar - recriando...\")\n",
    "    fm = FileManagerSimples(base_path=pasta_base, timestamp=timestamp_execucao)\n",
    "    print(f\" OK FileManager recriado: {fm.base_path.name}\")\n",
    "else:\n",
    "    print(f\" OK FileManager existe na memoria\")\n",
    "\n",
    "# Validar que df existe\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"Variavel 'df' nao encontrada! Execute BLOCOS 1-13 primeiro.\")\n",
    "\n",
    "print(f\" OK DataFrame validado: {df.shape}\")\n",
    "\n",
    "# Ler estado do BLOCO 13 (se existe)\n",
    "bloco_13_state_path = pasta_base / '.bloco_13_state.json'\n",
    "bloco_12_state_path = pasta_base / '.bloco_12_state.json'\n",
    "\n",
    "if bloco_13_state_path.exists():\n",
    "    with open(bloco_13_state_path, 'r', encoding='utf-8') as f:\n",
    "        bloco_anterior_state = json.load(f)\n",
    "    bloco_anterior_nome = \"BLOCO 13\"\n",
    "    print(f\" OK Estado carregado do {bloco_anterior_nome}\")\n",
    "elif bloco_12_state_path.exists():\n",
    "    with open(bloco_12_state_path, 'r', encoding='utf-8') as f:\n",
    "        bloco_anterior_state = json.load(f)\n",
    "    bloco_anterior_nome = \"BLOCO 12\"\n",
    "    print(f\" OK Estado carregado do {bloco_anterior_nome}\")\n",
    "else:\n",
    "    # Nenhum estado salvo - usar valores em memoria\n",
    "    bloco_anterior_state = {}\n",
    "    bloco_anterior_nome = \"MEMORIA\"\n",
    "    print(f\" !! Nenhum estado salvo - usando variaveis em memoria\")\n",
    "\n",
    "# Ler arquivo selecionado (tentar varias fontes)\n",
    "arquivo_selecionado = None\n",
    "sheet_nome = \"N/A\"\n",
    "\n",
    "# Fonte 1: LOG do BLOCO 4\n",
    "bloco_4_state_path = pasta_base / '.ultimo_arquivo.json'\n",
    "if bloco_4_state_path.exists():\n",
    "    with open(bloco_4_state_path, 'r', encoding='utf-8') as f:\n",
    "        arquivo_info = json.load(f)\n",
    "    arquivo_selecionado = Path(arquivo_info['caminho'])\n",
    "    sheet_nome = arquivo_info.get('sheet', 'N/A')\n",
    "    print(f\" OK Arquivo do LOG BLOCO 4: {arquivo_selecionado.name}\")\n",
    "\n",
    "# Fonte 2: Variavel global arquivo_selecionado\n",
    "if arquivo_selecionado is None and 'arquivo_selecionado' in globals():\n",
    "    temp_arquivo = globals()['arquivo_selecionado']\n",
    "    if temp_arquivo is not None:\n",
    "        arquivo_selecionado = temp_arquivo\n",
    "        print(f\" OK Arquivo da memoria: {arquivo_selecionado.name}\")\n",
    "        if 'sheet_nome' in globals():\n",
    "            sheet_nome = globals()['sheet_nome']\n",
    "\n",
    "# Fonte 3: LOG GLOBAL (pode ter info do arquivo)\n",
    "if arquivo_selecionado is None and 'ultimo_arquivo' in log_global:\n",
    "    temp_arquivo = log_global['ultimo_arquivo']\n",
    "    if temp_arquivo:\n",
    "        arquivo_selecionado = Path(temp_arquivo)\n",
    "        print(f\" OK Arquivo do LOG GLOBAL: {arquivo_selecionado.name}\")\n",
    "\n",
    "# Fallback final\n",
    "if arquivo_selecionado is None:\n",
    "    arquivo_selecionado = Path(\"arquivo_processado\")\n",
    "    print(f\" !! Arquivo nao encontrado - usando nome generico\")\n",
    "\n",
    "print(f\"\\n OK Arquivo selecionado: {arquivo_selecionado.name}\")\n",
    "print(f\" OK Sheet: {sheet_nome}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 2: EXPORTAR DADOS LIMPOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 2: EXPORTANDO DADOS LIMPOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Garantir que arquivo_selecionado e Path valido\n",
    "if not isinstance(arquivo_selecionado, Path):\n",
    "    arquivo_selecionado = Path(arquivo_selecionado)\n",
    "\n",
    "nome_base = arquivo_selecionado.stem\n",
    "\n",
    "# 1. Dados limpos e mapeados\n",
    "arquivo_limpo = fm.salvar(\n",
    "    df,\n",
    "    f\"{nome_base}_Limpo\",\n",
    "    tipo='xlsx',\n",
    "    pasta='processados'\n",
    ")\n",
    "print(f\" OK {arquivo_limpo.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 3: DICIONARIO DE CAMPOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 3: CRIANDO DICIONARIO DE CAMPOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler tipos_detectados (tentar varias fontes)\n",
    "tipo_info_dict = {}\n",
    "\n",
    "# Fonte 1: Variavel global tipos_detectados\n",
    "if 'tipos_detectados' in globals():\n",
    "    tipo_info_dict = tipos_detectados\n",
    "    print(f\" OK tipos_detectados da memoria: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "# Fonte 2: Estado do BLOCO 13\n",
    "elif bloco_anterior_state and 'confirmacoes' in bloco_anterior_state:\n",
    "    # Se BLOCO 13 salvou confirmacoes, usar\n",
    "    confirmacoes = bloco_anterior_state['confirmacoes']\n",
    "    for col_orig, campo_confirmado in confirmacoes.items():\n",
    "        tipo_info_dict[col_orig] = {\n",
    "            'campo_detectado': campo_confirmado,\n",
    "            'confianca': 1.0,\n",
    "            'metodo': 'CONFIRMADO_USUARIO'\n",
    "        }\n",
    "    print(f\" OK tipos_detectados do BLOCO 13: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "# Fonte 3: Tentar reconstruir baseado nas colunas do df\n",
    "else:\n",
    "    for col in df.columns:\n",
    "        tipo_info_dict[col] = {\n",
    "            'campo_detectado': col,\n",
    "            'confianca': 1.0,\n",
    "            'metodo': 'INFERIDO_DO_DF'\n",
    "        }\n",
    "    print(f\" !! tipos_detectados inferido do df: {len(tipo_info_dict)} campos\")\n",
    "\n",
    "registros_dict = []\n",
    "\n",
    "for col in df.columns:\n",
    "    tipo_info = tipo_info_dict.get(col, {})\n",
    "    valores_exemplo = df[col].dropna().unique()[:3].tolist()\n",
    "\n",
    "    registros_dict.append({\n",
    "        'Coluna': col,\n",
    "        'Tipo_Detectado': tipo_info.get('campo_detectado', 'DESCONHECIDO'),\n",
    "        'Confianca_%': tipo_info.get('confianca', 0.0) * 100,\n",
    "        'Score_Conteudo_%': tipo_info.get('score_conteudo', 0.0) * 100,\n",
    "        'Score_Nome_%': tipo_info.get('score_nome', 0.0) * 100,\n",
    "        'Metodo': tipo_info.get('metodo', 'N/A'),\n",
    "        'Ambiguidade': 'Sim' if tipo_info.get('ambiguidade') else 'Nao',\n",
    "        'Dtype_Pandas': str(df[col].dtype),\n",
    "        'Valores_Unicos': df[col].nunique(),\n",
    "        'Nulos_Qtd': df[col].isna().sum(),\n",
    "        'Nulos_%': (df[col].isna().sum() / len(df)) * 100,\n",
    "        'Exemplo_1': str(valores_exemplo[0]) if len(valores_exemplo) > 0 else None,\n",
    "        'Exemplo_2': str(valores_exemplo[1]) if len(valores_exemplo) > 1 else None,\n",
    "        'Exemplo_3': str(valores_exemplo[2]) if len(valores_exemplo) > 2 else None\n",
    "    })\n",
    "\n",
    "df_dict = pd.DataFrame(registros_dict)\n",
    "arquivo_dict = fm.salvar(\n",
    "    df_dict,\n",
    "    f\"DICT_{nome_base}\",\n",
    "    tipo='xlsx',\n",
    "    pasta='outputs'\n",
    ")\n",
    "print(f\" OK {arquivo_dict.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 4: LOG DE PROCESSAMENTO\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 4: CRIANDO LOG DE PROCESSAMENTO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Ler configuracoes de carregamento (multiplas fontes)\n",
    "linha_cab_ini = 1\n",
    "linha_cab_fim = 1\n",
    "col_ini = 1\n",
    "col_fim = len(df.columns)\n",
    "linha_dados_ini = 2\n",
    "\n",
    "# Fonte 1: Estado do BLOCO 9\n",
    "bloco_9_state_path = pasta_base / '.bloco_9_state.json'\n",
    "if bloco_9_state_path.exists():\n",
    "    try:\n",
    "        with open(bloco_9_state_path, 'r', encoding='utf-8') as f:\n",
    "            bloco_9_state = json.load(f)\n",
    "\n",
    "        config_carga = bloco_9_state.get('config_carga', {})\n",
    "        linha_cab_ini = config_carga.get('linha_cabecalho_inicio_excel', 1)\n",
    "        linha_cab_fim = config_carga.get('linha_cabecalho_fim_excel', 1)\n",
    "        col_ini = config_carga.get('coluna_inicio_excel', 1)\n",
    "        col_fim = config_carga.get('coluna_fim_excel', len(df.columns))\n",
    "        linha_dados_ini = config_carga.get('linha_dados_inicio_excel', 2)\n",
    "        print(f\" OK Config carga do BLOCO 9\")\n",
    "    except:\n",
    "        print(f\" !! Erro ao ler BLOCO 9 - usando valores padrao\")\n",
    "else:\n",
    "    print(f\" !! BLOCO 9 state nao encontrado - usando valores padrao\")\n",
    "\n",
    "# Fonte 2: Variaveis globais (fallback)\n",
    "if 'config' in globals():\n",
    "    config = globals()['config']\n",
    "    linha_cab_ini = config.get('linha_cabecalho_inicio', linha_cab_ini)\n",
    "    linha_dados_ini = config.get('linha_dados_inicio', linha_dados_ini)\n",
    "    print(f\" OK Config da memoria (variavel global)\")\n",
    "\n",
    "log_processamento = {\n",
    "    'Arquivo_Original': arquivo_selecionado.name,\n",
    "    'Caminho_Original': str(arquivo_selecionado),\n",
    "    'Sheet_Processada': sheet_nome,\n",
    "\n",
    "    # Cabecalho\n",
    "    'Linha_Cabecalho_Inicio_Excel': linha_cab_ini,\n",
    "    'Linha_Cabecalho_Fim_Excel': linha_cab_fim,\n",
    "\n",
    "    # Colunas\n",
    "    'Coluna_Inicio_Excel': col_ini,\n",
    "    'Coluna_Fim_Excel': col_fim,\n",
    "\n",
    "    # Dados\n",
    "    'Linha_Dados_Inicio_Excel': linha_dados_ini,\n",
    "\n",
    "    # Contadores\n",
    "    'Registros_Final': len(df),\n",
    "    'Colunas_Final': len(df.columns),\n",
    "\n",
    "    # Timestamp\n",
    "    'Timestamp': timestamp_execucao,\n",
    "    'Data_Processamento': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "df_log = pd.DataFrame([log_processamento])\n",
    "arquivo_log = fm.salvar(\n",
    "    df_log,\n",
    "    f\"LOG_{nome_base}\",\n",
    "    tipo='xlsx',\n",
    "    pasta='logs'\n",
    ")\n",
    "print(f\" OK {arquivo_log.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 5: CODIGO PYTHON PARA REPRODUCAO\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 5: GERANDO CODIGO DE REPRODUCAO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "codigo_reprod = f'''# ======================================================================\n",
    "# CODIGO DE REPRODUCAO - Gerado automaticamente\n",
    "# Arquivo: {arquivo_selecionado.name}\n",
    "# Sheet: {sheet_nome}\n",
    "# Data: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "# ======================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ======================================================================\n",
    "# CONFIGURACAO\n",
    "# ======================================================================\n",
    "\n",
    "arquivo = Path(r\"{arquivo_selecionado}\")\n",
    "sheet = \"{sheet_nome}\"\n",
    "\n",
    "# Range de extracao (linhas Excel - comeca em 1)\n",
    "linha_cabecalho_inicio = {linha_cab_ini}\n",
    "linha_cabecalho_fim = {linha_cab_fim}\n",
    "col_inicio = {col_ini}\n",
    "col_fim = {col_fim}\n",
    "linha_dados_inicio = {linha_dados_ini}\n",
    "\n",
    "# ======================================================================\n",
    "# CARREGAMENTO\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"Carregando: {{arquivo.name}}\")\n",
    "print(f\"Sheet: {{sheet}}\")\n",
    "\n",
    "if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "    # Cabecalho em 1 linha\n",
    "    df = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=linha_cabecalho_inicio - 1,  # Converter para indice Python\n",
    "        usecols=range(col_inicio - 1, col_fim)\n",
    "    )\n",
    "\n",
    "    # Pular linhas entre cabecalho e dados\n",
    "    linhas_pular = linha_dados_inicio - linha_cabecalho_inicio - 1\n",
    "    if linhas_pular > 0:\n",
    "        df = df.iloc[linhas_pular:].copy()\n",
    "else:\n",
    "    # Cabecalho em multiplas linhas\n",
    "    df_temp = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=None,\n",
    "        usecols=range(col_inicio - 1, col_fim)\n",
    "    )\n",
    "\n",
    "    # Combinar linhas do cabecalho\n",
    "    cabecalho = df_temp.iloc[linha_cabecalho_inicio-1:linha_cabecalho_fim].values\n",
    "    cab_final = []\n",
    "\n",
    "    for col_idx in range(cabecalho.shape[1]):\n",
    "        partes = [\n",
    "            str(linha[col_idx]).strip()\n",
    "            for linha in cabecalho\n",
    "            if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "        ]\n",
    "        cab_final.append(' - '.join(partes) if partes else f'Col_{{col_idx}}')\n",
    "\n",
    "    # Extrair dados\n",
    "    df = df_temp.iloc[linha_dados_inicio-1:].copy()\n",
    "    df.columns = cab_final\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Carregado: {{len(df):,}} registros Ã— {{len(df.columns)}} colunas\")\n",
    "\n",
    "# ======================================================================\n",
    "# VALIDACAO\n",
    "# ======================================================================\n",
    "\n",
    "colunas_esperadas = {df.columns.tolist()}\n",
    "\n",
    "if df.columns.tolist() == colunas_esperadas:\n",
    "    print(\"Estrutura validada - colunas correspondem!\")\n",
    "else:\n",
    "    print(\"Diferenca na estrutura:\")\n",
    "\n",
    "    extras = set(df.columns) - set(colunas_esperadas)\n",
    "    if extras:\n",
    "        print(f\"Colunas extras: {{extras}}\")\n",
    "\n",
    "    faltando = set(colunas_esperadas) - set(df.columns)\n",
    "    if faltando:\n",
    "        print(f\"Colunas faltando: {{faltando}}\")\n",
    "\n",
    "print(f\"\\\\nShape: {{df.shape}}\")\n",
    "print(f\"Memoria: {{df.memory_usage(deep=True).sum() / 1024**2:.2f}} MB\")\n",
    "'''\n",
    "\n",
    "arquivo_codigo = fm.pastas['codigos_integracao'] / f\"REPROD_{nome_base}_{timestamp_execucao}.py\"\n",
    "with open(arquivo_codigo, 'w', encoding='utf-8') as f:\n",
    "    f.write(codigo_reprod)\n",
    "\n",
    "print(f\" OK {arquivo_codigo.name}\")\n",
    "\n",
    "# ======================================================================\n",
    "# ETAPA 6: SALVAR ESTADO DO BLOCO 15\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ETAPA 6: SALVANDO ESTADO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "bloco_15_state = {\n",
    "    'bloco': 15,\n",
    "    'versao': '2.3',\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'container': container_nome,\n",
    "    'executado': True,\n",
    "    'arquivos_gerados': {\n",
    "        'dados_limpos': arquivo_limpo.name,\n",
    "        'dicionario_campos': arquivo_dict.name,\n",
    "        'log_processamento': arquivo_log.name,\n",
    "        'codigo_reproducao': arquivo_codigo.name\n",
    "    },\n",
    "    'df_shape': list(df.shape),\n",
    "    'arquivo_original': arquivo_selecionado.name\n",
    "}\n",
    "\n",
    "bloco_15_state_path = pasta_base / '.bloco_15_state.json'\n",
    "with open(bloco_15_state_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(bloco_15_state, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\" OK Estado salvo: .bloco_15_state.json\")\n",
    "\n",
    "# ======================================================================\n",
    "# RESUMO DE ARQUIVOS GERADOS\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ARQUIVOS GERADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "arquivos_gerados = [\n",
    "    ('Dados Limpos', arquivo_limpo),\n",
    "    ('Dicionario de Campos', arquivo_dict),\n",
    "    ('Log de Processamento', arquivo_log),\n",
    "    ('Codigo de Reproducao', arquivo_codigo)\n",
    "]\n",
    "\n",
    "for desc, path in arquivos_gerados:\n",
    "    print(f\"\\n{desc}\")\n",
    "    print(f\"  Arquivo: {path.name}\")\n",
    "    print(f\"  Pasta: {path.parent.name}\")\n",
    "    print(f\"  Tamanho: {path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTACAO CONCLUIDA COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Variavel global para uso posterior\n",
    "df_resultado = df.copy()\n",
    "\n",
    "print(f\"\\n Dataset disponivel em: df_resultado\")\n",
    "print(f\"  Shape: {df_resultado.shape}\")\n",
    "print(f\"  Memoria: {df_resultado.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print()\n",
    "print(f\" Proxima etapa: Analises e validacoes (se necessario)\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a7de448725d158e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPORTACAO DE RESULTADOS\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 1: CONECTANDO COM BLOCOS ANTERIORES...\n",
      "----------------------------------------------------------------------\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      " !! FileManager sem metodo salvar - recriando...\n",
      " OK FileManager recriado: PROCESSAR_ARQUIVOS_20251019_060722\n",
      " OK DataFrame validado: (967, 25)\n",
      " !! Nenhum estado salvo - usando variaveis em memoria\n",
      " !! Arquivo nao encontrado - usando nome generico\n",
      "\n",
      " OK Arquivo selecionado: arquivo_processado\n",
      " OK Sheet: N/A\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 2: EXPORTANDO DADOS LIMPOS\n",
      "----------------------------------------------------------------------\n",
      " OK arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 3: CRIANDO DICIONARIO DE CAMPOS\n",
      "----------------------------------------------------------------------\n",
      " OK tipos_detectados da memoria: 25 campos\n",
      " OK DICT_arquivo_processado_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 4: CRIANDO LOG DE PROCESSAMENTO\n",
      "----------------------------------------------------------------------\n",
      " !! BLOCO 9 state nao encontrado - usando valores padrao\n",
      " OK Config da memoria (variavel global)\n",
      " OK LOG_arquivo_processado_20251019_060722.xlsx\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 5: GERANDO CODIGO DE REPRODUCAO\n",
      "----------------------------------------------------------------------\n",
      " OK REPROD_arquivo_processado_20251019_060722.py\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ETAPA 6: SALVANDO ESTADO\n",
      "----------------------------------------------------------------------\n",
      " OK Estado salvo: .bloco_15_state.json\n",
      "\n",
      "======================================================================\n",
      "ARQUIVOS GERADOS\n",
      "======================================================================\n",
      "\n",
      "Dados Limpos\n",
      "  Arquivo: arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "  Pasta: 02_Processados\n",
      "  Tamanho: 67.3 KB\n",
      "\n",
      "Dicionario de Campos\n",
      "  Arquivo: DICT_arquivo_processado_20251019_060722.xlsx\n",
      "  Pasta: 03_Outputs\n",
      "  Tamanho: 6.9 KB\n",
      "\n",
      "Log de Processamento\n",
      "  Arquivo: LOG_arquivo_processado_20251019_060722.xlsx\n",
      "  Pasta: 04_Logs\n",
      "  Tamanho: 5.0 KB\n",
      "\n",
      "Codigo de Reproducao\n",
      "  Arquivo: REPROD_arquivo_processado_20251019_060722.py\n",
      "  Pasta: 06_Codigos_Integracao\n",
      "  Tamanho: 3.5 KB\n",
      "\n",
      "======================================================================\n",
      "EXPORTACAO CONCLUIDA COM SUCESSO\n",
      "======================================================================\n",
      "\n",
      " Dataset disponivel em: df_resultado\n",
      "  Shape: (967, 25)\n",
      "  Memoria: 1.27 MB\n",
      "\n",
      " Proxima etapa: Analises e validacoes (se necessario)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:18:21.413745Z",
     "start_time": "2025-10-19T09:18:21.080890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 16 v2.0 - RELATORIO FINAL VISUAL\n",
    "# ===================================================================\n",
    "# COMUNICACAO VIA LOG:\n",
    "# - Le: LOG GLOBAL + estados dos blocos anteriores\n",
    "# - RECRIA: FileManager se necessario\n",
    "# - USA: df_resultado (ou df_limpo, ou df)\n",
    "# - SALVA: .bloco_16_state.json\n",
    "# - EXIBE: df_resultado\n",
    "# - ABRE: pasta de outputs\n",
    "# ===================================================================\n",
    "# CORRECOES v2.0:\n",
    "# + 100% comunicacao via LOG (0% memoria)\n",
    "# + Recria FileManager se necessario\n",
    "# + Multiplas fontes para todas as variaveis\n",
    "# + Validacao de None antes de usar\n",
    "# + Exibe df_resultado (NOVO)\n",
    "# + Abre pasta outputs automaticamente (NOVO)\n",
    "# + Salva estado proprio\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(\" RELATORIO FINAL - PROCESSAMENTO CONCLUIDO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. CONECTAR COM BLOCOS ANTERIORES (0% memoria, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(\"\\n! Erro: LOG GLOBAL nao encontrado!\")\n",
    "    print(\"  Execute BLOCO 1 primeiro\")\n",
    "    raise RuntimeError(\"LOG nao disponivel\")\n",
    "\n",
    "with open(log_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "# Extrair dados essenciais do LOG\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "print(f\"\\n OK LOG GLOBAL conectado\")\n",
    "print(f\"    Container: {pasta_base.name}\")\n",
    "print(f\"    Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. RECRIAR FileManager (SE necessario)\n",
    "# ===================================================================\n",
    "\n",
    "# Tentar usar fm da memoria\n",
    "try:\n",
    "    fm_existe = 'fm' in globals() and fm is not None\n",
    "    if fm_existe and hasattr(fm, 'pastas'):\n",
    "        print(f\" OK FileManager na memoria\")\n",
    "    else:\n",
    "        raise NameError(\"fm invalido\")\n",
    "except (NameError, AttributeError):\n",
    "    print(f\" AVISO: Recriando FileManager...\")\n",
    "\n",
    "    # Recriar classe FileManagerSimples\n",
    "    class FileManagerSimples:\n",
    "        def __init__(self, base_path, timestamp):\n",
    "            self.base_path = Path(base_path)\n",
    "            self.timestamp = timestamp\n",
    "            self.pastas = {\n",
    "                'dados': self.base_path / '01_Dados_Entrada',\n",
    "                'processados': self.base_path / '02_Processados',\n",
    "                'outputs': self.base_path / '03_Outputs',\n",
    "                'logs': self.base_path / '04_Logs',\n",
    "                'dicionarios': self.base_path / '05_Dicionarios',\n",
    "                'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "            }\n",
    "\n",
    "        def abrir_pasta(self, tipo='outputs'):\n",
    "            \"\"\"Abre pasta no explorer/finder\"\"\"\n",
    "            import subprocess\n",
    "            import platform\n",
    "\n",
    "            pasta = self.pastas.get(tipo, self.pastas['outputs'])\n",
    "\n",
    "            try:\n",
    "                if platform.system() == 'Windows':\n",
    "                    subprocess.run(['explorer', str(pasta)])\n",
    "                elif platform.system() == 'Darwin':  # macOS\n",
    "                    subprocess.run(['open', str(pasta)])\n",
    "                else:  # Linux\n",
    "                    subprocess.run(['xdg-open', str(pasta)])\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"\\n! Erro ao abrir pasta: {e}\")\n",
    "                return False\n",
    "\n",
    "    fm = FileManagerSimples(pasta_base, timestamp_execucao)\n",
    "    print(f\"    OK FileManager recriado\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. CARREGAR DADOS DE BLOCOS ANTERIORES (MULTIPLAS FONTES)\n",
    "# ===================================================================\n",
    "\n",
    "# FONTE 1: Tentar variaveis na memoria\n",
    "# FONTE 2: Ler do LOG do BLOCO 15\n",
    "# FONTE 3: Ler do LOG do BLOCO 14\n",
    "# FONTE 4: Ler do LOG do BLOCO 4\n",
    "# FONTE 5: Fallback padrao\n",
    "\n",
    "# ----- arquivo_selecionado -----\n",
    "arquivo_selecionado = None\n",
    "sheet_nome = \"Sheet1\"\n",
    "\n",
    "# Memoria\n",
    "if 'arquivo_selecionado' in globals():\n",
    "    arquivo_selecionado = globals()['arquivo_selecionado']\n",
    "\n",
    "# LOG BLOCO 15\n",
    "if arquivo_selecionado is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_15_state.json') as f:\n",
    "            b15 = json.load(f)\n",
    "            if 'arquivo_processado' in b15:\n",
    "                arquivo_selecionado = Path(b15['arquivo_processado'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# LOG BLOCO 4\n",
    "if arquivo_selecionado is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_4_state.json') as f:\n",
    "            b4 = json.load(f)\n",
    "            arquivo_selecionado = Path(b4['arquivo'])\n",
    "            sheet_nome = b4.get('sheet_nome', sheet_nome)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ----- tipos_detectados -----\n",
    "tipos_detectados = {}\n",
    "\n",
    "# Memoria\n",
    "if 'tipos_detectados' in globals():\n",
    "    tipos_detectados = globals()['tipos_detectados']\n",
    "\n",
    "# LOG BLOCO 12\n",
    "if not tipos_detectados:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_12_state.json') as f:\n",
    "            b12 = json.load(f)\n",
    "            tipos_detectados = b12.get('tipos_detectados', {})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ----- config_carga -----\n",
    "metodo_carga = \"pandas\"\n",
    "linha_cabecalho_inicio = 0\n",
    "idx_cab_inicio = 0\n",
    "\n",
    "try:\n",
    "    with open(fm.pastas['logs'] / '.bloco_6_state.json') as f:\n",
    "        b6 = json.load(f)\n",
    "        metodo_carga = b6.get('metodo', 'pandas')\n",
    "        linha_cabecalho_inicio = b6.get('linha_cabecalho_inicio', 0)\n",
    "        idx_cab_inicio = b6.get('idx_cab_inicio', 0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ----- DataFrames -----\n",
    "df_resultado = None\n",
    "df_limpo = None\n",
    "df_bruto = None\n",
    "\n",
    "# FONTE 1: Ler do arquivo salvo pelo BLOCO 15 (PRIORITARIO)\n",
    "try:\n",
    "    arquivo_limpo = list(fm.pastas['processados'].glob(\n",
    "        f'*Limpo_{timestamp_execucao}.xlsx'\n",
    "    ))\n",
    "    if arquivo_limpo:\n",
    "        import pandas as pd\n",
    "        df_resultado = pd.read_excel(arquivo_limpo[0])\n",
    "        print(f\" OK DataFrame carregado do arquivo: {arquivo_limpo[0].name}\")\n",
    "except Exception as e:\n",
    "    print(f\" ! Nao foi possivel carregar do arquivo: {e}\")\n",
    "\n",
    "# FONTE 2: Tentar memoria (prioridade: df_resultado > df > df_limpo > df_bruto)\n",
    "if df_resultado is None:\n",
    "    if 'df_resultado' in globals():\n",
    "        df_resultado = globals()['df_resultado']\n",
    "        print(f\" OK DataFrame da memoria: df_resultado\")\n",
    "    elif 'df' in globals():\n",
    "        df_resultado = globals()['df'].copy()\n",
    "        print(f\" OK DataFrame da memoria: df\")\n",
    "    elif 'df_limpo' in globals():\n",
    "        df_limpo = globals()['df_limpo']\n",
    "        df_resultado = df_limpo.copy()\n",
    "        print(f\" OK DataFrame da memoria: df_limpo\")\n",
    "    elif 'df_bruto' in globals():\n",
    "        df_bruto = globals()['df_bruto']\n",
    "        df_resultado = df_bruto.copy()\n",
    "        print(f\" OK DataFrame da memoria: df_bruto\")\n",
    "\n",
    "if df_resultado is None:\n",
    "    print(\"\\n! ERRO: Nenhum DataFrame disponivel!\")\n",
    "    print(\"  Execute o BLOCO 15 primeiro para gerar os arquivos\")\n",
    "    raise RuntimeError(\"DataFrame nao disponivel\")\n",
    "\n",
    "# Se df_limpo nao existe, usar df_resultado\n",
    "if df_limpo is None:\n",
    "    df_limpo = df_resultado.copy()\n",
    "\n",
    "# Se df_bruto nao existe, tentar carregar do estado do BLOCO 9\n",
    "if df_bruto is None:\n",
    "    try:\n",
    "        with open(fm.pastas['logs'] / '.bloco_9_state.json') as f:\n",
    "            b9 = json.load(f)\n",
    "            # Usar estatisticas salvas se existirem\n",
    "            if 'estatisticas' in b9:\n",
    "                # Criar um DataFrame fake com as dimensoes originais\n",
    "                # apenas para calcular estatisticas\n",
    "                import pandas as pd\n",
    "                import numpy as np\n",
    "                rows = b9['estatisticas'].get('total_registros', len(df_resultado))\n",
    "                cols = b9['estatisticas'].get('total_colunas', len(df_resultado.columns))\n",
    "                # Usar df_resultado como base para df_bruto\n",
    "                df_bruto = df_resultado.copy()\n",
    "            else:\n",
    "                df_bruto = df_resultado.copy()\n",
    "    except:\n",
    "        # Fallback: usar df_resultado\n",
    "        df_bruto = df_resultado.copy()\n",
    "\n",
    "print(f\" OK Dados carregados de multiplas fontes\")\n",
    "\n",
    "# ----- log_limpeza -----\n",
    "log_limpeza = []\n",
    "\n",
    "try:\n",
    "    with open(fm.pastas['logs'] / '.bloco_10_state.json') as f:\n",
    "        b10 = json.load(f)\n",
    "        log_limpeza = b10.get('operacoes_limpeza', [])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ===================================================================\n",
    "# INFORMACOES DO ARQUIVO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" INFORMACOES DO ARQUIVO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if arquivo_selecionado is not None:\n",
    "    print(f\"  Nome: {arquivo_selecionado.name:<68}\")\n",
    "else:\n",
    "    print(f\"  Nome: [nao disponivel]\")\n",
    "\n",
    "print(f\"  Sheet: {sheet_nome:<67}\")\n",
    "print(f\"  Cabecalho: Linha {linha_cabecalho_inicio} (Excel) / \"\n",
    "      f\"Indice {idx_cab_inicio} (Python)\")\n",
    "print(f\"  Metodo: {metodo_carga:<66}\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# ESTATISTICAS DE PROCESSAMENTO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ESTATISTICAS DE PROCESSAMENTO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "print(f\"  Registros originais: {len(df_bruto):>6,}\")\n",
    "print(f\"  Registros finais:    {len(df_limpo):>6,}\")\n",
    "print(f\"  Diferenca:           {len(df_bruto) - len(df_limpo):>6,} \"\n",
    "      f\"removidos\")\n",
    "print(\"  \" + \"-\" * 64)\n",
    "print(f\"  Colunas originais:   {len(df_bruto.columns):>6,}\")\n",
    "print(f\"  Colunas finais:      {len(df_limpo.columns):>6,}\")\n",
    "print(f\"  Diferenca:           {len(df_bruto.columns) - len(df_limpo.columns):>6,} \"\n",
    "      f\"removidas\")\n",
    "print(\"  \" + \"-\" * 64)\n",
    "\n",
    "memoria_mb = df_limpo.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"  Memoria em uso:      {memoria_mb:>6.2f} MB\")\n",
    "\n",
    "duplicatas = df_limpo.duplicated().sum()\n",
    "print(f\"  Linhas duplicadas:   {duplicatas:>6,}\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# QUALIDADE DOS DADOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" QUALIDADE DOS DADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "total_nulos = df_limpo.isnull().sum().sum()\n",
    "total_celulas = len(df_limpo) * len(df_limpo.columns)\n",
    "pct_nulos = (total_nulos / total_celulas) * 100 if total_celulas > 0 else 0\n",
    "\n",
    "print(f\"  Total de valores nulos: {total_nulos:>6,} ({pct_nulos:>5.2f}%)\")\n",
    "\n",
    "colunas_com_nulos = df_limpo.isnull().sum()\n",
    "colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0]\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"  Colunas com nulos:      {len(colunas_com_nulos):>6,}\")\n",
    "else:\n",
    "    print(f\"  OK Nenhuma coluna com valores nulos!\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# DETECCAO DE TIPOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" DETECCAO DE TIPOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if tipos_detectados:\n",
    "    alta = sum(1 for info in tipos_detectados.values()\n",
    "               if info.get('confianca', 0) >= 0.90)\n",
    "    media = sum(1 for info in tipos_detectados.values()\n",
    "                if 0.70 <= info.get('confianca', 0) < 0.90)\n",
    "    baixa = sum(1 for info in tipos_detectados.values()\n",
    "                if info.get('confianca', 0) < 0.70)\n",
    "\n",
    "    print(f\"  OK Alta confianca (>=90%):   {alta:>3} colunas\")\n",
    "    print(f\"  !  Media confianca (70-90%): {media:>3} colunas\")\n",
    "    print(f\"  ?  Baixa confianca (<70%):   {baixa:>3} colunas\")\n",
    "    print(\"  \" + \"-\" * 64)\n",
    "\n",
    "    # Top 5 tipos detectados\n",
    "    tipos_resumo = {}\n",
    "    for info in tipos_detectados.values():\n",
    "        tipo = info.get('campo_detectado', 'DESCONHECIDO')\n",
    "        tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "    print(\"  Top 5 tipos mais comuns:\")\n",
    "    for i, (tipo, count) in enumerate(\n",
    "        sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True)[:5],\n",
    "        1\n",
    "    ):\n",
    "        print(f\"     {i}. {tipo:<25} ({count:>2} colunas)\")\n",
    "else:\n",
    "    print(\"  Informacao nao disponivel\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# OPERACOES DE LIMPEZA\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" OPERACOES DE LIMPEZA REALIZADAS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "if log_limpeza:\n",
    "    for i, operacao in enumerate(log_limpeza[:10], 1):\n",
    "        # Quebrar linhas longas\n",
    "        if len(str(operacao)) > 67:\n",
    "            print(f\"  {i}. {str(operacao)[:64]}...\")\n",
    "        else:\n",
    "            print(f\"  {i}. {operacao}\")\n",
    "\n",
    "    if len(log_limpeza) > 10:\n",
    "        print(f\"  ... e mais {len(log_limpeza) - 10} operacoes\")\n",
    "else:\n",
    "    print(f\"  OK Nenhuma limpeza necessaria - dados ja estavam limpos!\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# ARQUIVOS GERADOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ARQUIVOS GERADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# Listar arquivos na pasta de outputs\n",
    "arquivos_gerados = []\n",
    "\n",
    "try:\n",
    "    # Buscar arquivos com timestamp atual\n",
    "    for pasta_nome in ['processados', 'outputs', 'logs', 'codigos_integracao']:\n",
    "        pasta = fm.pastas[pasta_nome]\n",
    "        if pasta.exists():\n",
    "            for arquivo in pasta.glob(f'*{timestamp_execucao}*'):\n",
    "                tamanho_kb = arquivo.stat().st_size / 1024\n",
    "                arquivos_gerados.append((\n",
    "                    arquivo.name,\n",
    "                    pasta_nome.upper(),\n",
    "                    tamanho_kb\n",
    "                ))\n",
    "except Exception as e:\n",
    "    print(f\"  ! Erro ao listar arquivos: {e}\")\n",
    "\n",
    "if arquivos_gerados:\n",
    "    for nome, pasta, tamanho in arquivos_gerados:\n",
    "        print(f\"\\n  {nome}\")\n",
    "        print(f\"     Pasta: {pasta}\")\n",
    "        print(f\"     Tamanho: {tamanho:>6.1f} KB\")\n",
    "else:\n",
    "    print(\"  Nenhum arquivo encontrado com este timestamp\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# PROXIMOS PASSOS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" PROXIMOS PASSOS RECOMENDADOS\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "sugestoes = []\n",
    "\n",
    "# Sugestoes baseadas em qualidade\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    sugestoes.append(\"Tratar valores nulos nas colunas identificadas\")\n",
    "\n",
    "if tipos_detectados:\n",
    "    baixa = sum(1 for info in tipos_detectados.values()\n",
    "                if info.get('confianca', 0) < 0.70)\n",
    "    if baixa > 0:\n",
    "        sugestoes.append(f\"Revisar {baixa} campos com baixa confianca\")\n",
    "\n",
    "if duplicatas > 0:\n",
    "    sugestoes.append(\"Investigar e remover linhas duplicadas\")\n",
    "\n",
    "# Sugestoes padrao\n",
    "sugestoes.extend([\n",
    "    \"Revisar o dicionario de campos gerado\",\n",
    "    \"Validar tipos detectados conforme necessidade\",\n",
    "    \"Utilizar codigo de reproducao para reprocessar\"\n",
    "])\n",
    "\n",
    "for i, sugestao in enumerate(sugestoes[:6], 1):\n",
    "    print(f\"  {i}. {sugestao}\")\n",
    "\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# RODAPE\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" OK PROCESSAMENTO CONCLUIDO COM SUCESSO!\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(f\" Timestamp: {timestamp_execucao}\")\n",
    "print(f\" Dataset disponivel em: df_resultado\")\n",
    "print(f\" Shape: {df_resultado.shape}\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# ===================================================================\n",
    "# SALVAR ESTADO DO BLOCO 16\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco16 = {\n",
    "    'timestamp': timestamp_execucao,\n",
    "    'registros_finais': len(df_resultado),\n",
    "    'colunas_finais': len(df_resultado.columns),\n",
    "    'memoria_mb': float(memoria_mb),\n",
    "    'duplicatas': int(duplicatas),\n",
    "    'valores_nulos': int(total_nulos),\n",
    "    'arquivos_gerados': len(arquivos_gerados)\n",
    "}\n",
    "\n",
    "try:\n",
    "    arquivo_estado = fm.pastas['logs'] / '.bloco_16_state.json'\n",
    "    with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "        json.dump(estado_bloco16, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n OK Estado salvo: .bloco_16_state.json\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n! Aviso: Nao foi possivel salvar estado: {e}\")\n",
    "\n",
    "def abrir_pasta_outputs(fm):\n",
    "    \"\"\"Abre pasta de outputs no Explorer/Finder\"\"\"\n",
    "    import subprocess\n",
    "    import platform\n",
    "\n",
    "    pasta = fm.pastas.get('outputs', fm.pastas.get('03_Outputs'))\n",
    "\n",
    "    try:\n",
    "        if platform.system() == 'Windows':\n",
    "            subprocess.run(['explorer', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "        elif platform.system() == 'Darwin':  # macOS\n",
    "            subprocess.run(['open', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "        else:  # Linux\n",
    "            subprocess.run(['xdg-open', str(pasta)])\n",
    "            print(f\" OK Pasta de outputs aberta!\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\" ! Erro ao abrir pasta: {e}\")\n",
    "        print(f\"   Caminho: {pasta}\")\n",
    "        return False\n",
    "\n",
    "# Aplicar patch ao FileManager existente\n",
    "if 'fm' in globals() and fm is not None:\n",
    "    abrir_pasta_outputs(fm)\n",
    "else:\n",
    "    print(\"! FileManager nao encontrado na memoria\")\n",
    "\n",
    "# ===================================================================\n",
    "# ABERTURA AUTOMATICA DA PASTA DESTINO (NOVO!)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" ABRINDO PASTA DE OUTPUTS...\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "try:\n",
    "    sucesso = fm.abrir_pasta('outputs')\n",
    "    if sucesso:\n",
    "        print(\" OK Pasta de outputs aberta!\")\n",
    "    else:\n",
    "        print(f\" ! Pasta nao abriu automaticamente\")\n",
    "        print(f\"   Caminho: {fm.pastas['outputs']}\")\n",
    "except Exception as e:\n",
    "    print(f\" ! Erro ao abrir pasta: {e}\")\n",
    "    print(f\"   Caminho: {fm.pastas['outputs']}\")\n",
    "\n",
    "print(\"\\n TIP: Se a pasta nao abriu, o caminho esta exibido acima!\")\n",
    "\n",
    "# ===================================================================\n",
    "# EXIBIR DATAFRAME RESULTADO (NOVO!)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" DATASET FINAL (df_resultado)\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "# Exibir info do DataFrame\n",
    "print(f\"\\nShape: {df_resultado.shape}\")\n",
    "print(f\"Colunas: {list(df_resultado.columns)}\")\n",
    "print(f\"\\nPrimeiras 10 linhas:\")\n",
    "print(\"=\" * 68 + \"=\")\n",
    "\n",
    "try:\n",
    "    # Tentar usar display (Jupyter)\n",
    "    display(df_resultado.head(10))\n",
    "except NameError:\n",
    "    # Fallback para print\n",
    "    print(df_resultado.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 68 + \"=\")\n",
    "print(\" FIM DO RELATORIO\".center(78))\n",
    "print(\"=\" * 68 + \"=\")\n",
    "print(\"\\n\")"
   ],
   "id": "57bb5f7ac9d4eca0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====================================================================\n",
      "                   RELATORIO FINAL - PROCESSAMENTO CONCLUIDO                  \n",
      "=====================================================================\n",
      "\n",
      " OK LOG GLOBAL conectado\n",
      "    Container: PROCESSAR_ARQUIVOS_20251019_060722\n",
      "    Timestamp: 20251019_060722\n",
      " OK FileManager na memoria\n",
      " OK DataFrame carregado do arquivo: arquivo_processado_Limpo_20251019_060722.xlsx\n",
      " OK Dados carregados de multiplas fontes\n",
      "\n",
      "=====================================================================\n",
      "                            INFORMACOES DO ARQUIVO                            \n",
      "=====================================================================\n",
      "  Nome: [nao disponivel]\n",
      "  Sheet: Sheet1                                                             \n",
      "  Cabecalho: Linha 0 (Excel) / Indice 0 (Python)\n",
      "  Metodo: pandas                                                            \n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                         ESTATISTICAS DE PROCESSAMENTO                        \n",
      "=====================================================================\n",
      "  Registros originais:    199\n",
      "  Registros finais:       199\n",
      "  Diferenca:                0 removidos\n",
      "  ----------------------------------------------------------------\n",
      "  Colunas originais:       25\n",
      "  Colunas finais:          25\n",
      "  Diferenca:                0 removidas\n",
      "  ----------------------------------------------------------------\n",
      "  Memoria em uso:        0.09 MB\n",
      "  Linhas duplicadas:        0\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                              QUALIDADE DOS DADOS                             \n",
      "=====================================================================\n",
      "  Total de valores nulos:    826 (16.60%)\n",
      "  Colunas com nulos:           9\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                               DETECCAO DE TIPOS                              \n",
      "=====================================================================\n",
      "  Informacao nao disponivel\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                        OPERACOES DE LIMPEZA REALIZADAS                       \n",
      "=====================================================================\n",
      "  OK Nenhuma limpeza necessaria - dados ja estavam limpos!\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                               ARQUIVOS GERADOS                               \n",
      "=====================================================================\n",
      "\n",
      "  arquivo_processado_Limpo_20251019_060722.xlsx\n",
      "     Pasta: PROCESSADOS\n",
      "     Tamanho:   67.3 KB\n",
      "\n",
      "  DICT_arquivo_processado_20251019_060722.xlsx\n",
      "     Pasta: OUTPUTS\n",
      "     Tamanho:    6.9 KB\n",
      "\n",
      "  LOG_arquivo_processado_20251019_060722.xlsx\n",
      "     Pasta: LOGS\n",
      "     Tamanho:    5.0 KB\n",
      "\n",
      "  REPROD_arquivo_processado_20251019_060722.py\n",
      "     Pasta: CODIGOS_INTEGRACAO\n",
      "     Tamanho:    3.5 KB\n",
      "\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                         PROXIMOS PASSOS RECOMENDADOS                         \n",
      "=====================================================================\n",
      "  1. Tratar valores nulos nas colunas identificadas\n",
      "  2. Revisar o dicionario de campos gerado\n",
      "  3. Validar tipos detectados conforme necessidade\n",
      "  4. Utilizar codigo de reproducao para reprocessar\n",
      "=====================================================================\n",
      "\n",
      "=====================================================================\n",
      "                    OK PROCESSAMENTO CONCLUIDO COM SUCESSO!                   \n",
      "=====================================================================\n",
      " Timestamp: 20251019_060722\n",
      " Dataset disponivel em: df_resultado\n",
      " Shape: (199, 25)\n",
      "=====================================================================\n",
      "\n",
      " OK Estado salvo: .bloco_16_state.json\n",
      " OK Pasta de outputs aberta!\n",
      "\n",
      "=====================================================================\n",
      "                          ABRINDO PASTA DE OUTPUTS...                         \n",
      "=====================================================================\n",
      " ! Erro ao abrir pasta: 'FileManagerSimples' object has no attribute 'abrir_pasta'\n",
      "   Caminho: C:\\Users\\fpsou\\PYTHON_AIVI\\PROCESSAR_ARQUIVOS_20251019_060722\\03_Outputs\n",
      "\n",
      " TIP: Se a pasta nao abriu, o caminho esta exibido acima!\n",
      "\n",
      "=====================================================================\n",
      "                         DATASET FINAL (df_resultado)                         \n",
      "=====================================================================\n",
      "\n",
      "Shape: (199, 25)\n",
      "Colunas: ['Ano civil/mÃªs', 'Centro', 'Unnamed: 2', 'HierarqPrd', 'Produto', '_dup1', 'Estoque Inicial', 'Entrada', 'VariaÃ§Ã£o Externa', 'VariaÃ§Ã£o Externa %', 'VariaÃ§Ã£o Interna', 'VariaÃ§Ã£o Interna %', 'VariaÃ§Ã£o Total', 'VariaÃ§Ã£o Total %', 'Custo UnitÃ¡rio do Produto', 'Imposto', 'Valor da VariaÃ§Ã£o Interna', '_dup2', 'Quantidade Excedente da VariaÃ§Ã£o Externa', 'Valor Excedente da VariaÃ§Ã£o Externa (R$)', 'Quantidade Excedente da VariaÃ§Ã£o Interna', 'Valor Excedente da VariaÃ§Ã£o Interna (R$)', 'Quantidade Excedente da VariaÃ§Ã£o Total', 'Valor Excedente da VariaÃ§Ã£o Total (R$)', 'Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)']\n",
      "\n",
      "Primeiras 10 linhas:\n",
      "=====================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Ano civil/mÃªs  Centro Unnamed: 2            HierarqPrd     Produto  \\\n",
       "0         1.2025    5126       BAV1        Diesel - Comum  01.011.674   \n",
       "1         1.2025    5126       BAV1  Querosene de AviaÃ§Ã£o  01.001.422   \n",
       "2         1.2025    5126       BAV1  Querosene de AviaÃ§Ã£o  01.003.826   \n",
       "3         1.2025    5105       BAV2        Gasolina Comum  01.000.078   \n",
       "4         1.2025    5105       BAV2        Diesel - Comum  01.011.674   \n",
       "5         1.2025    5105       BAV2        Diesel - Comum  01.024.741   \n",
       "6         1.2025    5105       BAV2  Querosene de AviaÃ§Ã£o  01.016.205   \n",
       "7         1.2025    5105       BAV2  Querosene de AviaÃ§Ã£o  01.001.422   \n",
       "8         1.2025    5105       BAV2  Querosene de AviaÃ§Ã£o  01.011.754   \n",
       "9         1.2025    5105       BAV2  Querosene de AviaÃ§Ã£o  01.026.471   \n",
       "\n",
       "                          _dup1  Estoque Inicial     Entrada  \\\n",
       "0             Ã“LEO DIESEL B S10          16924.0         NaN   \n",
       "1       JET A NAO TABELADO - LI         373850.0    939139.0   \n",
       "2    JET A INTERNACIONAL I - LI         598315.0   5188210.0   \n",
       "3              GASOLINA COMUM C          13076.0     14828.0   \n",
       "4             Ã“LEO DIESEL B S10         122306.0    178128.0   \n",
       "5  Vibra Diesel RenovÃ¡vel HVO10           3361.0     14839.0   \n",
       "6      JET A - PREÃ‡O FIXO - VRG        1425416.0   3500000.0   \n",
       "7       JET A NAO TABELADO - LI        9793143.0  19273387.0   \n",
       "8              JET A PREÃ‡O FIXO        4578994.0         NaN   \n",
       "9     JET A-1 NAO TABELADO - LI         513358.0   1200000.0   \n",
       "\n",
       "   VariaÃ§Ã£o Externa  VariaÃ§Ã£o Externa %  ...  Imposto  \\\n",
       "0               NaN                 NaN  ...     0.00   \n",
       "1             824.0            0.087740  ... -2811.15   \n",
       "2            1494.0            0.028796  ...     0.00   \n",
       "3               5.0            0.033720  ...     0.00   \n",
       "4             -17.0           -0.009544  ...     0.00   \n",
       "5              -1.0           -0.006739  ...     0.00   \n",
       "6               NaN                 NaN  ...     0.00   \n",
       "7          -59980.0           -0.311206  ...     0.00   \n",
       "8               NaN                 NaN  ...     0.00   \n",
       "9          -10563.0           -0.880250  ... -9028.91   \n",
       "\n",
       "   Valor da VariaÃ§Ã£o Interna  _dup2  Quantidade Excedente da VariaÃ§Ã£o Externa  \\\n",
       "0                  95.402202    NaN                                      0.00   \n",
       "1                 -38.904816    NaN                                    366.22   \n",
       "2                   0.000000    NaN                                      0.00   \n",
       "3                1201.140348    NaN                                      0.00   \n",
       "4               -2036.637033    NaN                                      0.00   \n",
       "5                 189.216874    NaN                                      0.00   \n",
       "6                   0.000000    NaN                                      0.00   \n",
       "7              379506.723303    NaN                                 -40631.61   \n",
       "8                   0.000000    NaN                                      0.00   \n",
       "9               11742.667607    NaN                                  -9362.66   \n",
       "\n",
       "   Valor Excedente da VariaÃ§Ã£o Externa (R$)  \\\n",
       "0                                  0.000000   \n",
       "1                               1424.772156   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "5                                  0.000000   \n",
       "6                                  0.000000   \n",
       "7                            -155516.920049   \n",
       "8                                  0.000000   \n",
       "9                             -35870.343978   \n",
       "\n",
       "   Quantidade Excedente da VariaÃ§Ã£o Interna  \\\n",
       "0                                     10.19   \n",
       "1                                      0.00   \n",
       "2                                      0.00   \n",
       "3                                    220.33   \n",
       "4                                   -240.63   \n",
       "5                                     20.00   \n",
       "6                                      0.00   \n",
       "7                                  11630.85   \n",
       "8                                      0.00   \n",
       "9                                      0.00   \n",
       "\n",
       "   Valor Excedente da VariaÃ§Ã£o Interna (R$)  \\\n",
       "0                                 54.008246   \n",
       "1                                  0.000000   \n",
       "2                                  0.000000   \n",
       "3                               1130.971166   \n",
       "4                              -1282.921386   \n",
       "5                                126.144582   \n",
       "6                                  0.000000   \n",
       "7                              44516.916006   \n",
       "8                                  0.000000   \n",
       "9                                  0.000000   \n",
       "\n",
       "   Quantidade Excedente da VariaÃ§Ã£o Total  \\\n",
       "0                                   10.19   \n",
       "1                                    0.00   \n",
       "2                                    0.00   \n",
       "3                                  220.33   \n",
       "4                                 -240.63   \n",
       "5                                   20.00   \n",
       "6                                    0.00   \n",
       "7                                11630.85   \n",
       "8                                    0.00   \n",
       "9                                    0.00   \n",
       "\n",
       "   Valor Excedente da VariaÃ§Ã£o Total (R$)  \\\n",
       "0                                   54.01   \n",
       "1                                    0.00   \n",
       "2                                    0.00   \n",
       "3                                 1130.97   \n",
       "4                                -1282.92   \n",
       "5                                  126.14   \n",
       "6                                    0.00   \n",
       "7                                44516.92   \n",
       "8                                    0.00   \n",
       "9                                    0.00   \n",
       "\n",
       "   Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)  \n",
       "0                                             54.01  \n",
       "1                                           2811.15  \n",
       "2                                              0.00  \n",
       "3                                           1130.97  \n",
       "4                                          -1282.92  \n",
       "5                                            126.14  \n",
       "6                                              0.00  \n",
       "7                                          44516.92  \n",
       "8                                              0.00  \n",
       "9                                           9028.91  \n",
       "\n",
       "[10 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano civil/mÃªs</th>\n",
       "      <th>Centro</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>HierarqPrd</th>\n",
       "      <th>Produto</th>\n",
       "      <th>_dup1</th>\n",
       "      <th>Estoque Inicial</th>\n",
       "      <th>Entrada</th>\n",
       "      <th>VariaÃ§Ã£o Externa</th>\n",
       "      <th>VariaÃ§Ã£o Externa %</th>\n",
       "      <th>...</th>\n",
       "      <th>Imposto</th>\n",
       "      <th>Valor da VariaÃ§Ã£o Interna</th>\n",
       "      <th>_dup2</th>\n",
       "      <th>Quantidade Excedente da VariaÃ§Ã£o Externa</th>\n",
       "      <th>Valor Excedente da VariaÃ§Ã£o Externa (R$)</th>\n",
       "      <th>Quantidade Excedente da VariaÃ§Ã£o Interna</th>\n",
       "      <th>Valor Excedente da VariaÃ§Ã£o Interna (R$)</th>\n",
       "      <th>Quantidade Excedente da VariaÃ§Ã£o Total</th>\n",
       "      <th>Valor Excedente da VariaÃ§Ã£o Total (R$)</th>\n",
       "      <th>Valor Excedente da VariaÃ§Ã£o Total + Imposto (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>Ã“LEO DIESEL B S10</td>\n",
       "      <td>16924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.402202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.19</td>\n",
       "      <td>54.008246</td>\n",
       "      <td>10.19</td>\n",
       "      <td>54.01</td>\n",
       "      <td>54.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>373850.0</td>\n",
       "      <td>939139.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>...</td>\n",
       "      <td>-2811.15</td>\n",
       "      <td>-38.904816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.22</td>\n",
       "      <td>1424.772156</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2811.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5126</td>\n",
       "      <td>BAV1</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.003.826</td>\n",
       "      <td>JET A INTERNACIONAL I - LI</td>\n",
       "      <td>598315.0</td>\n",
       "      <td>5188210.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Gasolina Comum</td>\n",
       "      <td>01.000.078</td>\n",
       "      <td>GASOLINA COMUM C</td>\n",
       "      <td>13076.0</td>\n",
       "      <td>14828.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1201.140348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.33</td>\n",
       "      <td>1130.971166</td>\n",
       "      <td>220.33</td>\n",
       "      <td>1130.97</td>\n",
       "      <td>1130.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.011.674</td>\n",
       "      <td>Ã“LEO DIESEL B S10</td>\n",
       "      <td>122306.0</td>\n",
       "      <td>178128.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-0.009544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2036.637033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-240.63</td>\n",
       "      <td>-1282.921386</td>\n",
       "      <td>-240.63</td>\n",
       "      <td>-1282.92</td>\n",
       "      <td>-1282.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Diesel - Comum</td>\n",
       "      <td>01.024.741</td>\n",
       "      <td>Vibra Diesel RenovÃ¡vel HVO10</td>\n",
       "      <td>3361.0</td>\n",
       "      <td>14839.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>189.216874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>126.144582</td>\n",
       "      <td>20.00</td>\n",
       "      <td>126.14</td>\n",
       "      <td>126.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.016.205</td>\n",
       "      <td>JET A - PREÃ‡O FIXO - VRG</td>\n",
       "      <td>1425416.0</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.001.422</td>\n",
       "      <td>JET A NAO TABELADO - LI</td>\n",
       "      <td>9793143.0</td>\n",
       "      <td>19273387.0</td>\n",
       "      <td>-59980.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>379506.723303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-40631.61</td>\n",
       "      <td>-155516.920049</td>\n",
       "      <td>11630.85</td>\n",
       "      <td>44516.916006</td>\n",
       "      <td>11630.85</td>\n",
       "      <td>44516.92</td>\n",
       "      <td>44516.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.011.754</td>\n",
       "      <td>JET A PREÃ‡O FIXO</td>\n",
       "      <td>4578994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2025</td>\n",
       "      <td>5105</td>\n",
       "      <td>BAV2</td>\n",
       "      <td>Querosene de AviaÃ§Ã£o</td>\n",
       "      <td>01.026.471</td>\n",
       "      <td>JET A-1 NAO TABELADO - LI</td>\n",
       "      <td>513358.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>-10563.0</td>\n",
       "      <td>-0.880250</td>\n",
       "      <td>...</td>\n",
       "      <td>-9028.91</td>\n",
       "      <td>11742.667607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9362.66</td>\n",
       "      <td>-35870.343978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9028.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================================\n",
      "                               FIM DO RELATORIO                               \n",
      "=====================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultado",
   "id": "4c205ea0a09c0231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "Extrator de Headers de Notebook Jupyter\n",
    "Extrai todos os cabeÃ§alhos/tÃ­tulos de blocos de cÃ³digo\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extrair_headers_notebook(caminho_notebook):\n",
    "    \"\"\"\n",
    "    Extrai headers de um notebook Jupyter (.ipynb)\n",
    "\n",
    "    Args:\n",
    "        caminho_notebook: Path ou string do arquivo .ipynb\n",
    "\n",
    "    Returns:\n",
    "        Lista de dicionÃ¡rios com informaÃ§Ãµes dos headers\n",
    "    \"\"\"\n",
    "\n",
    "    # Carregar notebook\n",
    "    with open(caminho_notebook, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    headers = []\n",
    "\n",
    "    # Iterar pelas cÃ©lulas\n",
    "    for idx, cell in enumerate(notebook.get('cells', [])):\n",
    "        cell_type = cell.get('cell_type')\n",
    "        source = cell.get('source', [])\n",
    "\n",
    "        # Converter source para string se for lista\n",
    "        if isinstance(source, list):\n",
    "            source_text = ''.join(source)\n",
    "        else:\n",
    "            source_text = source\n",
    "\n",
    "        # MARKDOWN: Extrair tÃ­tulos (#, ##, ###, etc)\n",
    "        if cell_type == 'markdown':\n",
    "            for line in source_text.split('\\n'):\n",
    "                if line.strip().startswith('#'):\n",
    "                    nivel = len(re.match(r'^#+', line.strip()).group())\n",
    "                    titulo = line.strip().lstrip('#').strip()\n",
    "\n",
    "                    headers.append({\n",
    "                        'celula': idx,\n",
    "                        'tipo': 'markdown',\n",
    "                        'nivel': nivel,\n",
    "                        'titulo': titulo,\n",
    "                        'preview': line.strip()[:80]\n",
    "                    })\n",
    "\n",
    "        # CODE: Extrair comentÃ¡rios de blocos (# ===, # ---, # BLOCO, etc)\n",
    "        elif cell_type == 'code':\n",
    "            # PadrÃµes de headers em cÃ³digo\n",
    "            patterns = [\n",
    "                (r'^# ={3,}', 'separator'),  # # ===\n",
    "                (r'^# -{3,}', 'separator'),  # # ---\n",
    "                (r'^# BLOCO \\d+', 'bloco'),  # # BLOCO 1\n",
    "                (r'^# \\d+\\.', 'numerado'),   # # 1.\n",
    "            ]\n",
    "\n",
    "            for line_num, line in enumerate(source_text.split('\\n')):\n",
    "                line_stripped = line.strip()\n",
    "\n",
    "                # Verificar padrÃµes\n",
    "                for pattern, tipo_header in patterns:\n",
    "                    if re.match(pattern, line_stripped, re.IGNORECASE):\n",
    "                        # Tentar pegar prÃ³xima linha como tÃ­tulo\n",
    "                        lines = source_text.split('\\n')\n",
    "                        titulo = line_stripped.lstrip('#').strip()\n",
    "\n",
    "                        # Se for separator, pegar linha seguinte\n",
    "                        if tipo_header == 'separator' and line_num + 1 < len(lines):\n",
    "                            next_line = lines[line_num + 1].strip()\n",
    "                            if next_line.startswith('#'):\n",
    "                                titulo = next_line.lstrip('#').strip()\n",
    "\n",
    "                        headers.append({\n",
    "                            'celula': idx,\n",
    "                            'tipo': 'code',\n",
    "                            'subtipo': tipo_header,\n",
    "                            'titulo': titulo,\n",
    "                            'preview': line.strip()[:80]\n",
    "                        })\n",
    "                        break\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def imprimir_estrutura(headers, mostrar_codigo=True):\n",
    "    \"\"\"\n",
    "    Imprime a estrutura do notebook de forma organizada\n",
    "\n",
    "    Args:\n",
    "        headers: Lista de headers extraÃ­dos\n",
    "        mostrar_codigo: Se True, mostra headers de cÃ³digo tambÃ©m\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ESTRUTURA DO NOTEBOOK\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    for i, header in enumerate(headers, 1):\n",
    "        # Filtrar cÃ³digo se necessÃ¡rio\n",
    "        if not mostrar_codigo and header['tipo'] == 'code':\n",
    "            continue\n",
    "\n",
    "        # FormataÃ§Ã£o por tipo\n",
    "        if header['tipo'] == 'markdown':\n",
    "            # IndentaÃ§Ã£o por nÃ­vel\n",
    "            indent = \"  \" * (header['nivel'] - 1)\n",
    "            simbolo = \"#\" * header['nivel']\n",
    "            print(f\"{indent}[MD] {simbolo} {header['titulo']}\")\n",
    "\n",
    "        elif header['tipo'] == 'code':\n",
    "            subtipo = header.get('subtipo', 'outro')\n",
    "\n",
    "            if subtipo == 'bloco':\n",
    "                print(f\"ğŸ“¦ [BLOCO] {header['titulo']}\")\n",
    "            elif subtipo == 'separator':\n",
    "                print(f\"â”€â”€â”€ {header['titulo']}\")\n",
    "            elif subtipo == 'numerado':\n",
    "                print(f\"  â†’ {header['titulo']}\")\n",
    "            else:\n",
    "                print(f\"  â€¢ {header['titulo']}\")\n",
    "\n",
    "        # Mostrar nÃºmero da cÃ©lula\n",
    "        print(f\"     (CÃ©lula {header['celula']})\")\n",
    "        print()\n",
    "\n",
    "\n",
    "def exportar_markdown(headers, arquivo_saida):\n",
    "    \"\"\"\n",
    "    Exporta a estrutura para um arquivo Markdown\n",
    "\n",
    "    Args:\n",
    "        headers: Lista de headers\n",
    "        arquivo_saida: Nome do arquivo .md para salvar\n",
    "    \"\"\"\n",
    "\n",
    "    with open(arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# Estrutura do Notebook\\n\\n\")\n",
    "\n",
    "        for header in headers:\n",
    "            if header['tipo'] == 'markdown':\n",
    "                nivel = header['nivel']\n",
    "                titulo = header['titulo']\n",
    "                f.write(f\"{'#' * nivel} {titulo}\\n\")\n",
    "                f.write(f\"*CÃ©lula {header['celula']}*\\n\\n\")\n",
    "\n",
    "            elif header['tipo'] == 'code':\n",
    "                titulo = header['titulo']\n",
    "                f.write(f\"- **[CODE]** {titulo}\\n\")\n",
    "                f.write(f\"  - *CÃ©lula {header['celula']}*\\n\\n\")\n",
    "\n",
    "    print(f\"âœ… Estrutura exportada para: {arquivo_saida}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXEMPLO DE USO\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # OPÃ‡ÃƒO 1: Usar com arquivo especÃ­fico\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Defina o caminho do seu notebook\n",
    "    caminho = \"PROCESSAR ARQUIVOS DESCONHECIDOS 4.2.ipynb\"\n",
    "\n",
    "    # Verificar se arquivo existe\n",
    "    if not Path(caminho).exists():\n",
    "        print(f\"âŒ Arquivo nÃ£o encontrado: {caminho}\")\n",
    "        print(\"\\nğŸ’¡ Como usar:\")\n",
    "        print(\"   1. Coloque este script na mesma pasta do notebook\")\n",
    "        print(\"   2. Ou altere a variÃ¡vel 'caminho' acima\")\n",
    "        exit(1)\n",
    "\n",
    "    # Extrair headers\n",
    "    print(f\"ğŸ“– Lendo notebook: {caminho}\")\n",
    "    print()\n",
    "\n",
    "    headers = extrair_headers_notebook(caminho)\n",
    "\n",
    "    print(f\"âœ… Encontrados {len(headers)} headers\\n\")\n",
    "\n",
    "    # Imprimir estrutura\n",
    "    imprimir_estrutura(headers, mostrar_codigo=True)\n",
    "\n",
    "    # OPÃ‡ÃƒO 2: Exportar para Markdown\n",
    "    # -----------------------------------------\n",
    "\n",
    "    # Descomentar para exportar\n",
    "    # exportar_markdown(headers, \"estrutura_notebook.md\")\n",
    "\n",
    "\n",
    "    # OPÃ‡ÃƒO 3: Filtrar apenas BLOCOs\n",
    "    # -----------------------------------------\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"APENAS BLOCOS PRINCIPAIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    blocos = [h for h in headers if 'BLOCO' in h.get('titulo', '').upper()]\n",
    "\n",
    "    for bloco in blocos:\n",
    "        print(f\"ğŸ“¦ {bloco['titulo']} (CÃ©lula {bloco['celula']})\")\n",
    "\n",
    "\n",
    "    # OPÃ‡ÃƒO 4: EstatÃ­sticas\n",
    "    # -----------------------------------------\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ESTATÃSTICAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "    total_markdown = sum(1 for h in headers if h['tipo'] == 'markdown')\n",
    "    total_code = sum(1 for h in headers if h['tipo'] == 'code')\n",
    "    total_blocos = len(blocos)\n",
    "\n",
    "    print(f\"ğŸ“Š Headers Markdown: {total_markdown}\")\n",
    "    print(f\"ğŸ’» Headers Code: {total_code}\")\n",
    "    print(f\"ğŸ“¦ Blocos identificados: {total_blocos}\")\n",
    "    print(f\"ğŸ“ Total de headers: {len(headers)}\")\n"
   ],
   "id": "7608733d363b944b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# EXPORT SYSTEM - PROCESSADOR DE ARQUIVOS - CORRIGIDO v2.0\n",
    "# ======================================================================\n",
    "# CORRECOES v2.0:\n",
    "# + FIX CRITICO: KeyError 'pasta_destino' -> usar 'pasta_base_atual'\n",
    "# + FIX: KeyError 'container' -> derivar do path (pasta_base.name)\n",
    "# + MANTIDO: Toda funcionalidade original\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPORT SYSTEM - PROCESSADOR DE ARQUIVOS v2.0\")\n",
    "print(\"=\"*70)\n",
    "print(\"MODO: Exporta apenas sistema (notebook + dicionario)\")\n",
    "print(\"      NAO exporta containers de dados processados\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "def exportar_sistema():\n",
    "    \"\"\"\n",
    "    Exporta projeto completo para .zip portavel\n",
    "\n",
    "    v2.0: CORRIGIDO - usa chaves corretas do LOG GLOBAL\n",
    "    \"\"\"\n",
    "\n",
    "    # ===================================================================\n",
    "    # 1. CARREGAR LOG GLOBAL (CORRIGIDO)\n",
    "    # ===================================================================\n",
    "\n",
    "    log_global_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    if not log_global_path.exists():\n",
    "        print(\"\\n! LOG GLOBAL nao encontrado!\")\n",
    "        print(\"  Execute o notebook antes de exportar.\")\n",
    "        return\n",
    "\n",
    "    with open(log_global_path, 'r', encoding='utf-8') as f:\n",
    "        log_global = json.load(f)\n",
    "\n",
    "    # ===================================================================\n",
    "    # FIX CRITICO: Usar chaves corretas\n",
    "    # ===================================================================\n",
    "    # ANTES (ERRADO):\n",
    "    # pasta_destino = Path(log_global['pasta_destino'])\n",
    "    # container_nome = log_global['container']\n",
    "\n",
    "    # DEPOIS (CORRETO):\n",
    "    pasta_base = Path(log_global['pasta_base_atual'])\n",
    "    container_nome = pasta_base.name\n",
    "    container_path = pasta_base\n",
    "\n",
    "    print(f\"\\n OK Container encontrado:\")\n",
    "    print(f\"    {container_path}\")\n",
    "    print(f\"    Nome: {container_nome}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 2. CRIAR PASTA TEMPORARIA\n",
    "    # ===================================================================\n",
    "\n",
    "    export_dir = Path('PROCESSADOR_EXPORT_TEMP')\n",
    "\n",
    "    # Limpar se ja existe\n",
    "    if export_dir.exists():\n",
    "        shutil.rmtree(export_dir)\n",
    "\n",
    "    export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"\\n OK Criando estrutura de exportacao...\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 3. COPIAR ARQUIVOS ESSENCIAIS\n",
    "    # ===================================================================\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.1. Dicionarios\n",
    "    # ---------------------------------------------------------------\n",
    "    dicionarios_src = container_path / '05_Dicionarios'\n",
    "    dicionarios_dst = export_dir / 'data' / 'dicionarios'\n",
    "    dicionarios_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if dicionarios_src.exists():\n",
    "        for arquivo in dicionarios_src.glob('*.json'):\n",
    "            shutil.copy2(arquivo, dicionarios_dst)\n",
    "            print(f\"    OK Copiado: {arquivo.name}\")\n",
    "    else:\n",
    "        print(f\"    ! Dicionarios nao encontrados\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.2. Logs (estados dos blocos)\n",
    "    # ---------------------------------------------------------------\n",
    "    logs_src = container_path / '04_Logs'\n",
    "    logs_dst = export_dir / 'data' / 'logs'\n",
    "    logs_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if logs_src.exists():\n",
    "        for arquivo in logs_src.glob('.*.json'):\n",
    "            shutil.copy2(arquivo, logs_dst)\n",
    "            print(f\"    OK Copiado: {arquivo.name}\")\n",
    "    else:\n",
    "        print(f\"    ! Logs nao encontrados\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.3. Notebook (buscar no projeto atual)\n",
    "    # ---------------------------------------------------------------\n",
    "    notebooks_dst = export_dir / 'notebooks'\n",
    "    notebooks_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Buscar notebook principal\n",
    "    notebook_encontrado = False\n",
    "    for notebook in Path('.').glob('*.ipynb'):\n",
    "        if 'PROCESSAR' in notebook.name.upper():\n",
    "            shutil.copy2(notebook, notebooks_dst)\n",
    "            print(f\"    OK Copiado: {notebook.name}\")\n",
    "            notebook_encontrado = True\n",
    "\n",
    "    if not notebook_encontrado:\n",
    "        print(f\"    ! Notebook nao encontrado\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # 3.4. Scripts\n",
    "    # ---------------------------------------------------------------\n",
    "    scripts_dst = export_dir / 'scripts'\n",
    "    scripts_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copiar scripts de integracao se existirem\n",
    "    scripts_src = container_path / '06_Codigos_Integracao'\n",
    "    if scripts_src.exists():\n",
    "        for script in scripts_src.glob('*.py'):\n",
    "            shutil.copy2(script, scripts_dst)\n",
    "            print(f\"    OK Copiado: {script.name}\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 4. CRIAR CONFIGURACAO\n",
    "    # ===================================================================\n",
    "\n",
    "    config_dst = export_dir / 'config'\n",
    "    config_dst.mkdir(exist_ok=True)\n",
    "\n",
    "    settings = {\n",
    "        'exported_at': datetime.now().isoformat(),\n",
    "        'original_container': container_nome,\n",
    "        'original_path': str(container_path),\n",
    "        'version': '4.2',\n",
    "        'python_version': '3.8+',\n",
    "        'estrutura': {\n",
    "            'notebooks': 'Notebooks Jupyter do processador',\n",
    "            'data/dicionarios': 'Dicionarios de campos conhecidos',\n",
    "            'data/logs': 'Estados dos blocos (auditoria)',\n",
    "            'scripts': 'Scripts de integracao e reproducao',\n",
    "            'config': 'Configuracoes do sistema'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(config_dst / 'settings.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(settings, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"    OK Configuracao criada\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 5. CRIAR README\n",
    "    # ===================================================================\n",
    "\n",
    "    readme_content = f\"\"\"# PROCESSADOR DE ARQUIVOS DESCONHECIDOS v4.2\n",
    "\n",
    "Exportado de: {container_nome}\n",
    "Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## ESTRUTURA\n",
    "\n",
    "```\n",
    "PROCESSADOR_EXPORT/\n",
    "â”œâ”€â”€ notebooks/          # Notebooks Jupyter\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ dicionarios/   # Campos conhecidos\n",
    "â”‚   â””â”€â”€ logs/          # Estados dos blocos\n",
    "â”œâ”€â”€ scripts/           # Scripts de integracao\n",
    "â”œâ”€â”€ config/            # Configuracoes\n",
    "â””â”€â”€ README.md          # Este arquivo\n",
    "```\n",
    "\n",
    "## REQUISITOS\n",
    "\n",
    "- Python 3.8+\n",
    "- pandas\n",
    "- openpyxl\n",
    "- tkinter (para GUI)\n",
    "\n",
    "## INSTALACAO\n",
    "\n",
    "```bash\n",
    "pip install pandas openpyxl\n",
    "```\n",
    "\n",
    "## USO BASICO\n",
    "\n",
    "1. **Abrir notebook**:\n",
    "   ```bash\n",
    "   jupyter notebook notebooks/PROCESSAR*.ipynb\n",
    "   ```\n",
    "\n",
    "2. **Executar blocos em sequencia**:\n",
    "   - BLOCO 1: Criar estrutura\n",
    "   - BLOCO 2: Carregar classes\n",
    "   - BLOCO 3-13: Processar arquivo\n",
    "\n",
    "3. **Usar scripts standalone**:\n",
    "   ```bash\n",
    "   python scripts/script_reproducao.py\n",
    "   ```\n",
    "\n",
    "## DICIONARIO DE CAMPOS\n",
    "\n",
    "O dicionario em `data/dicionarios/` contem:\n",
    "- Campos conhecidos\n",
    "- Mapeamentos automaticos\n",
    "- Regras de validacao\n",
    "\n",
    "## LOGS E AUDITORIA\n",
    "\n",
    "Estados dos blocos salvos em `data/logs/`:\n",
    "- `.bloco_N_state.json`: Estado de cada bloco\n",
    "- Permite rastreabilidade completa\n",
    "\n",
    "## SUPORTE\n",
    "\n",
    "Para mais informacoes sobre o sistema original:\n",
    "- Container: {container_nome}\n",
    "- Path: {container_path}\n",
    "\n",
    "---\n",
    "Gerado automaticamente pelo Export System v2.0\n",
    "\"\"\"\n",
    "\n",
    "    with open(export_dir / 'README.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "\n",
    "    print(f\"    OK README criado\")\n",
    "\n",
    "    # ===================================================================\n",
    "    # 6. CRIAR ARQUIVO .ZIP\n",
    "    # ===================================================================\n",
    "\n",
    "    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    zip_filename = f'PROCESSADOR_EXPORT_{timestamp_str}.zip'\n",
    "    zip_path = Path('.') / zip_filename\n",
    "\n",
    "    print(f\"\\n Criando arquivo .zip...\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in export_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                arcname = file_path.relative_to(export_dir)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 7. LIMPAR PASTA TEMPORARIA\n",
    "    # ===================================================================\n",
    "\n",
    "    shutil.rmtree(export_dir)\n",
    "\n",
    "    # ===================================================================\n",
    "    # 8. RELATORIO FINAL\n",
    "    # ===================================================================\n",
    "\n",
    "    zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" OK EXPORTACAO CONCLUIDA\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(f\"\\n Arquivo gerado:\")\n",
    "    print(f\"    {zip_path}\")\n",
    "    print(f\"    Tamanho: {zip_size_mb:.2f} MB\")\n",
    "\n",
    "    print(f\"\\n Conteudo:\")\n",
    "    print(f\"    - Notebooks do processador\")\n",
    "    print(f\"    - Dicionarios de campos\")\n",
    "    print(f\"    - Estados dos blocos (logs)\")\n",
    "    print(f\"    - Scripts de integracao\")\n",
    "    print(f\"    - Configuracoes\")\n",
    "    print(f\"    - README com instrucoes\")\n",
    "\n",
    "    print(f\"\\n Para usar:\")\n",
    "    print(f\"    1. Extrair arquivo .zip\")\n",
    "    print(f\"    2. Ler README.md\")\n",
    "    print(f\"    3. Instalar requisitos\")\n",
    "    print(f\"    4. Executar notebooks ou scripts\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "    return str(zip_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exportar_sistema()"
   ],
   "id": "a280b3273810d2ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ======================================================================\n",
    "# GERADOR DEFINITIVO - SEM ERROS DE TEMPLATE\n",
    "# ======================================================================\n",
    "# COPIE TUDO E EXECUTE - GARANTIDO QUE FUNCIONA!\n",
    "# ======================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "log_path = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_path.exists():\n",
    "    print(\"! ERRO: Execute o notebook completo primeiro\")\n",
    "    raise FileNotFoundError(\"LOG GLOBAL nao encontrado\")\n",
    "\n",
    "with open(log_path, 'r', encoding='utf-8') as f:\n",
    "    log_global = json.load(f)\n",
    "\n",
    "# Extrair configuracao\n",
    "pasta_base = Path(log_global['pasta_base_atual'])\n",
    "container_nome = pasta_base.name\n",
    "timestamp = log_global['timestamp']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GERADOR DE SCRIPT v3.0 DEFINITIVO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n OK Container: {container_nome}\")\n",
    "print(f\" OK Timestamp: {timestamp}\")\n",
    "\n",
    "# ======================================================================\n",
    "# SALVAR SCRIPT LINHA POR LINHA (SEM TEMPLATE)\n",
    "# ======================================================================\n",
    "\n",
    "output_path = pasta_base / '06_Codigos_Integracao' / 'script_reproducao.py'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    # Cabecalho\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# SCRIPT DE REPRODUCAO - PROCESSADOR v4.2\\n')\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write(f'# Gerado: {datetime.now().isoformat()}\\n')\n",
    "    f.write(f'# Container: {container_nome}\\n')\n",
    "    f.write(f'# Timestamp: {timestamp}\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "\n",
    "    # Imports\n",
    "    f.write('from pathlib import Path\\n')\n",
    "    f.write('import json\\n')\n",
    "    f.write('import pandas as pd\\n')\n",
    "    f.write('from datetime import datetime\\n\\n')\n",
    "\n",
    "    # Configuracao\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# CONFIGURACAO\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('SCRIPT_DIR = Path(__file__).parent\\n')\n",
    "    f.write('BASE_DIR = SCRIPT_DIR.parent\\n')\n",
    "    f.write('PASTA_ENTRADA = Path(\"./entrada\")\\n\\n')\n",
    "\n",
    "    f.write('print(\"=\"*70)\\n')\n",
    "    f.write('print(\"SCRIPT DE REPRODUCAO - PROCESSADOR v4.2\")\\n')\n",
    "    f.write('print(\"=\"*70)\\n')\n",
    "    f.write(f'print(\"\\\\nContainer original: {container_nome}\")\\n')\n",
    "    f.write(f'print(\"Timestamp: {timestamp}\")\\n\\n')\n",
    "\n",
    "    # Carregar configuracoes\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# CARREGAR CONFIGURACOES\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('print(\"\\\\n\" + \"=\"*70)\\n')\n",
    "    f.write('print(\"CARREGANDO CONFIGURACOES\")\\n')\n",
    "    f.write('print(\"=\"*70)\\n\\n')\n",
    "\n",
    "    # Carregar dicionario\n",
    "    f.write('# Carregar dicionario\\n')\n",
    "    f.write('dicionario_file = BASE_DIR / \"data\" / \"dicionarios\" / \"DICT_Dicionario_Persistente.json\"\\n')\n",
    "    f.write('if dicionario_file.exists():\\n')\n",
    "    f.write('    with open(dicionario_file, \"r\", encoding=\"utf-8\") as f:\\n')\n",
    "    f.write('        DICIONARIO = json.load(f)\\n')\n",
    "    f.write('    print(f\"\\\\n OK Dicionario: {len(DICIONARIO.get(\\'campos_conhecidos\\', {}))} campos\")\\n')\n",
    "    f.write('else:\\n')\n",
    "    f.write('    DICIONARIO = {\"campos_conhecidos\": {}}\\n')\n",
    "    f.write('    print(\"\\\\n! Dicionario nao encontrado\")\\n\\n')\n",
    "\n",
    "    # Carregar estados\n",
    "    f.write('# Carregar estados dos blocos\\n')\n",
    "    f.write('estados_dir = BASE_DIR / \"data\" / \"logs\"\\n')\n",
    "    f.write('ESTADOS = {}\\n')\n",
    "    f.write('if estados_dir.exists():\\n')\n",
    "    f.write('    for arquivo in estados_dir.glob(\".bloco_*_state.json\"):\\n')\n",
    "    f.write('        bloco_nome = arquivo.stem.replace(\".\", \"\")\\n')\n",
    "    f.write('        with open(arquivo, \"r\", encoding=\"utf-8\") as f:\\n')\n",
    "    f.write('            ESTADOS[bloco_nome] = json.load(f)\\n')\n",
    "    f.write('    print(f\" OK Estados: {len(ESTADOS)} blocos carregados\")\\n')\n",
    "    f.write('else:\\n')\n",
    "    f.write('    print(\"! Pasta de estados nao encontrada\")\\n\\n')\n",
    "\n",
    "    # Funcao processar_arquivo\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# FUNCAO DE PROCESSAMENTO\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('def processar_arquivo(arquivo_path):\\n')\n",
    "    f.write('    \"\"\"Processa um arquivo conforme configuracoes originais\"\"\"\\n\\n')\n",
    "    f.write('    print(f\"\\\\n{\\'=\\'*70}\")\\n')\n",
    "    f.write('    print(f\"Processando: {arquivo_path.name}\")\\n')\n",
    "    f.write('    print(f\"{\\'=\\'*70}\")\\n\\n')\n",
    "\n",
    "    # Carregar arquivo\n",
    "    f.write('    # Carregar arquivo\\n')\n",
    "    f.write('    print(\"\\\\n[1/3] Carregando arquivo...\")\\n')\n",
    "    f.write('    try:\\n')\n",
    "    f.write('        if arquivo_path.suffix.lower() in [\\'.xlsx\\', \\'.xls\\', \\'.xlsm\\']:\\n')\n",
    "    f.write('            df = pd.read_excel(arquivo_path)\\n')\n",
    "    f.write('        elif arquivo_path.suffix.lower() == \\'.csv\\':\\n')\n",
    "    f.write('            df = pd.read_csv(arquivo_path, encoding=\\'utf-8\\')\\n')\n",
    "    f.write('        else:\\n')\n",
    "    f.write('            print(f\"  ! Formato nao suportado: {arquivo_path.suffix}\")\\n')\n",
    "    f.write('            return None\\n')\n",
    "    f.write('        print(f\"  OK Shape original: {df.shape}\")\\n')\n",
    "    f.write('    except Exception as e:\\n')\n",
    "    f.write('        print(f\"  ! ERRO ao carregar: {e}\")\\n')\n",
    "    f.write('        return None\\n\\n')\n",
    "\n",
    "    # Mapeamentos\n",
    "    f.write('    # Aplicar mapeamentos\\n')\n",
    "    f.write('    print(\"\\\\n[2/3] Aplicando mapeamentos...\")\\n')\n",
    "    f.write('    if \\'bloco_12_state\\' in ESTADOS:\\n')\n",
    "    f.write('        bloco12 = ESTADOS[\\'bloco_12_state\\']\\n')\n",
    "    f.write('        campos_mapeados = bloco12.get(\\'campos_mapeados\\', {})\\n')\n",
    "    f.write('        rename_dict = {}\\n')\n",
    "    f.write('        for col_orig, info in campos_mapeados.items():\\n')\n",
    "    f.write('            if col_orig in df.columns:\\n')\n",
    "    f.write('                tipo = info.get(\\'tipo\\', col_orig)\\n')\n",
    "    f.write('                if tipo != col_orig:\\n')\n",
    "    f.write('                    rename_dict[col_orig] = tipo\\n')\n",
    "    f.write('        if rename_dict:\\n')\n",
    "    f.write('            df.rename(columns=rename_dict, inplace=True)\\n')\n",
    "    f.write('            print(f\"  OK {len(rename_dict)} colunas renomeadas\")\\n')\n",
    "    f.write('        else:\\n')\n",
    "    f.write('            print(\"  -- Nenhum mapeamento necessario\")\\n')\n",
    "    f.write('    else:\\n')\n",
    "    f.write('        print(\"  -- BLOCO 12 nao disponivel\")\\n\\n')\n",
    "\n",
    "    # Limpeza\n",
    "    f.write('    # Limpeza basica\\n')\n",
    "    f.write('    print(\"\\\\n[3/3] Limpando dados...\")\\n')\n",
    "    f.write('    linhas_antes = len(df)\\n')\n",
    "    f.write('    df.dropna(how=\\'all\\', inplace=True)\\n')\n",
    "    f.write('    df.dropna(axis=1, how=\\'all\\', inplace=True)\\n')\n",
    "    f.write('    linhas_depois = len(df)\\n')\n",
    "    f.write('    if linhas_antes != linhas_depois:\\n')\n",
    "    f.write('        print(f\"  OK Removidas {linhas_antes - linhas_depois} linhas vazias\")\\n')\n",
    "    f.write('    print(f\"  OK Shape final: {df.shape}\")\\n')\n",
    "    f.write('    return df\\n\\n')\n",
    "\n",
    "    # Funcao main\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# MAIN\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('def main():\\n')\n",
    "    f.write('    \"\"\"Processa todos os arquivos da pasta entrada\"\"\"\\n\\n')\n",
    "\n",
    "    # Verificar entrada\n",
    "    f.write('    # Verificar pasta de entrada\\n')\n",
    "    f.write('    if not PASTA_ENTRADA.exists():\\n')\n",
    "    f.write('        print(f\"\\\\n! ERRO: Pasta de entrada nao encontrada\")\\n')\n",
    "    f.write('        print(f\"  Esperado: {PASTA_ENTRADA.absolute()}\")\\n')\n",
    "    f.write('        print(f\"\\\\n  COMO USAR:\")\\n')\n",
    "    f.write('        print(f\"  1. Criar pasta \\'entrada\\' no mesmo nivel do script\")\\n')\n",
    "    f.write('        print(f\"  2. Colocar arquivos .xlsx ou .csv na pasta\")\\n')\n",
    "    f.write('        print(f\"  3. Executar novamente\")\\n')\n",
    "    f.write('        return\\n\\n')\n",
    "\n",
    "    # Buscar arquivos\n",
    "    f.write('    # Buscar arquivos\\n')\n",
    "    f.write('    arquivos = (\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xlsx\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xls\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.xlsm\")) +\\n')\n",
    "    f.write('        list(PASTA_ENTRADA.glob(\"*.csv\"))\\n')\n",
    "    f.write('    )\\n')\n",
    "    f.write('    if not arquivos:\\n')\n",
    "    f.write('        print(f\"\\\\n! Nenhum arquivo encontrado em {PASTA_ENTRADA}\")\\n')\n",
    "    f.write('        return\\n\\n')\n",
    "\n",
    "    f.write('    print(f\"\\\\n{\\'=\\'*70}\")\\n')\n",
    "    f.write('    print(f\"ARQUIVOS ENCONTRADOS: {len(arquivos)}\")\\n')\n",
    "    f.write('    print(f\"{\\'=\\'*70}\")\\n')\n",
    "    f.write('    for arq in arquivos:\\n')\n",
    "    f.write('        print(f\"  - {arq.name}\")\\n\\n')\n",
    "\n",
    "    # Criar saida\n",
    "    f.write('    # Criar pasta de saida\\n')\n",
    "    f.write('    timestamp_exec = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\\n')\n",
    "    f.write('    pasta_saida = Path(f\"./saida_{timestamp_exec}\")\\n')\n",
    "    f.write('    pasta_saida.mkdir(exist_ok=True, parents=True)\\n')\n",
    "    f.write('    print(f\"\\\\n OK Pasta de saida: {pasta_saida.absolute()}\")\\n\\n')\n",
    "\n",
    "    # Processar\n",
    "    f.write('    # Processar cada arquivo\\n')\n",
    "    f.write('    resultados = {}\\n')\n",
    "    f.write('    for arquivo in arquivos:\\n')\n",
    "    f.write('        try:\\n')\n",
    "    f.write('            df_processado = processar_arquivo(arquivo)\\n')\n",
    "    f.write('            if df_processado is not None:\\n')\n",
    "    f.write('                output_file = pasta_saida / f\"processado_{arquivo.stem}.xlsx\"\\n')\n",
    "    f.write('                df_processado.to_excel(output_file, index=False)\\n')\n",
    "    f.write('                resultados[arquivo.name] = {\\n')\n",
    "    f.write('                    \\'status\\': \\'OK\\',\\n')\n",
    "    f.write('                    \\'linhas\\': len(df_processado),\\n')\n",
    "    f.write('                    \\'colunas\\': len(df_processado.columns),\\n')\n",
    "    f.write('                    \\'arquivo_saida\\': output_file.name\\n')\n",
    "    f.write('                }\\n')\n",
    "    f.write('                print(f\"\\\\n OK SALVO: {output_file.name}\")\\n')\n",
    "    f.write('            else:\\n')\n",
    "    f.write('                resultados[arquivo.name] = {\\'status\\': \\'ERRO\\', \\'erro\\': \\'Processamento retornou None\\'}\\n')\n",
    "    f.write('        except Exception as e:\\n')\n",
    "    f.write('            print(f\"\\\\n! ERRO: {e}\")\\n')\n",
    "    f.write('            resultados[arquivo.name] = {\\'status\\': \\'ERRO\\', \\'erro\\': str(e)}\\n\\n')\n",
    "\n",
    "    # Relatorio\n",
    "    f.write('    # Salvar relatorio\\n')\n",
    "    f.write('    relatorio = {\\n')\n",
    "    f.write('        \\'timestamp\\': datetime.now().isoformat(),\\n')\n",
    "    f.write(f'        \\'configuracao_original\\': {{\"container\": \"{container_nome}\", \"timestamp\": \"{timestamp}\"}},\\n')\n",
    "    f.write('        \\'resultados\\': resultados,\\n')\n",
    "    f.write('        \\'resumo\\': {\\n')\n",
    "    f.write('            \\'total\\': len(resultados),\\n')\n",
    "    f.write('            \\'sucesso\\': sum(1 for r in resultados.values() if r[\\'status\\'] == \\'OK\\'),\\n')\n",
    "    f.write('            \\'erro\\': sum(1 for r in resultados.values() if r[\\'status\\'] == \\'ERRO\\')\\n')\n",
    "    f.write('        }\\n')\n",
    "    f.write('    }\\n')\n",
    "    f.write('    relatorio_file = pasta_saida / \\'RELATORIO.json\\'\\n')\n",
    "    f.write('    with open(relatorio_file, \\'w\\', encoding=\\'utf-8\\') as f:\\n')\n",
    "    f.write('        json.dump(relatorio, f, indent=2, ensure_ascii=False)\\n\\n')\n",
    "\n",
    "    # Resumo\n",
    "    f.write('    # Resumo final\\n')\n",
    "    f.write('    print(\"\\\\n\" + \"=\"*70)\\n')\n",
    "    f.write('    print(\"RESUMO FINAL\")\\n')\n",
    "    f.write('    print(\"=\"*70)\\n')\n",
    "    f.write('    print(f\"Total: {relatorio[\\'resumo\\'][\\'total\\']}\")\\n')\n",
    "    f.write('    print(f\"Sucesso: {relatorio[\\'resumo\\'][\\'sucesso\\']}\")\\n')\n",
    "    f.write('    print(f\"Erros: {relatorio[\\'resumo\\'][\\'erro\\']}\")\\n')\n",
    "    f.write('    print(f\"Pasta saida: {pasta_saida.absolute()}\")\\n')\n",
    "    f.write('    print(f\"Relatorio: {relatorio_file.name}\")\\n')\n",
    "    f.write('    print(\"=\"*70)\\n\\n')\n",
    "\n",
    "    # Executar\n",
    "    f.write('# ' + '='*70 + '\\n')\n",
    "    f.write('# EXECUTAR\\n')\n",
    "    f.write('# ' + '='*70 + '\\n\\n')\n",
    "    f.write('if __name__ == \"__main__\":\\n')\n",
    "    f.write('    try:\\n')\n",
    "    f.write('        main()\\n')\n",
    "    f.write('    except KeyboardInterrupt:\\n')\n",
    "    f.write('        print(\"\\\\n\\\\nProcessamento interrompido pelo usuario\")\\n')\n",
    "    f.write('    except Exception as e:\\n')\n",
    "    f.write('        print(f\"\\\\n\\\\nERRO FATAL: {e}\")\\n')\n",
    "    f.write('        import traceback\\n')\n",
    "    f.write('        traceback.print_exc()\\n')\n",
    "\n",
    "print(f\"\\nâœ… SCRIPT GERADO COM SUCESSO!\")\n",
    "print(f\"\\nğŸ“ Local:\")\n",
    "print(f\"   {output_path}\")\n",
    "print(f\"\\nğŸ“– COMO USAR:\")\n",
    "print(f\"   1. cd \\\"{output_path.parent}\\\"\")\n",
    "print(f\"   2. mkdir entrada\")\n",
    "print(f\"   3. Colocar arquivos em entrada/\")\n",
    "print(f\"   4. python script_reproducao.py\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "id": "2b30f963334f0548",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "34cebe917d524e5a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
