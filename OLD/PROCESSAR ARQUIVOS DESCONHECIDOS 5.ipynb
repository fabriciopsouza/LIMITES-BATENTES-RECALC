{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:24:45.934738Z",
     "start_time": "2025-10-19T01:24:43.404261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 1: SELETOR DE PASTA COM TIMER + MIGRAÃ‡ÃƒO\n",
    "# VersÃ£o: 4.4 - COM MELHORIAS DE OBSERVABILIDADE E CONSISTÃŠNCIA\n",
    "# Data: 2025-10-17\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIAS v4.4:\n",
    "# âœ… MELHORIA 1: Salvar estado local .bloco_1_state.json\n",
    "# âœ… MELHORIA 2: Registro de versÃ£o do cÃ³digo\n",
    "# âœ… MELHORIA 3: ValidaÃ§Ã£o de dependÃªncias\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# METADADOS DA VERSÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "VERSAO_BLOCO1 = '4.4'\n",
    "DATA_VERSAO = '2025-10-17'\n",
    "CHANGELOG_V44 = {\n",
    "    'v4.4': {\n",
    "        'data': '2025-10-17',\n",
    "        'melhorias': [\n",
    "            'Salvar estado local em .bloco_1_state.json',\n",
    "            'Registro de versÃ£o do cÃ³digo',\n",
    "            'ValidaÃ§Ã£o de dependÃªncias no inÃ­cio'\n",
    "        ],\n",
    "        'compatibilidade': 'v4.3'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\" ğŸ” PROCESSADOR DE ARQUIVOS DESCONHECIDOS v{VERSAO_BLOCO1}\")\n",
    "print(\"=\"*70)\n",
    "print(f\" VersÃ£o: {VERSAO_BLOCO1} | Data: {DATA_VERSAO}\")\n",
    "print(\" Timer | MigraÃ§Ã£o | DicionÃ¡rios | ValidaÃ§Ãµes | Logs | Estado\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIA 3: VALIDAÃ‡ÃƒO DE DEPENDÃŠNCIAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def validar_dependencias():\n",
    "    \"\"\"\n",
    "    Valida que todas as bibliotecas necessÃ¡rias estÃ£o instaladas.\n",
    "\n",
    "    Evita erros confusos mais tarde na execuÃ§Ã£o.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ” Validando dependÃªncias...\")\n",
    "\n",
    "    dependencias = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'openpyxl': 'openpyxl',\n",
    "        'xlrd': 'xlrd',\n",
    "        'tkinter': 'tkinter (built-in Python)'\n",
    "    }\n",
    "\n",
    "    faltando = []\n",
    "    instaladas = []\n",
    "\n",
    "    for modulo, nome_pip in dependencias.items():\n",
    "        try:\n",
    "            __import__(modulo)\n",
    "            instaladas.append(f\"âœ… {modulo}\")\n",
    "        except ImportError:\n",
    "            faltando.append(nome_pip)\n",
    "\n",
    "    # Mostrar resultado\n",
    "    for lib in instaladas:\n",
    "        print(f\"   {lib}\")\n",
    "\n",
    "    if faltando:\n",
    "        print(\"\\nâŒ ERRO: Bibliotecas faltando!\")\n",
    "        print(\"â”€\" * 70)\n",
    "        for lib in faltando:\n",
    "            print(f\"   âŒ {lib}\")\n",
    "        print(\"\\nğŸ’¡ SoluÃ§Ã£o:\")\n",
    "        libs_pip = [lib for lib in faltando if 'built-in' not in lib]\n",
    "        if libs_pip:\n",
    "            print(f\"   Execute: pip install {' '.join(libs_pip)}\")\n",
    "        print()\n",
    "        raise ImportError(\n",
    "            f\"Bibliotecas necessÃ¡rias nÃ£o instaladas: {', '.join(faltando)}\"\n",
    "        )\n",
    "\n",
    "    print(\"âœ… Todas as dependÃªncias instaladas!\\n\")\n",
    "\n",
    "# Validar ANTES de importar\n",
    "validar_dependencias()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# IMPORTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "\n",
    "print(\"âœ… Imports carregados\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: LocalizadorDicionario (SISTEMA DE PERSISTÃŠNCIA GLOBAL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localizaÃ§Ã£o persistente de dicionÃ¡rios entre sessÃµes.\n",
    "\n",
    "    MantÃ©m log global em: ~/.processador_dicionario_localizador.json\n",
    "\n",
    "    MÃ©todos PÃºblicos:\n",
    "    - obter_dicionario_atual() -> Path  # Para BLOCO 2+\n",
    "    - obter_pasta_base_atual() -> Path  # Para FileManager\n",
    "    - obter_timestamp_atual() -> str    # Para recuperar timestamp\n",
    "    - registrar_mudanca()               # Chamado por BLOCO 1\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.1',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'timestamp': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def salvar_log(cls, log):\n",
    "        \"\"\"Salva log com backup automÃ¡tico\"\"\"\n",
    "        # Backup do log anterior\n",
    "        if cls.LOG_FILE.exists():\n",
    "            backup_file = cls.LOG_FILE.with_suffix('.json.bak')\n",
    "            shutil.copy2(cls.LOG_FILE, backup_file)\n",
    "\n",
    "        # Salvar novo log\n",
    "        with open(cls.LOG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(log, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicionÃ¡rio atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ DicionÃ¡rio nÃ£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"âŒ DicionÃ¡rio nÃ£o existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual (para FileManager)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ Pasta base nÃ£o encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"âŒ Pasta base nÃ£o existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "    @classmethod\n",
    "    def obter_timestamp_atual(cls):\n",
    "        \"\"\"Retorna timestamp da execuÃ§Ã£o atual (para BLOCO 2+)\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log.get('timestamp'):\n",
    "            raise FileNotFoundError(\n",
    "                \"âŒ Timestamp nÃ£o encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "        return log['timestamp']\n",
    "\n",
    "    @classmethod\n",
    "    def registrar_mudanca(cls, pasta_base, timestamp, dicionario_path=None,\n",
    "                         migrado_de=None, versao_bloco1=None):\n",
    "        \"\"\"\n",
    "        Registra mudanÃ§a de localizaÃ§Ã£o no log global.\n",
    "\n",
    "        IMPORTANTE: Agora aceita timestamp e registra no LOG GLOBAL.\n",
    "        dicionario_path Ã© OPCIONAL - sÃ³ registra se existir.\n",
    "\n",
    "        Args:\n",
    "            pasta_base: Path da pasta container\n",
    "            timestamp: String timestamp da execuÃ§Ã£o\n",
    "            dicionario_path: Path do dicionÃ¡rio (opcional)\n",
    "            migrado_de: Path de onde migrou (opcional)\n",
    "            versao_bloco1: VersÃ£o do BLOCO 1 que criou (opcional)\n",
    "        \"\"\"\n",
    "        log = cls.carregar_log()\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'pasta_base': str(pasta_base),\n",
    "            'dicionario_path': str(dicionario_path) if dicionario_path else None,\n",
    "            'timestamp_execucao': timestamp,\n",
    "            'existe': dicionario_path.exists() if dicionario_path else False,\n",
    "            'versao_bloco1': versao_bloco1 or 'desconhecida'\n",
    "        }\n",
    "\n",
    "        if migrado_de:\n",
    "            entrada['migrado_de'] = str(migrado_de)\n",
    "\n",
    "        log['pasta_base_atual'] = str(pasta_base)\n",
    "        log['timestamp'] = timestamp\n",
    "\n",
    "        # SÃ³ registrar dicionÃ¡rio se ele REALMENTE existir\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            log['dicionario_atual'] = str(dicionario_path)\n",
    "        else:\n",
    "            log['dicionario_atual'] = None\n",
    "\n",
    "        log['historico'].append(entrada)\n",
    "        log['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "\n",
    "        cls.salvar_log(log)\n",
    "\n",
    "        print(f\"\\nğŸ“ Localizador atualizado:\")\n",
    "        print(f\"   Container: {pasta_base.name}\")\n",
    "        print(f\"   Timestamp: {timestamp}\")\n",
    "        print(f\"   VersÃ£o BLOCO 1: {versao_bloco1 or 'desconhecida'}\")\n",
    "        if dicionario_path and dicionario_path.exists():\n",
    "            print(f\"   DicionÃ¡rio: {dicionario_path.name}\")\n",
    "        print(f\"   Log: {cls.LOG_FILE}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: SeletorPastaComTimer (GUI COM TIMER)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SeletorPastaComTimer:\n",
    "    \"\"\"Seletor de pasta destino com timer de 10s e memÃ³ria\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_directory.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultima_pasta(self):\n",
    "        \"\"\"Carrega Ãºltima pasta usada\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultima_pasta = Path(config.get('last_directory', ''))\n",
    "                if ultima_pasta.exists():\n",
    "                    return ultima_pasta\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, pasta):\n",
    "        \"\"\"Salva escolha para prÃ³xima execuÃ§Ã£o\"\"\"\n",
    "        config = {\n",
    "            'last_directory': str(pasta),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_pasta_destino(self, pasta):\n",
    "        \"\"\"Valida se pasta tem permissÃµes adequadas\"\"\"\n",
    "        pasta = Path(pasta)\n",
    "\n",
    "        # Verificar permissÃ£o de escrita\n",
    "        if not os.access(pasta, os.W_OK):\n",
    "            return False, \"âŒ Sem permissÃ£o de escrita\"\n",
    "\n",
    "        # Verificar espaÃ§o em disco (mÃ­nimo 100MB)\n",
    "        stat = os.statvfs(pasta) if hasattr(os, 'statvfs') else None\n",
    "        if stat:\n",
    "            espaco_livre = stat.f_bavail * stat.f_frsize\n",
    "            if espaco_livre < 100 * 1024 * 1024:  # 100MB\n",
    "                return False, (\n",
    "                    f\"âŒ EspaÃ§o insuficiente \"\n",
    "                    f\"({espaco_livre/1024/1024:.1f}MB)\"\n",
    "                )\n",
    "\n",
    "        return True, \"âœ… Pasta vÃ¡lida\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultima_pasta = self.carregar_ultima_pasta()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Pasta Destino\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # TÃ­tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ Pasta DESTINO\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultima_pasta:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultima_pasta}\"\n",
    "        else:\n",
    "            msg = \"Primeira execuÃ§Ã£o - selecione pasta\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [10]\n",
    "        if ultima_pasta:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # BotÃµes\n",
    "        def escolher_nova():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            nova_pasta = filedialog.askdirectory(\n",
    "                title=\"Pasta DESTINO\",\n",
    "                initialdir=ultima_pasta if ultima_pasta else None\n",
    "            )\n",
    "\n",
    "            if nova_pasta:\n",
    "                valido, msg = self.validar_pasta_destino(nova_pasta)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Pasta InvÃ¡lida\", msg)\n",
    "                    self.resultado['path'] = ultima_pasta\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(nova_pasta)\n",
    "                    self.resultado['acao'] = 'NOVA'\n",
    "            else:\n",
    "                self.resultado['path'] = ultima_pasta\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultima_pasta\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ“ Nova Pasta\",\n",
    "            command=escolher_nova,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultima_pasta:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"âœ… Usar Ãšltima\",\n",
    "                command=usar_ultima,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: SeletorOrigemComTimer (GUI MIGRAÃ‡ÃƒO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class SeletorOrigemComTimer:\n",
    "    \"\"\"Pergunta se deseja copiar arquivos de execuÃ§Ã£o anterior\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'copiar': False, 'path': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def perguntar_origem(self):\n",
    "        \"\"\"GUI com timer de 5s (default: NÃƒO)\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Copiar Arquivos Anteriores?\")\n",
    "        root.geometry(\"650x350\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 175\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ Copiar arquivos de execuÃ§Ã£o anterior?\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        msg = (\n",
    "            \"Se houver dicionÃ¡rios, logs ou outputs anteriores,\\n\"\n",
    "            \"vocÃª pode copiÃ¡-los para a nova estrutura.\"\n",
    "        )\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        contador = [5]\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"{contador[0]}s (auto: NÃƒO)\",\n",
    "            font=('Arial', 18, 'bold'),\n",
    "            fg='#FF6600',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 20))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"{contador[0]}s (auto: NÃƒO)\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0:\n",
    "                self.timeout_ocorreu = True\n",
    "                self.resultado['copiar'] = False\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "        def sim_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "            pasta_origem = filedialog.askdirectory(\n",
    "                title=\"Selecione pasta ORIGEM (execuÃ§Ã£o anterior)\"\n",
    "            )\n",
    "            if pasta_origem:\n",
    "                self.resultado['copiar'] = True\n",
    "                self.resultado['path'] = Path(pasta_origem)\n",
    "            else:\n",
    "                self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def nao_copiar():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['copiar'] = False\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"âœ… SIM - Selecionar Origem\",\n",
    "            command=sim_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"âŒ NÃƒO - ComeÃ§ar do Zero\",\n",
    "            command=nao_copiar,\n",
    "            width=25,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: LimpadorRoot (DETECÃ‡ÃƒO DE POLUIÃ‡ÃƒO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class LimpadorRoot:\n",
    "    \"\"\"Detecta e limpa pastas antigas no root\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_root):\n",
    "        self.pasta_root = Path(pasta_root)\n",
    "\n",
    "    def detectar_poluicao(self):\n",
    "        \"\"\"Encontra pastas numeradas antigas\"\"\"\n",
    "        pastas_numeradas = [\n",
    "            p for p in self.pasta_root.iterdir()\n",
    "            if p.is_dir() and p.name[:2].isdigit() and '_' in p.name\n",
    "        ]\n",
    "        return pastas_numeradas\n",
    "\n",
    "    def perguntar_limpeza(self, pastas):\n",
    "        \"\"\"GUI para decidir o que fazer com pastas antigas\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Limpar Root?\")\n",
    "        root.geometry(\"650x400\")\n",
    "\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 200\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"âš ï¸  Pastas antigas detectadas no root\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white',\n",
    "            fg='#FF6600'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        msg = f\"Encontradas {len(pastas)} pastas soltas:\\n\\n\"\n",
    "        msg += \"\\n\".join([f\"â€¢ {p.name}\" for p in pastas[:5]])\n",
    "        if len(pastas) > 5:\n",
    "            msg += f\"\\n... e mais {len(pastas)-5}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        resultado = {'acao': None}\n",
    "\n",
    "        def mover():\n",
    "            resultado['acao'] = 'MOVER'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def deletar():\n",
    "            resultado['acao'] = 'DELETAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def ignorar():\n",
    "            resultado['acao'] = 'IGNORAR'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ“¦ Mover p/ Estrutura\",\n",
    "            command=mover,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"ğŸ—‘ï¸  Deletar\",\n",
    "            command=deletar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#F44336',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"â­ï¸  Ignorar\",\n",
    "            command=ignorar,\n",
    "            width=15,\n",
    "            height=2,\n",
    "            font=('Arial', 9),\n",
    "            bg='#757575',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.mainloop()\n",
    "        return resultado['acao']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: GerenciadorMigracao (CÃ“PIA COMPLETA COM LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class GerenciadorMigracao:\n",
    "    \"\"\"Gerencia cÃ³pia completa de execuÃ§Ãµes anteriores\"\"\"\n",
    "\n",
    "    def __init__(self, pasta_origem, pasta_destino_container):\n",
    "        self.pasta_origem = Path(pasta_origem)\n",
    "        self.pasta_destino = Path(pasta_destino_container)\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.log_detalhado = []\n",
    "        self.erros = []\n",
    "\n",
    "    def detectar_estrutura(self):\n",
    "        \"\"\"Detecta pastas e dicionÃ¡rios na origem\"\"\"\n",
    "        pastas = [\n",
    "            p for p in self.pasta_origem.iterdir()\n",
    "            if p.is_dir() and (\n",
    "                p.name[:2].isdigit() or\n",
    "                'dicionario' in p.name.lower()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        dicionarios = []\n",
    "        pasta_dict = self.pasta_origem / '05_Dicionarios'\n",
    "\n",
    "        if pasta_dict.exists():\n",
    "            dicionarios.extend(list(pasta_dict.glob('*.json')))\n",
    "\n",
    "        dicionarios.extend(\n",
    "            list(self.pasta_origem.glob('dicionario*.json'))\n",
    "        )\n",
    "        dicionarios = list(set(dicionarios))\n",
    "\n",
    "        return pastas, dicionarios\n",
    "\n",
    "    def validar_dicionario(self, arquivo_json):\n",
    "        \"\"\"Valida integridade do dicionÃ¡rio JSON\"\"\"\n",
    "        try:\n",
    "            with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Verificar estrutura mÃ­nima\n",
    "            if not isinstance(data, dict):\n",
    "                return False, \"JSON nÃ£o Ã© um dicionÃ¡rio\"\n",
    "\n",
    "            return True, \"âœ… VÃ¡lido\"\n",
    "        except json.JSONDecodeError as e:\n",
    "            return False, f\"JSON invÃ¡lido: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Erro: {str(e)}\"\n",
    "\n",
    "    def copiar_tudo(self):\n",
    "        \"\"\"Copia tudo com tratamento de erros\"\"\"\n",
    "        pastas, dicionarios = self.detectar_estrutura()\n",
    "\n",
    "        print(f\"\\nğŸ“‚ MIGRAÃ‡ÃƒO COMPLETA\")\n",
    "        print(\"â”€\" * 70)\n",
    "        print(f\"   De: {self.pasta_origem}\")\n",
    "        print(f\"   Para: {self.pasta_destino}\")\n",
    "        print(f\"   Pastas: {len(pastas)}\")\n",
    "        print(f\"   DicionÃ¡rios: {len(dicionarios)}\")\n",
    "        print()\n",
    "\n",
    "        if not pastas and not dicionarios:\n",
    "            print(\"â„¹ï¸  Nada para copiar\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(\"Copiar? (S/N ou Enter=S): \", end='')\n",
    "        resposta = input().strip().upper()\n",
    "        if resposta and resposta != 'S':\n",
    "            print(\"âŒ MigraÃ§Ã£o cancelada\")\n",
    "            return {'migrado': False}\n",
    "\n",
    "        print(f\"\\nğŸ”„ Copiando...\\n\")\n",
    "\n",
    "        arquivos_copiados = 0\n",
    "        bytes_copiados = 0\n",
    "        dicionarios_copiados = []\n",
    "\n",
    "        # Copiar pastas\n",
    "        for pasta in sorted(pastas):\n",
    "            try:\n",
    "                if pasta.name == '05_Dicionarios':\n",
    "                    continue\n",
    "\n",
    "                destino_pasta = self.pasta_destino / pasta.name\n",
    "                destino_pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                print(f\"ğŸ“ {pasta.name}\", end='')\n",
    "                arquivos_pasta = 0\n",
    "                bytes_pasta = 0\n",
    "\n",
    "                for arquivo in pasta.rglob('*'):\n",
    "                    if arquivo.is_file():\n",
    "                        try:\n",
    "                            destino_arq = (\n",
    "                                destino_pasta /\n",
    "                                arquivo.relative_to(pasta)\n",
    "                            )\n",
    "                            destino_arq.parent.mkdir(\n",
    "                                parents=True,\n",
    "                                exist_ok=True\n",
    "                            )\n",
    "                            shutil.copy2(arquivo, destino_arq)\n",
    "                            arquivos_copiados += 1\n",
    "                            arquivos_pasta += 1\n",
    "                            bytes_pasta += arquivo.stat().st_size\n",
    "                        except Exception as e:\n",
    "                            self.erros.append({\n",
    "                                'arquivo': str(arquivo),\n",
    "                                'erro': str(e)\n",
    "                            })\n",
    "\n",
    "                bytes_copiados += bytes_pasta\n",
    "                tamanho_kb = bytes_pasta/1024\n",
    "                print(f\" â†’ {arquivos_pasta} arquivos ({tamanho_kb:.1f} KB)\")\n",
    "\n",
    "                self.log_detalhado.append({\n",
    "                    'tipo': 'pasta',\n",
    "                    'nome': pasta.name,\n",
    "                    'arquivos': arquivos_pasta,\n",
    "                    'bytes': bytes_pasta\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" âŒ ERRO: {str(e)}\")\n",
    "                self.erros.append({\n",
    "                    'pasta': pasta.name,\n",
    "                    'erro': str(e)\n",
    "                })\n",
    "\n",
    "        # Copiar dicionÃ¡rios\n",
    "        if dicionarios:\n",
    "            pasta_dict_destino = self.pasta_destino / '05_Dicionarios'\n",
    "            pasta_dict_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            print(f\"\\nğŸ“š DICIONÃRIOS ({len(dicionarios)}):\")\n",
    "\n",
    "            for dic in dicionarios:\n",
    "                try:\n",
    "                    # Validar antes de copiar\n",
    "                    valido, msg = self.validar_dicionario(dic)\n",
    "\n",
    "                    destino_dic = pasta_dict_destino / dic.name\n",
    "                    shutil.copy2(dic, destino_dic)\n",
    "                    tamanho = dic.stat().st_size\n",
    "\n",
    "                    status = \"âœ…\" if valido else \"âš ï¸\"\n",
    "                    tamanho_kb = tamanho/1024\n",
    "                    print(f\"   {status} {dic.name} ({tamanho_kb:.1f} KB) - {msg}\")\n",
    "\n",
    "                    dicionarios_copiados.append(str(destino_dic))\n",
    "                    arquivos_copiados += 1\n",
    "                    bytes_copiados += tamanho\n",
    "\n",
    "                    self.log_detalhado.append({\n",
    "                        'tipo': 'dicionario',\n",
    "                        'nome': dic.name,\n",
    "                        'bytes': tamanho,\n",
    "                        'path': str(destino_dic),\n",
    "                        'validado': valido\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ {dic.name}: {str(e)}\")\n",
    "                    self.erros.append({\n",
    "                        'dicionario': dic.name,\n",
    "                        'erro': str(e)\n",
    "                    })\n",
    "\n",
    "        total_mb = bytes_copiados/1024/1024\n",
    "        print(f\"\\nâœ… TOTAL: {arquivos_copiados} arquivos, {total_mb:.2f} MB\")\n",
    "\n",
    "        if self.erros:\n",
    "            print(f\"âš ï¸  {len(self.erros)} erros durante cÃ³pia (ver log)\")\n",
    "\n",
    "        self._salvar_log_local({\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'bytes': bytes_copiados,\n",
    "            'dicionarios': len(dicionarios_copiados),\n",
    "            'erros': len(self.erros),\n",
    "            'detalhes': self.log_detalhado,\n",
    "            'log_erros': self.erros\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'migrado': True,\n",
    "            'arquivos': arquivos_copiados,\n",
    "            'dicionarios': dicionarios_copiados,\n",
    "            'erros': self.erros\n",
    "        }\n",
    "\n",
    "    def _salvar_log_local(self, info):\n",
    "        \"\"\"Salva log detalhado da migraÃ§Ã£o\"\"\"\n",
    "        log_file = self.pasta_destino / 'log_migracoes.json'\n",
    "\n",
    "        if log_file.exists():\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                historico = json.load(f)\n",
    "        else:\n",
    "            historico = {'migracoes': []}\n",
    "\n",
    "        entrada = {\n",
    "            'timestamp': self.timestamp,\n",
    "            'data_hora': datetime.now().isoformat(),\n",
    "            'pasta_origem': str(self.pasta_origem),\n",
    "            'pasta_destino': str(self.pasta_destino),\n",
    "            **info\n",
    "        }\n",
    "\n",
    "        historico['migracoes'].append(entrada)\n",
    "        historico['ultima_migracao'] = self.timestamp\n",
    "\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(historico, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"ğŸ’¾ Log: {log_file.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE: FileManagerInterativo (GERENCIADOR DE ARQUIVOS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path=None):\n",
    "        self.base_path = Path(base_path) if base_path else Path.cwd()\n",
    "\n",
    "        # Estrutura de pastas padrÃ£o\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        print(f\"âœ… FileManager inicializado\")\n",
    "        print(f\"   ğŸ“‚ Container: {self.base_path.name}\")\n",
    "        print(f\"   ğŸ• Timestamp: {self.timestamp}\")\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = (\n",
    "            self.pastas[pasta] /\n",
    "            f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "        )\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  NÃ£o foi possÃ­vel abrir pasta: {e}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡ÃƒO: gerar_readme\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def gerar_readme(pasta_base, versao_bloco1):\n",
    "    \"\"\"Gera README.md na pasta container\"\"\"\n",
    "    readme = f\"\"\"# ğŸ“š PROCESSADOR DE ARQUIVOS DESCONHECIDOS\n",
    "\n",
    "**Gerado:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Pasta:** {pasta_base}\n",
    "**VersÃ£o BLOCO 1:** {versao_bloco1}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ESTRUTURA\n",
    "\n",
    "```\n",
    "{pasta_base.name}/\n",
    "â”œâ”€â”€ 01_Entrada/          â† Arquivos originais\n",
    "â”œâ”€â”€ 02_Processados/      â† Dados limpos\n",
    "â”œâ”€â”€ 03_Outputs/          â† Resultados finais\n",
    "â”œâ”€â”€ 04_Logs/             â† Logs de execuÃ§Ã£o â­ COMUNICAÃ‡ÃƒO VIA LOG\n",
    "â”œâ”€â”€ 05_Dicionarios/      â† Mapeamentos DE-PARA\n",
    "â”œâ”€â”€ 06_Codigos_Integracao/ â† Scripts reutilizÃ¡veis\n",
    "â”œâ”€â”€ README.md            â† Este arquivo\n",
    "â””â”€â”€ log_migracoes.json   â† HistÃ³rico de migraÃ§Ãµes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š LOCALIZADOR DE DICIONÃRIO\n",
    "\n",
    "**Para notebooks consumidores (BLOCO 2+):**\n",
    "\n",
    "```python\n",
    "from bloco1 import LocalizadorDicionario\n",
    "\n",
    "# Obter dicionÃ¡rio atual\n",
    "dicionario_path = LocalizadorDicionario.obter_dicionario_atual()\n",
    "\n",
    "# Obter pasta base\n",
    "pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "# Obter timestamp da execuÃ§Ã£o\n",
    "timestamp = LocalizadorDicionario.obter_timestamp_atual()\n",
    "\n",
    "# Carregar dicionÃ¡rio\n",
    "import json\n",
    "with open(dicionario_path, 'r', encoding='utf-8') as f:\n",
    "    dicionario = json.load(f)\n",
    "```\n",
    "\n",
    "**Log global:** `~/.processador_dicionario_localizador.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— COMUNICAÃ‡ÃƒO ENTRE BLOCOS (0% MEMÃ“RIA, 100% LOG)\n",
    "\n",
    "Todos os blocos seguem o padrÃ£o:\n",
    "\n",
    "1. **LER** do LOG GLOBAL:\n",
    "   - pasta_base_atual\n",
    "   - timestamp\n",
    "   - dicionario_atual (se existir)\n",
    "\n",
    "2. **RECRIAR** objetos localmente:\n",
    "   - FileManager(pasta_base)\n",
    "   - Carregar dicionÃ¡rio de 04_Logs/\n",
    "\n",
    "3. **PROCESSAR** dados do bloco\n",
    "\n",
    "4. **SALVAR** estado em 04_Logs/:\n",
    "   - .bloco_N_state.json\n",
    "   - Dados especÃ­ficos do bloco\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ HISTÃ“RICO DE MIGRAÃ‡Ã•ES\n",
    "\n",
    "Ver: `log_migracoes.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ESTADO DO BLOCO 1\n",
    "\n",
    "Ver: `04_Logs/.bloco_1_state.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ†˜ SUPORTE\n",
    "\n",
    "- Erros: `04_Logs/`\n",
    "- DicionÃ¡rio perdido: Execute BLOCO 1\n",
    "- MigraÃ§Ã£o: Consulte `log_migracoes.json`\n",
    "- VersÃ£o do cÃ³digo: `{versao_bloco1}`\n",
    "\"\"\"\n",
    "\n",
    "    readme_path = pasta_base / 'README.md'\n",
    "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    print(f\"ğŸ“– README: {readme_path.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUÃ‡ÃƒO PRINCIPAL DO BLOCO 1\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 1: SELECIONANDO PASTA DESTINO...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor = SeletorPastaComTimer()\n",
    "resultado_destino = seletor.selecionar_com_timer()\n",
    "\n",
    "if not resultado_destino['path']:\n",
    "    print(\"âŒ Nenhuma pasta selecionada\")\n",
    "    raise ValueError(\"ExecuÃ§Ã£o cancelada\")\n",
    "\n",
    "print(f\"\\nâœ… Destino: {resultado_destino['path']}\")\n",
    "print(f\"   AÃ§Ã£o: {resultado_destino['acao']}\")\n",
    "seletor.salvar_escolha(resultado_destino['path'])\n",
    "\n",
    "pasta_root_destino = resultado_destino['path']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 2: VERIFICANDO POLUIÃ‡ÃƒO NO ROOT...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "limpador = LimpadorRoot(pasta_root_destino)\n",
    "pastas_poluidas = limpador.detectar_poluicao()\n",
    "\n",
    "acao = None\n",
    "if pastas_poluidas:\n",
    "    print(f\"\\nâš ï¸  {len(pastas_poluidas)} pastas antigas no root!\")\n",
    "    acao = limpador.perguntar_limpeza(pastas_poluidas)\n",
    "\n",
    "    if acao == 'DELETAR':\n",
    "        print(\"\\nğŸ—‘ï¸  Deletando...\")\n",
    "        for pasta in pastas_poluidas:\n",
    "            try:\n",
    "                shutil.rmtree(pasta)\n",
    "                print(f\"   âœ… {pasta.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {pasta.name}: {e}\")\n",
    "\n",
    "    elif acao == 'MOVER':\n",
    "        print(\"\\nğŸ“¦ Mover serÃ¡ feito apÃ³s criar container\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nâ­ï¸  Ignorando pastas antigas\")\n",
    "else:\n",
    "    print(\"âœ… Root limpo\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 3: CRIANDO PASTA CONTAINER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "nome_container = f\"PROCESSAR_ARQUIVOS_{timestamp}\"\n",
    "pasta_container = pasta_root_destino / nome_container\n",
    "\n",
    "pasta_container.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Container: {nome_container}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 4: COPIAR DE EXECUÃ‡ÃƒO ANTERIOR?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seletor_origem = SeletorOrigemComTimer()\n",
    "resultado_origem = seletor_origem.perguntar_origem()\n",
    "\n",
    "dicionarios_migrados = []\n",
    "info_mig = {}\n",
    "\n",
    "if resultado_origem['copiar'] and resultado_origem['path']:\n",
    "    print(f\"\\nğŸ“‚ Origem: {resultado_origem['path']}\")\n",
    "    gerenciador_mig = GerenciadorMigracao(\n",
    "        resultado_origem['path'],\n",
    "        pasta_container\n",
    "    )\n",
    "    info_mig = gerenciador_mig.copiar_tudo()\n",
    "\n",
    "    if info_mig.get('migrado'):\n",
    "        print(f\"\\nâœ… MigraÃ§Ã£o concluÃ­da\")\n",
    "        if info_mig.get('dicionarios'):\n",
    "            dicionarios_migrados = info_mig['dicionarios']\n",
    "            print(f\"   ğŸ“š {len(dicionarios_migrados)} dicionÃ¡rios copiados\")\n",
    "        if info_mig.get('erros'):\n",
    "            print(f\"   âš ï¸  {len(info_mig['erros'])} erros (ver log)\")\n",
    "else:\n",
    "    print(\"âœ… ComeÃ§ando do zero (sem cÃ³pia)\")\n",
    "\n",
    "# Mover pastas antigas se solicitado\n",
    "if pastas_poluidas and acao == 'MOVER':\n",
    "    print(\"\\nğŸ“¦ Movendo pastas antigas para container...\")\n",
    "    for pasta in pastas_poluidas:\n",
    "        try:\n",
    "            destino = pasta_container / pasta.name\n",
    "            if destino.exists():\n",
    "                shutil.rmtree(destino)\n",
    "            shutil.move(str(pasta), str(destino))\n",
    "            print(f\"   âœ… {pasta.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ {pasta.name}: {e}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 5: INICIALIZANDO FILEMANAGER...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fm = FileManagerInterativo(pasta_container)\n",
    "\n",
    "# Detectar dicionÃ¡rio migrado (se existir)\n",
    "pasta_dict = fm.pastas['dicionarios']\n",
    "arquivos_dict = list(pasta_dict.glob('*.json'))\n",
    "\n",
    "dicionario_existente = None\n",
    "if arquivos_dict:\n",
    "    # Usar o mais recente\n",
    "    dicionario_existente = max(\n",
    "        arquivos_dict,\n",
    "        key=lambda p: p.stat().st_mtime\n",
    "    )\n",
    "    print(f\"ğŸ“š DicionÃ¡rio detectado: {dicionario_existente.name}\")\n",
    "\n",
    "# Registrar no localizador com timestamp E versÃ£o\n",
    "LocalizadorDicionario.registrar_mudanca(\n",
    "    pasta_base=pasta_container,\n",
    "    timestamp=timestamp,\n",
    "    dicionario_path=dicionario_existente,  # None se nÃ£o existir\n",
    "    versao_bloco1=VERSAO_BLOCO1\n",
    ")\n",
    "\n",
    "# Gerar README\n",
    "gerar_readme(pasta_container, VERSAO_BLOCO1)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MELHORIA 1: SALVAR ESTADO LOCAL (NOVO v4.4)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”µ ETAPA 6: SALVANDO ESTADO LOCAL...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calcular tamanho total do container\n",
    "tamanho_total = sum(\n",
    "    f.stat().st_size for f in pasta_container.rglob('*') if f.is_file()\n",
    ") / 1024 / 1024\n",
    "\n",
    "estado_bloco1 = {\n",
    "    'bloco': 1,\n",
    "    'versao': VERSAO_BLOCO1,\n",
    "    'versao_codigo': VERSAO_BLOCO1,\n",
    "    'data_versao': DATA_VERSAO,\n",
    "    'timestamp_execucao': timestamp,\n",
    "    'timestamp_registro': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'pasta_container': {\n",
    "        'nome': pasta_container.name,\n",
    "        'caminho': str(pasta_container),\n",
    "        'tamanho_mb': round(tamanho_total, 2)\n",
    "    },\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp,\n",
    "        'pastas_criadas': list(fm.pastas.keys())\n",
    "    },\n",
    "    'migracao': {\n",
    "        'realizada': resultado_origem.get('copiar', False),\n",
    "        'arquivos_migrados': info_mig.get('arquivos', 0),\n",
    "        'pasta_origem': str(resultado_origem.get('path', '')) if resultado_origem.get('copiar') else None\n",
    "    },\n",
    "    'localizador': {\n",
    "        'log_file': str(LocalizadorDicionario.LOG_FILE),\n",
    "        'pasta_base_registrada': str(pasta_container),\n",
    "        'timestamp_registrado': timestamp,\n",
    "        'dicionario_registrado': str(dicionario_existente) if dicionario_existente else None\n",
    "    },\n",
    "    'poluicao_root': {\n",
    "        'detectada': len(pastas_poluidas) if pastas_poluidas else 0,\n",
    "        'acao_tomada': acao if pastas_poluidas else 'NENHUMA'\n",
    "    },\n",
    "    'changelog': CHANGELOG_V44\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_1_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco1, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Estado local salvo\")\n",
    "print(f\"   ğŸ“„ {arquivo_estado.name}\")\n",
    "print(f\"   ğŸ“Š Tamanho container: {tamanho_total:.2f} MB\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 1 v4.4 CONCLUÃDO COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“‚ Container: {pasta_container}\")\n",
    "print(f\"ğŸ• Timestamp: {timestamp}\")\n",
    "print(f\"ğŸ“ Localizador: {LocalizadorDicionario.LOG_FILE}\")\n",
    "print(f\"ğŸ”– VersÃ£o: {VERSAO_BLOCO1}\")\n",
    "print(f\"\\nğŸ“‹ Estrutura criada:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   â€¢ {pasta.name}\")\n",
    "print(f\"\\nğŸ’¾ Arquivos de estado:\")\n",
    "print(f\"   â€¢ LOG GLOBAL: {LocalizadorDicionario.LOG_FILE.name}\")\n",
    "print(f\"   â€¢ Estado local: {arquivo_estado.name}\")\n",
    "print(f\"   â€¢ README: README.md\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nğŸ’¡ PrÃ³ximo: BLOCO 2 vai ler configuraÃ§Ã£o do LOG GLOBAL\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a370b26a4e017376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " ğŸ” PROCESSADOR DE ARQUIVOS DESCONHECIDOS v4.4\n",
      "======================================================================\n",
      " VersÃ£o: 4.4 | Data: 2025-10-17\n",
      " Timer | MigraÃ§Ã£o | DicionÃ¡rios | ValidaÃ§Ãµes | Logs | Estado\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Validando dependÃªncias...\n",
      "   âœ… pandas\n",
      "   âœ… numpy\n",
      "   âœ… openpyxl\n",
      "   âœ… xlrd\n",
      "   âœ… tkinter\n",
      "âœ… Todas as dependÃªncias instaladas!\n",
      "\n",
      "âœ… Imports carregados\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 1: SELECIONANDO PASTA DESTINO...\n",
      "======================================================================\n",
      "\n",
      "âœ… Destino: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\n",
      "   AÃ§Ã£o: MANTEVE\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 2: VERIFICANDO POLUIÃ‡ÃƒO NO ROOT...\n",
      "======================================================================\n",
      "âœ… Root limpo\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 3: CRIANDO PASTA CONTAINER...\n",
      "======================================================================\n",
      "âœ… Container: PROCESSAR_ARQUIVOS_20251018_222445\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 4: COPIAR DE EXECUÃ‡ÃƒO ANTERIOR?\n",
      "======================================================================\n",
      "âœ… ComeÃ§ando do zero (sem cÃ³pia)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 5: INICIALIZANDO FILEMANAGER...\n",
      "======================================================================\n",
      "âœ… FileManager inicializado\n",
      "   ğŸ“‚ Container: PROCESSAR_ARQUIVOS_20251018_222445\n",
      "   ğŸ• Timestamp: 20251018_222445\n",
      "\n",
      "ğŸ“ Localizador atualizado:\n",
      "   Container: PROCESSAR_ARQUIVOS_20251018_222445\n",
      "   Timestamp: 20251018_222445\n",
      "   VersÃ£o BLOCO 1: 4.4\n",
      "   Log: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "ğŸ“– README: README.md\n",
      "\n",
      "======================================================================\n",
      "ğŸ”µ ETAPA 6: SALVANDO ESTADO LOCAL...\n",
      "======================================================================\n",
      "âœ… Estado local salvo\n",
      "   ğŸ“„ .bloco_1_state.json\n",
      "   ğŸ“Š Tamanho container: 0.00 MB\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 1 v4.4 CONCLUÃDO COM SUCESSO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Container: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251018_222445\n",
      "ğŸ• Timestamp: 20251018_222445\n",
      "ğŸ“ Localizador: C:\\Users\\fpsou\\.processador_dicionario_localizador.json\n",
      "ğŸ”– VersÃ£o: 4.4\n",
      "\n",
      "ğŸ“‹ Estrutura criada:\n",
      "   â€¢ 01_Entrada\n",
      "   â€¢ 02_Processados\n",
      "   â€¢ 03_Outputs\n",
      "   â€¢ 04_Logs\n",
      "   â€¢ 05_Dicionarios\n",
      "   â€¢ 06_Codigos_Integracao\n",
      "\n",
      "ğŸ’¾ Arquivos de estado:\n",
      "   â€¢ LOG GLOBAL: .processador_dicionario_localizador.json\n",
      "   â€¢ Estado local: .bloco_1_state.json\n",
      "   â€¢ README: README.md\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 2 vai ler configuraÃ§Ã£o do LOG GLOBAL\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:24:47.600831Z",
     "start_time": "2025-10-19T01:24:47.571960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 2: CLASSES AUXILIARES\n",
    "# Versao: 4.3 - REVISADO (COMUNICACAO VIA LOG COMPLETA)\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: LocalizadorDicionario (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class LocalizadorDicionario:\n",
    "    \"\"\"\n",
    "    Sistema de localizacao persistente de dicionarios entre\n",
    "    sessoes.\n",
    "\n",
    "    Mantem log global em: ~/.processador_dicionario_localizador.json\n",
    "    \"\"\"\n",
    "\n",
    "    LOG_FILE = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "    @classmethod\n",
    "    def carregar_log(cls):\n",
    "        \"\"\"Carrega log global com fallback para encoding\"\"\"\n",
    "        if cls.LOG_FILE.exists():\n",
    "            for encoding in ['utf-8', 'utf-8-sig', 'latin-1']:\n",
    "                try:\n",
    "                    with open(cls.LOG_FILE, 'r', encoding=encoding) as f:\n",
    "                        return json.load(f)\n",
    "                except (UnicodeDecodeError, json.JSONDecodeError):\n",
    "                    continue\n",
    "        return {\n",
    "            'versao': '2.0',\n",
    "            'dicionario_atual': None,\n",
    "            'pasta_base_atual': None,\n",
    "            'historico': []\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def obter_dicionario_atual(cls):\n",
    "        \"\"\"Retorna Path do dicionario atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['dicionario_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Dicionario nao encontrado! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        dicionario_path = Path(log['dicionario_atual'])\n",
    "        if not dicionario_path.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Dicionario nao existe: {dicionario_path}\"\n",
    "            )\n",
    "\n",
    "        return dicionario_path\n",
    "\n",
    "    @classmethod\n",
    "    def obter_pasta_base_atual(cls):\n",
    "        \"\"\"Retorna Path da pasta base atual\"\"\"\n",
    "        log = cls.carregar_log()\n",
    "        if not log['pasta_base_atual']:\n",
    "            raise FileNotFoundError(\n",
    "                \"Pasta base nao encontrada! Execute BLOCO 1.\"\n",
    "            )\n",
    "\n",
    "        pasta_base = Path(log['pasta_base_atual'])\n",
    "        if not pasta_base.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Pasta base nao existe: {pasta_base}\"\n",
    "            )\n",
    "\n",
    "        return pasta_base\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: FileManagerInterativo (INTEGRADA DO BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos e estrutura de pastas\"\"\"\n",
    "\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "\n",
    "        # Estrutura de pastas padrao\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos_integracao': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "        # Criar todas as pastas\n",
    "        for pasta in self.pastas.values():\n",
    "            pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    def salvar(self, df, nome, tipo='xlsx', pasta='processados'):\n",
    "        \"\"\"Salva DataFrame na pasta especificada\"\"\"\n",
    "        arquivo = self.pastas[pasta] / f\"{nome}_{self.timestamp}.{tipo}\"\n",
    "\n",
    "        if tipo == 'xlsx':\n",
    "            df.to_excel(arquivo, index=False, engine='openpyxl')\n",
    "        elif tipo == 'csv':\n",
    "            df.to_csv(arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        return arquivo\n",
    "\n",
    "    def abrir_pasta(self, pasta):\n",
    "        \"\"\"Abre pasta no explorer do sistema\"\"\"\n",
    "        caminho = self.pastas[pasta]\n",
    "        sistema = platform.system()\n",
    "\n",
    "        try:\n",
    "            if sistema == 'Windows':\n",
    "                os.startfile(caminho)\n",
    "            elif sistema == 'Darwin':  # macOS\n",
    "                subprocess.run(['open', caminho])\n",
    "            else:  # Linux\n",
    "                subprocess.run(['xdg-open', caminho])\n",
    "        except Exception as e:\n",
    "            print(f\"Nao foi possivel abrir pasta: {e}\")\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: SeletorArquivo (GUI COM TIMER E VALIDACOES)\n",
    "# ===================================================================\n",
    "\n",
    "class SeletorArquivo:\n",
    "    \"\"\"Seletor de arquivo com timer de 10s e validacoes robustas\"\"\"\n",
    "\n",
    "    CONFIG_FILE = Path.home() / '.processador_last_file.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.resultado = {'path': None, 'acao': None}\n",
    "        self.timeout_ocorreu = False\n",
    "\n",
    "    def carregar_ultimo_arquivo(self):\n",
    "        \"\"\"Carrega ultimo arquivo usado\"\"\"\n",
    "        if self.CONFIG_FILE.exists():\n",
    "            try:\n",
    "                with open(self.CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                ultimo_arquivo = Path(config.get('last_file', ''))\n",
    "                if ultimo_arquivo.exists():\n",
    "                    return ultimo_arquivo\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def salvar_escolha(self, arquivo):\n",
    "        \"\"\"Salva escolha para proxima execucao\"\"\"\n",
    "        config = {\n",
    "            'last_file': str(arquivo),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "\n",
    "    def validar_arquivo(self, arquivo_path):\n",
    "        \"\"\"Valida se arquivo e adequado para processamento\"\"\"\n",
    "        arquivo = Path(arquivo_path)\n",
    "\n",
    "        # Verificar existencia\n",
    "        if not arquivo.exists():\n",
    "            return False, \"Arquivo nao existe\"\n",
    "\n",
    "        # Verificar se e arquivo (nao diretorio)\n",
    "        if not arquivo.is_file():\n",
    "            return False, \"Nao e um arquivo\"\n",
    "\n",
    "        # Verificar permissao de leitura\n",
    "        if not os.access(arquivo, os.R_OK):\n",
    "            return False, \"Sem permissao de leitura\"\n",
    "\n",
    "        # Verificar tamanho (maximo 500MB)\n",
    "        tamanho_mb = arquivo.stat().st_size / (1024 * 1024)\n",
    "        if tamanho_mb > 500:\n",
    "            return False, f\"Arquivo muito grande ({tamanho_mb:.1f}MB)\"\n",
    "\n",
    "        # Verificar extensao\n",
    "        extensoes_validas = {'.xlsx', '.xls', '.csv', '.txt'}\n",
    "        if arquivo.suffix.lower() not in extensoes_validas:\n",
    "            return False, f\"Extensao invalida ({arquivo.suffix})\"\n",
    "\n",
    "        return True, \"Arquivo valido\"\n",
    "\n",
    "    def selecionar_com_timer(self):\n",
    "        \"\"\"Exibe GUI com timer de 10s\"\"\"\n",
    "        ultimo_arquivo = self.carregar_ultimo_arquivo()\n",
    "\n",
    "        root = tk.Tk()\n",
    "        root.title(\"Processador - Selecionar Arquivo\")\n",
    "        root.geometry(\"650x450\")\n",
    "\n",
    "        # Centralizar janela\n",
    "        x = (root.winfo_screenwidth() // 2) - 325\n",
    "        y = (root.winfo_screenheight() // 2) - 225\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Titulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecionar Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Mensagem\n",
    "        if ultimo_arquivo:\n",
    "            msg = f\"Timer de 10s para usar:\\n\\n{ultimo_arquivo.name}\"\n",
    "        else:\n",
    "            msg = \"Primeira execucao - selecione arquivo\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=msg,\n",
    "            justify=tk.LEFT,\n",
    "            font=('Arial', 9),\n",
    "            bg='white',\n",
    "            wraplength=600\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        # Timer\n",
    "        contador = [15]\n",
    "        if ultimo_arquivo:\n",
    "            label_timer = tk.Label(\n",
    "                frame,\n",
    "                text=f\"{contador[0]}s\",\n",
    "                font=('Arial', 24, 'bold'),\n",
    "                fg='#FF4444',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_timer.pack(pady=(5, 20))\n",
    "\n",
    "            def countdown():\n",
    "                if contador[0] > 0 and not self.timeout_ocorreu:\n",
    "                    contador[0] -= 1\n",
    "                    label_timer.config(text=f\"{contador[0]}s\")\n",
    "                    root.after(1000, countdown)\n",
    "                elif contador[0] == 0:\n",
    "                    self.timeout_ocorreu = True\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'TIMEOUT'\n",
    "                    root.quit()\n",
    "                    root.destroy()\n",
    "\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        # Botoes\n",
    "        def escolher_novo():\n",
    "            self.timeout_ocorreu = True\n",
    "            root.withdraw()\n",
    "\n",
    "            novo_arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecionar Arquivo\",\n",
    "                initialdir=ultimo_arquivo.parent if ultimo_arquivo else None,\n",
    "                filetypes=[\n",
    "                    (\"Arquivos suportados\", \"*.xlsx;*.xls;*.csv;*.txt\"),\n",
    "                    (\"Excel\", \"*.xlsx;*.xls\"),\n",
    "                    (\"CSV\", \"*.csv\"),\n",
    "                    (\"Todos\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if novo_arquivo:\n",
    "                valido, msg = self.validar_arquivo(novo_arquivo)\n",
    "                if not valido:\n",
    "                    messagebox.showerror(\"Arquivo Invalido\", msg)\n",
    "                    self.resultado['path'] = ultimo_arquivo\n",
    "                    self.resultado['acao'] = 'CANCELADO'\n",
    "                else:\n",
    "                    self.resultado['path'] = Path(novo_arquivo)\n",
    "                    self.resultado['acao'] = 'NOVO'\n",
    "            else:\n",
    "                self.resultado['path'] = ultimo_arquivo\n",
    "                self.resultado['acao'] = 'CANCELADO'\n",
    "\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultimo():\n",
    "            self.timeout_ocorreu = True\n",
    "            self.resultado['path'] = ultimo_arquivo\n",
    "            self.resultado['acao'] = 'MANTEVE'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=15)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=20,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white'\n",
    "        ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        if ultimo_arquivo:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"Usar Ultimo\",\n",
    "                command=usar_ultimo,\n",
    "                width=20,\n",
    "                height=2,\n",
    "                font=('Arial', 10),\n",
    "                bg='#2196F3',\n",
    "                fg='white'\n",
    "            ).pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        root.mainloop()\n",
    "        return self.resultado\n",
    "\n",
    "# ===================================================================\n",
    "# CLASSE: DetectorCabecalho (ANALISE INTELIGENTE COM LOG)\n",
    "# ===================================================================\n",
    "\n",
    "class DetectorCabecalho:\n",
    "    \"\"\"\n",
    "    Detecta automaticamente a linha de cabecalho em arquivos.\n",
    "\n",
    "    Usa sistema de scoring baseado em:\n",
    "    - Preenchimento (70%+ colunas com dados)\n",
    "    - Tipo String (80%+ colunas texto)\n",
    "    - Valores unicos (indicador de rotulos)\n",
    "    - Palavras-chave tipicas de cabecalho\n",
    "    - Posicao na planilha (primeiras linhas tem prioridade)\n",
    "    \"\"\"\n",
    "\n",
    "    # CONFIGURACAO EXTERNALIZAVEL\n",
    "    PALAVRAS_CHAVE_PADRAO = [\n",
    "        'codigo', 'nome', 'descri', 'data', 'valor', 'quantidade',\n",
    "        'centro', 'produto', 'material', 'sigla', 'tipo', 'grupo'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, df, palavras_chave=None):\n",
    "        self.df = df\n",
    "        self.scores = []\n",
    "        self.log_decisoes = []\n",
    "        self.palavras_chave = (\n",
    "            palavras_chave if palavras_chave\n",
    "            else self.PALAVRAS_CHAVE_PADRAO\n",
    "        )\n",
    "\n",
    "    def detectar(self, n_linhas=50):\n",
    "        \"\"\"\n",
    "        Analisa primeiras n linhas e retorna indice do cabecalho.\n",
    "\n",
    "        Args:\n",
    "            n_linhas: Numero de linhas a analisar\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                'indice': int,  # Linha detectada como cabecalho\n",
    "                'score': float,  # Confianca da deteccao (0-1)\n",
    "                'metodo': str,   # Como foi detectado\n",
    "                'scores_todas_linhas': list,  # Para debug\n",
    "                'log_decisoes': list  # Historico de analise\n",
    "            }\n",
    "        \"\"\"\n",
    "        n_linhas = min(n_linhas, len(self.df))\n",
    "\n",
    "        for i in range(n_linhas):\n",
    "            linha = self.df.iloc[i]\n",
    "            score = 0\n",
    "            detalhes = {'linha': i, 'criterios': {}}\n",
    "\n",
    "            # Criterio 1: Preenchimento (30 pontos)\n",
    "            preenchimento = linha.notna().sum() / len(linha)\n",
    "            if preenchimento >= 0.7:\n",
    "                pontos = 30 * (preenchimento - 0.7) / 0.3\n",
    "                score += pontos\n",
    "                detalhes['criterios']['preenchimento'] = (\n",
    "                    f\"{preenchimento:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 2: Tipo String (30 pontos)\n",
    "            tipos_string = sum(isinstance(v, str) for v in linha)\n",
    "            proporcao_string = tipos_string / len(linha)\n",
    "            if proporcao_string >= 0.8:\n",
    "                pontos = 30 * (proporcao_string - 0.8) / 0.2\n",
    "                score += pontos\n",
    "                detalhes['criterios']['strings'] = (\n",
    "                    f\"{proporcao_string:.1%} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 3: Valores unicos (20 pontos)\n",
    "            valores_unicos = len(\n",
    "                set(str(v) for v in linha if pd.notna(v))\n",
    "            )\n",
    "            if valores_unicos >= len(linha) * 0.8:\n",
    "                pontos = 20\n",
    "                score += pontos\n",
    "                detalhes['criterios']['unicos'] = (\n",
    "                    f\"{valores_unicos}/{len(linha)} (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 4: Palavras-chave (10 pontos)\n",
    "            texto_linha = ' '.join(\n",
    "                str(v).lower() for v in linha if pd.notna(v)\n",
    "            )\n",
    "            palavras_encontradas = sum(\n",
    "                1 for p in self.palavras_chave if p in texto_linha\n",
    "            )\n",
    "            if palavras_encontradas > 0:\n",
    "                pontos = min(10, palavras_encontradas * 3)\n",
    "                score += pontos\n",
    "                detalhes['criterios']['palavras'] = (\n",
    "                    f\"{palavras_encontradas} palavras (+{pontos})\"\n",
    "                )\n",
    "\n",
    "            # Criterio 5: Posicao (10 pontos)\n",
    "            # Primeiras linhas tem vantagem\n",
    "            if i < 50:\n",
    "                pontos = 10 * (1 - (i / 50))\n",
    "                score += pontos\n",
    "                detalhes['criterios']['posicao'] = (\n",
    "                    f\"linha {i} (+{pontos:.1f})\"\n",
    "                )\n",
    "\n",
    "            detalhes['score_total'] = score\n",
    "            self.scores.append(score)\n",
    "            self.log_decisoes.append(detalhes)\n",
    "\n",
    "        # Encontrar melhor score\n",
    "        melhor_indice = self.scores.index(max(self.scores))\n",
    "        melhor_score = self.scores[melhor_indice]\n",
    "\n",
    "        # Normalizar score para 0-1\n",
    "        score_normalizado = min(1.0, melhor_score / 100)\n",
    "\n",
    "        resultado = {\n",
    "            'indice': melhor_indice,\n",
    "            'score': score_normalizado,\n",
    "            'metodo': 'SCORING_AUTOMATICO',\n",
    "            'scores_todas_linhas': self.scores,\n",
    "            'log_decisoes': self.log_decisoes\n",
    "        }\n",
    "\n",
    "        return resultado\n",
    "\n",
    "# ===================================================================\n",
    "# INICIALIZACAO DO FILEMANAGER (CONECTANDO COM BLOCO 1)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    pasta_base = LocalizadorDicionario.obter_pasta_base_atual()\n",
    "\n",
    "    print(f\"Container do BLOCO 1 encontrado!\")\n",
    "    print(f\"   {pasta_base}\")\n",
    "\n",
    "    fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n{e}\")\n",
    "    print(\"\\nATENCAO: Execute o BLOCO 1 primeiro!\")\n",
    "    raise\n",
    "\n",
    "# ===================================================================\n",
    "# SALVAR ESTADO DO BLOCO 2 NO LOG\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco2 = {\n",
    "    'bloco': 2,\n",
    "    'versao': '4.3',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'classes_carregadas': [\n",
    "        'LocalizadorDicionario',\n",
    "        'FileManagerInterativo',\n",
    "        'SeletorArquivo',\n",
    "        'DetectorCabecalho'\n",
    "    ],\n",
    "    'filemanager': {\n",
    "        'base_path': str(fm.base_path),\n",
    "        'timestamp': fm.timestamp\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_2_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco2, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 2 CONCLUIDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nClasses carregadas:\")\n",
    "print(\"   LocalizadorDicionario ........... OK\")\n",
    "print(\"   FileManagerInterativo ........... OK\")\n",
    "print(\"   SeletorArquivo .................. OK\")\n",
    "print(\"   DetectorCabecalho ............... OK\")\n",
    "print(\"\\nFileManager ativo:\")\n",
    "print(f\"   Base: {fm.base_path}\")\n",
    "print(f\"   Timestamp: {fm.timestamp}\")\n",
    "print(\"\\nEstrutura de pastas:\")\n",
    "for nome, pasta in fm.pastas.items():\n",
    "    print(f\"   {nome.ljust(20)}: {pasta.name}\")\n",
    "print(\"\\nEstado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\")\n",
    "print(\"=\"*70)"
   ],
   "id": "edd92dbd01fb89e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 2: CLASSES AUXILIARES v4.3 REVISADO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO FILEMANAGER - CONECTANDO COM BLOCO 1\n",
      "======================================================================\n",
      "Container do BLOCO 1 encontrado!\n",
      "   E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251018_222445\n",
      "\n",
      "======================================================================\n",
      "BLOCO 2 CONCLUIDO\n",
      "======================================================================\n",
      "\n",
      "Classes carregadas:\n",
      "   LocalizadorDicionario ........... OK\n",
      "   FileManagerInterativo ........... OK\n",
      "   SeletorArquivo .................. OK\n",
      "   DetectorCabecalho ............... OK\n",
      "\n",
      "FileManager ativo:\n",
      "   Base: E:\\OneDrive - VIBRA\\NMCV - Documentos\\Indicador\\_DataLake\\2- Dados Processados (PROCESSED)\\PROCESSAR_ARQUIVOS_20251018_222445\n",
      "   Timestamp: 20251018_222447\n",
      "\n",
      "Estrutura de pastas:\n",
      "   entrada             : 01_Entrada\n",
      "   processados         : 02_Processados\n",
      "   outputs             : 03_Outputs\n",
      "   logs                : 04_Logs\n",
      "   dicionarios         : 05_Dicionarios\n",
      "   codigos_integracao  : 06_Codigos_Integracao\n",
      "\n",
      "Estado salvo:\n",
      "   .bloco_2_state.json\n",
      "\n",
      "======================================================================\n",
      "Digite 'BLOCO 2 OK' para prosseguir ao BLOCO 3\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:03:50.108915Z",
     "start_time": "2025-10-19T01:03:50.075675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 3: DICIONÃRIO INTELIGENTE + CLASSE GUI COM TIMER\n",
    "# VersÃ£o: v5.0 - Com persistÃªncia completa de variÃ¡veis/objetos\n",
    "# MudanÃ§a v4.5 â†’ v5.0: Adiciona recuperaÃ§Ã£o de estado\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tkinter as tk\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 3: DICIONÃRIO INTELIGENTE + GUI COM TIMER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. LER CONFIGURAÃ‡Ã•ES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# ===================================================================\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ LOG GLOBAL nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\")\n",
    "print(f\"   ğŸ“ Pasta base: {pasta_base.name}\")\n",
    "print(f\"   ğŸ• Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. VALIDAR QUE BLOCO 2 FOI EXECUTADO\n",
    "# ===================================================================\n",
    "\n",
    "log_bloco2 = pasta_base / '04_Logs' / '.bloco_2_state.json'\n",
    "\n",
    "if not log_bloco2.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ BLOCO 2 nÃ£o foi executado!\\n\"\n",
    "        \"   Execute BLOCO 2 primeiro.\"\n",
    "    )\n",
    "\n",
    "with open(log_bloco2, 'r', encoding='utf-8') as f:\n",
    "    estado_bloco2 = json.load(f)\n",
    "\n",
    "print(f\"\\nâœ… BLOCO 2 VALIDADO\")\n",
    "print(f\"   Executado em: {estado_bloco2['timestamp']}\")\n",
    "print(f\"   Classes: {', '.join(estado_bloco2['classes_carregadas'])}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. RECUPERAR/RECRIAR FILEMANAGER (0% MEMÃ“RIA, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECUPERAÃ‡ÃƒO DE ESTADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class FileManagerInterativo:\n",
    "    \"\"\"Gerenciador de arquivos\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.pastas = {\n",
    "            'entrada': self.base_path / '01_Entrada',\n",
    "            'processados': self.base_path / '02_Processados',\n",
    "            'outputs': self.base_path / '03_Outputs',\n",
    "            'logs': self.base_path / '04_Logs',\n",
    "            'dicionarios': self.base_path / '05_Dicionarios',\n",
    "            'codigos': self.base_path / '06_Codigos_Integracao'\n",
    "        }\n",
    "\n",
    "# Tentar recuperar fm da memÃ³ria OU recriar\n",
    "try:\n",
    "    _ = fm.base_path\n",
    "    print(\"âœ… FileManager jÃ¡ existe na memÃ³ria\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸  FileManager nÃ£o encontrado - recriando...\")\n",
    "    fm = FileManagerInterativo(pasta_base)\n",
    "    print(f\"âœ… FileManager recriado: {fm.base_path.name}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4. CLASSE GUI COM TIMER - PERSISTIDA EM ARQUIVO\n",
    "# ===================================================================\n",
    "\n",
    "arquivo_gui = pasta_base / '04_Logs' / '.bloco_3_gui_timer.py'\n",
    "\n",
    "# Salvar cÃ³digo da classe para importaÃ§Ã£o futura\n",
    "codigo_gui = '''import tkinter as tk\n",
    "\n",
    "class GUIComTimer:\n",
    "    \"\"\"Implementa timer de 10s com countdown visual\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_janela_com_timer(titulo, largura, altura, tem_timer=True):\n",
    "        \"\"\"Cria janela base com timer\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.title(titulo)\n",
    "        root.geometry(f\"{largura}x{altura}\")\n",
    "        root.resizable(False, False)\n",
    "\n",
    "        # Centralizar\n",
    "        x = (root.winfo_screenwidth() // 2) - (largura // 2)\n",
    "        y = (root.winfo_screenheight() // 2) - (altura // 2)\n",
    "        root.geometry(f\"+{x}+{y}\")\n",
    "        root.attributes('-topmost', True)\n",
    "        root.after(100, lambda: root.attributes('-topmost', False))\n",
    "\n",
    "        frame = tk.Frame(root, padx=20, pady=20, bg='white')\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        resultado = {'valor': None, 'cancelado': False, 'timeout': False}\n",
    "        contador = [10] if tem_timer else [0]\n",
    "\n",
    "        return root, frame, resultado, contador\n",
    "\n",
    "    @staticmethod\n",
    "    def adicionar_timer(frame, root, resultado, contador):\n",
    "        \"\"\"Adiciona timer visual\"\"\"\n",
    "        label_timer = tk.Label(\n",
    "            frame,\n",
    "            text=f\"â±ï¸  {contador[0]}s\",\n",
    "            font=('Arial', 16, 'bold'),\n",
    "            fg='#FF4444',\n",
    "            bg='white'\n",
    "        )\n",
    "        label_timer.pack(pady=(5, 15))\n",
    "\n",
    "        def countdown():\n",
    "            if contador[0] > 0 and not resultado['cancelado']:\n",
    "                contador[0] -= 1\n",
    "                label_timer.config(text=f\"â±ï¸  {contador[0]}s\")\n",
    "                root.after(1000, countdown)\n",
    "            elif contador[0] == 0 and not resultado['cancelado']:\n",
    "                resultado['timeout'] = True\n",
    "                root.quit()\n",
    "                root.destroy()\n",
    "\n",
    "        return countdown\n",
    "\n",
    "    @staticmethod\n",
    "    def criar_botoes(frame, cmd_principal, cmd_secundario=None,\n",
    "                     label_principal=\"Confirmar\",\n",
    "                     label_secundario=\"Usar Ãšltimo\"):\n",
    "        \"\"\"Cria botÃµes padronizados\"\"\"\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(\n",
    "            fill=tk.X, pady=10\n",
    "        )\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=label_principal,\n",
    "            command=cmd_principal,\n",
    "            width=18,\n",
    "            height=2,\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        if cmd_secundario:\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=label_secundario,\n",
    "                command=cmd_secundario,\n",
    "                width=18,\n",
    "                height=2,\n",
    "                bg='#2196F3',\n",
    "                fg='white',\n",
    "                font=('Arial', 10),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "'''\n",
    "\n",
    "# Salvar classe em arquivo\n",
    "with open(arquivo_gui, 'w', encoding='utf-8') as f:\n",
    "    f.write(codigo_gui)\n",
    "\n",
    "# Tentar importar classe OU definir localmente\n",
    "try:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location(\"gui_timer\", arquivo_gui)\n",
    "    modulo_gui = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(modulo_gui)\n",
    "    GUIComTimer = modulo_gui.GUIComTimer\n",
    "    print(\"âœ… Classe GUIComTimer importada de arquivo\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erro ao importar ({e}), definindo localmente...\")\n",
    "    exec(codigo_gui)\n",
    "    print(\"âœ… Classe GUIComTimer definida localmente\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. DICIONÃRIO INTELIGENTE\n",
    "# ===================================================================\n",
    "\n",
    "class DicionarioInteligente:\n",
    "    \"\"\"DicionÃ¡rio com detecÃ§Ã£o avanÃ§ada\"\"\"\n",
    "\n",
    "    def __init__(self, fm):\n",
    "        self.fm = fm\n",
    "        self.arquivo_dict = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "        self.dados = self._carregar_ou_criar()\n",
    "\n",
    "    def _carregar_ou_criar(self):\n",
    "        if self.arquivo_dict.exists():\n",
    "            try:\n",
    "                with open(self.arquivo_dict, 'r', encoding='utf-8') as f:\n",
    "                    dados = json.load(f)\n",
    "\n",
    "                if 'campos_conhecidos' not in dados:\n",
    "                    dados = self._migrar_formato_antigo(dados)\n",
    "                    self._salvar(dados)\n",
    "\n",
    "                n_campos = len(dados['campos_conhecidos'])\n",
    "                n_arquivos = len(dados.get('historico_arquivos', []))\n",
    "\n",
    "                print(f\"\\nâœ… DICIONÃRIO PERSISTENTE CARREGADO\")\n",
    "                print(f\"   ğŸ“š {n_campos} campos conhecidos\")\n",
    "                print(f\"   ğŸ“ {n_arquivos} arquivos processados\")\n",
    "\n",
    "                return dados\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nâš ï¸  Erro ao carregar: {e}\")\n",
    "                print(\"   Criando novo dicionÃ¡rio...\")\n",
    "                dados = self._criar_novo()\n",
    "                self._salvar(dados)\n",
    "                return dados\n",
    "        else:\n",
    "            print(f\"\\nğŸ“ CRIANDO NOVO DICIONÃRIO...\")\n",
    "            dados = self._criar_novo()\n",
    "            self._salvar(dados)\n",
    "            print(f\"âœ… DicionÃ¡rio criado: {len(dados['campos_conhecidos'])} campos\")\n",
    "            return dados\n",
    "\n",
    "    def _migrar_formato_antigo(self, dados_antigos):\n",
    "        novo = self._criar_novo()\n",
    "        if 'arquivos_processados' in dados_antigos:\n",
    "            novo['historico_arquivos'] = dados_antigos['arquivos_processados']\n",
    "        return novo\n",
    "\n",
    "    def _criar_novo(self):\n",
    "        \"\"\"DicionÃ¡rio com 22 campos padrÃ£o\"\"\"\n",
    "        return {\n",
    "            'versao': '5.0',\n",
    "            'criado_em': datetime.now().isoformat(),\n",
    "            'ultima_atualizacao': datetime.now().isoformat(),\n",
    "            'config_sistema': {\n",
    "                'timeout_sessao_minutos': 60,\n",
    "                'padroes_csv_detectados': []\n",
    "            },\n",
    "            'campos_conhecidos': {\n",
    "                'Centro': {\n",
    "                    'tipo_dado': 'Codigo_Centro',\n",
    "                    'regex': r'^[5-9]\\d{3}$',\n",
    "                    'sinonimos': ['Centro', 'CÃ³digo de Centro', 'Cod Centro',\n",
    "                                  'Unidade Operacional:Centro'],\n",
    "                    'exemplos': ['5025', '5065', '5174'],\n",
    "                    'descricao': 'CÃ³digo numÃ©rico de 4 dÃ­gitos',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla': {\n",
    "                    'tipo_dado': 'Sigla_Base',\n",
    "                    'regex': r'^[A-Z]{4,10}$',\n",
    "                    'sinonimos': ['Sigla', 'Sigla Base', 'Sigla Centro', 'Base'],\n",
    "                    'exemplos': ['BABET', 'BAPLAN', 'AIBET'],\n",
    "                    'descricao': 'Sigla alfabÃ©tica (4-10 letras maiÃºsculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Material',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$',\n",
    "                    'sinonimos': ['CÃ³digo Produto', 'CÃ³digo Material',\n",
    "                                  'Cod Produto', 'Cod Material'],\n",
    "                    'exemplos': ['10.123.456', '1.234.567', '1234567'],\n",
    "                    'descricao': 'CÃ³digo numÃ©rico do material/produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Codigo_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Codigo_Grupo',\n",
    "                    'regex': r'^\\d{1,2}\\.\\d{3}\\.\\d{3}$|^\\d{7,8}$|^[A-Z_]+$',\n",
    "                    'sinonimos': ['CÃ³d Grupo de produto', 'CÃ³digo Grupo',\n",
    "                                  'Grupo Produto', 'Produto:CodGrupoProduto'],\n",
    "                    'exemplos': ['10.123.456', 'DIESEL_S10_SIMPLES',\n",
    "                                 'GASOLINA_COMUM'],\n",
    "                    'descricao': 'CÃ³digo grupo (numÃ©rico OU texto_underscore)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Desc_Grupo_Produto': {\n",
    "                    'tipo_dado': 'Texto_Descricao',\n",
    "                    'regex': r'^[A-Za-z0-9\\s\\-]+$',\n",
    "                    'sinonimos': ['Desc. Grupo de Produto', 'DescriÃ§Ã£o Produto',\n",
    "                                  'Nome Produto', 'Produto'],\n",
    "                    'exemplos': ['DIESEL S10', 'GASOLINA COMUM',\n",
    "                                 'ETANOL HIDRATADO'],\n",
    "                    'descricao': 'DescriÃ§Ã£o textual do grupo de produto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Nome_Pessoa': {\n",
    "                    'tipo_dado': 'Texto_Nome_Pessoa',\n",
    "                    'regex': r'^[A-ZÃÃ€Ã‚ÃƒÃ‰ÃˆÃŠÃÃÃ“Ã”Ã•Ã–ÃšÃ‡Ã‘][a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]+(\\s[A-ZÃÃ€Ã‚ÃƒÃ‰ÃˆÃŠÃÃÃ“Ã”Ã•Ã–ÃšÃ‡Ã‘][a-zÃ¡Ã Ã¢Ã£Ã©Ã¨ÃªÃ­Ã¯Ã³Ã´ÃµÃ¶ÃºÃ§Ã±]+)+$',\n",
    "                    'sinonimos': ['Criado por', 'Nome', 'ResponsÃ¡vel',\n",
    "                                  'Solicitante'],\n",
    "                    'exemplos': ['Kenedy VinÃ­cius Rodrigues',\n",
    "                                 'Joao Carlos Stival'],\n",
    "                    'descricao': 'Nome completo de pessoa',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Email': {\n",
    "                    'tipo_dado': 'Texto_Email',\n",
    "                    'regex': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n",
    "                    'sinonimos': ['Email', 'E-mail', 'Modificado por'],\n",
    "                    'exemplos': ['usuario@vibraenergia.com.br'],\n",
    "                    'descricao': 'EndereÃ§o de email',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Status_Workflow': {\n",
    "                    'tipo_dado': 'Texto_Status',\n",
    "                    'regex': r'^(Em aprovaÃ§Ã£o|Aprovado|Rejeitado|Pendente|ConcluÃ­do|Ãtem Criado|Item Criado)$',\n",
    "                    'sinonimos': ['Status', 'Status AprovaÃ§Ã£o', 'SituaÃ§Ã£o'],\n",
    "                    'exemplos': ['Em aprovaÃ§Ã£o', 'Ãtem Criado', 'Aprovado'],\n",
    "                    'descricao': 'Status de workflow/aprovaÃ§Ã£o',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Booleano_Texto': {\n",
    "                    'tipo_dado': 'Texto_Booleano',\n",
    "                    'regex': r'^(Sim|NÃ£o|sim|nÃ£o|SIM|NÃƒO|Yes|No|TRUE|FALSE)$',\n",
    "                    'sinonimos': ['ConcluÃ­do?', 'Ativo?', 'Habilitado?'],\n",
    "                    'exemplos': ['Sim', 'NÃ£o'],\n",
    "                    'descricao': 'Valor booleano como texto',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Texto_Longo': {\n",
    "                    'tipo_dado': 'Texto_Justificativa',\n",
    "                    'regex': r'^.{50,}$',\n",
    "                    'sinonimos': ['Justificativa', 'ObservaÃ§Ã£o', 'ComentÃ¡rio'],\n",
    "                    'exemplos': ['Solicitamos a revisÃ£o do limite...'],\n",
    "                    'descricao': 'Texto longo (mais de 50 caracteres)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Path_URL': {\n",
    "                    'tipo_dado': 'Texto_Caminho',\n",
    "                    'regex': r'^(teams/|http|https|ftp|\\\\\\\\|/).*',\n",
    "                    'sinonimos': ['Caminho', 'Path', 'URL', 'Link'],\n",
    "                    'exemplos': ['teams/portaleso/Lists/...',\n",
    "                                 'https://example.com'],\n",
    "                    'descricao': 'Caminho de arquivo ou URL',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Sigla_Curta': {\n",
    "                    'tipo_dado': 'Texto_Sigla_Curta',\n",
    "                    'regex': r'^[A-Z]{2,4}$',\n",
    "                    'sinonimos': ['CME', 'GerÃªncia', 'UF', 'Tipo'],\n",
    "                    'exemplos': ['OPC', 'OPN', 'Norte', 'Sul', 'CME'],\n",
    "                    'descricao': 'Sigla curta (2-4 letras maiÃºsculas)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Tipo_Item': {\n",
    "                    'tipo_dado': 'Texto_Tipo_Item',\n",
    "                    'regex': r'^(Item|Documento|Pasta|Arquivo)$',\n",
    "                    'sinonimos': ['Tipo de Item', 'Tipo'],\n",
    "                    'exemplos': ['Item'],\n",
    "                    'descricao': 'Tipo de item em lista SharePoint',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_ISO': {\n",
    "                    'tipo_dado': 'Data_YYYY-MM-DD',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}$',\n",
    "                    'sinonimos': ['Data', 'PerÃ­odo',\n",
    "                                  'PerÃ­odo InÃ­cio Validade Novo Limite'],\n",
    "                    'exemplos': ['2025-08-01', '2024-12-31', '2025-01-07'],\n",
    "                    'descricao': 'Data formato ISO (YYYY-MM-DD)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Datetime_ISO': {\n",
    "                    'tipo_dado': 'Datetime_YYYY-MM-DD_HH:MM:SS',\n",
    "                    'regex': r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}$',\n",
    "                    'sinonimos': ['Criado', 'Modificado', 'Data Hora',\n",
    "                                  'Timestamp'],\n",
    "                    'exemplos': ['2025-08-04 19:22:17',\n",
    "                                 '2025-08-04 20:45:37'],\n",
    "                    'descricao': 'Data e hora formato ISO',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Data_BR': {\n",
    "                    'tipo_dado': 'Data_DD/MM/YYYY',\n",
    "                    'regex': r'^\\d{2}/\\d{2}/\\d{4}$',\n",
    "                    'sinonimos': ['Data'],\n",
    "                    'exemplos': ['15/01/2024', '31/12/2025'],\n",
    "                    'descricao': 'Data formato brasileiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Decimal': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Decimal',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?$',\n",
    "                    'sinonimos': ['Limite Inferior Atual',\n",
    "                                  'Limite Superior Atual', 'AVG VI %',\n",
    "                                  '% VI', 'AVG VI % 2024 SAP'],\n",
    "                    'exemplos': ['-0.08', '0.08', '-0.14', '0.05', '-0.03'],\n",
    "                    'descricao': 'Percentual em decimal (pode ser negativo)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Percentual_Com_Simbolo': {\n",
    "                    'tipo_dado': 'Numero_Percentual_Simbolo',\n",
    "                    'regex': r'^-?\\d+(\\.\\d+)?%$',\n",
    "                    'sinonimos': ['Percentual', '% VI'],\n",
    "                    'exemplos': ['10.5%', '-5.2%', '100%'],\n",
    "                    'descricao': 'Percentual com sÃ­mbolo %',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Numero_Inteiro': {\n",
    "                    'tipo_dado': 'Numero_Inteiro',\n",
    "                    'regex': r'^-?\\d+$',\n",
    "                    'sinonimos': ['Quantidade', 'Qtd', 'Total'],\n",
    "                    'exemplos': ['123', '-456', '1000'],\n",
    "                    'descricao': 'NÃºmero inteiro',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Monetario': {\n",
    "                    'tipo_dado': 'Numero_Monetario',\n",
    "                    'regex': r'^R\\$\\s?-?\\d{1,3}(\\.\\d{3})*(,\\d{2})?$|^-?\\d+([.,]\\d{2})?$',\n",
    "                    'sinonimos': ['Valor', 'Custo', 'PreÃ§o', 'R$'],\n",
    "                    'exemplos': ['R$ 1.234,56', '1234.56'],\n",
    "                    'descricao': 'Valor monetÃ¡rio',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Unidade_Operacional_Nome': {\n",
    "                    'tipo_dado': 'Texto_Unidade_Operacional',\n",
    "                    'regex': r'^[A-Z]{4,10}\\s+Base\\s+de\\s+.+$',\n",
    "                    'sinonimos': ['Unidade Operacional', 'Nome Base'],\n",
    "                    'exemplos': ['BABET Base de Betim',\n",
    "                                 'BAPLAN Base de PaulÃ­nia'],\n",
    "                    'descricao': 'Nome completo da unidade operacional',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                },\n",
    "                'Rotulo_Retencao': {\n",
    "                    'tipo_dado': 'Texto_Rotulo_Vazio',\n",
    "                    'regex': r'^(NaN|nan|None|null|)$',\n",
    "                    'sinonimos': ['RÃ³tulo de retenÃ§Ã£o Aplicado'],\n",
    "                    'exemplos': ['NaN'],\n",
    "                    'descricao': 'Campo de rÃ³tulo (geralmente vazio)',\n",
    "                    'aprendido_de': 'PADRAO_INICIAL'\n",
    "                }\n",
    "            },\n",
    "            'historico_arquivos': []\n",
    "        }\n",
    "\n",
    "    def detectar_campo(self, coluna_nome, valores_amostra):\n",
    "        \"\"\"DetecÃ§Ã£o AVANÃ‡ADA com mÃºltiplas estratÃ©gias\"\"\"\n",
    "        valores_str = [str(v).strip() for v in valores_amostra\n",
    "                      if pd.notna(v) and str(v).strip() not in\n",
    "                      ['', 'nan', 'None']]\n",
    "\n",
    "        if not valores_str:\n",
    "            return {\n",
    "                'campo_detectado': 'VAZIO',\n",
    "                'confianca': 0.0,\n",
    "                'score_conteudo': 0.0,\n",
    "                'score_nome': 0.0,\n",
    "                'matches': 0,\n",
    "                'total': 0,\n",
    "                'ambiguidade': False,\n",
    "                'candidatos': [],\n",
    "                'metodo': 'VAZIO'\n",
    "            }\n",
    "\n",
    "        # HeurÃ­sticas especÃ­ficas\n",
    "        campo_heuristico = self._detectar_por_heuristica(\n",
    "            coluna_nome, valores_str\n",
    "        )\n",
    "\n",
    "        if campo_heuristico and campo_heuristico.get('confianca', 0) >= 0.85:\n",
    "            campo_heuristico.setdefault('score_nome', 0.0)\n",
    "            campo_heuristico.setdefault('score_conteudo',\n",
    "                                        campo_heuristico.get('confianca', 0.0))\n",
    "            campo_heuristico.setdefault('matches', len(valores_str))\n",
    "            campo_heuristico.setdefault('total', len(valores_str))\n",
    "            campo_heuristico.setdefault('ambiguidade', False)\n",
    "            campo_heuristico.setdefault('candidatos', [])\n",
    "            return campo_heuristico\n",
    "\n",
    "        # Match por regex\n",
    "        resultados_regex = []\n",
    "        for nome_campo, info in self.dados['campos_conhecidos'].items():\n",
    "            matches = sum(1 for v in valores_str\n",
    "                         if re.match(info['regex'], v))\n",
    "            score_conteudo = matches / len(valores_str)\n",
    "\n",
    "            score_nome = 0.0\n",
    "            for sinonimo in info['sinonimos']:\n",
    "                if sinonimo.lower() in coluna_nome.lower():\n",
    "                    score_nome = 0.3\n",
    "                    break\n",
    "\n",
    "            score_final = score_conteudo + score_nome\n",
    "\n",
    "            resultados_regex.append({\n",
    "                'campo': nome_campo,\n",
    "                'score': min(score_final, 1.0),\n",
    "                'score_conteudo': score_conteudo,\n",
    "                'score_nome': score_nome,\n",
    "                'matches': matches,\n",
    "                'total': len(valores_str)\n",
    "            })\n",
    "\n",
    "        resultados_regex = sorted(resultados_regex,\n",
    "                                 key=lambda x: x['score'],\n",
    "                                 reverse=True)\n",
    "        melhor_regex = resultados_regex[0]\n",
    "        segundo_regex = resultados_regex[1] if len(resultados_regex) > 1 else None\n",
    "\n",
    "        ambiguidade = False\n",
    "        candidatos = []\n",
    "        if segundo_regex and abs(melhor_regex['score'] -\n",
    "                                segundo_regex['score']) < 0.10:\n",
    "            ambiguidade = True\n",
    "            candidatos = [segundo_regex['campo']]\n",
    "\n",
    "        resultado_final = {\n",
    "            'campo_detectado': melhor_regex['campo'],\n",
    "            'confianca': melhor_regex['score'],\n",
    "            'score_conteudo': melhor_regex['score_conteudo'],\n",
    "            'score_nome': melhor_regex['score_nome'],\n",
    "            'matches': melhor_regex['matches'],\n",
    "            'total': melhor_regex['total'],\n",
    "            'ambiguidade': ambiguidade,\n",
    "            'candidatos': candidatos,\n",
    "            'metodo': 'REGEX'\n",
    "        }\n",
    "\n",
    "        if resultado_final['confianca'] < 0.50:\n",
    "            resultado_final['campo_detectado'] = 'DESCONHECIDO'\n",
    "\n",
    "        return resultado_final\n",
    "\n",
    "    def _detectar_por_heuristica(self, nome_coluna, valores_str):\n",
    "        \"\"\"DetecÃ§Ã£o por heurÃ­sticas especÃ­ficas\"\"\"\n",
    "        if not valores_str:\n",
    "            return None\n",
    "\n",
    "        tamanho_medio = sum(len(v) for v in valores_str) / len(valores_str)\n",
    "        valores_unicos = set(valores_str)\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}$', v) for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Data_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATA_ISO'}\n",
    "\n",
    "        if all(re.match(r'^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}:\\d{2}:\\d{2}', v)\n",
    "               for v in valores_str[:5]):\n",
    "            return {'campo_detectado': 'Datetime_ISO', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_DATETIME'}\n",
    "\n",
    "        if all('@' in v for v in valores_str):\n",
    "            return {'campo_detectado': 'Email', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_EMAIL'}\n",
    "\n",
    "        if 'limite' in nome_coluna.lower() or '%' in nome_coluna or 'vi' in nome_coluna.lower():\n",
    "            try:\n",
    "                valores_float = [float(v) for v in valores_str\n",
    "                                if v not in ['nan', '', 'None', 'NaN']]\n",
    "                if valores_float and all(-1 <= v <= 1 for v in valores_float):\n",
    "                    return {'campo_detectado': 'Percentual_Decimal',\n",
    "                           'confianca': 0.90,\n",
    "                           'metodo': 'HEURISTICA_PERCENTUAL'}\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if tamanho_medio > 50:\n",
    "            return {'campo_detectado': 'Texto_Longo', 'confianca': 0.85,\n",
    "                   'metodo': 'HEURISTICA_TEXTO_LONGO'}\n",
    "\n",
    "        if any(v.startswith(('teams/', 'http', 'https', '//', '\\\\\\\\'))\n",
    "               for v in valores_str):\n",
    "            return {'campo_detectado': 'Path_URL', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_PATH'}\n",
    "\n",
    "        if valores_unicos <= {'Sim', 'NÃ£o', 'sim', 'nÃ£o'}:\n",
    "            return {'campo_detectado': 'Booleano_Texto', 'confianca': 0.95,\n",
    "                   'metodo': 'HEURISTICA_BOOLEANO'}\n",
    "\n",
    "        if 'por' in nome_coluna.lower() or 'nome' in nome_coluna.lower():\n",
    "            if all(len(v.split()) >= 2 and '@' not in v\n",
    "                   for v in valores_str[:5]):\n",
    "                return {'campo_detectado': 'Nome_Pessoa', 'confianca': 0.85,\n",
    "                       'metodo': 'HEURISTICA_NOME'}\n",
    "\n",
    "        palavras_status = {'em aprovaÃ§Ã£o', 'aprovado', 'rejeitado',\n",
    "                          'Ã­tem criado', 'item criado', 'pendente'}\n",
    "        if any(v.lower() in palavras_status for v in valores_str):\n",
    "            return {'campo_detectado': 'Status_Workflow', 'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_STATUS'}\n",
    "\n",
    "        if 'base de' in ' '.join(valores_str[:3]).lower():\n",
    "            return {'campo_detectado': 'Unidade_Operacional_Nome',\n",
    "                   'confianca': 0.90,\n",
    "                   'metodo': 'HEURISTICA_UNIDADE_OP'}\n",
    "\n",
    "        return None\n",
    "\n",
    "    def atualizar_historico(self, info):\n",
    "        self.dados['historico_arquivos'].append(info)\n",
    "        self.dados['ultima_atualizacao'] = datetime.now().isoformat()\n",
    "        self._salvar(self.dados)\n",
    "\n",
    "    def _salvar(self, dados):\n",
    "        with open(self.arquivo_dict, 'w', encoding='utf-8') as f:\n",
    "            json.dump(dados, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ===================================================================\n",
    "# 6. RECUPERAR/RECRIAR DICIONÃRIO (0% MEMÃ“RIA, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INICIALIZANDO DICIONÃRIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Tentar recuperar dicionario da memÃ³ria OU recriar\n",
    "try:\n",
    "    _ = dicionario.dados\n",
    "    print(\"âœ… DicionarioInteligente jÃ¡ existe na memÃ³ria\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸  DicionarioInteligente nÃ£o encontrado - recriando...\")\n",
    "    dicionario = DicionarioInteligente(fm)\n",
    "\n",
    "# ===================================================================\n",
    "# 7. SALVAR ESTADO COMPLETO PARA PRÃ“XIMO BLOCO\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco3 = {\n",
    "    'bloco': 3,\n",
    "    'versao': '5.0',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'status': 'concluido',\n",
    "    'mudancas_v5': [\n",
    "        'Adiciona recuperaÃ§Ã£o automÃ¡tica de fm',\n",
    "        'Adiciona recuperaÃ§Ã£o automÃ¡tica de dicionario',\n",
    "        'Persiste classe GUIComTimer em arquivo .py',\n",
    "        'Documenta como recriar todos os objetos'\n",
    "    ],\n",
    "    'dicionario': {\n",
    "        'arquivo': str(dicionario.arquivo_dict),\n",
    "        'campos_conhecidos': len(dicionario.dados['campos_conhecidos']),\n",
    "        'arquivos_processados': len(dicionario.dados['historico_arquivos']),\n",
    "        'config_sistema': dicionario.dados.get('config_sistema', {})\n",
    "    },\n",
    "    'componentes_carregados': ['DicionarioInteligente', 'GUIComTimer'],\n",
    "    'persistencia': {\n",
    "        'gui_timer_arquivo': str(arquivo_gui),\n",
    "        'como_recriar_fm': {\n",
    "            'codigo': 'fm = FileManagerInterativo(pasta_base)',\n",
    "            'depende_de': ['pasta_base do LOG GLOBAL']\n",
    "        },\n",
    "        'como_recriar_dicionario': {\n",
    "            'codigo': 'dicionario = DicionarioInteligente(fm)',\n",
    "            'depende_de': ['fm', 'DICT_Dicionario_Persistente.json']\n",
    "        },\n",
    "        'como_importar_gui': {\n",
    "            'codigo': [\n",
    "                'import importlib.util',\n",
    "                'spec = importlib.util.spec_from_file_location(\"gui_timer\", arquivo_gui)',\n",
    "                'modulo_gui = importlib.util.module_from_spec(spec)',\n",
    "                'spec.loader.exec_module(modulo_gui)',\n",
    "                'GUIComTimer = modulo_gui.GUIComTimer'\n",
    "            ],\n",
    "            'depende_de': ['.bloco_3_gui_timer.py']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_3_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco3, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 3 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“‹ Componentes:\")\n",
    "print(\"   â€¢ DicionarioInteligente ........... âœ…\")\n",
    "n_campos = len(dicionario.dados['campos_conhecidos'])\n",
    "n_arquivos = len(dicionario.dados['historico_arquivos'])\n",
    "print(f\"     - Campos: {n_campos}\")\n",
    "print(f\"     - Arquivos: {n_arquivos}\")\n",
    "timeout = dicionario.dados.get('config_sistema', {}).get('timeout_sessao_minutos', 60)\n",
    "print(f\"     - Timeout: {timeout}min\")\n",
    "print(\"   â€¢ GUIComTimer ..................... âœ…\")\n",
    "print(\"\\nğŸ’¾ PersistÃªncia v5.0:\")\n",
    "print(\"   â€¢ .bloco_3_state.json ............. âœ…\")\n",
    "print(\"   â€¢ DICT_Dicionario_Persistente.json  âœ…\")\n",
    "print(\"   â€¢ .bloco_3_gui_timer.py ........... âœ… NOVO\")\n",
    "print(\"\\nğŸ”„ RecuperaÃ§Ã£o de estado:\")\n",
    "print(\"   â€¢ fm recriÃ¡vel .................... âœ…\")\n",
    "print(\"   â€¢ dicionario recriÃ¡vel ............ âœ…\")\n",
    "print(\"   â€¢ GUIComTimer importÃ¡vel .......... âœ…\")\n",
    "print(\"\\nğŸ’¡ PrÃ³ximo: BLOCO 4 seleciona arquivo de dados\")\n",
    "print(\"=\"*70)"
   ],
   "id": "67bda94dc68661ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BLOCO 3: DICIONÃRIO INTELIGENTE + GUI COM TIMER\n",
      "======================================================================\n",
      "\n",
      "âœ… CONFIGURAÃ‡ÃƒO CARREGADA DO LOG GLOBAL\n",
      "   ğŸ“ Pasta base: PROCESSAR_ARQUIVOS_20251018_220345\n",
      "   ğŸ• Timestamp: 20251018_220345\n",
      "\n",
      "âœ… BLOCO 2 VALIDADO\n",
      "   Executado em: 2025-10-18T22:03:48.053686\n",
      "   Classes: LocalizadorDicionario, FileManagerInterativo, SeletorArquivo, DetectorCabecalho\n",
      "\n",
      "======================================================================\n",
      "RECUPERAÃ‡ÃƒO DE ESTADO\n",
      "======================================================================\n",
      "âœ… FileManager jÃ¡ existe na memÃ³ria\n",
      "âœ… Classe GUIComTimer importada de arquivo\n",
      "\n",
      "======================================================================\n",
      "INICIALIZANDO DICIONÃRIO\n",
      "======================================================================\n",
      "âœ… DicionarioInteligente jÃ¡ existe na memÃ³ria\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 3 CONCLUÃDO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Componentes:\n",
      "   â€¢ DicionarioInteligente ........... âœ…\n",
      "     - Campos: 22\n",
      "     - Arquivos: 0\n",
      "     - Timeout: 60min\n",
      "   â€¢ GUIComTimer ..................... âœ…\n",
      "\n",
      "ğŸ’¾ PersistÃªncia v5.0:\n",
      "   â€¢ .bloco_3_state.json ............. âœ…\n",
      "   â€¢ DICT_Dicionario_Persistente.json  âœ…\n",
      "   â€¢ .bloco_3_gui_timer.py ........... âœ… NOVO\n",
      "\n",
      "ğŸ”„ RecuperaÃ§Ã£o de estado:\n",
      "   â€¢ fm recriÃ¡vel .................... âœ…\n",
      "   â€¢ dicionario recriÃ¡vel ............ âœ…\n",
      "   â€¢ GUIComTimer importÃ¡vel .......... âœ…\n",
      "\n",
      "ğŸ’¡ PrÃ³ximo: BLOCO 4 seleciona arquivo de dados\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:03:54.487906Z",
     "start_time": "2025-10-19T01:03:54.330186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 4 - SELEÃ‡ÃƒO DE ARQUIVO - SUPORTE MULTI-FORMATO (REVISADO v4.0)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PRINCÃPIO: 0% MEMÃ“RIA, 100% LOG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMUNICAÃ‡ÃƒO VIA LOG:\n",
    "# - LÃŠ: pasta_base (LOG global), timestamp, dicionÃ¡rio persistente\n",
    "# - RECRIA: FileManager localmente\n",
    "# - SALVA:\n",
    "#   1. Estado JSON (.bloco_4_state.json)\n",
    "#   2. VariÃ¡veis PKL (.bloco_4_vars.pkl)\n",
    "#   3. ConfiguraÃ§Ã£o arquivo (.ultimo_arquivo.json)\n",
    "#   4. Log de transformaÃ§Ãµes (.bloco_4_transformacoes.json)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BLOCO 4: SELEÃ‡ÃƒO DE ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. LER CONFIGURAÃ‡Ã•ES DO BLOCO ANTERIOR (VIA LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "log_global = Path.home() / '.processador_dicionario_localizador.json'\n",
    "\n",
    "if not log_global.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ LOG GLOBAL nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 1 primeiro para criar a estrutura.\"\n",
    "    )\n",
    "\n",
    "with open(log_global, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "pasta_base = Path(config['pasta_base_atual'])\n",
    "timestamp_execucao = config['timestamp']\n",
    "\n",
    "print(f\"\\nğŸ“‚ Pasta base carregada: {pasta_base.name}\")\n",
    "print(f\"â° Timestamp: {timestamp_execucao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. RECRIAR OBJETOS NECESSÃRIOS (NÃƒO ASSUMIR MEMÃ“RIA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Recriar FileManager\n",
    "fm = FileManagerInterativo(pasta_base)\n",
    "\n",
    "# Carregar dicionÃ¡rio persistente\n",
    "dict_file = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "\n",
    "if dict_file.exists():\n",
    "    with open(dict_file, 'r', encoding='utf-8') as f:\n",
    "        DICIONARIO_PERSISTENTE = json.load(f)\n",
    "    print(f\"ğŸ“š DicionÃ¡rio carregado: {len(DICIONARIO_PERSISTENTE.get('campos_conhecidos', {}))} campos\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ DicionÃ¡rio nÃ£o encontrado!\\n\"\n",
    "        \"   Execute BLOCO 3 primeiro.\"\n",
    "    )\n",
    "\n",
    "# Inicializar log de transformaÃ§Ãµes\n",
    "LOG_TRANSFORMACOES = {\n",
    "    'bloco': 4,\n",
    "    'inicio': datetime.now().isoformat(),\n",
    "    'operacoes': []\n",
    "}\n",
    "\n",
    "def registrar_operacao(tipo, descricao, dados=None):\n",
    "    \"\"\"Registra operaÃ§Ã£o no log de transformaÃ§Ãµes\"\"\"\n",
    "    operacao = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'tipo': tipo,\n",
    "        'descricao': descricao\n",
    "    }\n",
    "    if dados:\n",
    "        operacao['dados'] = dados\n",
    "    LOG_TRANSFORMACOES['operacoes'].append(operacao)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONSTANTES E CONFIGURAÃ‡Ã•ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "FILETYPES_SUPORTADOS = [\n",
    "    (\"Todos os suportados\", \"*.xlsx *.xls *.xlsm *.csv *.txt\"),\n",
    "    (\"Excel\", \"*.xlsx *.xls *.xlsm\"),\n",
    "    (\"CSV\", \"*.csv\"),\n",
    "    (\"TXT (Tabelas)\", \"*.txt\"),\n",
    "    (\"Todos\", \"*.*\")\n",
    "]\n",
    "\n",
    "TIMEOUT_SESSAO_MINUTOS = DICIONARIO_PERSISTENTE.get(\n",
    "    'config_sistema', {}\n",
    ").get('timeout_sessao_minutos', 60)\n",
    "\n",
    "registrar_operacao('config', 'Constantes carregadas', {\n",
    "    'timeout_minutos': TIMEOUT_SESSAO_MINUTOS,\n",
    "    'tipos_suportados': len(FILETYPES_SUPORTADOS)\n",
    "})\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡Ã•ES AUXILIARES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def detectar_config_csv(arquivo_path):\n",
    "    \"\"\"\n",
    "    Detecta encoding e separador ideal para CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: {'encoding': str, 'sep': str, 'colunas': int}\n",
    "        None: se falhar\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    separadores = [',', ';', '\\t', '|']\n",
    "\n",
    "    melhor_config = None\n",
    "    max_colunas = 0\n",
    "\n",
    "    for encoding in encodings:\n",
    "        for sep in separadores:\n",
    "            try:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=5,\n",
    "                    encoding=encoding,\n",
    "                    sep=sep,\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                n_cols = len(df_test.columns)\n",
    "\n",
    "                if n_cols > max_colunas and n_cols > 1:\n",
    "                    max_colunas = n_cols\n",
    "                    melhor_config = {\n",
    "                        'encoding': encoding,\n",
    "                        'sep': sep,\n",
    "                        'colunas': n_cols\n",
    "                    }\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return melhor_config\n",
    "\n",
    "\n",
    "def validar_arquivo_selecionado(arquivo_path):\n",
    "    \"\"\"\n",
    "    ValidaÃ§Ã£o bÃ¡sica do arquivo selecionado.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Se arquivo nÃ£o existe\n",
    "        ValueError: Se arquivo invÃ¡lido\n",
    "\n",
    "    Returns:\n",
    "        dict: InformaÃ§Ãµes de validaÃ§Ã£o\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if not arquivo_path.exists():\n",
    "        raise FileNotFoundError(f\"Arquivo nÃ£o encontrado: {arquivo_path}\")\n",
    "\n",
    "    tamanho = arquivo_path.stat().st_size\n",
    "    if tamanho == 0:\n",
    "        raise ValueError(f\"Arquivo vazio: {arquivo_path.name}\")\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "    extensoes_validas = ['.xlsx', '.xls', '.xlsm', '.csv', '.txt']\n",
    "\n",
    "    if extensao not in extensoes_validas:\n",
    "        print(f\"   âš ï¸ ExtensÃ£o incomum: {extensao}\")\n",
    "\n",
    "    config_extra = {}\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            pd.read_excel(arquivo_path, nrows=1)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "\n",
    "            if config_csv:\n",
    "                config_extra['csv'] = config_csv\n",
    "                print(f\"   ğŸ“Š CSV: {config_csv['colunas']} colunas\")\n",
    "                print(f\"   ğŸ”¤ Encoding: {config_csv['encoding']}\")\n",
    "                print(f\"   â— Separador: {repr(config_csv['sep'])}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ Config CSV nÃ£o detectada automaticamente\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Arquivo corrompido ou ilegÃ­vel: {str(e)[:100]}\")\n",
    "\n",
    "    return {\n",
    "        'valido': True,\n",
    "        'tamanho_kb': tamanho / 1024,\n",
    "        'extensao': extensao,\n",
    "        **config_extra\n",
    "    }\n",
    "\n",
    "\n",
    "def carregar_preview_inteligente(arquivo_path, frame_preview):\n",
    "    \"\"\"\n",
    "    Carrega preview do arquivo com tratamento de erro amigÃ¡vel.\n",
    "\n",
    "    Args:\n",
    "        arquivo_path: Path do arquivo\n",
    "        frame_preview: Frame tkinter para mostrar preview\n",
    "    \"\"\"\n",
    "    import tkinter as tk\n",
    "    import pandas as pd\n",
    "\n",
    "    extensao = arquivo_path.suffix.lower()\n",
    "\n",
    "    try:\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            df_quick = pd.read_excel(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.csv':\n",
    "            config_csv = detectar_config_csv(arquivo_path)\n",
    "            if config_csv:\n",
    "                df_quick = pd.read_csv(\n",
    "                    arquivo_path,\n",
    "                    nrows=3,\n",
    "                    encoding=config_csv['encoding'],\n",
    "                    sep=config_csv['sep']\n",
    "                )\n",
    "            else:\n",
    "                df_quick = pd.read_csv(arquivo_path, nrows=3)\n",
    "\n",
    "        elif extensao == '.txt':\n",
    "            for sep in ['\\t', ';', '|', ',']:\n",
    "                try:\n",
    "                    df_quick = pd.read_csv(arquivo_path, nrows=3, sep=sep)\n",
    "                    if len(df_quick.columns) > 1:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        preview_text = f\"{len(df_quick)} linhas Ã— {len(df_quick.columns)} colunas\"\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=preview_text,\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#666666',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "    except Exception as e:\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"âš ï¸ Preview indisponÃ­vel\",\n",
    "            font=('Arial', 8),\n",
    "            bg='#F5F5F5',\n",
    "            fg='#FF6B6B',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(0, 3))\n",
    "\n",
    "        print(f\"   âš ï¸ Preview falhou: {str(e)[:50]}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. PROCESSAR DADOS DO BLOCO (LÃ“GICA PRINCIPAL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Carregar Ãºltima seleÃ§Ã£o\n",
    "config_file = fm.pastas['logs'] / '.ultimo_arquivo.json'\n",
    "ultimo_arquivo = None\n",
    "sessao_atual = False\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        try:\n",
    "            ts_config = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "            ts_agora = datetime.now()\n",
    "            diff_minutos = (ts_agora - ts_config).total_seconds() / 60\n",
    "\n",
    "            if diff_minutos < TIMEOUT_SESSAO_MINUTOS:\n",
    "                caminho_salvo = config.get('caminho')\n",
    "                if caminho_salvo and Path(caminho_salvo).exists():\n",
    "                    ultimo_arquivo = Path(caminho_salvo)\n",
    "                    sessao_atual = True\n",
    "\n",
    "                    registrar_operacao('sessao', 'SessÃ£o ativa detectada', {\n",
    "                        'arquivo_anterior': caminho_salvo,\n",
    "                        'minutos_desde_ultimo': round(diff_minutos, 2)\n",
    "                    })\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nğŸ’¡ Ãšltima seleÃ§Ã£o: {ultimo_arquivo.name if ultimo_arquivo else 'Nenhuma'}\")\n",
    "print(f\"   Mesma sessÃ£o: {'Sim' if sessao_atual else 'NÃ£o'}\")\n",
    "\n",
    "# CASO 1: Tem arquivo da sessÃ£o atual â†’ GUI com timer\n",
    "if ultimo_arquivo and sessao_atual:\n",
    "    def selecionar_arquivo_com_timer(ultimo_path):\n",
    "        \"\"\"GUI com timer para confirmar ou trocar arquivo\"\"\"\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - SeleÃ§Ã£o de Arquivo\",\n",
    "            650, 520,\n",
    "            tem_timer=True\n",
    "        )\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‚ SeleÃ§Ã£o de Arquivo\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 15))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ’¡ Ãšltimo arquivo selecionado nesta sessÃ£o:\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 5))\n",
    "\n",
    "        extensao = ultimo_path.suffix.lower()\n",
    "        if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "            tipo_arquivo = \"Excel\"\n",
    "            icone = \"ğŸ“Š\"\n",
    "        elif extensao == '.csv':\n",
    "            tipo_arquivo = \"CSV\"\n",
    "            icone = \"ğŸ“„\"\n",
    "        elif extensao == '.txt':\n",
    "            tipo_arquivo = \"TXT\"\n",
    "            icone = \"ğŸ“\"\n",
    "        else:\n",
    "            tipo_arquivo = \"Desconhecido\"\n",
    "            icone = \"â“\"\n",
    "\n",
    "        frame_info = tk.Frame(frame, bg='#E3F2FD', relief=tk.SUNKEN, borderwidth=2)\n",
    "        frame_info.pack(fill=tk.X, pady=(0, 10), padx=10)\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"{icone} {ultimo_path.name}\",\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(5, 2))\n",
    "\n",
    "        tamanho_kb = ultimo_path.stat().st_size / 1024\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"ğŸ“¦ Tipo: {tipo_arquivo} | ğŸ“ Tamanho: {tamanho_kb:.1f} KB\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 2))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_info,\n",
    "            text=f\"ğŸ“‚ Local: {ultimo_path.parent}\",\n",
    "            font=('Arial', 9),\n",
    "            bg='#E3F2FD',\n",
    "            fg='#1565C0',\n",
    "            anchor='w',\n",
    "            wraplength=600\n",
    "        ).pack(fill=tk.X, padx=10, pady=(0, 5))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Deseja usar este arquivo ou escolher outro?\",\n",
    "            font=('Arial', 10),\n",
    "            bg='white'\n",
    "        ).pack(pady=(10, 10))\n",
    "\n",
    "        frame_preview = tk.Frame(frame, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "        frame_preview.pack(fill=tk.X, padx=10, pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame_preview,\n",
    "            text=\"ğŸ“Š Preview (3 primeiras linhas):\",\n",
    "            font=('Arial', 9, 'bold'),\n",
    "            bg='#F5F5F5',\n",
    "            anchor='w'\n",
    "        ).pack(fill=tk.X, padx=5, pady=(3, 2))\n",
    "\n",
    "        carregar_preview_inteligente(ultimo_path, frame_preview)\n",
    "\n",
    "        def usar_ultimo():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultimo_path\n",
    "            resultado['origem'] = 'sessao_anterior'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def escolher_novo():\n",
    "            resultado['cancelado'] = True\n",
    "            root.withdraw()\n",
    "\n",
    "            arquivo = filedialog.askopenfilename(\n",
    "                title=\"Selecione o arquivo de dados\",\n",
    "                initialdir=ultimo_path.parent,\n",
    "                filetypes=FILETYPES_SUPORTADOS\n",
    "            )\n",
    "\n",
    "            resultado['valor'] = Path(arquivo) if arquivo else ultimo_path\n",
    "            resultado['origem'] = 'usuario_novo' if arquivo else 'sessao_anterior'\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        tk.Frame(frame, height=2, bg='#CCCCCC').pack(fill=tk.X, pady=10)\n",
    "\n",
    "        frame_btns = tk.Frame(frame, bg='white')\n",
    "        frame_btns.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=\"Escolher Novo Arquivo\",\n",
    "            command=escolher_novo,\n",
    "            width=22,\n",
    "            height=2,\n",
    "            font=('Arial', 10, 'bold'),\n",
    "            bg='#4CAF50',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        nome_curto = ultimo_path.name[:15] + '...' if len(ultimo_path.name) > 15 else ultimo_path.name\n",
    "        tk.Button(\n",
    "            frame_btns,\n",
    "            text=f\"Usar '{nome_curto}' (10s)\",\n",
    "            command=usar_ultimo,\n",
    "            width=30,\n",
    "            height=2,\n",
    "            font=('Arial', 10),\n",
    "            bg='#2196F3',\n",
    "            fg='white',\n",
    "            cursor='hand2'\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        root.after(1000, countdown)\n",
    "        root.mainloop()\n",
    "\n",
    "        if resultado.get('timeout'):\n",
    "            print(f\"   â±ï¸ Timeout (10s) - usando Ãºltimo arquivo\")\n",
    "            resultado['origem'] = 'timeout'\n",
    "            return ultimo_path, 'timeout'\n",
    "\n",
    "        return resultado['valor'], resultado.get('origem', 'usuario')\n",
    "\n",
    "    print(\"\\nAbrindo janela...\")\n",
    "    arquivo_selecionado, origem_selecao = selecionar_arquivo_com_timer(ultimo_arquivo)\n",
    "\n",
    "    registrar_operacao('selecao', 'Arquivo selecionado (sessÃ£o ativa)', {\n",
    "        'arquivo': str(arquivo_selecionado),\n",
    "        'origem': origem_selecao\n",
    "    })\n",
    "\n",
    "# CASO 2: NÃ£o tem arquivo da sessÃ£o â†’ GUI direta sem timer\n",
    "else:\n",
    "    def selecionar_arquivo_direto():\n",
    "        \"\"\"GUI direta para primeira seleÃ§Ã£o\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)\n",
    "\n",
    "        arquivo = filedialog.askopenfilename(\n",
    "            title=\"Selecione o arquivo de dados\",\n",
    "            initialdir=ultimo_arquivo.parent if ultimo_arquivo else fm.pastas['entrada'],\n",
    "            filetypes=FILETYPES_SUPORTADOS\n",
    "        )\n",
    "\n",
    "        root.destroy()\n",
    "\n",
    "        if not arquivo:\n",
    "            raise ValueError(\"âŒ Nenhum arquivo selecionado\")\n",
    "\n",
    "        return Path(arquivo)\n",
    "\n",
    "    print(\"\\nAbrindo janela de seleÃ§Ã£o...\")\n",
    "    print(\"(A janela pode estar atrÃ¡s do navegador)\")\n",
    "    arquivo_selecionado = selecionar_arquivo_direto()\n",
    "    origem_selecao = 'primeira_selecao'\n",
    "\n",
    "    registrar_operacao('selecao', 'Arquivo selecionado (primeira vez)', {\n",
    "        'arquivo': str(arquivo_selecionado)\n",
    "    })\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VALIDAÃ‡ÃƒO E DETECÃ‡ÃƒO DE TIPO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” Validando arquivo...\")\n",
    "\n",
    "try:\n",
    "    info_validacao = validar_arquivo_selecionado(arquivo_selecionado)\n",
    "    print(\"   âœ… Arquivo validado com sucesso\")\n",
    "\n",
    "    registrar_operacao('validacao', 'Arquivo validado', {\n",
    "        'tamanho_kb': info_validacao['tamanho_kb'],\n",
    "        'extensao': info_validacao['extensao']\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERRO: {e}\")\n",
    "    registrar_operacao('erro', 'Falha na validaÃ§Ã£o', {'erro': str(e)})\n",
    "    raise\n",
    "\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "if extensao in ['.xlsx', '.xls', '.xlsm']:\n",
    "    tipo_arquivo = \"Excel\"\n",
    "elif extensao == '.csv':\n",
    "    tipo_arquivo = \"CSV\"\n",
    "elif extensao == '.txt':\n",
    "    tipo_arquivo = \"TXT\"\n",
    "else:\n",
    "    tipo_arquivo = \"Desconhecido\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. SALVAR ESTADO PARA PRÃ“XIMO BLOCO (PRINCÃPIO 100% LOG)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ’¾ Salvando estado completo (0% memÃ³ria, 100% LOG)...\")\n",
    "\n",
    "# 4.1 - ConfiguraÃ§Ã£o do arquivo selecionado (.ultimo_arquivo.json)\n",
    "config_salvar = {\n",
    "    'nome': arquivo_selecionado.name,\n",
    "    'caminho': str(arquivo_selecionado),\n",
    "    'tamanho_kb': info_validacao['tamanho_kb'],\n",
    "    'tipo': tipo_arquivo,\n",
    "    'extensao': extensao,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'origem_selecao': origem_selecao\n",
    "}\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    config_salvar['config_csv'] = info_validacao['csv']\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_salvar, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   âœ… ConfiguraÃ§Ã£o salva: .ultimo_arquivo.json\")\n",
    "\n",
    "# 4.2 - Estado do BLOCO 4 (.bloco_4_state.json)\n",
    "estado_bloco = {\n",
    "    'bloco': 4,\n",
    "    'status': 'concluido',\n",
    "    'timestamp_inicio': LOG_TRANSFORMACOES['inicio'],\n",
    "    'timestamp_fim': datetime.now().isoformat(),\n",
    "    'arquivo_selecionado': {\n",
    "        'nome': arquivo_selecionado.name,\n",
    "        'caminho': str(arquivo_selecionado),\n",
    "        'tipo': tipo_arquivo,\n",
    "        'extensao': extensao,\n",
    "        'tamanho_kb': info_validacao['tamanho_kb'],\n",
    "        'origem_selecao': origem_selecao\n",
    "    },\n",
    "    'validacao': info_validacao,\n",
    "    'sessao': {\n",
    "        'tinha_arquivo_anterior': ultimo_arquivo is not None,\n",
    "        'sessao_ativa': sessao_atual,\n",
    "        'timeout_minutos': TIMEOUT_SESSAO_MINUTOS\n",
    "    }\n",
    "}\n",
    "\n",
    "estado_file = fm.pastas['logs'] / '.bloco_4_state.json'\n",
    "with open(estado_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   âœ… Estado salvo: .bloco_4_state.json\")\n",
    "\n",
    "# 4.3 - VariÃ¡veis Python (.bloco_4_vars.pkl)\n",
    "variaveis_bloco = {\n",
    "    'arquivo_selecionado': arquivo_selecionado,\n",
    "    'info_validacao': info_validacao,\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'extensao': extensao,\n",
    "    'origem_selecao': origem_selecao,\n",
    "    'config_salvar': config_salvar,\n",
    "    'ultimo_arquivo': ultimo_arquivo,\n",
    "    'sessao_atual': sessao_atual,\n",
    "    'TIMEOUT_SESSAO_MINUTOS': TIMEOUT_SESSAO_MINUTOS,\n",
    "    'FILETYPES_SUPORTADOS': FILETYPES_SUPORTADOS,\n",
    "    'timestamp_bloco': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "vars_file = fm.pastas['logs'] / '.bloco_4_vars.pkl'\n",
    "with open(vars_file, 'wb') as f:\n",
    "    pickle.dump(variaveis_bloco, f)\n",
    "\n",
    "print(f\"   âœ… VariÃ¡veis salvas: .bloco_4_vars.pkl ({len(variaveis_bloco)} variÃ¡veis)\")\n",
    "\n",
    "# 4.4 - Log de transformaÃ§Ãµes (.bloco_4_transformacoes.json)\n",
    "LOG_TRANSFORMACOES['fim'] = datetime.now().isoformat()\n",
    "LOG_TRANSFORMACOES['total_operacoes'] = len(LOG_TRANSFORMACOES['operacoes'])\n",
    "LOG_TRANSFORMACOES['resumo'] = {\n",
    "    'arquivo_final': arquivo_selecionado.name,\n",
    "    'tipo': tipo_arquivo,\n",
    "    'origem': origem_selecao,\n",
    "    'validado': True\n",
    "}\n",
    "\n",
    "transform_file = fm.pastas['logs'] / '.bloco_4_transformacoes.json'\n",
    "with open(transform_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(LOG_TRANSFORMACOES, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   âœ… TransformaÃ§Ãµes salvas: .bloco_4_transformacoes.json ({LOG_TRANSFORMACOES['total_operacoes']} operaÃ§Ãµes)\")\n",
    "\n",
    "# 4.5 - Metadados para recuperaÃ§Ã£o rÃ¡pida\n",
    "metadados = {\n",
    "    'bloco': 4,\n",
    "    'arquivos_salvos': {\n",
    "        'estado_json': str(estado_file.name),\n",
    "        'variaveis_pkl': str(vars_file.name),\n",
    "        'transformacoes_json': str(transform_file.name),\n",
    "        'config_arquivo': str(config_file.name)\n",
    "    },\n",
    "    'como_recuperar': {\n",
    "        'estado': 'json.load(open(estado_file))',\n",
    "        'variaveis': 'pickle.load(open(vars_file, \"rb\"))',\n",
    "        'transformacoes': 'json.load(open(transform_file))',\n",
    "        'arquivo_selecionado': 'Path(estado[\"arquivo_selecionado\"][\"caminho\"])'\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "meta_file = fm.pastas['logs'] / '.bloco_4_metadados.json'\n",
    "with open(meta_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadados, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   âœ… Metadados salvos: .bloco_4_metadados.json\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. VERIFICAÃ‡ÃƒO DE INTEGRIDADE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” Verificando integridade dos arquivos salvos...\")\n",
    "\n",
    "arquivos_esperados = [\n",
    "    estado_file,\n",
    "    vars_file,\n",
    "    transform_file,\n",
    "    config_file,\n",
    "    meta_file\n",
    "]\n",
    "\n",
    "todos_ok = True\n",
    "for arq in arquivos_esperados:\n",
    "    if arq.exists():\n",
    "        tamanho = arq.stat().st_size\n",
    "        print(f\"   âœ… {arq.name} ({tamanho} bytes)\")\n",
    "    else:\n",
    "        print(f\"   âŒ {arq.name} NÃƒO ENCONTRADO\")\n",
    "        todos_ok = False\n",
    "\n",
    "if not todos_ok:\n",
    "    raise RuntimeError(\"âŒ Falha na gravaÃ§Ã£o de arquivos de estado!\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 6. CONFIRMAÃ‡ÃƒO FINAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… ARQUIVO SELECIONADO E VALIDADO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ğŸ“„ Nome: {arquivo_selecionado.name}\")\n",
    "print(f\"ğŸ“¦ Tipo: {tipo_arquivo}\")\n",
    "print(f\"ğŸ“ Tamanho: {info_validacao['tamanho_kb']:.1f} KB\")\n",
    "print(f\"ğŸ“‚ Pasta: {arquivo_selecionado.parent.name}\")\n",
    "print(f\"ğŸ”„ Origem: {origem_selecao}\")\n",
    "\n",
    "if 'csv' in info_validacao:\n",
    "    csv_info = info_validacao['csv']\n",
    "    print(f\"ğŸ“Š Colunas detectadas: {csv_info['colunas']}\")\n",
    "    print(f\"ğŸ”¤ Encoding: {csv_info['encoding']}\")\n",
    "    print(f\"â— Separador: {repr(csv_info['sep'])}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ğŸ’¾ ESTADO PERSISTENTE SALVO (0% MEMÃ“RIA, 100% LOG)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"ğŸ“‹ Estado JSON: {estado_file.name}\")\n",
    "print(f\"ğŸ”§ VariÃ¡veis PKL: {vars_file.name}\")\n",
    "print(f\"ğŸ“ TransformaÃ§Ãµes: {transform_file.name}\")\n",
    "print(f\"âš™ï¸ Config arquivo: {config_file.name}\")\n",
    "print(f\"ğŸ“Š Metadados: {meta_file.name}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… BLOCO 4 CONCLUÃDO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nğŸ’¾ Estado completo em: {fm.pastas['logs']}\")\n",
    "print(f\"ğŸ“‹ PrÃ³ximo: BLOCO 5 carregarÃ¡ todos os dados via arquivos .pkl/.json\")\n",
    "print(f\"\\nğŸ’¡ Exemplo de recuperaÃ§Ã£o:\")\n",
    "print(f\"   import pickle, json\")\n",
    "print(f\"   vars = pickle.load(open('{vars_file}', 'rb'))\")\n",
    "print(f\"   arquivo = vars['arquivo_selecionado']\")"
   ],
   "id": "eab16a4648d87882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BLOCO 4: SELEÃ‡ÃƒO DE ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Pasta base carregada: PROCESSAR_ARQUIVOS_20251018_220345\n",
      "â° Timestamp: 20251018_220345\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "âŒ DicionÃ¡rio nÃ£o encontrado!\n   Execute BLOCO 3 primeiro.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 61\u001B[39m\n\u001B[32m     59\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mğŸ“š DicionÃ¡rio carregado: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(DICIONARIO_PERSISTENTE.get(\u001B[33m'\u001B[39m\u001B[33mcampos_conhecidos\u001B[39m\u001B[33m'\u001B[39m,\u001B[38;5;250m \u001B[39m{}))\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m campos\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[32m     62\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mâŒ DicionÃ¡rio nÃ£o encontrado!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     63\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m   Execute BLOCO 3 primeiro.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     64\u001B[39m     )\n\u001B[32m     66\u001B[39m \u001B[38;5;66;03m# Inicializar log de transformaÃ§Ãµes\u001B[39;00m\n\u001B[32m     67\u001B[39m LOG_TRANSFORMACOES = {\n\u001B[32m     68\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mbloco\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m4\u001B[39m,\n\u001B[32m     69\u001B[39m     \u001B[33m'\u001B[39m\u001B[33minicio\u001B[39m\u001B[33m'\u001B[39m: datetime.now().isoformat(),\n\u001B[32m     70\u001B[39m     \u001B[33m'\u001B[39m\u001B[33moperacoes\u001B[39m\u001B[33m'\u001B[39m: []\n\u001B[32m     71\u001B[39m }\n",
      "\u001B[31mFileNotFoundError\u001B[39m: âŒ DicionÃ¡rio nÃ£o encontrado!\n   Execute BLOCO 3 primeiro."
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T22:16:05.910883Z",
     "start_time": "2025-10-18T22:16:05.835632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 5: CARREGAMENTO INTELIGENTE - EXCEL E CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¥ CARREGAMENTO DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Detectar tipo de arquivo pela extensÃ£o\n",
    "extensao = arquivo_selecionado.suffix.lower()\n",
    "print(f\"\\nğŸ” ExtensÃ£o detectada: {extensao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: ARQUIVOS EXCEL (.xls, .xlsx, .xlsm)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if extensao in ['.xls', '.xlsx', '.xlsm']:\n",
    "    print(f\"ğŸ“Š Tipo: EXCEL\")\n",
    "\n",
    "    try:\n",
    "        # Tentar xlrd primeiro (para .xls antigos)\n",
    "        workbook = xlrd.open_workbook(str(arquivo_selecionado))\n",
    "        sheets = workbook.sheet_names()\n",
    "        metodo_carga = 'xlrd'\n",
    "        print(f\"   âœ… MÃ©todo: xlrd (XLS)\")\n",
    "\n",
    "    except:\n",
    "        # Se falhar, usar pandas (para .xlsx/.xlsm)\n",
    "        try:\n",
    "            workbook = pd.ExcelFile(str(arquivo_selecionado))\n",
    "            sheets = workbook.sheet_names\n",
    "            metodo_carga = 'pandas'\n",
    "            print(f\"   âœ… MÃ©todo: pandas (XLSX/XLSM)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ERRO ao abrir Excel: {e}\")\n",
    "            raise\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Sheets encontradas: {len(sheets)}\")\n",
    "    for i, sheet in enumerate(sheets, 1):\n",
    "        print(f\"   {i}. {sheet}\")\n",
    "\n",
    "    tipo_arquivo = 'EXCEL'\n",
    "    separador_detectado = None\n",
    "    skiprows_csv = 0\n",
    "\n",
    "    # Extrair informaÃ§Ãµes adicionais das sheets\n",
    "    sheets_info = []\n",
    "    for sheet_name in sheets:\n",
    "        try:\n",
    "            if metodo_carga == 'xlrd':\n",
    "                sheet_obj = workbook.sheet_by_name(sheet_name)\n",
    "                nrows = sheet_obj.nrows\n",
    "                ncols = sheet_obj.ncols\n",
    "            else:  # pandas\n",
    "                df_temp = pd.read_excel(workbook, sheet_name=sheet_name, nrows=1)\n",
    "                # Contar linhas do arquivo\n",
    "                df_full = pd.read_excel(str(arquivo_selecionado), sheet_name=sheet_name)\n",
    "                nrows = len(df_full) + 1  # +1 para header\n",
    "                ncols = len(df_temp.columns)\n",
    "\n",
    "            sheets_info.append({\n",
    "                'nome': sheet_name,\n",
    "                'linhas': nrows,\n",
    "                'colunas': ncols\n",
    "            })\n",
    "        except Exception as e:\n",
    "            sheets_info.append({\n",
    "                'nome': sheet_name,\n",
    "                'linhas': 'N/A',\n",
    "                'colunas': 'N/A',\n",
    "                'erro': str(e)\n",
    "            })\n",
    "\n",
    "    # IMPORTANTE: Fechar o workbook para liberar recursos\n",
    "    if metodo_carga == 'pandas' and hasattr(workbook, 'close'):\n",
    "        workbook.close()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: ARQUIVOS CSV (.csv)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif extensao == '.csv':\n",
    "    print(f\"ğŸ“„ Tipo: CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nğŸ” Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha explÃ­cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   âœ… Separador explÃ­cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   âœ… Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"âŒ Separador CSV nÃ£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nğŸ“Š Estrutura do CSV:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Contar linhas totais\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            total_linhas = sum(1 for _ in f) - skiprows_csv\n",
    "\n",
    "        # Simular sheets (CSV = 1 sheet virtual)\n",
    "        sheets = ['Dados CSV']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'CSV'\n",
    "\n",
    "        sheets_info = [{\n",
    "            'nome': 'Dados CSV',\n",
    "            'linhas': total_linhas,\n",
    "            'colunas': len(df_preview.columns)\n",
    "        }]\n",
    "\n",
    "        print(f\"\\nğŸ“‹ Sheet virtual: 'Dados CSV'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO ao processar CSV: {e}\")\n",
    "        raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: ARQUIVOS TXT (.txt)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif extensao == '.txt':\n",
    "    print(f\"ğŸ“ Tipo: TXT\")\n",
    "    print(f\"   â„¹ï¸  Processamento similar a CSV\")\n",
    "\n",
    "    try:\n",
    "        # Ler primeira linha para detectar separador\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            primeira_linha = f.readline().strip()\n",
    "\n",
    "        print(f\"\\nğŸ” Primeira linha: {primeira_linha[:100]}\")\n",
    "\n",
    "        # Detectar separador\n",
    "        separador_detectado = None\n",
    "\n",
    "        # Caso 1: Linha explÃ­cita com \"sep=\"\n",
    "        if primeira_linha.lower().startswith('sep='):\n",
    "            separador_detectado = primeira_linha.split('=')[1]\n",
    "            skiprows_csv = 1\n",
    "            print(f\"   âœ… Separador explÃ­cito: '{separador_detectado}'\")\n",
    "\n",
    "        # Caso 2: Tentar detectar automaticamente\n",
    "        else:\n",
    "            for sep in ['^', ';', ',', '\\t', '|']:\n",
    "                df_test = pd.read_csv(\n",
    "                    arquivo_selecionado,\n",
    "                    nrows=2,\n",
    "                    sep=sep,\n",
    "                    encoding='cp1252',\n",
    "                    on_bad_lines='skip'\n",
    "                )\n",
    "                if len(df_test.columns) > 1:\n",
    "                    separador_detectado = sep\n",
    "                    skiprows_csv = 0\n",
    "                    print(f\"   âœ… Separador auto: '{separador_detectado}'\")\n",
    "                    break\n",
    "\n",
    "        if not separador_detectado:\n",
    "            raise ValueError(\"âŒ Separador TXT nÃ£o detectado\")\n",
    "\n",
    "        # Carregar preview\n",
    "        df_preview = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv,\n",
    "            nrows=5\n",
    "        )\n",
    "\n",
    "        print(f\"\\nğŸ“Š Estrutura do TXT:\")\n",
    "        print(f\"   Colunas: {len(df_preview.columns)}\")\n",
    "        print(f\"   Encoding: cp1252\")\n",
    "        print(f\"   Separador: '{separador_detectado}'\")\n",
    "\n",
    "        # Contar linhas totais\n",
    "        with open(arquivo_selecionado, 'r', encoding='cp1252') as f:\n",
    "            total_linhas = sum(1 for _ in f) - skiprows_csv\n",
    "\n",
    "        # Simular sheets (TXT = 1 sheet virtual)\n",
    "        sheets = ['Dados TXT']\n",
    "        metodo_carga = 'csv'\n",
    "        workbook = None\n",
    "        tipo_arquivo = 'TXT'\n",
    "\n",
    "        sheets_info = [{\n",
    "            'nome': 'Dados TXT',\n",
    "            'linhas': total_linhas,\n",
    "            'colunas': len(df_preview.columns)\n",
    "        }]\n",
    "\n",
    "        print(f\"\\nğŸ“‹ Sheet virtual: 'Dados TXT'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ERRO ao processar TXT: {e}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"âŒ Formato nÃ£o suportado: {extensao}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAMENTO DE ESTADO NO LOG (APENAS METADADOS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco5 = {\n",
    "    'bloco': 5,\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'metodo_carga': metodo_carga,\n",
    "    'extensao': extensao,\n",
    "    'sheets': sheets,\n",
    "    'sheets_info': sheets_info,\n",
    "    'workbook_path': str(arquivo_selecionado),\n",
    "    'workbook_path_absolute': str(arquivo_selecionado.resolve()),\n",
    "    'separador_detectado': separador_detectado,\n",
    "    'skiprows_csv': skiprows_csv,\n",
    "    'encoding': 'cp1252' if tipo_arquivo in ['CSV', 'TXT'] else None,\n",
    "    'total_sheets': len(sheets)\n",
    "}\n",
    "\n",
    "# Salvar estado em JSON\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_5_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco5, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RESUMO DO CARREGAMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"âœ… CARREGAMENTO CONCLUÃDO\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "print(f\"   MÃ©todo: {metodo_carga}\")\n",
    "print(f\"   Sheets/Tabelas: {len(sheets)}\")\n",
    "if sheets_info:\n",
    "    print(f\"\\nğŸ“Š Detalhes das Sheets:\")\n",
    "    for info in sheets_info:\n",
    "        print(f\"   â€¢ {info['nome']}: {info['linhas']} linhas x {info['colunas']} colunas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… BLOCO 5 CONCLUÃDO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸ’¾ Estado salvo: .bloco_5_state.json\")\n",
    "print(f\"ğŸ“‹ PrÃ³ximo: BLOCO 6 selecionarÃ¡ a sheet e farÃ¡ preview\")\n",
    "print(\"\\nâš ï¸  NOTA: Workbook NÃƒO persistido (serÃ¡ reaberto quando necessÃ¡rio)\")"
   ],
   "id": "a36bbbc312051633",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“¥ CARREGAMENTO DO ARQUIVO\n",
      "======================================================================\n",
      "\n",
      "ğŸ” ExtensÃ£o detectada: .xlsx\n",
      "ğŸ“Š Tipo: EXCEL\n",
      "   âœ… MÃ©todo: pandas (XLSX/XLSM)\n",
      "\n",
      "ğŸ“‹ Sheets encontradas: 2\n",
      "   1. Grupos de Produto e Desc\n",
      "   2. Material x Grupos de Produtos\n",
      "\n",
      "ğŸ’¾ Estado salvo: .bloco_5_state.json\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… CARREGAMENTO CONCLUÃDO\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Tipo: EXCEL\n",
      "   MÃ©todo: pandas\n",
      "   Sheets/Tabelas: 2\n",
      "\n",
      "ğŸ“Š Detalhes das Sheets:\n",
      "   â€¢ Grupos de Produto e Desc: 31 linhas x 2 colunas\n",
      "   â€¢ Material x Grupos de Produtos: 213 linhas x 2 colunas\n",
      "\n",
      "======================================================================\n",
      "âœ… BLOCO 5 CONCLUÃDO\n",
      "======================================================================\n",
      "ğŸ’¾ Estado salvo: .bloco_5_state.json\n",
      "ğŸ“‹ PrÃ³ximo: BLOCO 6 selecionarÃ¡ a sheet e farÃ¡ preview\n",
      "\n",
      "âš ï¸  NOTA: Workbook NÃƒO persistido (serÃ¡ reaberto quando necessÃ¡rio)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T22:26:59.285802Z",
     "start_time": "2025-10-18T22:26:54.790148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 6 - SELEÃ‡ÃƒO DE SHEET (COM SUPORTE CSV + PERSISTÃŠNCIA)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ SELEÃ‡ÃƒO DE SHEET/TABELA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INICIALIZAÃ‡ÃƒO DE VARIÃVEIS DE ESTADO\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "state_file = fm.pastas['logs'] / '.bloco_6_state.json'\n",
    "config_file = fm.pastas['logs'] / '.ultima_sheet.json'\n",
    "log_transformacoes = fm.pastas['logs'] / 'bloco_6_transformacoes.log'\n",
    "\n",
    "# VariÃ¡veis que serÃ£o persistidas\n",
    "estado_bloco_6 = {\n",
    "    'sheet_nome': None,\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'sheets_disponiveis': sheets,\n",
    "    'arquivo_nome': arquivo_selecionado.name,\n",
    "    'arquivo_path': str(arquivo_selecionado),\n",
    "    'total_sheets': len(sheets),\n",
    "    'metodo_selecao': None,  # 'auto_csv', 'auto_unica', 'gui_timer', 'gui_manual'\n",
    "    'timestamp_inicio': datetime.now().isoformat(),\n",
    "    'timestamp_fim': None,\n",
    "    'arquivo_mudou': True,\n",
    "    'ultima_sheet_usada': None\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FUNÃ‡ÃƒO DE LOGGING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def log_transformacao(acao, detalhes):\n",
    "    \"\"\"Registra todas as aÃ§Ãµes e decisÃµes do bloco\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    log_entry = f\"[{timestamp}] {acao}: {detalhes}\\n\"\n",
    "\n",
    "    with open(log_transformacoes, 'a', encoding='utf-8') as f:\n",
    "        f.write(log_entry)\n",
    "\n",
    "    print(f\"   ğŸ“ LOG: {acao}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CARREGAR ÃšLTIMA SELEÃ‡ÃƒO E VERIFICAR MUDANÃ‡AS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "log_transformacao(\"INICIO_BLOCO_6\", f\"Arquivo: {arquivo_selecionado.name}, Tipo: {tipo_arquivo}, Sheets: {len(sheets)}\")\n",
    "\n",
    "ultima_sheet = None\n",
    "arquivo_mudou = True\n",
    "\n",
    "if config_file.exists():\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "            log_transformacao(\"CONFIG_CARREGADA\", f\"Ãšltima configuraÃ§Ã£o encontrada: {config.get('arquivo')}\")\n",
    "\n",
    "            # Verificar se Ã© o mesmo arquivo E timestamp recente (Ãºltima hora)\n",
    "            if config.get('arquivo') == arquivo_selecionado.name:\n",
    "                ultima_sheet = config.get('sheet')\n",
    "                estado_bloco_6['ultima_sheet_usada'] = ultima_sheet\n",
    "\n",
    "                # Verificar se timestamp Ã© recente\n",
    "                try:\n",
    "                    ts_salvo = datetime.fromisoformat(config.get('timestamp', ''))\n",
    "                    ts_agora = datetime.now()\n",
    "                    diff_minutos = (ts_agora - ts_salvo).total_seconds() / 60\n",
    "\n",
    "                    if diff_minutos < 60:  # Ãšltima hora\n",
    "                        arquivo_mudou = False\n",
    "                        log_transformacao(\"ARQUIVO_INALTERADO\", f\"Mesmo arquivo em < 60min, diff: {diff_minutos:.1f}min\")\n",
    "                    else:\n",
    "                        log_transformacao(\"ARQUIVO_ANTIGO\", f\"Mesmo arquivo mas > 60min, diff: {diff_minutos:.1f}min\")\n",
    "                except Exception as e:\n",
    "                    log_transformacao(\"ERRO_TIMESTAMP\", f\"Erro ao verificar timestamp: {str(e)}\")\n",
    "            else:\n",
    "                log_transformacao(\"ARQUIVO_DIFERENTE\", f\"Arquivo mudou de '{config.get('arquivo')}' para '{arquivo_selecionado.name}'\")\n",
    "    except Exception as e:\n",
    "        log_transformacao(\"ERRO_CONFIG\", f\"Erro ao carregar config: {str(e)}\")\n",
    "\n",
    "estado_bloco_6['arquivo_mudou'] = arquivo_mudou\n",
    "estado_bloco_6['ultima_sheet_usada'] = ultima_sheet\n",
    "\n",
    "print(f\"\\nğŸ’¡ Ãšltima sheet: {ultima_sheet if ultima_sheet else 'Nenhuma'}\")\n",
    "print(f\"   Arquivo mudou: {'Sim' if arquivo_mudou else 'NÃ£o'}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: CSV - SELEÃ‡ÃƒO AUTOMÃTICA (apenas 1 sheet virtual)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if tipo_arquivo == 'CSV':\n",
    "    sheet_nome = sheets[0]  # 'Dados CSV'\n",
    "    estado_bloco_6['sheet_nome'] = sheet_nome\n",
    "    estado_bloco_6['metodo_selecao'] = 'auto_csv'\n",
    "\n",
    "    log_transformacao(\"SELECAO_AUTO_CSV\", f\"Sheet virtual automÃ¡tica: '{sheet_nome}'\")\n",
    "    print(f\"\\nâœ… Arquivo CSV - usando sheet virtual automÃ¡tica: '{sheet_nome}'\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: EXCEL - Apenas 1 sheet E arquivo mudou â†’ Usar diretamente\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif len(sheets) == 1 and arquivo_mudou:\n",
    "    sheet_nome = sheets[0]\n",
    "    estado_bloco_6['sheet_nome'] = sheet_nome\n",
    "    estado_bloco_6['metodo_selecao'] = 'auto_unica'\n",
    "\n",
    "    log_transformacao(\"SELECAO_AUTO_UNICA\", f\"Ãšnica sheet disponÃ­vel: '{sheet_nome}'\")\n",
    "    print(f\"\\nâœ… Apenas 1 sheet - selecionando automaticamente: '{sheet_nome}'\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: EXCEL - Mais de 1 sheet OU tem histÃ³rico â†’ GUI COM TIMER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "else:\n",
    "    def selecionar_sheet_com_timer(sheets, ultima=None, mostrar_timer=True):\n",
    "        \"\"\"GUI com timer para seleÃ§Ã£o de sheet\"\"\"\n",
    "        log_transformacao(\"GUI_INICIADA\", f\"Sheets: {len(sheets)}, Ãšltima: {ultima}, Timer: {mostrar_timer}\")\n",
    "\n",
    "        root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "            \"DETECTOR - SeleÃ§Ã£o de Sheet\",\n",
    "            600, 450,\n",
    "            tem_timer=(mostrar_timer and ultima is not None)\n",
    "        )\n",
    "\n",
    "        # TÃ­tulo\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"ğŸ“‹ SeleÃ§Ã£o de Sheet\",\n",
    "            font=('Arial', 14, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=\"Selecione a Sheet para processar:\",\n",
    "            font=('Arial', 12, 'bold'),\n",
    "            bg='white'\n",
    "        ).pack(pady=(0, 10))\n",
    "\n",
    "        # Timer (se tem Ãºltima E timer ativo)\n",
    "        if ultima and mostrar_timer:\n",
    "            tk.Label(\n",
    "                frame,\n",
    "                text=f\"ğŸ’¡ Ãšltima sheet usada: '{ultima}'\",\n",
    "                font=('Arial', 10),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0',\n",
    "                padx=10,\n",
    "                pady=10\n",
    "            ).pack(fill=tk.X, pady=(0, 5))\n",
    "\n",
    "            countdown = GUIComTimer.adicionar_timer(frame, root, resultado, contador)\n",
    "\n",
    "        # Listbox\n",
    "        frame_list = tk.Frame(frame, bg='white')\n",
    "        frame_list.pack(fill=tk.BOTH, expand=True, pady=(0, 10))\n",
    "\n",
    "        scrollbar = tk.Scrollbar(frame_list)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        listbox = tk.Listbox(\n",
    "            frame_list,\n",
    "            yscrollcommand=scrollbar.set,\n",
    "            font=('Arial', 10),\n",
    "            height=8\n",
    "        )\n",
    "        listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        scrollbar.config(command=listbox.yview)\n",
    "\n",
    "        for sheet in sheets:\n",
    "            listbox.insert(tk.END, sheet)\n",
    "\n",
    "        # Selecionar Ãºltima ou primeira\n",
    "        if ultima and ultima in sheets:\n",
    "            idx = sheets.index(ultima)\n",
    "            listbox.select_set(idx)\n",
    "            listbox.see(idx)\n",
    "        else:\n",
    "            listbox.select_set(0)\n",
    "\n",
    "        # FunÃ§Ãµes\n",
    "        def nova_selecao():\n",
    "            resultado['cancelado'] = True\n",
    "            selecao = listbox.curselection()\n",
    "            if selecao:\n",
    "                resultado['valor'] = sheets[selecao[0]]\n",
    "                log_transformacao(\"GUI_SELECAO_MANUAL\", f\"UsuÃ¡rio selecionou: '{sheets[selecao[0]]}'\")\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def usar_ultima():\n",
    "            resultado['cancelado'] = True\n",
    "            resultado['valor'] = ultima\n",
    "            log_transformacao(\"GUI_USAR_ULTIMA\", f\"UsuÃ¡rio escolheu usar Ãºltima: '{ultima}'\")\n",
    "            root.quit()\n",
    "            root.destroy()\n",
    "\n",
    "        def duplo_clique(event):\n",
    "            nova_selecao()\n",
    "\n",
    "        listbox.bind('<Double-Button-1>', duplo_clique)\n",
    "\n",
    "        # BotÃµes\n",
    "        GUIComTimer.criar_botoes(\n",
    "            frame,\n",
    "            nova_selecao,\n",
    "            usar_ultima if (ultima and mostrar_timer) else None,\n",
    "            \"Selecionar\",\n",
    "            f\"Usar '{ultima}' (10s)\" if ultima else None\n",
    "        )\n",
    "\n",
    "        # Iniciar timer\n",
    "        if ultima and mostrar_timer:\n",
    "            root.after(1000, countdown)\n",
    "\n",
    "        root.mainloop()\n",
    "\n",
    "        # Processar resultado\n",
    "        if resultado.get('timeout') and ultima:\n",
    "            log_transformacao(\"GUI_TIMEOUT\", f\"Timeout (10s) - usando Ãºltima sheet: '{ultima}'\")\n",
    "            print(f\"   â±ï¸  Timeout (10s) - usando Ãºltima sheet\")\n",
    "            return ultima\n",
    "\n",
    "        return resultado['valor']\n",
    "\n",
    "    # Executar GUI\n",
    "    print(f\"\\nAbrindo janela de seleÃ§Ã£o...\")\n",
    "    sheet_nome = selecionar_sheet_com_timer(\n",
    "        sheets,\n",
    "        ultima_sheet,\n",
    "        mostrar_timer=(not arquivo_mudou)  # Timer apenas se mesmo arquivo\n",
    "    )\n",
    "\n",
    "    estado_bloco_6['sheet_nome'] = sheet_nome\n",
    "    if ultima_sheet and not arquivo_mudou:\n",
    "        estado_bloco_6['metodo_selecao'] = 'gui_timer'\n",
    "    else:\n",
    "        estado_bloco_6['metodo_selecao'] = 'gui_manual'\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VALIDAÃ‡ÃƒO DA SELEÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if sheet_nome is None:\n",
    "    log_transformacao(\"ERRO_SELECAO\", \"Nenhuma sheet foi selecionada!\")\n",
    "    raise ValueError(\"âŒ Nenhuma sheet foi selecionada!\")\n",
    "\n",
    "if sheet_nome not in sheets:\n",
    "    log_transformacao(\"ERRO_SHEET_INVALIDA\", f\"Sheet '{sheet_nome}' nÃ£o existe nas sheets disponÃ­veis\")\n",
    "    raise ValueError(f\"âŒ Sheet '{sheet_nome}' nÃ£o encontrada nas sheets disponÃ­veis!\")\n",
    "\n",
    "log_transformacao(\"SELECAO_VALIDADA\", f\"Sheet '{sheet_nome}' validada com sucesso\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR ESCOLHA (ConfiguraÃ§Ã£o Ãšltima Sheet)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "config_data = {\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'tipo_arquivo': tipo_arquivo,\n",
    "    'metodo_selecao': estado_bloco_6['metodo_selecao']\n",
    "}\n",
    "\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "log_transformacao(\"CONFIG_SALVA\", f\"ConfiguraÃ§Ã£o salva em {config_file.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR ESTADO COMPLETO DO BLOCO 6\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco_6['timestamp_fim'] = datetime.now().isoformat()\n",
    "\n",
    "# Calcular tempo de execuÃ§Ã£o\n",
    "ts_inicio = datetime.fromisoformat(estado_bloco_6['timestamp_inicio'])\n",
    "ts_fim = datetime.fromisoformat(estado_bloco_6['timestamp_fim'])\n",
    "tempo_execucao = (ts_fim - ts_inicio).total_seconds()\n",
    "\n",
    "estado_bloco_6['tempo_execucao_segundos'] = tempo_execucao\n",
    "\n",
    "# Adicionar metadados\n",
    "estado_bloco_6['metadata'] = {\n",
    "    'bloco': 'BLOCO_6',\n",
    "    'descricao': 'SeleÃ§Ã£o de Sheet/Tabela',\n",
    "    'versao': '2.0',\n",
    "    'persistencia': True\n",
    "}\n",
    "\n",
    "# Salvar estado\n",
    "with open(state_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco_6, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "log_transformacao(\"ESTADO_SALVO\", f\"Estado completo salvo em {state_file.name}\")\n",
    "\n",
    "print(f\"\\nâœ… Sheet selecionada: '{sheet_nome}'\")\n",
    "print(f\"   ğŸ’¾ Estado persistido em: {state_file.name}\")\n",
    "print(f\"   ğŸ“ Log de transformaÃ§Ãµes em: {log_transformacoes.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RESUMO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"âœ… SELEÃ‡ÃƒO CONCLUÃDA\")\n",
    "print(\"â”€\"*70)\n",
    "print(f\"   Arquivo: {arquivo_selecionado.name}\")\n",
    "print(f\"   Sheet: {sheet_nome}\")\n",
    "print(f\"   Tipo: {tipo_arquivo}\")\n",
    "print(f\"   MÃ©todo: {estado_bloco_6['metodo_selecao']}\")\n",
    "print(f\"   Tempo: {tempo_execucao:.2f}s\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "log_transformacao(\"BLOCO_6_CONCLUIDO\",\n",
    "                 f\"Sheet='{sheet_nome}', MÃ©todo={estado_bloco_6['metodo_selecao']}, Tempo={tempo_execucao:.2f}s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXPORTAR VARIÃVEIS CRÃTICAS PARA PRÃ“XIMOS BLOCOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Estas variÃ¡veis devem estar disponÃ­veis para os blocos seguintes:\n",
    "# - sheet_nome: Nome da sheet selecionada\n",
    "# - tipo_arquivo: 'CSV' ou 'EXCEL'\n",
    "# - arquivo_selecionado: Path do arquivo\n",
    "# - sheets: Lista de todas as sheets disponÃ­veis\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ],
   "id": "bd9cdff8d1341b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“‹ SELEÃ‡ÃƒO DE SHEET/TABELA\n",
      "======================================================================\n",
      "   ğŸ“ LOG: INICIO_BLOCO_6\n",
      "   ğŸ“ LOG: CONFIG_CARREGADA\n",
      "   ğŸ“ LOG: ARQUIVO_ANTIGO\n",
      "\n",
      "ğŸ’¡ Ãšltima sheet: Grupos de Produto e Desc\n",
      "   Arquivo mudou: Sim\n",
      "\n",
      "Abrindo janela de seleÃ§Ã£o...\n",
      "   ğŸ“ LOG: GUI_INICIADA\n",
      "   ğŸ“ LOG: GUI_SELECAO_MANUAL\n",
      "   ğŸ“ LOG: SELECAO_VALIDADA\n",
      "   ğŸ“ LOG: CONFIG_SALVA\n",
      "   ğŸ“ LOG: ESTADO_SALVO\n",
      "\n",
      "âœ… Sheet selecionada: 'Grupos de Produto e Desc'\n",
      "   ğŸ’¾ Estado persistido em: .bloco_6_state.json\n",
      "   ğŸ“ Log de transformaÃ§Ãµes em: bloco_6_transformacoes.log\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… SELEÃ‡ÃƒO CONCLUÃDA\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Arquivo: Grupos de Produtos x CÃ³digos de Materiais.xlsx\n",
      "   Sheet: Grupos de Produto e Desc\n",
      "   Tipo: EXCEL\n",
      "   MÃ©todo: gui_manual\n",
      "   Tempo: 4.46s\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   ğŸ“ LOG: BLOCO_6_CONCLUIDO\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T22:41:47.068987Z",
     "start_time": "2025-10-18T22:41:47.039967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 7 - PREVIEW VISUAL (50 linhas Ã— 20 colunas) - SUPORTE CSV\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‘€ PREVIEW DO ARQUIVO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 1: EXCEL com xlrd (arquivos .xls antigos)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if metodo_carga == 'xlrd':\n",
    "    print(\"ğŸ“Š MÃ©todo: xlrd\")\n",
    "\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    data_preview = []\n",
    "\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_preview.append(sheet.row_values(row_idx))\n",
    "\n",
    "    df_preview = pd.DataFrame(data_preview)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 2: EXCEL com pandas (arquivos .xlsx/.xlsm)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(\"ğŸ“Š MÃ©todo: pandas Excel\")\n",
    "\n",
    "    # CORREÃ‡ÃƒO: Ler diretamente do arquivo, nÃ£o do objeto workbook que pode estar fechado\n",
    "    df_preview = pd.read_excel(\n",
    "        arquivo_selecionado,  # âœ… Usar caminho do arquivo\n",
    "        sheet_name=sheet_nome,\n",
    "        nrows=50,\n",
    "        header=None,\n",
    "        engine='openpyxl'\n",
    "    )\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CASO 3: CSV ğŸ†•\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "elif metodo_carga == 'csv':\n",
    "    print(\"ğŸ“„ MÃ©todo: CSV\")\n",
    "\n",
    "    df_preview = pd.read_csv(\n",
    "        arquivo_selecionado,\n",
    "        sep=separador_detectado,\n",
    "        encoding='cp1252',\n",
    "        skiprows=skiprows_csv,\n",
    "        nrows=50,\n",
    "        header=None  # Sem cabeÃ§alho por enquanto\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"âŒ MÃ©todo de carga desconhecido: {metodo_carga}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LIMITAR A 20 COLUNAS PARA VISUALIZAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "df_preview_limitado = df_preview.iloc[:, :20].copy()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXIBIR INFORMAÃ‡Ã•ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\nğŸ“Š DimensÃµes do preview:\")\n",
    "print(f\"   Total: {df_preview.shape[0]} linhas Ã— {df_preview.shape[1]} colunas\")\n",
    "print(f\"   Exibindo: {df_preview_limitado.shape[0]} linhas Ã— {df_preview_limitado.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nğŸ‘ï¸  Preview (primeiras 50 linhas, atÃ© 20 colunas):\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# Usar display ou print dependendo do ambiente\n",
    "try:\n",
    "    display(df_preview_limitado)\n",
    "except NameError:\n",
    "    print(df_preview_limitado.to_string())\n",
    "\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: SALVAR PREVIEW EM DISCO (PrincÃ­pio \"0% memÃ³ria, 100% LOG\")\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "try:\n",
    "    # Importar mÃ³dulos necessÃ¡rios se ainda nÃ£o estiverem disponÃ­veis\n",
    "    import os\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "\n",
    "    # âœ… RECUPERAR pasta_processamento do estado persistido\n",
    "    if 'pasta_processamento' not in locals() and 'pasta_processamento' not in globals():\n",
    "        # Tentar recuperar do arquivo de estado\n",
    "        estado_files = [f for f in os.listdir('..') if f.startswith('.bloco_') and f.endswith('_state.json')]\n",
    "\n",
    "        if estado_files:\n",
    "            # Pegar o estado mais recente\n",
    "            estado_file = sorted(estado_files)[-1]\n",
    "            with open(estado_file, 'r', encoding='utf-8') as f:\n",
    "                estado = json.load(f)\n",
    "                pasta_processamento = estado.get('pasta_processamento')\n",
    "                if not pasta_processamento:\n",
    "                    raise ValueError(\"pasta_processamento nÃ£o encontrada no estado\")\n",
    "        else:\n",
    "            # Se nÃ£o houver estado, criar pasta padrÃ£o baseada no arquivo atual\n",
    "            if 'arquivo_selecionado' in locals() or 'arquivo_selecionado' in globals():\n",
    "                base_name = os.path.splitext(os.path.basename(arquivo_selecionado))[0]\n",
    "                pasta_processamento = f'PROCESSAMENTO_{base_name}'\n",
    "                os.makedirs(pasta_processamento, exist_ok=True)\n",
    "            else:\n",
    "                raise ValueError(\"NÃ£o foi possÃ­vel determinar pasta_processamento\")\n",
    "\n",
    "    # âœ… RECUPERAR log_transformacoes do arquivo persistido ou criar novo\n",
    "    log_file = os.path.join(pasta_processamento, 'log_transformacoes.json')\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r', encoding='utf-8') as f:\n",
    "            log_transformacoes = json.load(f)\n",
    "    else:\n",
    "        log_transformacoes = []\n",
    "\n",
    "    # Salvar preview completo em Pickle (nÃ£o requer dependÃªncias extras)\n",
    "    arquivo_preview = os.path.join(pasta_processamento, 'bloco_7_preview.pkl')\n",
    "    df_preview.to_pickle(arquivo_preview)\n",
    "    print(f\"\\nğŸ’¾ Preview salvo: {arquivo_preview}\")\n",
    "\n",
    "    # Salvar preview limitado tambÃ©m (para referÃªncia visual)\n",
    "    arquivo_preview_limitado = os.path.join(pasta_processamento, 'bloco_7_preview_limitado.pkl')\n",
    "    df_preview_limitado.to_pickle(arquivo_preview_limitado)\n",
    "    print(f\"ğŸ’¾ Preview limitado salvo: {arquivo_preview_limitado}\")\n",
    "\n",
    "    # Registrar no log de transformaÃ§Ãµes\n",
    "    log_transformacoes.append({\n",
    "        'bloco': 7,\n",
    "        'operacao': 'preview_visual',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'metodo_carga': metodo_carga,\n",
    "        'linhas_preview': df_preview.shape[0],\n",
    "        'colunas_preview': df_preview.shape[1],\n",
    "        'linhas_exibidas': df_preview_limitado.shape[0],\n",
    "        'colunas_exibidas': df_preview_limitado.shape[1],\n",
    "        'arquivo_preview': arquivo_preview,\n",
    "        'arquivo_preview_limitado': arquivo_preview_limitado\n",
    "    })\n",
    "\n",
    "    # Salvar log atualizado\n",
    "    with open(os.path.join(pasta_processamento, 'log_transformacoes.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(log_transformacoes, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"âœ… Log de transformaÃ§Ãµes atualizado\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Aviso: NÃ£o foi possÃ­vel salvar preview em disco: {e}\")\n",
    "    print(\"   (Continuando sem persistÃªncia do preview)\")"
   ],
   "id": "e38c2bfb13dddecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‘€ PREVIEW DO ARQUIVO\n",
      "======================================================================\n",
      "ğŸ“Š MÃ©todo: pandas Excel\n",
      "\n",
      "ğŸ“Š DimensÃµes do preview:\n",
      "   Total: 31 linhas Ã— 2 colunas\n",
      "   Exibindo: 31 linhas Ã— 2 colunas\n",
      "\n",
      "ğŸ‘ï¸  Preview (primeiras 50 linhas, atÃ© 20 colunas):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       0                           1\n",
       "0   CÃ³d Grupo de produto      Desc. Grupo de Produto\n",
       "1                 AB9_KG                         AB9\n",
       "2       ACETATO_ETILA_KG            ACETATO DE ETILA\n",
       "3    ADIT_DIESEL_SIMPLES              ADITIVO DIESEL\n",
       "4            AGUARRAS_KG                    AGUARRAS\n",
       "5         ANIDRO_SIMPLES                      ANIDRO\n",
       "6           B100_SIMPLES                        B100\n",
       "7   DIESEL_MARÃTIMO_COMP             DIESEL MARÃTIMO\n",
       "8   DIESEL_MARÃTIMO_SIMP             DIESEL MARÃTIMO\n",
       "9   DIESEL_S10_ADITIVADO        DIESEL S10 ADITIVADO\n",
       "10   DIESEL_S10_COMPOSTO                  DIESEL S10\n",
       "11    DIESEL_S10_SIMPLES                  DIESEL S10\n",
       "12  DIESEL_S500_ADITIVAD       DIESEL S500 ADITIVADO\n",
       "13  DIESEL_S500_COMPOSTO                 DIESEL S500\n",
       "14   DIESEL_S500_SIMPLES                 DIESEL S500\n",
       "15  DIESEL_VERANA_SIMPLE               DIESEL VERANA\n",
       "16      ETANOL_ADITIVADO            ETANOL ADITIVADO\n",
       "17    GASOLINA_ADITIVADA          GASOLINA ADITIVADA\n",
       "18  GASOLINA_AVIAÃ‡ÃƒO_SIM            GASOLINA AVIAÃ‡ÃƒO\n",
       "19     GASOLINA_COMPOSTO                    GASOLINA\n",
       "20  GASOLINA_PODIUM_COMP             GASOLINA PODIUM\n",
       "21  GASOLINA_PODIUM_SIMP             GASOLINA PODIUM\n",
       "22      GASOLINA_SIMPLES                    GASOLINA\n",
       "23             HEXANO_KG                      HEXANO\n",
       "24     HIDRATADO_SIMPLES                   HIDRATADO\n",
       "25     QUEROSENE_SIMPLES                   QUEROSENE\n",
       "26    SOLBRAX_230_260_KG             SOLBRAX 260/230\n",
       "27            TOLUENO_KG                     TOLUENO\n",
       "28             XILENO_KG                      XILENO\n",
       "29  Ã“LEO_COMBUSTÃVEL_ADI  Ã“LEO COMBUSTÃVEL ADITIVADO\n",
       "30  Ã“LEO_COMBUSTÃVEL_SIM            Ã“LEO COMBUSTÃVEL"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CÃ³d Grupo de produto</td>\n",
       "      <td>Desc. Grupo de Produto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB9_KG</td>\n",
       "      <td>AB9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACETATO_ETILA_KG</td>\n",
       "      <td>ACETATO DE ETILA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIT_DIESEL_SIMPLES</td>\n",
       "      <td>ADITIVO DIESEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGUARRAS_KG</td>\n",
       "      <td>AGUARRAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANIDRO_SIMPLES</td>\n",
       "      <td>ANIDRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B100_SIMPLES</td>\n",
       "      <td>B100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIESEL_MARÃTIMO_COMP</td>\n",
       "      <td>DIESEL MARÃTIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIESEL_MARÃTIMO_SIMP</td>\n",
       "      <td>DIESEL MARÃTIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DIESEL_S10_ADITIVADO</td>\n",
       "      <td>DIESEL S10 ADITIVADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DIESEL_S10_COMPOSTO</td>\n",
       "      <td>DIESEL S10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DIESEL_S10_SIMPLES</td>\n",
       "      <td>DIESEL S10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DIESEL_S500_ADITIVAD</td>\n",
       "      <td>DIESEL S500 ADITIVADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DIESEL_S500_COMPOSTO</td>\n",
       "      <td>DIESEL S500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DIESEL_S500_SIMPLES</td>\n",
       "      <td>DIESEL S500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIESEL_VERANA_SIMPLE</td>\n",
       "      <td>DIESEL VERANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ETANOL_ADITIVADO</td>\n",
       "      <td>ETANOL ADITIVADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GASOLINA_ADITIVADA</td>\n",
       "      <td>GASOLINA ADITIVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GASOLINA_AVIAÃ‡ÃƒO_SIM</td>\n",
       "      <td>GASOLINA AVIAÃ‡ÃƒO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GASOLINA_COMPOSTO</td>\n",
       "      <td>GASOLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GASOLINA_PODIUM_COMP</td>\n",
       "      <td>GASOLINA PODIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GASOLINA_PODIUM_SIMP</td>\n",
       "      <td>GASOLINA PODIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GASOLINA_SIMPLES</td>\n",
       "      <td>GASOLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HEXANO_KG</td>\n",
       "      <td>HEXANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HIDRATADO_SIMPLES</td>\n",
       "      <td>HIDRATADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QUEROSENE_SIMPLES</td>\n",
       "      <td>QUEROSENE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SOLBRAX_230_260_KG</td>\n",
       "      <td>SOLBRAX 260/230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TOLUENO_KG</td>\n",
       "      <td>TOLUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XILENO_KG</td>\n",
       "      <td>XILENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ã“LEO_COMBUSTÃVEL_ADI</td>\n",
       "      <td>Ã“LEO COMBUSTÃVEL ADITIVADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ã“LEO_COMBUSTÃVEL_SIM</td>\n",
       "      <td>Ã“LEO COMBUSTÃVEL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ’¾ Preview salvo: PROCESSAMENTO_Grupos de Produtos x CÃ³digos de Materiais\\bloco_7_preview.pkl\n",
      "ğŸ’¾ Preview limitado salvo: PROCESSAMENTO_Grupos de Produtos x CÃ³digos de Materiais\\bloco_7_preview_limitado.pkl\n",
      "âœ… Log de transformaÃ§Ãµes atualizado\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T22:47:05.325625Z",
     "start_time": "2025-10-18T22:47:00.579052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# BLOCO 8 - DETECÃ‡ÃƒO E SELEÃ‡ÃƒO AVANÃ‡ADA DE CABEÃ‡ALHO - COMPLETO\n",
    "# VERSÃƒO PERSISTÃŠNCIA v2.2 - PRINCIPIO \"0% MEMÃ“RIA, 100% LOG\"\n",
    "# Com: DicionÃ¡rio + AnÃ¡lise RepetiÃ§Ã£o + Multi-linha + AnÃ¡lise Colunas COMPLETA\n",
    "# MudanÃ§as v2.2:\n",
    "#   - Salvamento completo de scores em .json\n",
    "#   - Salvamento de data_para_analise em .json\n",
    "#   - Salvamento de colunas_analise em .json\n",
    "#   - Salvamento de blocos_continuos em .json\n",
    "#   - Salvamento de linha_cabecalho extraÃ­da em .json\n",
    "#   - Estado .bloco_8_state.json com referÃªncias a todos arquivos\n",
    "#   - Log estruturado de transformaÃ§Ãµes\n",
    "#   - Usa APENAS JSON (sem dependÃªncias externas, 100% compatÃ­vel)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ DETECÃ‡ÃƒO E SELEÃ‡ÃƒO DE CABEÃ‡ALHO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CARREGAR DICIONÃRIO PERSISTENTE (se nÃ£o estiver carregado)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ” Verificando cabeÃ§alho multi-linha...\")\n",
    "\n",
    "if 'DICIONARIO_PERSISTENTE' not in globals():\n",
    "    print(\"\\nğŸ“š Carregando dicionÃ¡rio persistente...\")\n",
    "\n",
    "    locais_dicionario = [\n",
    "        Path.cwd() / 'DICT_Dicionario_Persistente.json',\n",
    "        fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json',\n",
    "        Path.cwd().parent / 'DICT_Dicionario_Persistente.json',\n",
    "    ]\n",
    "\n",
    "    DICIONARIO_PERSISTENTE = None\n",
    "\n",
    "    for local in locais_dicionario:\n",
    "        if local.exists():\n",
    "            try:\n",
    "                with open(local, 'r', encoding='utf-8') as f:\n",
    "                    DICIONARIO_PERSISTENTE = json.load(f)\n",
    "                print(f\"   âœ… Carregado de: {local.name}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not DICIONARIO_PERSISTENTE:\n",
    "        print(f\"   â„¹ï¸  DicionÃ¡rio nÃ£o encontrado - criando vazio\")\n",
    "        DICIONARIO_PERSISTENTE = {\n",
    "            'arquivos': {},\n",
    "            'ultima_atualizacao': None,\n",
    "            'versao': '1.0'\n",
    "        }\n",
    "else:\n",
    "    print(\"\\nğŸ“š DicionÃ¡rio persistente jÃ¡ carregado\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FUNÃ‡ÃƒO AVANÃ‡ADA DE AVALIAÃ‡ÃƒO DE LINHA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def avaliar_linha_cabecalho_avancada(\n",
    "    linha, idx, total_linhas, df_preview, dicionario_persistente\n",
    "):\n",
    "    \"\"\"Avalia linha como candidata a cabeÃ§alho com mÃºltiplas heurÃ­sticas.\"\"\"\n",
    "    celulas = [\n",
    "        str(c).strip() for c in linha\n",
    "        if str(c).strip() and str(c).strip().lower() not in\n",
    "        ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not celulas:\n",
    "        return {\n",
    "            'score': 0.0,\n",
    "            'detalhes': 'Linha vazia',\n",
    "            'matches_dicionario': []\n",
    "        }\n",
    "\n",
    "    score = 0.0\n",
    "    detalhes = []\n",
    "\n",
    "    # CRITÃ‰RIO 1: PROPORÃ‡ÃƒO DE CÃ‰LULAS PREENCHIDAS (peso 2.0)\n",
    "    prop_preenchidas = len(celulas) / len(linha)\n",
    "    score_preenchidas = prop_preenchidas * 2.0\n",
    "    score += score_preenchidas\n",
    "    detalhes.append(\n",
    "        f\"Preench: {prop_preenchidas:.0%} (+{score_preenchidas:.1f})\"\n",
    "    )\n",
    "\n",
    "    # CRITÃ‰RIO 2: PROPORÃ‡ÃƒO DE TEXTO (peso 2.5)\n",
    "    tem_texto = sum(1 for c in celulas if re.search(r'[a-zA-Z]', c))\n",
    "    prop_texto = tem_texto / len(celulas) if celulas else 0\n",
    "    score_texto = prop_texto * 2.5\n",
    "    score += score_texto\n",
    "    detalhes.append(f\"Texto: {prop_texto:.0%} (+{score_texto:.1f})\")\n",
    "\n",
    "    # CRITÃ‰RIO 3: MATCH COM DICIONÃRIO PERSISTENTE (peso 4.0)\n",
    "    bonus_dicionario = 0.0\n",
    "    matches_dicionario = []\n",
    "\n",
    "    if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "        campos_conhecidos = set()\n",
    "        for arquivo_info in dicionario_persistente.get(\n",
    "            'arquivos', {}\n",
    "        ).values():\n",
    "            if 'campos_mapeados' in arquivo_info:\n",
    "                for campo_info in arquivo_info[\n",
    "                    'campos_mapeados'\n",
    "                ].values():\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        campos_conhecidos.add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "        for celula in celulas:\n",
    "            celula_lower = celula.lower()\n",
    "            if celula_lower in campos_conhecidos:\n",
    "                bonus_dicionario += 0.8\n",
    "                matches_dicionario.append(celula[:20])\n",
    "            elif any(\n",
    "                conhecido in celula_lower\n",
    "                for conhecido in campos_conhecidos\n",
    "            ):\n",
    "                bonus_dicionario += 0.4\n",
    "                matches_dicionario.append(f\"{celula[:15]}*\")\n",
    "\n",
    "    bonus_dicionario = min(bonus_dicionario, 4.0)\n",
    "    score += bonus_dicionario\n",
    "\n",
    "    if bonus_dicionario > 0:\n",
    "        detalhes.append(\n",
    "            f\"Dict: {len(matches_dicionario)}m (+{bonus_dicionario:.1f})\"\n",
    "        )\n",
    "\n",
    "    # CRITÃ‰RIO 4: ANÃLISE DE REPETIÃ‡ÃƒO (peso 3.0)\n",
    "    try:\n",
    "        linhas_futuras = min(20, total_linhas - idx - 1)\n",
    "\n",
    "        if linhas_futuras >= 5:\n",
    "            colunas_com_repeticao = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for i in range(1, min(linhas_futuras + 1, 21)):\n",
    "                    if idx + i < len(df_preview):\n",
    "                        valor_futuro = str(\n",
    "                            df_preview.iloc[idx + i, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_futuro == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 2:\n",
    "                    colunas_com_repeticao += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_repeticao = (\n",
    "                    colunas_com_repeticao / total_colunas_analisadas\n",
    "                )\n",
    "                score_repeticao = (1 - prop_repeticao) * 3.0\n",
    "                score += score_repeticao\n",
    "                detalhes.append(\n",
    "                    f\"Unic: {(1-prop_repeticao):.0%} \"\n",
    "                    f\"(+{score_repeticao:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 5: TAMANHO MÃ‰DIO DE STRINGS (peso 1.0)\n",
    "    tamanho_medio = np.mean([len(c) for c in celulas]) if celulas else 0\n",
    "    if 5 <= tamanho_medio <= 50:\n",
    "        score += 1.0\n",
    "        detalhes.append(f\"Tam: {tamanho_medio:.0f} (+1.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 6: UNICIDADE DENTRO DA LINHA (peso 1.5)\n",
    "    if len(celulas) == len(set(celulas)):\n",
    "        score += 1.5\n",
    "        detalhes.append(\"Ãšnicos (+1.5)\")\n",
    "\n",
    "    # CRITÃ‰RIO 7: POSIÃ‡ÃƒO NO ARQUIVO (peso 0.5)\n",
    "    if idx < 50:\n",
    "        bonus_posicao = (50 - idx) / 100\n",
    "        score += bonus_posicao\n",
    "        detalhes.append(f\"Pos: {idx+1} (+{bonus_posicao:.2f})\")\n",
    "\n",
    "    # CRITÃ‰RIO 8: ANÃLISE DE DADOS ABAIXO (peso 2.5)\n",
    "    try:\n",
    "        if idx + 5 < total_linhas:\n",
    "            celulas_match_dict = 0\n",
    "            celulas_numericas_puras = 0\n",
    "            celulas_com_numeros = 0\n",
    "            total_celulas_validas = 0\n",
    "\n",
    "            campos_dict_lower = set()\n",
    "            if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "                for arquivo_info in dicionario_persistente.get(\n",
    "                    'arquivos', {}\n",
    "                ).values():\n",
    "                    if 'campos_mapeados' in arquivo_info:\n",
    "                        for campo_info in arquivo_info[\n",
    "                            'campos_mapeados'\n",
    "                        ].values():\n",
    "                            if 'nome_original' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_original'].lower()\n",
    "                                )\n",
    "                            if 'nome_padrao' in campo_info:\n",
    "                                campos_dict_lower.add(\n",
    "                                    campo_info['nome_padrao'].lower()\n",
    "                                )\n",
    "                            if 'sinonimos' in campo_info:\n",
    "                                for sin in campo_info['sinonimos']:\n",
    "                                    campos_dict_lower.add(sin.lower())\n",
    "\n",
    "            for offset in range(1, 6):\n",
    "                if idx + offset < len(df_preview):\n",
    "                    linha_seguinte = df_preview.iloc[idx + offset]\n",
    "\n",
    "                    for celula in linha_seguinte:\n",
    "                        celula_str = str(celula).strip()\n",
    "\n",
    "                        if not celula_str or celula_str.lower() in [\n",
    "                            'nan', 'none', ''\n",
    "                        ]:\n",
    "                            continue\n",
    "\n",
    "                        total_celulas_validas += 1\n",
    "                        celula_lower = celula_str.lower()\n",
    "\n",
    "                        matched = False\n",
    "                        if campos_dict_lower:\n",
    "                            if celula_lower in campos_dict_lower:\n",
    "                                celulas_match_dict += 1\n",
    "                                matched = True\n",
    "                            else:\n",
    "                                for campo_conhecido in campos_dict_lower:\n",
    "                                    if (campo_conhecido in celula_lower or\n",
    "                                        celula_lower in campo_conhecido):\n",
    "                                        if len(campo_conhecido) >= 3:\n",
    "                                            celulas_match_dict += 1\n",
    "                                            matched = True\n",
    "                                            break\n",
    "\n",
    "                        if not matched:\n",
    "                            apenas_numeros = re.sub(\n",
    "                                r'[^0-9.]', '', celula_str\n",
    "                            )\n",
    "\n",
    "                            if len(apenas_numeros) > 0:\n",
    "                                prop_digitos = (\n",
    "                                    len(apenas_numeros) / len(celula_str)\n",
    "                                )\n",
    "                                if prop_digitos > 0.5:\n",
    "                                    celulas_numericas_puras += 1\n",
    "                                elif re.search(r'\\d', celula_str):\n",
    "                                    celulas_com_numeros += 1\n",
    "\n",
    "            if total_celulas_validas > 0:\n",
    "                prop_dict = celulas_match_dict / total_celulas_validas\n",
    "                prop_num_puras = (\n",
    "                    celulas_numericas_puras / total_celulas_validas\n",
    "                )\n",
    "                prop_com_num = celulas_com_numeros / total_celulas_validas\n",
    "\n",
    "                bonus_dados = 0.0\n",
    "                metodo_usado = None\n",
    "\n",
    "                if prop_dict > 0.4:\n",
    "                    bonus_dados = 2.5\n",
    "                    metodo_usado = f\"Dict:{prop_dict:.0%}\"\n",
    "                elif prop_num_puras > 0.6:\n",
    "                    bonus_dados = 2.0\n",
    "                    metodo_usado = f\"Num:{prop_num_puras:.0%}\"\n",
    "                elif (prop_num_puras + prop_com_num) > 0.7:\n",
    "                    bonus_dados = 1.0\n",
    "                    metodo_usado = f\"Misto:{(prop_num_puras+prop_com_num):.0%}\"\n",
    "\n",
    "                if bonus_dados > 0:\n",
    "                    score += bonus_dados\n",
    "                    detalhes.append(\n",
    "                        f\"DadosAbaixo:{metodo_usado} (+{bonus_dados:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 9: ANTI-DADOS (penalidade)\n",
    "    try:\n",
    "        celulas_linha_atual = [\n",
    "            str(c).strip() for c in linha\n",
    "            if str(c).strip() and str(c).strip().lower() not in\n",
    "            ['nan', 'none', '']\n",
    "        ]\n",
    "\n",
    "        if celulas_linha_atual:\n",
    "            num_puras_linha = 0\n",
    "            for celula in celulas_linha_atual:\n",
    "                apenas_numeros = re.sub(r'[^0-9.]', '', celula)\n",
    "                if len(apenas_numeros) > 0:\n",
    "                    prop_digitos = len(apenas_numeros) / len(celula)\n",
    "                    if prop_digitos > 0.5:\n",
    "                        num_puras_linha += 1\n",
    "\n",
    "            prop_num_linha = num_puras_linha / len(celulas_linha_atual)\n",
    "\n",
    "            repeticoes_detectadas = 0\n",
    "            if idx + 5 < total_linhas:\n",
    "                for col_idx, valor_atual in enumerate(linha):\n",
    "                    valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                    if (not valor_atual_str or\n",
    "                        valor_atual_str.lower() in ['nan', 'none', '']):\n",
    "                        continue\n",
    "\n",
    "                    for offset in range(1, min(6, total_linhas - idx)):\n",
    "                        if idx + offset < len(df_preview):\n",
    "                            valor_seguinte = str(\n",
    "                                df_preview.iloc[idx + offset, col_idx]\n",
    "                            ).strip()\n",
    "                            if valor_seguinte == valor_atual_str:\n",
    "                                repeticoes_detectadas += 1\n",
    "                                break\n",
    "\n",
    "            prop_repeticoes = (\n",
    "                repeticoes_detectadas / len(celulas_linha_atual)\n",
    "                if celulas_linha_atual else 0\n",
    "            )\n",
    "\n",
    "            penalidade = 0.0\n",
    "\n",
    "            if prop_num_linha > 0.6 and prop_repeticoes > 0.3:\n",
    "                penalidade = -3.0\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%}+Rep\"\n",
    "                    f\"{prop_repeticoes:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "            elif prop_num_linha > 0.7:\n",
    "                penalidade = -1.5\n",
    "                score += penalidade\n",
    "                detalhes.append(\n",
    "                    f\"AntiDados:Num{prop_num_linha:.0%} ({penalidade:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 10: PADRÃƒO DE RÃ“TULOS (+4.0 pontos)\n",
    "    try:\n",
    "        palavras_rotulo = [\n",
    "            'centro', 'produto', 'material', 'data', 'valor', 'quantidade',\n",
    "            'codigo', 'nome', 'descricao', 'tipo', 'categoria', 'grupo',\n",
    "            'sigla', 'unidade', 'medida', 'periodo', 'mes', 'ano',\n",
    "            'referencia', 'documento', 'numero', 'id', 'chave', 'hierarq',\n",
    "            'lucro', 'receita', 'custo', 'despesa', 'saldo', 'total',\n",
    "            'indice', 'variacao', 'percentual', 'taxa', 'margem'\n",
    "        ]\n",
    "\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        if 'nome_original' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_original'].lower()\n",
    "                            )\n",
    "                        if 'nome_padrao' in campo_info:\n",
    "                            palavras_rotulo.append(\n",
    "                                campo_info['nome_padrao'].lower()\n",
    "                            )\n",
    "\n",
    "        palavras_rotulo = set(palavras_rotulo)\n",
    "\n",
    "        matches_rotulo = 0\n",
    "        celulas_validas = 0\n",
    "\n",
    "        for celula in linha:\n",
    "            celula_str = str(celula).strip()\n",
    "            if not celula_str or celula_str.lower() in ['nan', 'none', '']:\n",
    "                continue\n",
    "\n",
    "            celulas_validas += 1\n",
    "            celula_lower = celula_str.lower()\n",
    "\n",
    "            if celula_lower in palavras_rotulo:\n",
    "                matches_rotulo += 1\n",
    "            else:\n",
    "                for palavra in palavras_rotulo:\n",
    "                    if len(palavra) >= 4 and palavra in celula_lower:\n",
    "                        matches_rotulo += 1\n",
    "                        break\n",
    "\n",
    "        if celulas_validas > 0:\n",
    "            prop_rotulos = matches_rotulo / celulas_validas\n",
    "\n",
    "            if prop_rotulos > 0.4:\n",
    "                bonus_rotulos = 4.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "            elif prop_rotulos > 0.25:\n",
    "                bonus_rotulos = 2.0\n",
    "                score += bonus_rotulos\n",
    "                detalhes.append(\n",
    "                    f\"Rotulos:{prop_rotulos:.0%} (+{bonus_rotulos:.1f})\"\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 11: ANTI-REPETIÃ‡ÃƒO FORTE (-4.0 pontos)\n",
    "    try:\n",
    "        if idx + 10 < total_linhas:\n",
    "            colunas_com_repeticao_forte = 0\n",
    "            total_colunas_analisadas = 0\n",
    "\n",
    "            for col_idx, valor_atual in enumerate(linha):\n",
    "                valor_atual_str = str(valor_atual).strip()\n",
    "\n",
    "                if not valor_atual_str or valor_atual_str.lower() in [\n",
    "                    'nan', 'none', ''\n",
    "                ]:\n",
    "                    continue\n",
    "\n",
    "                total_colunas_analisadas += 1\n",
    "\n",
    "                repeticoes = 0\n",
    "                for offset in range(1, min(11, total_linhas - idx)):\n",
    "                    if idx + offset < len(df_preview):\n",
    "                        valor_seg = str(\n",
    "                            df_preview.iloc[idx + offset, col_idx]\n",
    "                        ).strip()\n",
    "                        if valor_seg == valor_atual_str:\n",
    "                            repeticoes += 1\n",
    "\n",
    "                if repeticoes >= 5:\n",
    "                    colunas_com_repeticao_forte += 1\n",
    "\n",
    "            if total_colunas_analisadas > 0:\n",
    "                prop_rep_forte = (\n",
    "                    colunas_com_repeticao_forte / total_colunas_analisadas\n",
    "                )\n",
    "\n",
    "                if prop_rep_forte > 0.3:\n",
    "                    penalidade_rep = -4.0\n",
    "                    score += penalidade_rep\n",
    "                    detalhes.append(\n",
    "                        f\"AntiRep:{prop_rep_forte:.0%} \"\n",
    "                        f\"({penalidade_rep:.1f})\"\n",
    "                    )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # CRITÃ‰RIO 12: DENSIDADE DE RÃ“TULOS DO DICIONÃRIO (+3.0 pontos)\n",
    "    try:\n",
    "        if dicionario_persistente and 'arquivos' in dicionario_persistente:\n",
    "            campos_conhecidos = {}\n",
    "\n",
    "            for arquivo_info in dicionario_persistente.get(\n",
    "                'arquivos', {}\n",
    "            ).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_info in arquivo_info[\n",
    "                        'campos_mapeados'\n",
    "                    ].values():\n",
    "                        nome_orig = campo_info.get('nome_original', '')\n",
    "                        nome_pad = campo_info.get('nome_padrao', '')\n",
    "\n",
    "                        if nome_orig:\n",
    "                            campos_conhecidos[nome_orig.lower()] = True\n",
    "                        if nome_pad:\n",
    "                            campos_conhecidos[nome_pad.lower()] = True\n",
    "\n",
    "            if campos_conhecidos:\n",
    "                matches_exatos = 0\n",
    "                celulas_validas = 0\n",
    "\n",
    "                for celula in linha:\n",
    "                    celula_str = str(celula).strip()\n",
    "                    if not celula_str or celula_str.lower() in [\n",
    "                        'nan', 'none', ''\n",
    "                    ]:\n",
    "                        continue\n",
    "\n",
    "                    celulas_validas += 1\n",
    "                    celula_lower = celula_str.lower()\n",
    "\n",
    "                    if celula_lower in campos_conhecidos:\n",
    "                        matches_exatos += 1\n",
    "\n",
    "                if celulas_validas > 0:\n",
    "                    prop_dict_exato = matches_exatos / celulas_validas\n",
    "\n",
    "                    if prop_dict_exato > 0.5:\n",
    "                        bonus_dict_dens = 3.0\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "                    elif prop_dict_exato > 0.3:\n",
    "                        bonus_dict_dens = 1.5\n",
    "                        score += bonus_dict_dens\n",
    "                        detalhes.append(\n",
    "                            f\"DictDens:{prop_dict_exato:.0%} \"\n",
    "                            f\"(+{bonus_dict_dens:.1f})\"\n",
    "                        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        'score': score,\n",
    "        'detalhes': ' | '.join(detalhes),\n",
    "        'matches_dicionario': matches_dicionario\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# AVALIAR TODAS AS LINHAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ“Š Analisando linhas para detectar cabeÃ§alho...\")\n",
    "\n",
    "if metodo_carga == 'csv':\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "elif metodo_carga == 'xlrd':\n",
    "    data_para_analise = []\n",
    "    sheet = workbook.sheet_by_name(sheet_nome)\n",
    "    for row_idx in range(min(50, sheet.nrows)):\n",
    "        data_para_analise.append(sheet.row_values(row_idx))\n",
    "else:\n",
    "    data_para_analise = df_preview.values.tolist()\n",
    "\n",
    "scores = []\n",
    "\n",
    "for idx, linha in enumerate(data_para_analise):\n",
    "    resultado = avaliar_linha_cabecalho_avancada(\n",
    "        linha,\n",
    "        idx,\n",
    "        len(data_para_analise),\n",
    "        df_preview,\n",
    "        DICIONARIO_PERSISTENTE\n",
    "    )\n",
    "\n",
    "    scores.append({\n",
    "        'linha_excel': idx + 1,\n",
    "        'indice': idx,\n",
    "        'score': resultado['score'],\n",
    "        'detalhes': resultado['detalhes'],\n",
    "        'matches': resultado['matches_dicionario']\n",
    "    })\n",
    "\n",
    "scores = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: SALVAR SCORES E DATA_PARA_ANALISE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ’¾ Salvando scores e preview dos dados...\")\n",
    "\n",
    "# Salvar scores como JSON (compatÃ­vel, sem dependÃªncias)\n",
    "arquivo_scores = fm.pastas['logs'] / '.bloco8_scores.json'\n",
    "with open(arquivo_scores, 'w', encoding='utf-8') as f:\n",
    "    json.dump(scores, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   âœ… Scores salvos: {arquivo_scores.name}\")\n",
    "\n",
    "# Salvar data_para_analise como JSON (lista de listas)\n",
    "# Converter para formato serializÃ¡vel\n",
    "data_serializada = []\n",
    "for linha in data_para_analise:\n",
    "    linha_serializada = []\n",
    "    for celula in linha:\n",
    "        # Converter para tipos bÃ¡sicos do Python\n",
    "        if pd.isna(celula):\n",
    "            linha_serializada.append(None)\n",
    "        else:\n",
    "            linha_serializada.append(str(celula) if not isinstance(celula, (int, float, str, bool, type(None))) else celula)\n",
    "    data_serializada.append(linha_serializada)\n",
    "\n",
    "arquivo_data_analise = fm.pastas['logs'] / '.bloco8_data_para_analise.json'\n",
    "with open(arquivo_data_analise, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'shape': [len(data_para_analise), len(data_para_analise[0]) if data_para_analise else 0],\n",
    "        'data': data_serializada\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   âœ… Preview salvo: {arquivo_data_analise.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXIBIR TOP 5 CANDIDATOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ† Top 5 candidatos a cabeÃ§alho:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“ NUMERAÃ‡ÃƒO: Usamos Ã­ndice Python (preview inicia em 0)\")\n",
    "print(\"   â€¢ Ãndice 0 = Linha 1 no Excel\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, item in enumerate(scores[:5], 1):\n",
    "    idx_py = item['indice']\n",
    "    linha_excel = item['linha_excel']\n",
    "\n",
    "    print(f\"\\n   {i}Âº. Ãndice {idx_py} (Excel: Linha {linha_excel})\")\n",
    "    print(f\"       Score: {item['score']:.2f}/24.5\")\n",
    "    print(f\"       {item['detalhes']}\")\n",
    "    if item['matches']:\n",
    "        matches_str = ', '.join(item['matches'][:5])\n",
    "        print(f\"       Matches: {matches_str}\")\n",
    "\n",
    "melhor = scores[0]\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\n",
    "    f\"ğŸ¯ SUGESTÃƒO AUTOMÃTICA: Ãndice {melhor['indice']} \"\n",
    "    f\"(Excel: Linha {melhor['linha_excel']})\"\n",
    ")\n",
    "print(f\"   ConfianÃ§a: {melhor['score']:.2f}/24.5\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ANÃLISE DE COLUNAS VÃLIDAS - SISTEMA COMPLETO v2.1\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def analisar_coluna_valida_COMPLETA(\n",
    "    col_idx,\n",
    "    nome_coluna,\n",
    "    dados_coluna,\n",
    "    dicionario,\n",
    "    todas_colunas_info=None\n",
    "):\n",
    "    \"\"\"\n",
    "    AnÃ¡lise COMPLETA de coluna com 12 critÃ©rios avanÃ§ados.\n",
    "    Funciona para TABELAS TRANSACIONAIS e RELATÃ“RIOS BI.\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    razoes = []\n",
    "    metodo_usado = None\n",
    "\n",
    "    valores = [\n",
    "        str(v).strip() for v in dados_coluna\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    if not valores:\n",
    "        return {\n",
    "            'valida': False,\n",
    "            'score': 0.0,\n",
    "            'razoes': ['Coluna vazia'],\n",
    "            'tipo_detectado': 'VAZIA',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'VAZIO',\n",
    "            'prop_preenchimento': 0.0,\n",
    "            'match_dicionario': None\n",
    "        }\n",
    "\n",
    "    # CRITÃ‰RIO 1: SIMILARIDADE COM ALIASES DO DICIONÃRIO (peso 8.0)\n",
    "    nome_lower = str(nome_coluna).lower().strip()\n",
    "    melhor_match_alias = None\n",
    "    melhor_score_alias = 0.0\n",
    "    campo_matched = None\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        aliases_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if nome_campo not in aliases_por_campo:\n",
    "                        aliases_por_campo[nome_campo] = set()\n",
    "\n",
    "                    if 'nome_original' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_original'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'nome_padrao' in campo_info:\n",
    "                        aliases_por_campo[nome_campo].add(\n",
    "                            campo_info['nome_padrao'].lower()\n",
    "                        )\n",
    "\n",
    "                    if 'sinonimos' in campo_info:\n",
    "                        for sin in campo_info['sinonimos']:\n",
    "                            aliases_por_campo[nome_campo].add(sin.lower())\n",
    "\n",
    "        for campo, aliases in aliases_por_campo.items():\n",
    "            for alias in aliases:\n",
    "                if nome_lower == alias:\n",
    "                    melhor_score_alias = 1.0\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "                    break\n",
    "\n",
    "                similaridade = SequenceMatcher(None, nome_lower, alias).ratio()\n",
    "\n",
    "                if similaridade > melhor_score_alias:\n",
    "                    melhor_score_alias = similaridade\n",
    "                    melhor_match_alias = alias\n",
    "                    campo_matched = campo\n",
    "\n",
    "            if melhor_score_alias == 1.0:\n",
    "                break\n",
    "\n",
    "    if melhor_score_alias >= 0.95:\n",
    "        bonus_alias = 8.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Exato({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_EXATO'\n",
    "\n",
    "    elif melhor_score_alias >= 0.80:\n",
    "        bonus_alias = 6.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Similar({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_SIMILAR'\n",
    "\n",
    "    elif melhor_score_alias >= 0.60:\n",
    "        bonus_alias = 3.0\n",
    "        score += bonus_alias\n",
    "        razoes.append(f\"Alias:Parcial({melhor_score_alias:.0%}) +{bonus_alias:.1f}\")\n",
    "        metodo_usado = 'ALIAS_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 2: REGEX NOS CONTEÃšDOS vs DICIONÃRIO (peso 7.0)\n",
    "    melhor_match_regex = None\n",
    "    melhor_score_regex = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        padroes_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'regex' in campo_info:\n",
    "                        if nome_campo not in padroes_por_campo:\n",
    "                            padroes_por_campo[nome_campo] = []\n",
    "                        padroes_por_campo[nome_campo].append(campo_info['regex'])\n",
    "\n",
    "        for campo, padroes in padroes_por_campo.items():\n",
    "            for padrao in padroes:\n",
    "                try:\n",
    "                    matches = sum(\n",
    "                        1 for v in valores[:50]\n",
    "                        if re.match(padrao, v, re.IGNORECASE)\n",
    "                    )\n",
    "\n",
    "                    prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "                    if prop_matches > melhor_score_regex:\n",
    "                        melhor_score_regex = prop_matches\n",
    "                        melhor_match_regex = campo\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    if melhor_score_regex >= 0.80:\n",
    "        bonus_regex = 7.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_CONTEUDO'\n",
    "\n",
    "    elif melhor_score_regex >= 0.60:\n",
    "        bonus_regex = 4.0\n",
    "        score += bonus_regex\n",
    "        razoes.append(f\"Regex:{melhor_score_regex:.0%} +{bonus_regex:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'REGEX_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 3: SIMILARIDADE COM CONTEÃšDOS CONHECIDOS (peso 6.0)\n",
    "    melhor_match_conteudo = None\n",
    "    melhor_score_conteudo = 0.0\n",
    "\n",
    "    if dicionario and 'arquivos' in dicionario:\n",
    "        exemplos_por_campo = {}\n",
    "\n",
    "        for arq_info in dicionario.get('arquivos', {}).values():\n",
    "            if 'campos_mapeados' in arq_info:\n",
    "                for nome_campo, campo_info in arq_info['campos_mapeados'].items():\n",
    "                    if 'exemplos' in campo_info:\n",
    "                        if nome_campo not in exemplos_por_campo:\n",
    "                            exemplos_por_campo[nome_campo] = set()\n",
    "\n",
    "                        for exemplo in campo_info['exemplos']:\n",
    "                            exemplos_por_campo[nome_campo].add(\n",
    "                                str(exemplo).lower().strip()\n",
    "                            )\n",
    "\n",
    "        for campo, exemplos in exemplos_por_campo.items():\n",
    "            matches = 0\n",
    "            for valor in valores[:50]:\n",
    "                valor_lower = valor.lower()\n",
    "\n",
    "                if valor_lower in exemplos:\n",
    "                    matches += 1\n",
    "                else:\n",
    "                    for exemplo in exemplos:\n",
    "                        sim = SequenceMatcher(None, valor_lower, exemplo).ratio()\n",
    "                        if sim >= 0.85:\n",
    "                            matches += 1\n",
    "                            break\n",
    "\n",
    "            prop_matches = matches / min(len(valores), 50)\n",
    "\n",
    "            if prop_matches > melhor_score_conteudo:\n",
    "                melhor_score_conteudo = prop_matches\n",
    "                melhor_match_conteudo = campo\n",
    "\n",
    "    if melhor_score_conteudo >= 0.70:\n",
    "        bonus_conteudo = 6.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'CONTEUDO_SIMILAR'\n",
    "\n",
    "    elif melhor_score_conteudo >= 0.50:\n",
    "        bonus_conteudo = 3.0\n",
    "        score += bonus_conteudo\n",
    "        razoes.append(f\"Conteudo:{melhor_score_conteudo:.0%} +{bonus_conteudo:.1f}\")\n",
    "\n",
    "    # CRITÃ‰RIO 4: DETECÃ‡ÃƒO DE FÃ“RMULAS (penalidade -8.0)\n",
    "    tem_formulas = False\n",
    "\n",
    "    padroes_formula = [\n",
    "        r'^=',\n",
    "        r'^\\+',\n",
    "        r'^SUM\\(',\n",
    "        r'^IF\\(',\n",
    "        r'^VLOOKUP\\(',\n",
    "    ]\n",
    "\n",
    "    for valor in valores[:20]:\n",
    "        for padrao in padroes_formula:\n",
    "            if re.match(padrao, valor, re.IGNORECASE):\n",
    "                tem_formulas = True\n",
    "                break\n",
    "        if tem_formulas:\n",
    "            break\n",
    "\n",
    "    if tem_formulas:\n",
    "        penalidade_formula = -8.0\n",
    "        score += penalidade_formula\n",
    "        razoes.append(f\"Formula! {penalidade_formula:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'FORMULA_DETECTADA'\n",
    "\n",
    "    # CRITÃ‰RIO 5: DIVERSIDADE DE VALORES (peso 4.0)\n",
    "    valores_unicos = len(set(valores))\n",
    "    total_valores = len(valores)\n",
    "    prop_unicos = valores_unicos / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_unicos > 0.7:\n",
    "        score += 4.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+4.0)\")\n",
    "    elif prop_unicos > 0.4:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (+2.0)\")\n",
    "    elif prop_unicos < 0.05 and valores_unicos <= 3:\n",
    "        score -= 3.0\n",
    "        razoes.append(f\"Divers:{prop_unicos:.0%} (-3.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 6: PADRÃƒO DE FLAGS (penalidade -4.0)\n",
    "    flags_comuns = {'true', 'false', 'x', 'âœ“', '0', '1', 'sim', 'nÃ£o', 'yes', 'no'}\n",
    "    valores_lower = [v.lower() for v in valores]\n",
    "\n",
    "    matches_flag = sum(1 for v in valores_lower if v in flags_comuns)\n",
    "    prop_flags = matches_flag / total_valores if total_valores else 0\n",
    "\n",
    "    if prop_flags > 0.8:\n",
    "        score -= 4.0\n",
    "        razoes.append(f\"Flags:{prop_flags:.0%} (-4.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 7: PALAVRAS-CHAVE DE DADOS (peso 3.0)\n",
    "    palavras_dados = [\n",
    "        'centro', 'produto', 'material', 'codigo', 'nome', 'data',\n",
    "        'valor', 'quantidade', 'preco', 'custo', 'receita',\n",
    "        'hierarq', 'grupo', 'categoria', 'tipo', 'unidade',\n",
    "        'periodo', 'mes', 'ano', 'sigla', 'descricao', 'lucro'\n",
    "    ]\n",
    "\n",
    "    tem_palavra_chave = any(palavra in nome_lower for palavra in palavras_dados)\n",
    "\n",
    "    if tem_palavra_chave:\n",
    "        score += 3.0\n",
    "        razoes.append(f\"Keyword (+3.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 8: TAMANHO MÃ‰DIO DOS VALORES (peso 2.0)\n",
    "    tamanho_medio = sum(len(v) for v in valores) / len(valores)\n",
    "\n",
    "    if 3 <= tamanho_medio <= 100:\n",
    "        score += 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (+2.0)\")\n",
    "    elif tamanho_medio <= 2:\n",
    "        score -= 2.0\n",
    "        razoes.append(f\"Tam:{tamanho_medio:.0f} (-2.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 9: MIX NUMÃ‰RICO/ALFABÃ‰TICO (peso 1.0)\n",
    "    tem_numeros = sum(1 for v in valores if any(c.isdigit() for c in v))\n",
    "    tem_letras = sum(1 for v in valores if any(c.isalpha() for c in v))\n",
    "\n",
    "    if tem_numeros > 0 and tem_letras > 0:\n",
    "        score += 1.0\n",
    "        razoes.append(f\"Mix (+1.0)\")\n",
    "\n",
    "    # CRITÃ‰RIO 10: PREENCHIMENTO PARCIAL (penalidade -5.0)\n",
    "    prop_preenchimento = len(valores) / len(dados_coluna) if dados_coluna else 0\n",
    "\n",
    "    if prop_preenchimento < 0.30:\n",
    "        penalidade_parcial = -5.0\n",
    "        score += penalidade_parcial\n",
    "        razoes.append(f\"Parcial:{prop_preenchimento:.0%} {penalidade_parcial:.1f}\")\n",
    "        if not metodo_usado:\n",
    "            metodo_usado = 'PREENCHIMENTO_PARCIAL'\n",
    "\n",
    "    # CRITÃ‰RIO 11: MUDANÃ‡A ESTRUTURAL (penalidade -6.0)\n",
    "    if todas_colunas_info and col_idx > 0:\n",
    "        colunas_anteriores = todas_colunas_info[:col_idx]\n",
    "\n",
    "        if len(colunas_anteriores) >= 5:\n",
    "            preench_ultimas_5 = sum(\n",
    "                c.get('prop_preenchimento', 1.0)\n",
    "                for c in colunas_anteriores[-5:]\n",
    "            ) / 5\n",
    "\n",
    "            if preench_ultimas_5 > 0.80 and prop_preenchimento < 0.50:\n",
    "                penalidade_estrutural = -6.0\n",
    "                score += penalidade_estrutural\n",
    "                razoes.append(\n",
    "                    f\"Estrutural:Queda ({penalidade_estrutural:.1f})\"\n",
    "                )\n",
    "                if not metodo_usado:\n",
    "                    metodo_usado = 'MUDANCA_ESTRUTURAL'\n",
    "\n",
    "    # CRITÃ‰RIO 12: PADRÃƒO DE NOME \"VAZIO\" (penalidade -7.0)\n",
    "    nomes_vazios = ['unnamed', 'column', 'col', 'field', 'nan', 'none']\n",
    "\n",
    "    nome_eh_vazio = (\n",
    "        len(nome_lower) == 0 or\n",
    "        nome_lower in nomes_vazios or\n",
    "        (len(nome_lower) < 15 and any(vazio in nome_lower for vazio in nomes_vazios if vazio))\n",
    "    )\n",
    "\n",
    "    if nome_eh_vazio:\n",
    "        penalidade_nome = -7.0\n",
    "        score += penalidade_nome\n",
    "        razoes.append(f\"NomeVazio {penalidade_nome:.1f}\")\n",
    "\n",
    "    # DECISÃƒO FINAL\n",
    "    confianca = max(0.0, min(1.0, (score + 10) / 40))\n",
    "\n",
    "    if score >= 10.0:\n",
    "        tipo = \"DADOS\"\n",
    "        valida = True\n",
    "    elif score >= 0.0:\n",
    "        tipo = \"INCERTO\"\n",
    "        valida = True\n",
    "    else:\n",
    "        tipo = \"FLAG/FORMULA/AUXILIAR\"\n",
    "        valida = False\n",
    "\n",
    "    if not metodo_usado:\n",
    "        metodo_usado = 'HEURISTICAS_BASICAS'\n",
    "\n",
    "    return {\n",
    "        'valida': valida,\n",
    "        'score': score,\n",
    "        'razoes': razoes,\n",
    "        'tipo_detectado': tipo,\n",
    "        'confianca': confianca,\n",
    "        'metodo': metodo_usado,\n",
    "        'prop_preenchimento': prop_preenchimento,\n",
    "        'match_dicionario': campo_matched or melhor_match_regex or melhor_match_conteudo\n",
    "    }\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTAR ANÃLISE DE COLUNAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” ANALISANDO COLUNAS (Sistema AvanÃ§ado v2.1)\")\n",
    "print(\"=\"*70)\n",
    "print(\"CritÃ©rios: Similaridade + Regex + ConteÃºdo + FÃ³rmulas + Estrutura\")\n",
    "print(\"Funciona para: Tabelas Transacionais e RelatÃ³rios BI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "linha_cabecalho_detectado = data_para_analise[melhor['indice']]\n",
    "\n",
    "inicio_dados = melhor['indice'] + 1\n",
    "fim_dados = min(inicio_dados + 50, len(data_para_analise))\n",
    "dados_para_colunas = data_para_analise[inicio_dados:fim_dados]\n",
    "\n",
    "print(f\"\\nğŸ“Š Analisando {len(linha_cabecalho_detectado)} colunas...\")\n",
    "print(f\"   Amostra de dados: {fim_dados - inicio_dados} linhas\")\n",
    "\n",
    "# PRIMEIRA PASSAGEM: InformaÃ§Ãµes bÃ¡sicas\n",
    "todas_colunas_info = []\n",
    "\n",
    "for col_idx, nome_col in enumerate(linha_cabecalho_detectado):\n",
    "    valores_col = [linha[col_idx] for linha in dados_para_colunas]\n",
    "\n",
    "    valores_validos = [\n",
    "        str(v).strip() for v in valores_col\n",
    "        if str(v).strip() and str(v).strip().lower() not in ['nan', 'none', '']\n",
    "    ]\n",
    "\n",
    "    prop_preenchimento = len(valores_validos) / len(valores_col) if valores_col else 0\n",
    "\n",
    "    todas_colunas_info.append({\n",
    "        'indice': col_idx,\n",
    "        'nome': str(nome_col),\n",
    "        'valores': valores_col,\n",
    "        'prop_preenchimento': prop_preenchimento\n",
    "    })\n",
    "\n",
    "# SEGUNDA PASSAGEM: AnÃ¡lise completa\n",
    "colunas_analise = []\n",
    "\n",
    "for col_info in todas_colunas_info:\n",
    "    col_idx = col_info['indice']\n",
    "    nome_col = col_info['nome']\n",
    "    valores_col = col_info['valores']\n",
    "\n",
    "    analise = analisar_coluna_valida_COMPLETA(\n",
    "        col_idx,\n",
    "        nome_col,\n",
    "        valores_col,\n",
    "        DICIONARIO_PERSISTENTE,\n",
    "        todas_colunas_info=todas_colunas_info\n",
    "    )\n",
    "\n",
    "    colunas_analise.append({\n",
    "        'indice': col_idx,\n",
    "        'excel_col': col_idx + 1,\n",
    "        'nome': str(nome_col)[:30],\n",
    "        **analise\n",
    "    })\n",
    "\n",
    "colunas_validas = [c for c in colunas_analise if c['valida']]\n",
    "colunas_invalidas = [c for c in colunas_analise if not c['valida']]\n",
    "\n",
    "print(f\"\\nâœ… Colunas VÃLIDAS (dados reais): {len(colunas_validas)}\")\n",
    "print(f\"âŒ Colunas INVÃLIDAS (flags/fÃ³rmulas/auxiliares): {len(colunas_invalidas)}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: SALVAR ANÃLISE DE COLUNAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ’¾ Salvando anÃ¡lise de colunas...\")\n",
    "\n",
    "# Preparar dados para salvar (jÃ¡ em formato JSON-compatÃ­vel)\n",
    "colunas_analise_salvar = []\n",
    "for col in colunas_analise:\n",
    "    col_salvar = col.copy()\n",
    "    # Converter lista de razoes para string se necessÃ¡rio\n",
    "    if 'razoes' in col_salvar and isinstance(col_salvar['razoes'], list):\n",
    "        col_salvar['razoes'] = ' | '.join(col_salvar['razoes'])\n",
    "    colunas_analise_salvar.append(col_salvar)\n",
    "\n",
    "arquivo_colunas = fm.pastas['logs'] / '.bloco8_colunas_analise.json'\n",
    "with open(arquivo_colunas, 'w', encoding='utf-8') as f:\n",
    "    json.dump(colunas_analise_salvar, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   âœ… AnÃ¡lise de colunas salva: {arquivo_colunas.name}\")\n",
    "\n",
    "# EXIBIR INVÃLIDAS\n",
    "if colunas_invalidas:\n",
    "    print(f\"\\nâŒ COLUNAS DETECTADAS COMO INVÃLIDAS:\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    for col in colunas_invalidas[:15]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"{col['tipo_detectado']}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_lista = col['razoes'] if isinstance(col['razoes'], list) else [col['razoes']]\n",
    "            razoes_str = ' | '.join(razoes_lista[:4])\n",
    "            print(f\"      RazÃµes: {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      Match: {col['match_dicionario']}\")\n",
    "\n",
    "# EXIBIR VÃLIDAS\n",
    "if colunas_validas:\n",
    "    print(f\"\\nâœ… TOP 10 COLUNAS VÃLIDAS (maiores scores):\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    colunas_validas_sorted = sorted(\n",
    "        colunas_validas,\n",
    "        key=lambda x: x['score'],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for col in colunas_validas_sorted[:10]:\n",
    "        print(\n",
    "            f\"   Col {col['excel_col']:2d} (idx {col['indice']:2d}): \"\n",
    "            f\"{col['nome'][:25]:<25} | \"\n",
    "            f\"Score: {col['score']:+6.1f} | \"\n",
    "            f\"Conf: {col['confianca']:.0%}\"\n",
    "        )\n",
    "\n",
    "        if col['razoes']:\n",
    "            razoes_lista = col['razoes'] if isinstance(col['razoes'], list) else [col['razoes']]\n",
    "            razoes_str = ' | '.join(razoes_lista[:3])\n",
    "            print(f\"      {razoes_str}\")\n",
    "\n",
    "        if col.get('match_dicionario'):\n",
    "            print(f\"      âœ“ Match: {col['match_dicionario']}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECTAR MUDANÃ‡AS ESTRUTURAIS E AGRUPAR EM BLOCOS CONTÃNUOS\n",
    "# v2.1: TolerÃ¢ncia a gaps de atÃ© 3 colunas invÃ¡lidas\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"\\nğŸ” DETECTANDO MUDANÃ‡AS ESTRUTURAIS:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Coletar Ã­ndices de colunas vÃ¡lidas\n",
    "colunas_validas_indices = [c['excel_col'] for c in colunas_analise if c['valida']]\n",
    "\n",
    "if not colunas_validas_indices:\n",
    "    blocos_continuos = []\n",
    "else:\n",
    "    # Agrupar com tolerÃ¢ncia a gaps de atÃ© 3 colunas\n",
    "    blocos_continuos = []\n",
    "    bloco_atual = [colunas_validas_indices[0]]\n",
    "\n",
    "    for i in range(1, len(colunas_validas_indices)):\n",
    "        col_atual = colunas_validas_indices[i]\n",
    "        col_anterior = colunas_validas_indices[i-1]\n",
    "\n",
    "        gap = col_atual - col_anterior - 1\n",
    "\n",
    "        if gap <= 3:\n",
    "            bloco_atual.append(col_atual)\n",
    "        else:\n",
    "            blocos_continuos.append(bloco_atual)\n",
    "            bloco_atual = [col_atual]\n",
    "\n",
    "    if bloco_atual:\n",
    "        blocos_continuos.append(bloco_atual)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: SALVAR BLOCOS CONTÃNUOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "blocos_info = []\n",
    "for i, bloco in enumerate(blocos_continuos, 1):\n",
    "    primeira = min(bloco)\n",
    "    ultima = max(bloco)\n",
    "    tamanho = len(bloco)\n",
    "    range_completo = ultima - primeira + 1\n",
    "    gaps_internos = range_completo - tamanho\n",
    "\n",
    "    blocos_info.append({\n",
    "        'bloco': i,\n",
    "        'inicio': primeira,\n",
    "        'fim': ultima,\n",
    "        'colunas_validas': tamanho,\n",
    "        'range_completo': range_completo,\n",
    "        'gaps': gaps_internos,\n",
    "        'principal': i == 1\n",
    "    })\n",
    "\n",
    "arquivo_blocos = fm.pastas['logs'] / '.bloco8_blocos_continuos.json'\n",
    "with open(arquivo_blocos, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'total_blocos': len(blocos_continuos),\n",
    "        'blocos': blocos_info,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "print(f\"\\nğŸ’¾ Blocos contÃ­nuos salvos: {arquivo_blocos.name}\")\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    print(f\"\\nâš ï¸  MÃšLTIPLAS TABELAS DETECTADAS!\")\n",
    "\n",
    "    for i, bloco in enumerate(blocos_continuos, 1):\n",
    "        primeira = min(bloco)\n",
    "        ultima = max(bloco)\n",
    "        tamanho = len(bloco)\n",
    "\n",
    "        range_completo = ultima - primeira + 1\n",
    "        gaps_internos = range_completo - tamanho\n",
    "\n",
    "        print(f\"\\n   Tabela {i}:\")\n",
    "        print(f\"      Range Excel: {primeira} a {ultima}\")\n",
    "        print(f\"      Colunas vÃ¡lidas: {tamanho}\")\n",
    "        if gaps_internos > 0:\n",
    "            print(f\"      Gaps tolerados: {gaps_internos} col(s)\")\n",
    "\n",
    "        if i == 1:\n",
    "            print(f\"      âœ“ TABELA PRINCIPAL (use esta!)\")\n",
    "        else:\n",
    "            print(f\"      âš ï¸  Tabela auxiliar/complementar\")\n",
    "\n",
    "    primeira_valida = min(blocos_continuos[0])\n",
    "    ultima_valida = max(blocos_continuos[0])\n",
    "\n",
    "    print(f\"\\nğŸ’¡ RECOMENDAÃ‡ÃƒO:\")\n",
    "    print(f\"   Use apenas TABELA PRINCIPAL: colunas {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        primeira_valida = min(c['excel_col'] for c in colunas_validas)\n",
    "        ultima_valida = max(c['excel_col'] for c in colunas_validas)\n",
    "\n",
    "        print(f\"\\nâœ“ Estrutura contÃ­nua detectada\")\n",
    "        print(f\"   Colunas vÃ¡lidas: {primeira_valida} a {ultima_valida}\")\n",
    "\n",
    "# DETERMINAR RANGE FINAL\n",
    "if blocos_continuos:\n",
    "    col_inicio_sugerido = min(blocos_continuos[0])\n",
    "    col_fim_sugerido = max(blocos_continuos[0])\n",
    "\n",
    "    total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "    total_validas = len(blocos_continuos[0])\n",
    "    total_gaps = total_range - total_validas\n",
    "else:\n",
    "    if colunas_validas:\n",
    "        col_inicio_sugerido = min(c['excel_col'] for c in colunas_validas)\n",
    "        col_fim_sugerido = max(c['excel_col'] for c in colunas_validas)\n",
    "        total_range = col_fim_sugerido - col_inicio_sugerido + 1\n",
    "        total_validas = len(colunas_validas)\n",
    "        total_gaps = total_range - total_validas\n",
    "    else:\n",
    "        col_inicio_sugerido = 1\n",
    "        col_fim_sugerido = len(linha_cabecalho_detectado)\n",
    "        total_range = col_fim_sugerido\n",
    "        total_validas = 0\n",
    "        total_gaps = 0\n",
    "\n",
    "print(f\"\\nğŸ¯ RANGE FINAL SUGERIDO:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Excel: {col_inicio_sugerido} a {col_fim_sugerido}\")\n",
    "print(f\"   Python: {col_inicio_sugerido-1} a {col_fim_sugerido}\")\n",
    "print(f\"   Total range: {total_range} colunas\")\n",
    "print(f\"   Colunas vÃ¡lidas: {total_validas}\")\n",
    "if total_gaps > 0:\n",
    "    print(f\"   Gaps internos: {total_gaps} (tolerados)\")\n",
    "\n",
    "if col_inicio_sugerido > 1:\n",
    "    colunas_ignoradas = col_inicio_sugerido - 1\n",
    "    print(f\"\\n   âš ï¸  Ignorando colunas 1-{colunas_ignoradas}\")\n",
    "\n",
    "if len(blocos_continuos) > 1:\n",
    "    total_auxiliares = sum(len(bloco) for bloco in blocos_continuos[1:])\n",
    "    print(f\"   âš ï¸  Ignorando {total_auxiliares} colunas de tabelas auxiliares\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SALVAR RELATÃ“RIO\n",
    "relatorio_colunas = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'total_colunas': len(colunas_analise),\n",
    "    'colunas_validas': len(colunas_validas),\n",
    "    'colunas_invalidas': len(colunas_invalidas),\n",
    "    'blocos_detectados': len(blocos_continuos),\n",
    "    'range_sugerido': {\n",
    "        'inicio': col_inicio_sugerido,\n",
    "        'fim': col_fim_sugerido,\n",
    "        'total_range': total_range if blocos_continuos else col_fim_sugerido - col_inicio_sugerido + 1,\n",
    "        'total_validas': total_validas if blocos_continuos else len(colunas_validas),\n",
    "        'total_gaps': total_gaps if blocos_continuos else 0\n",
    "    },\n",
    "    'blocos': blocos_info,\n",
    "    'detalhes_colunas': [\n",
    "        {\n",
    "            'col': c['excel_col'],\n",
    "            'nome': c['nome'],\n",
    "            'valida': c['valida'],\n",
    "            'score': c['score'],\n",
    "            'tipo': c['tipo_detectado'],\n",
    "            'metodo': c['metodo'],\n",
    "            'match': c.get('match_dicionario')\n",
    "        }\n",
    "        for c in colunas_analise\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.analise_colunas.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    json.dump(relatorio_colunas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ RelatÃ³rio salvo: .analise_colunas.json\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECTAR MULTI-LINHA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if len(scores) > 1:\n",
    "    segundo = scores[1]\n",
    "\n",
    "    if (segundo['indice'] == melhor['indice'] + 1 and\n",
    "        segundo['score'] > (melhor['score'] * 0.5)):\n",
    "\n",
    "        print(f\"   âš ï¸  POSSÃVEL CABEÃ‡ALHO MULTI-LINHA detectado!\")\n",
    "        print(f\"   Linha {melhor['linha_excel']}: Score {melhor['score']:.2f}\")\n",
    "        print(f\"   Linha {segundo['linha_excel']}: Score {segundo['score']:.2f}\")\n",
    "        print(f\"\\n   ğŸ’¡ RECOMENDAÃ‡ÃƒO:\")\n",
    "        print(f\"      1. CONCATENAR: Linha1 + ' - ' + Linha2\")\n",
    "        print(f\"      2. USAR PRIMEIRA: Linha {melhor['linha_excel']}\")\n",
    "        print(f\"      3. PERSONALIZAR via GUI\")\n",
    "\n",
    "        multi_linha_detectado = True\n",
    "        linha_fim_sugerida = segundo['linha_excel']\n",
    "    else:\n",
    "        multi_linha_detectado = False\n",
    "        linha_fim_sugerida = melhor['linha_excel']\n",
    "else:\n",
    "    multi_linha_detectado = False\n",
    "    linha_fim_sugerida = melhor['linha_excel']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI AVANÃ‡ADA COM TIMER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def selecionar_range_cabecalho_com_timer(\n",
    "    sugerido_linha,\n",
    "    sugerido_linha_fim,\n",
    "    total_linhas,\n",
    "    total_colunas,\n",
    "    multi_linha=False,\n",
    "    col_inicio_sug=1,\n",
    "    col_fim_sug=None\n",
    "):\n",
    "    \"\"\"GUI avanÃ§ada para seleÃ§Ã£o de range de cabeÃ§alho.\"\"\"\n",
    "\n",
    "    if col_fim_sug is None:\n",
    "        col_fim_sug = total_colunas\n",
    "\n",
    "    config_file = fm.pastas['logs'] / '.ultimo_range_cabecalho.json'\n",
    "    ultimo_config = None\n",
    "\n",
    "    if config_file.exists():\n",
    "        try:\n",
    "            with open(config_file, 'r', encoding='utf-8') as f:\n",
    "                cfg = json.load(f)\n",
    "                if cfg.get('arquivo') == arquivo_selecionado.name:\n",
    "                    ultimo_config = cfg\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    root, frame, resultado, contador = GUIComTimer.criar_janela_com_timer(\n",
    "        \"DETECTOR - SeleÃ§Ã£o AvanÃ§ada de CabeÃ§alho\",\n",
    "        650, 850,\n",
    "        tem_timer=bool(ultimo_config)\n",
    "    )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=\"ğŸ“‹ ConfiguraÃ§Ã£o de CabeÃ§alho e Dados\",\n",
    "        font=('Arial', 14, 'bold'),\n",
    "        bg='white'\n",
    "    ).pack(pady=(0, 10))\n",
    "\n",
    "    explicacao = tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"ğŸ“ IMPORTANTE: NumeraÃ§Ã£o\\n\\n\"\n",
    "            \"â€¢ Ãndice Python (preview): inicia em 0\\n\"\n",
    "            \"â€¢ Linha Excel (arquivo): inicia em 1\\n\"\n",
    "            \"â€¢ Use LINHA EXCEL nos campos abaixo\"\n",
    "        ),\n",
    "        font=('Arial', 9),\n",
    "        bg='#E3F2FD',\n",
    "        fg='#0D47A1',\n",
    "        justify=tk.LEFT,\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        relief=tk.RIDGE,\n",
    "        borderwidth=2\n",
    "    )\n",
    "    explicacao.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    idx_sugerido = sugerido_linha - 1\n",
    "    texto_sugestao = (\n",
    "        f\"ğŸ¤– SUGESTÃƒO AUTOMÃTICA\\n\"\n",
    "        f\"CabeÃ§alho: Ãndice {idx_sugerido} (Excel L{sugerido_linha})\\n\"\n",
    "        f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "        f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "    )\n",
    "\n",
    "    if multi_linha and sugerido_linha_fim != sugerido_linha:\n",
    "        idx_fim = sugerido_linha_fim - 1\n",
    "        texto_sugestao = (\n",
    "            f\"ğŸ¤– SUGESTÃƒO AUTOMÃTICA (MULTI-LINHA)\\n\"\n",
    "            f\"CabeÃ§alho: Ãndices {idx_sugerido}-{idx_fim} \"\n",
    "            f\"(Excel L{sugerido_linha}-L{sugerido_linha_fim})\\n\"\n",
    "            f\"Colunas: {col_inicio_sug} a {col_fim_sug} \"\n",
    "            f\"({col_fim_sug - col_inicio_sug + 1} colunas)\"\n",
    "        )\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=texto_sugestao,\n",
    "        font=('Arial', 10, 'bold'),\n",
    "        bg='#E8F5E9' if not multi_linha else '#FFF9C4',\n",
    "        fg='#2E7D32' if not multi_linha else '#F57F17',\n",
    "        padx=15,\n",
    "        pady=10,\n",
    "        justify=tk.CENTER\n",
    "    ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if col_inicio_sug > 1:\n",
    "        colunas_ignoradas = col_inicio_sug - 1\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=(\n",
    "                f\"âš ï¸ COLUNAS 1-{colunas_ignoradas} DETECTADAS COMO \"\n",
    "                f\"FLAGS/FÃ“RMULAS\\n\"\n",
    "                f\"(SerÃ£o ignoradas automaticamente)\"\n",
    "            ),\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFEBEE',\n",
    "            fg='#C62828',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "    if ultimo_config:\n",
    "        linha_ini = ultimo_config['linha_inicio']\n",
    "        linha_fim = ultimo_config.get('linha_fim', linha_ini)\n",
    "        col_ini = ultimo_config['col_inicio']\n",
    "        col_fim = ultimo_config['col_fim']\n",
    "\n",
    "        idx_ini = linha_ini - 1\n",
    "        idx_fim = linha_fim - 1\n",
    "\n",
    "        texto_ultimo = (\n",
    "            f\"ğŸ’¡ ÃšLTIMA CONFIGURAÃ‡ÃƒO USADA\\n\"\n",
    "            f\"CabeÃ§alho: Ãndice {idx_ini}\"\n",
    "        )\n",
    "        if idx_fim != idx_ini:\n",
    "            texto_ultimo += f\"-{idx_fim}\"\n",
    "        texto_ultimo += f\" (Excel L{linha_ini}\"\n",
    "        if linha_fim != linha_ini:\n",
    "            texto_ultimo += f\"-L{linha_fim}\"\n",
    "        texto_ultimo += f\") | Colunas {col_ini}-{col_fim}\"\n",
    "\n",
    "        tk.Label(\n",
    "            frame,\n",
    "            text=texto_ultimo,\n",
    "            font=('Arial', 9),\n",
    "            bg='#FFF3E0',\n",
    "            fg='#E65100',\n",
    "            padx=15,\n",
    "            pady=8,\n",
    "            justify=tk.CENTER\n",
    "        ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "        countdown = GUIComTimer.adicionar_timer(\n",
    "            frame, root, resultado, contador\n",
    "        )\n",
    "\n",
    "    frame_inputs = tk.Frame(frame, bg='white')\n",
    "    frame_inputs.pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha CabeÃ§alho INÃCIO (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=0, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['linha_inicio'] if ultimo_config\n",
    "            else sugerido_linha)\n",
    "    )\n",
    "    entry_cab_ini.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha CabeÃ§alho FIM (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=1, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_cab_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_cab_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "            if ultimo_config else sugerido_linha_fim)\n",
    "    )\n",
    "    entry_cab_fim.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna INÃCIO:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=2, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_ini = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_inicio'] if ultimo_config\n",
    "            else col_inicio_sug)\n",
    "    )\n",
    "    entry_col_ini.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Coluna FIM:\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=3, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_col_fim = tk.Entry(frame_inputs, width=10, font=('Arial', 10))\n",
    "    entry_col_fim.insert(\n",
    "        0,\n",
    "        str(ultimo_config['col_fim'] if ultimo_config\n",
    "            else col_fim_sug)\n",
    "    )\n",
    "    entry_col_fim.grid(row=3, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame_inputs,\n",
    "        text=\"Linha DADOS inÃ­cio (Excel):\",\n",
    "        bg='white',\n",
    "        font=('Arial', 9)\n",
    "    ).grid(row=4, column=0, sticky='w', padx=5, pady=5)\n",
    "\n",
    "    entry_dados_ini = tk.Entry(\n",
    "        frame_inputs, width=10, font=('Arial', 10)\n",
    "    )\n",
    "\n",
    "    dados_inicio_default = (\n",
    "        ultimo_config.get('linha_fim', sugerido_linha_fim)\n",
    "        if ultimo_config else sugerido_linha_fim\n",
    "    ) + 1\n",
    "\n",
    "    entry_dados_ini.insert(\n",
    "        0,\n",
    "        str(ultimo_config.get('linha_dados_inicio', dados_inicio_default)\n",
    "            if ultimo_config else dados_inicio_default)\n",
    "    )\n",
    "    entry_dados_ini.grid(row=4, column=1, padx=5, pady=5)\n",
    "\n",
    "    tk.Label(\n",
    "        frame,\n",
    "        text=(\n",
    "            \"ğŸ’¡ Para cabeÃ§alho 1 linha: InÃ­cio = Fim\\n\"\n",
    "            \"ğŸ’¡ Para multi-linha: InÃ­cio < Fim (ex: 3 a 4)\"\n",
    "        ),\n",
    "        font=('Arial', 8, 'italic'),\n",
    "        bg='#FFFDE7',\n",
    "        fg='#F57F17',\n",
    "        padx=10,\n",
    "        pady=8,\n",
    "        justify=tk.LEFT\n",
    "    ).pack(fill=tk.X, pady=(10, 0))\n",
    "\n",
    "    def confirmar():\n",
    "        resultado['cancelado'] = True\n",
    "        try:\n",
    "            resultado['valor'] = {\n",
    "                'linha_inicio': int(entry_cab_ini.get()),\n",
    "                'linha_fim': int(entry_cab_fim.get()),\n",
    "                'col_inicio': int(entry_col_ini.get()),\n",
    "                'col_fim': int(entry_col_fim.get()),\n",
    "                'linha_dados_inicio': int(entry_dados_ini.get())\n",
    "            }\n",
    "        except ValueError:\n",
    "            resultado['valor'] = None\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    def usar_ultima():\n",
    "        resultado['cancelado'] = True\n",
    "        resultado['valor'] = {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    GUIComTimer.criar_botoes(\n",
    "        frame,\n",
    "        confirmar,\n",
    "        usar_ultima if ultimo_config else None,\n",
    "        \"âœ… Confirmar\",\n",
    "        \"â±ï¸ Usar Ãšltima (10s)\"\n",
    "    )\n",
    "\n",
    "    if ultimo_config:\n",
    "        root.after(1000, countdown)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    if resultado.get('timeout') and ultimo_config:\n",
    "        print(f\"   â±ï¸  Timeout - usando Ãºltima configuraÃ§Ã£o\")\n",
    "        return {\n",
    "            'linha_inicio': ultimo_config['linha_inicio'],\n",
    "            'linha_fim': ultimo_config.get(\n",
    "                'linha_fim', ultimo_config['linha_inicio']\n",
    "            ),\n",
    "            'col_inicio': ultimo_config['col_inicio'],\n",
    "            'col_fim': ultimo_config['col_fim'],\n",
    "            'linha_dados_inicio': ultimo_config['linha_dados_inicio']\n",
    "        }\n",
    "\n",
    "    return resultado['valor']\n",
    "\n",
    "# EXECUTAR GUI\n",
    "print(\"\\nAbrindo janela de configuraÃ§Ã£o...\")\n",
    "config = selecionar_range_cabecalho_com_timer(\n",
    "    melhor['linha_excel'],\n",
    "    linha_fim_sugerida,\n",
    "    len(data_para_analise),\n",
    "    len(data_para_analise[0]) if data_para_analise else 1,\n",
    "    multi_linha=multi_linha_detectado,\n",
    "    col_inicio_sug=col_inicio_sugerido,\n",
    "    col_fim_sug=col_fim_sugerido\n",
    ")\n",
    "\n",
    "if not config:\n",
    "    raise ValueError(\"âŒ ConfiguraÃ§Ã£o invÃ¡lida ou cancelada\")\n",
    "\n",
    "# Salvar configuraÃ§Ã£o\n",
    "with open(\n",
    "    fm.pastas['logs'] / '.ultimo_range_cabecalho.json',\n",
    "    'w',\n",
    "    encoding='utf-8'\n",
    ") as f:\n",
    "    config_salvar = config.copy()\n",
    "    config_salvar['arquivo'] = arquivo_selecionado.name\n",
    "    config_salvar['sheet'] = sheet_nome\n",
    "    config_salvar['timestamp'] = datetime.now().isoformat()\n",
    "    json.dump(config_salvar, f, indent=2)\n",
    "\n",
    "# Extrair informaÃ§Ãµes\n",
    "linha_cabecalho_inicio = config['linha_inicio']\n",
    "linha_cabecalho_fim = config['linha_fim']\n",
    "col_inicio = config['col_inicio']\n",
    "col_fim = config['col_fim']\n",
    "linha_dados_inicio = config['linha_dados_inicio']\n",
    "\n",
    "print(f\"\\nâœ… CONFIGURAÃ‡ÃƒO CONFIRMADA:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   ğŸ“‹ CabeÃ§alho (Excel): L{linha_cabecalho_inicio}\", end=\"\")\n",
    "if linha_cabecalho_fim != linha_cabecalho_inicio:\n",
    "    print(f\" a L{linha_cabecalho_fim}\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "print(f\"   ğŸ“Š Colunas (Excel): {col_inicio} a {col_fim}\")\n",
    "print(f\"   ğŸ“ˆ Dados comeÃ§am (Excel): L{linha_dados_inicio}\")\n",
    "\n",
    "# Converter para Ã­ndices Python\n",
    "idx_cab_inicio = linha_cabecalho_inicio - 1\n",
    "idx_cab_fim = linha_cabecalho_fim - 1\n",
    "idx_col_inicio = col_inicio - 1\n",
    "idx_col_fim = col_fim\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "print(f\"\\n   ğŸ Ãndices Python (uso interno):\")\n",
    "print(f\"      CabeÃ§alho: idx {idx_cab_inicio}\", end=\"\")\n",
    "if idx_cab_fim != idx_cab_inicio:\n",
    "    print(f\" a {idx_cab_fim}\")\n",
    "else:\n",
    "    print()\n",
    "print(f\"      Colunas: idx {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"      Dados: a partir de idx {idx_dados_inicio}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: EXTRAIR E SALVAR CABEÃ‡ALHO FINAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ’¾ Extraindo e salvando cabeÃ§alho final...\")\n",
    "\n",
    "# Extrair linha(s) de cabeÃ§alho\n",
    "if idx_cab_fim == idx_cab_inicio:\n",
    "    # CabeÃ§alho de 1 linha\n",
    "    linha_cabecalho_final = data_para_analise[idx_cab_inicio][idx_col_inicio:idx_col_fim]\n",
    "else:\n",
    "    # CabeÃ§alho multi-linha - concatenar\n",
    "    linhas_cab = []\n",
    "    for i in range(idx_cab_inicio, idx_cab_fim + 1):\n",
    "        linhas_cab.append(data_para_analise[i][idx_col_inicio:idx_col_fim])\n",
    "\n",
    "    # Concatenar cÃ©lulas correspondentes\n",
    "    linha_cabecalho_final = []\n",
    "    for col_idx in range(len(linhas_cab[0])):\n",
    "        partes = []\n",
    "        for linha in linhas_cab:\n",
    "            valor = str(linha[col_idx]).strip()\n",
    "            if valor and valor.lower() not in ['nan', 'none', '']:\n",
    "                partes.append(valor)\n",
    "        linha_cabecalho_final.append(' - '.join(partes) if partes else f'Coluna_{col_idx+1}')\n",
    "\n",
    "# Salvar cabeÃ§alho como JSON\n",
    "cabecalho_dados = {\n",
    "    'colunas': [\n",
    "        {\n",
    "            'indice_python': i,\n",
    "            'excel_col': col_inicio + i,\n",
    "            'nome_coluna': nome\n",
    "        }\n",
    "        for i, nome in enumerate(linha_cabecalho_final)\n",
    "    ],\n",
    "    'shape': {\n",
    "        'total_colunas': len(linha_cabecalho_final),\n",
    "        'col_inicio': col_inicio,\n",
    "        'col_fim': col_fim\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_cabecalho = fm.pastas['logs'] / '.bloco8_cabecalho_final.json'\n",
    "with open(arquivo_cabecalho, 'w', encoding='utf-8') as f:\n",
    "    json.dump(cabecalho_dados, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   âœ… CabeÃ§alho final salvo: {arquivo_cabecalho.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: LOG DE TRANSFORMAÃ‡Ã•ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "log_transformacoes = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 8,\n",
    "    'arquivo_origem': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'transformacoes': [\n",
    "        {\n",
    "            'etapa': 'deteccao_cabecalho',\n",
    "            'metodo': 'scoring_avancado_v2.2',\n",
    "            'entrada': {\n",
    "                'linhas_analisadas': len(data_para_analise),\n",
    "                'total_colunas': len(data_para_analise[0]) if data_para_analise else 0\n",
    "            },\n",
    "            'saida': {\n",
    "                'linha_selecionada': melhor['indice'],\n",
    "                'score': melhor['score'],\n",
    "                'multi_linha': multi_linha_detectado\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'etapa': 'analise_colunas',\n",
    "            'metodo': 'criterios_12_v2.1',\n",
    "            'entrada': {\n",
    "                'total_colunas': len(linha_cabecalho_detectado)\n",
    "            },\n",
    "            'saida': {\n",
    "                'colunas_validas': len(colunas_validas),\n",
    "                'colunas_invalidas': len(colunas_invalidas),\n",
    "                'blocos_detectados': len(blocos_continuos)\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'etapa': 'configuracao_usuario',\n",
    "            'metodo': 'gui_com_timer',\n",
    "            'entrada': {\n",
    "                'sugestao_linha': melhor['linha_excel'],\n",
    "                'sugestao_linha_fim': linha_fim_sugerida,\n",
    "                'sugestao_col_inicio': col_inicio_sugerido,\n",
    "                'sugestao_col_fim': col_fim_sugerido\n",
    "            },\n",
    "            'saida': config\n",
    "        },\n",
    "        {\n",
    "            'etapa': 'extracao_cabecalho',\n",
    "            'metodo': 'concatenacao_multi_linha' if idx_cab_fim != idx_cab_inicio else 'linha_unica',\n",
    "            'entrada': {\n",
    "                'linhas_cab': list(range(idx_cab_inicio, idx_cab_fim + 1)),\n",
    "                'colunas': list(range(idx_col_inicio, idx_col_fim))\n",
    "            },\n",
    "            'saida': {\n",
    "                'total_colunas': len(linha_cabecalho_final),\n",
    "                'amostra': linha_cabecalho_final[:5]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "arquivo_log_trans = fm.pastas['logs'] / '.bloco8_log_transformacoes.json'\n",
    "with open(arquivo_log_trans, 'w', encoding='utf-8') as f:\n",
    "    json.dump(log_transformacoes, f, indent=2, ensure_ascii=False)\n",
    "print(f\"   âœ… Log de transformaÃ§Ãµes salvo: {arquivo_log_trans.name}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¾ PERSISTÃŠNCIA: ESTADO COMPLETO DO BLOCO 8\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "estado_bloco8 = {\n",
    "    'bloco': 8,\n",
    "    'versao': '2.2',\n",
    "    'status': 'concluido',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'arquivo_origem': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "\n",
    "    # ConfiguraÃ§Ã£o final\n",
    "    'config': config,\n",
    "\n",
    "    # Ãndices Python\n",
    "    'indices_python': {\n",
    "        'cabecalho_inicio': idx_cab_inicio,\n",
    "        'cabecalho_fim': idx_cab_fim,\n",
    "        'col_inicio': idx_col_inicio,\n",
    "        'col_fim': idx_col_fim,\n",
    "        'dados_inicio': idx_dados_inicio\n",
    "    },\n",
    "\n",
    "    # DetecÃ§Ã£o\n",
    "    'deteccao': {\n",
    "        'metodo': 'scoring_avancado_v2.2',\n",
    "        'melhor_score': melhor['score'],\n",
    "        'multi_linha': multi_linha_detectado,\n",
    "        'total_candidatos': len(scores),\n",
    "        'correcoes': ['bug_string_vazia', 'bug_diversidade', 'tolerancia_gaps']\n",
    "    },\n",
    "\n",
    "    # AnÃ¡lise de colunas\n",
    "    'analise_colunas': {\n",
    "        'total': len(colunas_analise),\n",
    "        'validas': len(colunas_validas),\n",
    "        'invalidas': len(colunas_invalidas),\n",
    "        'blocos_detectados': len(blocos_continuos),\n",
    "        'range_final': {\n",
    "            'inicio': col_inicio_sugerido,\n",
    "            'fim': col_fim_sugerido,\n",
    "            'total': total_range,\n",
    "            'gaps': total_gaps\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Arquivos salvos (REFERÃŠNCIAS)\n",
    "    'arquivos_gerados': {\n",
    "        'scores': '.bloco8_scores.json',\n",
    "        'data_analise': '.bloco8_data_para_analise.json',\n",
    "        'colunas_analise': '.bloco8_colunas_analise.json',\n",
    "        'blocos_continuos': '.bloco8_blocos_continuos.json',\n",
    "        'cabecalho_final': '.bloco8_cabecalho_final.json',\n",
    "        'log_transformacoes': '.bloco8_log_transformacoes.json',\n",
    "        'relatorio_colunas': '.analise_colunas.json',\n",
    "        'ultima_config': '.ultimo_range_cabecalho.json'\n",
    "    },\n",
    "\n",
    "    # Metadados para prÃ³ximos blocos\n",
    "    'output_para_proximo_bloco': {\n",
    "        'linha_cabecalho_final': True,\n",
    "        'idx_cab_inicio': idx_cab_inicio,\n",
    "        'idx_cab_fim': idx_cab_fim,\n",
    "        'idx_col_inicio': idx_col_inicio,\n",
    "        'idx_col_fim': idx_col_fim,\n",
    "        'idx_dados_inicio': idx_dados_inicio,\n",
    "        'total_colunas_validas': len(linha_cabecalho_final)\n",
    "    }\n",
    "}\n",
    "\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_8_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco8, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   âœ… Estado do bloco salvo: {arquivo_estado.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DETECÃ‡ÃƒO DE CABEÃ‡ALHO CONCLUÃDA\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“¦ ARQUIVOS GERADOS (princÃ­pio 0% memÃ³ria, 100% LOG):\")\n",
    "for nome, arquivo in estado_bloco8['arquivos_gerados'].items():\n",
    "    print(f\"   â€¢ {arquivo}\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a0c483a69d5db0c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¯ DETECÃ‡ÃƒO E SELEÃ‡ÃƒO DE CABEÃ‡ALHO\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Verificando cabeÃ§alho multi-linha...\n",
      "\n",
      "ğŸ“š DicionÃ¡rio persistente jÃ¡ carregado\n",
      "\n",
      "ğŸ“Š Analisando linhas para detectar cabeÃ§alho...\n",
      "\n",
      "ğŸ’¾ Salvando scores e preview dos dados...\n",
      "   âœ… Scores salvos: .bloco8_scores.json\n",
      "   âœ… Preview salvo: .bloco8_data_para_analise.json\n",
      "\n",
      "ğŸ† Top 5 candidatos a cabeÃ§alho:\n",
      "======================================================================\n",
      "ğŸ“ NUMERAÃ‡ÃƒO: Usamos Ã­ndice Python (preview inicia em 0)\n",
      "   â€¢ Ãndice 0 = Linha 1 no Excel\n",
      "======================================================================\n",
      "\n",
      "   1Âº. Ãndice 0 (Excel: Linha 1)\n",
      "       Score: 14.50/24.5\n",
      "       Preench: 100% (+2.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 21 (+1.0) | Ãšnicos (+1.5) | Pos: 1 (+0.50) | Rotulos:100% (+4.0)\n",
      "\n",
      "   2Âº. Ãndice 7 (Excel: Linha 8)\n",
      "       Score: 11.43/24.5\n",
      "       Preench: 100% (+2.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 18 (+1.0) | Ãšnicos (+1.5) | Pos: 8 (+0.43) | DadosAbaixo:Misto:80% (+1.0)\n",
      "\n",
      "   3Âº. Ãndice 8 (Excel: Linha 9)\n",
      "       Score: 11.42/24.5\n",
      "       Preench: 100% (+2.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 18 (+1.0) | Ãšnicos (+1.5) | Pos: 9 (+0.42) | DadosAbaixo:Misto:100% (+1.0)\n",
      "\n",
      "   4Âº. Ãndice 9 (Excel: Linha 10)\n",
      "       Score: 11.41/24.5\n",
      "       Preench: 100% (+2.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 20 (+1.0) | Ãšnicos (+1.5) | Pos: 10 (+0.41) | DadosAbaixo:Misto:100% (+1.0)\n",
      "\n",
      "   5Âº. Ãndice 10 (Excel: Linha 11)\n",
      "       Score: 11.40/24.5\n",
      "       Preench: 100% (+2.0) | Texto: 100% (+2.5) | Unic: 100% (+3.0) | Tam: 14 (+1.0) | Ãšnicos (+1.5) | Pos: 11 (+0.40) | DadosAbaixo:Misto:80% (+1.0)\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ SUGESTÃƒO AUTOMÃTICA: Ãndice 0 (Excel: Linha 1)\n",
      "   ConfianÃ§a: 14.50/24.5\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ANALISANDO COLUNAS (Sistema AvanÃ§ado v2.1)\n",
      "======================================================================\n",
      "CritÃ©rios: Similaridade + Regex + ConteÃºdo + FÃ³rmulas + Estrutura\n",
      "Funciona para: Tabelas Transacionais e RelatÃ³rios BI\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Analisando 2 colunas...\n",
      "   Amostra de dados: 30 linhas\n",
      "\n",
      "âœ… Colunas VÃLIDAS (dados reais): 2\n",
      "âŒ Colunas INVÃLIDAS (flags/fÃ³rmulas/auxiliares): 0\n",
      "\n",
      "ğŸ’¾ Salvando anÃ¡lise de colunas...\n",
      "   âœ… AnÃ¡lise de colunas salva: .bloco8_colunas_analise.json\n",
      "\n",
      "âœ… TOP 10 COLUNAS VÃLIDAS (maiores scores):\n",
      "======================================================================\n",
      "   Col  1 (idx  0): CÃ³d Grupo de produto      | Score:  +10.0 | Conf: 50%\n",
      "      Divers:100% (+4.0) | Keyword (+3.0) | Tam:17 (+2.0)\n",
      "   Col  2 (idx  1): Desc. Grupo de Produto    | Score:  +10.0 | Conf: 50%\n",
      "      Divers:83% (+4.0) | Keyword (+3.0) | Tam:12 (+2.0)\n",
      "\n",
      "ğŸ” DETECTANDO MUDANÃ‡AS ESTRUTURAIS:\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¾ Blocos contÃ­nuos salvos: .bloco8_blocos_continuos.json\n",
      "\n",
      "âœ“ Estrutura contÃ­nua detectada\n",
      "   Colunas vÃ¡lidas: 1 a 2\n",
      "\n",
      "ğŸ¯ RANGE FINAL SUGERIDO:\n",
      "======================================================================\n",
      "   Excel: 1 a 2\n",
      "   Python: 0 a 2\n",
      "   Total range: 2 colunas\n",
      "   Colunas vÃ¡lidas: 2\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¾ RelatÃ³rio salvo: .analise_colunas.json\n",
      "\n",
      "Abrindo janela de configuraÃ§Ã£o...\n",
      "\n",
      "âœ… CONFIGURAÃ‡ÃƒO CONFIRMADA:\n",
      "======================================================================\n",
      "   ğŸ“‹ CabeÃ§alho (Excel): L1\n",
      "   ğŸ“Š Colunas (Excel): 1 a 2\n",
      "   ğŸ“ˆ Dados comeÃ§am (Excel): L2\n",
      "\n",
      "   ğŸ Ãndices Python (uso interno):\n",
      "      CabeÃ§alho: idx 0\n",
      "      Colunas: idx 0 a 2\n",
      "      Dados: a partir de idx 1\n",
      "======================================================================\n",
      "\n",
      "ğŸ’¾ Extraindo e salvando cabeÃ§alho final...\n",
      "   âœ… CabeÃ§alho final salvo: .bloco8_cabecalho_final.json\n",
      "   âœ… Log de transformaÃ§Ãµes salvo: .bloco8_log_transformacoes.json\n",
      "   âœ… Estado do bloco salvo: .bloco_8_state.json\n",
      "\n",
      "======================================================================\n",
      "âœ… DETECÃ‡ÃƒO DE CABEÃ‡ALHO CONCLUÃDA\n",
      "======================================================================\n",
      "\n",
      "ğŸ“¦ ARQUIVOS GERADOS (princÃ­pio 0% memÃ³ria, 100% LOG):\n",
      "   â€¢ .bloco8_scores.json\n",
      "   â€¢ .bloco8_data_para_analise.json\n",
      "   â€¢ .bloco8_colunas_analise.json\n",
      "   â€¢ .bloco8_blocos_continuos.json\n",
      "   â€¢ .bloco8_cabecalho_final.json\n",
      "   â€¢ .bloco8_log_transformacoes.json\n",
      "   â€¢ .analise_colunas.json\n",
      "   â€¢ .ultimo_range_cabecalho.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T01:03:11.809919Z",
     "start_time": "2025-10-19T01:03:11.734904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 9 - EXTRAÃ‡ÃƒO DE DADOS (REVISADO v2.1)\n",
    "# ===================================================================\n",
    "# MUDANÃ‡AS v2.1:\n",
    "# + Salvamento de TODAS variÃ¡veis necessÃ¡rias (df, df_bruto) em .parquet\n",
    "# + Estado completo com paths de recuperaÃ§Ã£o\n",
    "# + InstruÃ§Ãµes de recuperaÃ§Ã£o documentadas\n",
    "# + 100% recuperÃ¡vel de arquivos\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRACAO DE DADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. CONECTAR COM BLOCOS ANTERIORES (0% memoria, 100% LOG)\n",
    "# ===================================================================\n",
    "\n",
    "# Carregar LOG GLOBAL\n",
    "try:\n",
    "    arquivo_log_global = Path('.logs/.log_global.json')\n",
    "    with open(arquivo_log_global, 'r', encoding='utf-8') as f:\n",
    "        log_global = json.load(f)\n",
    "\n",
    "    pasta_base = Path(log_global['pasta_base'])\n",
    "    timestamp_execucao = log_global['timestamp']\n",
    "\n",
    "    print(f\"LOG GLOBAL conectado!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: Nao foi possivel conectar ao LOG GLOBAL\")\n",
    "    print(f\"   Execute o BLOCO 1 primeiro!\")\n",
    "    raise\n",
    "\n",
    "# Recriar FileManager\n",
    "fm = FileManagerInterativo(pasta_base, timestamp_execucao)\n",
    "\n",
    "# Validar que BLOCOS 4-8 foram executados\n",
    "arquivo_config = fm.pastas['logs'] / '.config_detectada.json'\n",
    "if not arquivo_config.exists():\n",
    "    print(f\"\\nERRO: Configuracao nao encontrada!\")\n",
    "    print(f\"   Execute os BLOCOS 4-8 primeiro!\")\n",
    "    raise FileNotFoundError(\"Config necessaria\")\n",
    "\n",
    "with open(arquivo_config, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"\\nConfiguracao carregada:\")\n",
    "print(f\"   Arquivo: {config['arquivo_processado']}\")\n",
    "print(f\"   Sheet: {config['sheet_nome']}\")\n",
    "print(f\"   Cabecalho: Linhas {config['linha_cabecalho_inicio']} a {config['linha_cabecalho_fim']}\")\n",
    "print(f\"   Colunas: {config['col_inicio']} a {config['col_fim']}\")\n",
    "\n",
    "# Extrair variaveis necessarias\n",
    "arquivo_selecionado = Path(config['caminho_completo'])\n",
    "metodo_carga = config['metodo_carga']\n",
    "sheet_nome = config['sheet_nome']\n",
    "linha_cabecalho_inicio = config['linha_cabecalho_inicio']\n",
    "linha_cabecalho_fim = config['linha_cabecalho_fim']\n",
    "idx_cab_inicio = config['idx_cab_inicio']\n",
    "idx_cab_fim = config['idx_cab_fim']\n",
    "col_inicio = config['col_inicio']\n",
    "col_fim = config['col_fim']\n",
    "idx_col_inicio = config['idx_col_inicio']\n",
    "idx_col_fim = config['idx_col_fim']\n",
    "linha_dados_inicio = config.get('linha_dados_inicio', linha_cabecalho_inicio + 1)\n",
    "idx_dados_inicio = linha_dados_inicio - 1\n",
    "\n",
    "# Carregar workbook (pode estar na memoria ou nao)\n",
    "if 'workbook' not in globals():\n",
    "    print(f\"\\nRecarregando workbook...\")\n",
    "    if metodo_carga == 'xlrd':\n",
    "        workbook = xlrd.open_workbook(str(arquivo_selecionado))\n",
    "    elif metodo_carga == 'pandas':\n",
    "        workbook = pd.ExcelFile(str(arquivo_selecionado))\n",
    "    else:\n",
    "        workbook = None  # CSV nao precisa\n",
    "    print(f\"   Workbook recarregado!\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. EXTRAÃ‡ÃƒO DE DADOS (3 CASOS: CSV, PANDAS, XLRD)\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nConfiguracao (notacao Excel para usuario):\")\n",
    "print(f\"   Cabecalho: Linha(s) {linha_cabecalho_inicio} a {linha_cabecalho_fim}\")\n",
    "print(f\"   Colunas: {col_inicio} a {col_fim}\")\n",
    "print(f\"   Dados: A partir da linha {linha_dados_inicio}\")\n",
    "\n",
    "print(f\"\\nIndices Python (interno):\")\n",
    "print(f\"   Cabecalho: {idx_cab_inicio} a {idx_cab_fim}\")\n",
    "print(f\"   Colunas: {idx_col_inicio} a {idx_col_fim}\")\n",
    "print(f\"   Dados: a partir de {idx_dados_inicio}\")\n",
    "\n",
    "# CASO 1: ARQUIVO CSV\n",
    "if metodo_carga == 'csv':\n",
    "    print(f\"\\nMetodo: CSV\")\n",
    "    print(f\"   Detectando separador...\")\n",
    "\n",
    "    # Detectar separador\n",
    "    with open(arquivo_selecionado, 'r', encoding='utf-8') as f:\n",
    "        sample = f.read(1024)\n",
    "\n",
    "    sniffer = csv.Sniffer()\n",
    "    separador = sniffer.sniff(sample).delimiter\n",
    "    print(f\"   Separador detectado: '{separador}'\")\n",
    "\n",
    "    # Carregar CSV\n",
    "    df = pd.read_csv(\n",
    "        arquivo_selecionado,\n",
    "        sep=separador,\n",
    "        header=idx_cab_inicio,\n",
    "        usecols=range(idx_col_inicio, idx_col_fim)\n",
    "    )\n",
    "\n",
    "    # Pular linhas se necessario\n",
    "    linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "    if linhas_pular > 0:\n",
    "        df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "    print(f\"   Carregado: {len(df):,} registros x {len(df.columns)} colunas\")\n",
    "\n",
    "# CASO 2: ARQUIVO EXCEL (PANDAS) - .xlsx, .xlsm\n",
    "elif metodo_carga == 'pandas':\n",
    "    print(f\"\\nMetodo: pandas (XLSX/XLSM)\")\n",
    "\n",
    "    try:\n",
    "        # CASO 2A: Cabecalho em 1 linha\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   Cabecalho: Linha unica ({linha_cabecalho_inicio})\")\n",
    "\n",
    "            df = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=idx_cab_inicio,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            # Remover linhas antes dos dados\n",
    "            linhas_pular = idx_dados_inicio - idx_cab_inicio - 1\n",
    "            if linhas_pular > 0:\n",
    "                print(f\"   Pulando {linhas_pular} linha(s) apos cabecalho\")\n",
    "                df = df.iloc[linhas_pular:].copy()\n",
    "\n",
    "        # CASO 2B: Cabecalho multi-linha\n",
    "        else:\n",
    "            print(f\"   Cabecalho: Multi-linha ({linha_cabecalho_inicio} a {linha_cabecalho_fim})\")\n",
    "\n",
    "            df_temp = pd.read_excel(\n",
    "                arquivo_selecionado,\n",
    "                sheet_name=sheet_nome,\n",
    "                header=None,\n",
    "                usecols=range(idx_col_inicio, idx_col_fim)\n",
    "            )\n",
    "\n",
    "            # Combinar linhas do cabecalho\n",
    "            cabecalho_linhas = df_temp.iloc[idx_cab_inicio:idx_cab_fim+1].values\n",
    "            cab_final = []\n",
    "\n",
    "            for col_idx in range(cabecalho_linhas.shape[1]):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cabecalho_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            # Extrair dados\n",
    "            df = df_temp.iloc[idx_dados_inicio:].copy()\n",
    "            df.columns = cab_final\n",
    "\n",
    "        print(f\"   Carregado: {len(df):,} registros x {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERRO ao extrair com pandas: {str(e)}\")\n",
    "        print(f\"\\n   DEBUG:\")\n",
    "        print(f\"      Arquivo: {arquivo_selecionado}\")\n",
    "        print(f\"      Sheet: {sheet_nome}\")\n",
    "        print(f\"      Cabecalho: linhas {idx_cab_inicio} a {idx_cab_fim}\")\n",
    "        print(f\"      Colunas: {idx_col_inicio} a {idx_col_fim}\")\n",
    "        raise\n",
    "\n",
    "# CASO 3: ARQUIVO EXCEL (XLRD) - .xls antigos\n",
    "elif metodo_carga == 'xlrd':\n",
    "    print(f\"\\nMetodo: xlrd (XLS)\")\n",
    "\n",
    "    try:\n",
    "        sheet = workbook.sheet_by_name(sheet_nome)\n",
    "\n",
    "        # CASO 3A: Cabecalho em 1 linha\n",
    "        if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "            print(f\"   Cabecalho: Linha unica ({linha_cabecalho_inicio})\")\n",
    "\n",
    "            # Extrair cabecalho\n",
    "            cabecalho = sheet.row_values(idx_cab_inicio)[idx_col_inicio:idx_col_fim]\n",
    "\n",
    "            # Extrair dados\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cabecalho)\n",
    "\n",
    "        # CASO 3B: Cabecalho multi-linha\n",
    "        else:\n",
    "            print(f\"   Cabecalho: Multi-linha ({linha_cabecalho_inicio} a {linha_cabecalho_fim})\")\n",
    "\n",
    "            # Extrair linhas do cabecalho\n",
    "            cabecalho_linhas = []\n",
    "            for linha_idx in range(idx_cab_inicio, idx_cab_fim + 1):\n",
    "                cabecalho_linhas.append(\n",
    "                    sheet.row_values(linha_idx)[idx_col_inicio:idx_col_fim]\n",
    "                )\n",
    "\n",
    "            # Combinar linhas do cabecalho\n",
    "            cab_final = []\n",
    "            for col_idx in range(len(cabecalho_linhas[0])):\n",
    "                partes = [\n",
    "                    str(linha[col_idx]).strip()\n",
    "                    for linha in cabecalho_linhas\n",
    "                    if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "                ]\n",
    "                cab_final.append(' - '.join(partes) if partes else f'Col_{col_idx}')\n",
    "\n",
    "            # Extrair dados\n",
    "            data = []\n",
    "            for row_idx in range(idx_dados_inicio, sheet.nrows):\n",
    "                data.append(sheet.row_values(row_idx)[idx_col_inicio:idx_col_fim])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=cab_final)\n",
    "\n",
    "        print(f\"   Carregado: {len(df):,} registros x {len(df.columns)} colunas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ERRO ao extrair com xlrd: {str(e)}\")\n",
    "        print(f\"\\n   DEBUG:\")\n",
    "        print(f\"      Sheet: {sheet_nome}\")\n",
    "        print(f\"      Cabecalho: linhas {idx_cab_inicio} a {idx_cab_fim}\")\n",
    "        raise\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Metodo de carga desconhecido: {metodo_carga}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. VALIDAÃ‡Ã•ES PÃ“S-EXTRAÃ‡ÃƒO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"VALIDACOES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Validar shape\n",
    "print(f\"\\nShape final:\")\n",
    "print(f\"   Registros: {len(df):,}\")\n",
    "print(f\"   Colunas: {len(df.columns)}\")\n",
    "\n",
    "# Validar colunas\n",
    "print(f\"\\nPrimeiras 10 colunas:\")\n",
    "for i, col in enumerate(df.columns[:10], 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "if len(df.columns) > 10:\n",
    "    print(f\"   ... e mais {len(df.columns) - 10} colunas\")\n",
    "\n",
    "# Primeiras 5 linhas\n",
    "print(f\"\\nPrimeiras 5 linhas (amostra):\")\n",
    "print(df.head().to_string())\n",
    "\n",
    "# Tipos detectados\n",
    "print(f\"\\nTipos detectados:\")\n",
    "tipos_count = df.dtypes.value_counts()\n",
    "for tipo, count in tipos_count.items():\n",
    "    print(f\"   {str(tipo).ljust(15)}: {count} coluna(s)\")\n",
    "\n",
    "# Valores nulos\n",
    "print(f\"\\nValores nulos:\")\n",
    "nulos_total = df.isnull().sum().sum()\n",
    "if nulos_total > 0:\n",
    "    print(f\"   Total: {nulos_total:,} celulas vazias\")\n",
    "    colunas_com_nulos = df.isnull().sum()\n",
    "    colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0].sort_values(ascending=False)\n",
    "    print(f\"\\n   Top 5 colunas com nulos:\")\n",
    "    for col, count in colunas_com_nulos.head(5).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"      {col[:40].ljust(40)}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "else:\n",
    "    print(f\"   Nenhum valor nulo!\")\n",
    "\n",
    "# Memoria\n",
    "memoria_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nMemoria utilizada: {memoria_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRACAO CONCLUIDA COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 4. CRIAR E SALVAR TODAS AS VARIÃVEIS NECESSÃRIAS\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(\"SALVANDO VARIAVEIS EM ARQUIVO (Principio 0% memoria)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Criar df_bruto (cÃ³pia do dataframe original extraÃ­do)\n",
    "df_bruto = df.copy()\n",
    "\n",
    "# DicionÃ¡rio para rastrear todos os arquivos salvos\n",
    "arquivos_salvos = {}\n",
    "\n",
    "# 1. SALVAR df_bruto\n",
    "print(f\"\\n1. Salvando df_bruto...\")\n",
    "nome_df_bruto = f\"DF_BRUTO_{fm.timestamp}.parquet\"\n",
    "arquivo_df_bruto = fm.pastas['dados_processados'] / nome_df_bruto\n",
    "df_bruto.to_parquet(arquivo_df_bruto, index=False, compression='snappy')\n",
    "tamanho_df_bruto_mb = arquivo_df_bruto.stat().st_size / 1024**2\n",
    "arquivos_salvos['df_bruto'] = {\n",
    "    'arquivo': nome_df_bruto,\n",
    "    'path_completo': str(arquivo_df_bruto),\n",
    "    'tamanho_mb': round(tamanho_df_bruto_mb, 2),\n",
    "    'formato': 'parquet',\n",
    "    'descricao': 'DataFrame original extraÃ­do do arquivo fonte'\n",
    "}\n",
    "print(f\"   âœ“ {nome_df_bruto} ({tamanho_df_bruto_mb:.2f} MB)\")\n",
    "\n",
    "# 2. SALVAR df (inicialmente igual a df_bruto, mas pode divergir em blocos futuros)\n",
    "print(f\"\\n2. Salvando df...\")\n",
    "nome_df = f\"DF_{fm.timestamp}.parquet\"\n",
    "arquivo_df = fm.pastas['dados_processados'] / nome_df\n",
    "df.to_parquet(arquivo_df, index=False, compression='snappy')\n",
    "tamanho_df_mb = arquivo_df.stat().st_size / 1024**2\n",
    "arquivos_salvos['df'] = {\n",
    "    'arquivo': nome_df,\n",
    "    'path_completo': str(arquivo_df),\n",
    "    'tamanho_mb': round(tamanho_df_mb, 2),\n",
    "    'formato': 'parquet',\n",
    "    'descricao': 'DataFrame de trabalho (serÃ¡ modificado em blocos posteriores)'\n",
    "}\n",
    "print(f\"   âœ“ {nome_df} ({tamanho_df_mb:.2f} MB)\")\n",
    "\n",
    "# 3. SALVAR METADADOS DAS COLUNAS (para referÃªncia rÃ¡pida)\n",
    "print(f\"\\n3. Salvando metadados das colunas...\")\n",
    "metadados_colunas = {\n",
    "    'colunas': list(df.columns),\n",
    "    'total': len(df.columns),\n",
    "    'tipos': {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "    'nulos_por_coluna': df.isnull().sum().to_dict()\n",
    "}\n",
    "nome_metadata = f\"METADATA_COLUNAS_{fm.timestamp}.json\"\n",
    "arquivo_metadata = fm.pastas['logs'] / nome_metadata\n",
    "with open(arquivo_metadata, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadados_colunas, f, indent=2, ensure_ascii=False)\n",
    "arquivos_salvos['metadados_colunas'] = {\n",
    "    'arquivo': nome_metadata,\n",
    "    'path_completo': str(arquivo_metadata),\n",
    "    'descricao': 'Metadados das colunas extraÃ­das (nomes, tipos, nulos)'\n",
    "}\n",
    "print(f\"   âœ“ {nome_metadata}\")\n",
    "\n",
    "print(f\"\\nTotal de arquivos salvos: {len(arquivos_salvos)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. SALVAR ESTADO COMPLETO COM INSTRUÃ‡Ã•ES DE RECUPERAÃ‡ÃƒO\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(\"SALVANDO ESTADO COMPLETO\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "estado_bloco9 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 9,\n",
    "    'nome': 'EXTRACAO DE DADOS',\n",
    "    'status': 'concluido',\n",
    "\n",
    "    # VARIÃVEIS CRIADAS E ONDE ESTÃƒO SALVAS\n",
    "    'variaveis_criadas': {\n",
    "        'df': {\n",
    "            'tipo': 'DataFrame',\n",
    "            'arquivo': arquivos_salvos['df']['arquivo'],\n",
    "            'path_completo': arquivos_salvos['df']['path_completo'],\n",
    "            'recuperacao': 'df = pd.read_parquet(Path(estado[\"variaveis_criadas\"][\"df\"][\"path_completo\"]))'\n",
    "        },\n",
    "        'df_bruto': {\n",
    "            'tipo': 'DataFrame',\n",
    "            'arquivo': arquivos_salvos['df_bruto']['arquivo'],\n",
    "            'path_completo': arquivos_salvos['df_bruto']['path_completo'],\n",
    "            'recuperacao': 'df_bruto = pd.read_parquet(Path(estado[\"variaveis_criadas\"][\"df_bruto\"][\"path_completo\"]))'\n",
    "        },\n",
    "        'fm': {\n",
    "            'tipo': 'FileManagerInterativo',\n",
    "            'recuperacao': 'fm = FileManagerInterativo(Path(log_global[\"pasta_base\"]), log_global[\"timestamp\"])'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ARQUIVOS SALVOS\n",
    "    'arquivos_salvos': arquivos_salvos,\n",
    "\n",
    "    # ESTATÃSTICAS DOS DADOS\n",
    "    'estatisticas': {\n",
    "        'total_registros': len(df_bruto),\n",
    "        'total_colunas': len(df_bruto.columns),\n",
    "        'memoria_mb': round(memoria_mb, 2),\n",
    "        'valores_nulos': int(nulos_total),\n",
    "        'tamanho_total_mb': round(tamanho_df_bruto_mb + tamanho_df_mb, 2)\n",
    "    },\n",
    "\n",
    "    # CONFIGURAÃ‡ÃƒO DA EXTRAÃ‡ÃƒO\n",
    "    'configuracao_extracao': {\n",
    "        'arquivo_processado': arquivo_selecionado.name,\n",
    "        'metodo_carga': metodo_carga,\n",
    "        'sheet_nome': sheet_nome,\n",
    "        'linha_cabecalho_inicio': linha_cabecalho_inicio,\n",
    "        'linha_cabecalho_fim': linha_cabecalho_fim,\n",
    "        'linha_dados_inicio': linha_dados_inicio,\n",
    "        'col_inicio': col_inicio,\n",
    "        'col_fim': col_fim,\n",
    "        'total_colunas_extraidas': len(df_bruto.columns),\n",
    "        'indices_python': {\n",
    "            'idx_cab_inicio': idx_cab_inicio,\n",
    "            'idx_cab_fim': idx_cab_fim,\n",
    "            'idx_dados_inicio': idx_dados_inicio,\n",
    "            'idx_col_inicio': idx_col_inicio,\n",
    "            'idx_col_fim': idx_col_fim\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # TIPOS DE DADOS\n",
    "    'tipos_dados': {\n",
    "        str(tipo): int(count)\n",
    "        for tipo, count in tipos_count.items()\n",
    "    },\n",
    "\n",
    "    # INSTRUÃ‡Ã•ES DE RECUPERAÃ‡ÃƒO\n",
    "    'instrucoes_recuperacao': {\n",
    "        'descricao': 'Como recuperar as variaveis em uma nova sessao',\n",
    "        'passo_1': 'Carregar log_global: with open(Path(\".logs/.log_global.json\")) as f: log_global = json.load(f)',\n",
    "        'passo_2': 'Carregar este estado: with open(Path(\".logs/.bloco_9_state.json\")) as f: estado_b9 = json.load(f)',\n",
    "        'passo_3': 'Recriar FileManager: fm = FileManagerInterativo(Path(log_global[\"pasta_base\"]), log_global[\"timestamp\"])',\n",
    "        'passo_4': 'Carregar df: df = pd.read_parquet(Path(estado_b9[\"variaveis_criadas\"][\"df\"][\"path_completo\"]))',\n",
    "        'passo_5': 'Carregar df_bruto: df_bruto = pd.read_parquet(Path(estado_b9[\"variaveis_criadas\"][\"df_bruto\"][\"path_completo\"]))',\n",
    "        'exemplo_completo': '''\n",
    "# Recuperacao completa do BLOCO 9:\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Carregar logs\n",
    "with open(Path('.logs/.log_global.json'), 'r') as f:\n",
    "    log_global = json.load(f)\n",
    "with open(Path('.logs/.bloco_9_state.json'), 'r') as f:\n",
    "    estado_b9 = json.load(f)\n",
    "\n",
    "# Recriar FileManager\n",
    "fm = FileManagerInterativo(\n",
    "    Path(log_global['pasta_base']),\n",
    "    log_global['timestamp']\n",
    ")\n",
    "\n",
    "# Recuperar DataFrames\n",
    "df = pd.read_parquet(Path(estado_b9['variaveis_criadas']['df']['path_completo']))\n",
    "df_bruto = pd.read_parquet(Path(estado_b9['variaveis_criadas']['df_bruto']['path_completo']))\n",
    "\n",
    "print(f\"Recuperado: df com {len(df):,} linhas e df_bruto com {len(df_bruto):,} linhas\")\n",
    "        '''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar estado\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_9_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco9, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ“ Estado salvo: {arquivo_estado.name}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 6. VALIDAÃ‡ÃƒO FINAL\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDACAO FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nArquivos criados:\")\n",
    "for var_nome, info in arquivos_salvos.items():\n",
    "    print(f\"   â€¢ {var_nome.ljust(20)}: {info['arquivo']} ({info.get('tamanho_mb', 'N/A')} MB)\")\n",
    "\n",
    "print(f\"\\nVariaveis disponiveis:\")\n",
    "print(f\"   â€¢ df: {len(df):,} registros x {len(df.columns)} colunas\")\n",
    "print(f\"   â€¢ df_bruto: {len(df_bruto):,} registros x {len(df_bruto.columns)} colunas\")\n",
    "print(f\"   â€¢ fm: FileManagerInterativo\")\n",
    "\n",
    "print(f\"\\nâœ“ Principio '0% memoria, 100% LOG' aplicado:\")\n",
    "print(f\"   - Todas as variaveis salvas em arquivo\")\n",
    "print(f\"   - Estado completo salvo com instrucoes de recuperacao\")\n",
    "print(f\"   - Sistema totalmente recuperavel de arquivos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 9 CONCLUIDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDigite 'BLOCO 9 OK' para prosseguir ao BLOCO 10\")\n",
    "print(\"=\"*70)"
   ],
   "id": "51575848480d0ea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXTRACAO DE DADOS\n",
      "======================================================================\n",
      "ERRO: Nao foi possivel conectar ao LOG GLOBAL\n",
      "   Execute o BLOCO 1 primeiro!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.logs\\\\.log_global.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     22\u001B[39m     arquivo_log_global = Path(\u001B[33m'\u001B[39m\u001B[33m.logs/.log_global.json\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43marquivo_log_global\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m     24\u001B[39m         log_global = json.load(f)\n\u001B[32m     26\u001B[39m     pasta_base = Path(log_global[\u001B[33m'\u001B[39m\u001B[33mpasta_base\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\AIVI-RECALCULOBatentesLimites\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    336\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    337\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    338\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    339\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    341\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m343\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '.logs\\\\.log_global.json'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T21:16:14.300647Z",
     "start_time": "2025-10-18T21:16:14.251379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================================================================\n",
    "# BLOCO 10 - LIMPEZA DE ESTRUTURA (REVISADO v2.1)\n",
    "# ===================================================================\n",
    "# MUDANCAS v2.1 (CORRIGIDO):\n",
    "# - Removida reconexao desnecessaria (usa fm e df_bruto da memoria)\n",
    "# + Salvamento de estado no LOG (.bloco_10_state.json)\n",
    "# + Registro de transformacoes em JSON (LOG_Transformacoes_Limpeza.json)\n",
    "# + Rastreabilidade completa de todas as operacoes\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIMPEZA DE ESTRUTURA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===================================================================\n",
    "# 1. INICIALIZAR (fm e df_bruto ja existem na memoria!)\n",
    "# ===================================================================\n",
    "\n",
    "# Validar que variaveis necessarias existem\n",
    "if 'fm' not in globals():\n",
    "    print(\"ERRO: FileManager (fm) nao encontrado!\")\n",
    "    print(\"   Execute o BLOCO 1 primeiro!\")\n",
    "    raise NameError(\"fm nao definido\")\n",
    "\n",
    "if 'df_bruto' not in globals():\n",
    "    print(\"ERRO: DataFrame bruto (df_bruto) nao encontrado!\")\n",
    "    print(\"   Execute os BLOCOS 1-9 primeiro!\")\n",
    "    raise NameError(\"df_bruto nao definido\")\n",
    "\n",
    "print(f\"Conectado ao container: {fm.base_path.name}\")\n",
    "print(f\"DataFrame bruto carregado: {len(df_bruto):,} registros\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. COPIAR df_bruto (necessario para limpeza)\n",
    "# ===================================================================\n",
    "\n",
    "df = df_bruto.copy()\n",
    "log_limpeza = []\n",
    "transformacoes_detalhadas = {\n",
    "    'colunas_removidas': [],\n",
    "    'linhas_removidas': [],\n",
    "    'colunas_renomeadas': {},\n",
    "    'linhas_totais_detectadas': [],\n",
    "    'padroes_aplicados': []\n",
    "}\n",
    "\n",
    "print(f\"\\nIniciando limpeza...\")\n",
    "print(f\"   Registros iniciais: {len(df):,}\")\n",
    "print(f\"   Colunas iniciais: {len(df.columns)}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 3. REMOVER COLUNAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "if colunas_vazias:\n",
    "    print(f\"\\nRemovendo {len(colunas_vazias)} colunas vazias:\")\n",
    "    for col in colunas_vazias[:5]:\n",
    "        print(f\"   * {col}\")\n",
    "    if len(colunas_vazias) > 5:\n",
    "        print(f\"   ... e mais {len(colunas_vazias) - 5}\")\n",
    "\n",
    "    df = df.drop(columns=colunas_vazias)\n",
    "    log_limpeza.append(f\"Removidas {len(colunas_vazias)} colunas vazias\")\n",
    "    transformacoes_detalhadas['colunas_removidas'] = colunas_vazias\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_colunas_vazias',\n",
    "        'criterio': 'df.isna().all()',\n",
    "        'quantidade': len(colunas_vazias)\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 4. REMOVER LINHAS COMPLETAMENTE VAZIAS\n",
    "# ===================================================================\n",
    "\n",
    "linhas_vazias_antes = len(df)\n",
    "df = df.dropna(how='all')\n",
    "linhas_vazias = linhas_vazias_antes - len(df)\n",
    "\n",
    "if linhas_vazias > 0:\n",
    "    print(f\"\\nRemovidas {linhas_vazias} linhas completamente vazias\")\n",
    "    log_limpeza.append(f\"Removidas {linhas_vazias} linhas vazias\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_linhas_vazias',\n",
    "        'criterio': 'df.dropna(how=all)',\n",
    "        'quantidade': linhas_vazias\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 5. LIMPAR NOMES DE COLUNAS\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nLimpando nomes de colunas...\")\n",
    "colunas_antes = df.columns.tolist()\n",
    "colunas_limpas = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Limpar\n",
    "    col_limpo = str(col).strip()\n",
    "    col_limpo = col_limpo.lstrip(\"'\\\"\")\n",
    "    col_limpo = col_limpo.replace('\\n', ' ').replace('\\r', '')\n",
    "    col_limpo = ' '.join(col_limpo.split())\n",
    "\n",
    "    # Remover espacos extras\n",
    "    col_limpo = re.sub(r'\\s+', ' ', col_limpo)\n",
    "\n",
    "    colunas_limpas.append(col_limpo)\n",
    "\n",
    "# Contar modificacoes\n",
    "modificados = sum(1 for orig, limpo in zip(colunas_antes, colunas_limpas)\n",
    "                  if orig != limpo)\n",
    "if modificados > 0:\n",
    "    print(f\"   {modificados} nomes limpos\")\n",
    "    log_limpeza.append(f\"Limpeza de nomes: {modificados} colunas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'limpeza_nomes',\n",
    "        'criterio': 'strip + lstrip + regex',\n",
    "        'quantidade': modificados\n",
    "    })\n",
    "\n",
    "df.columns = colunas_limpas\n",
    "\n",
    "# ===================================================================\n",
    "# 6. RENOMEAR COLUNAS DUPLICADAS\n",
    "# ===================================================================\n",
    "\n",
    "contagem = Counter(colunas_limpas)\n",
    "duplicadas = {c: n for c, n in contagem.items() if n > 1}\n",
    "\n",
    "if duplicadas:\n",
    "    print(f\"\\nRenomeando {len(duplicadas)} colunas duplicadas:\")\n",
    "    colunas_finais = []\n",
    "    contador = {}\n",
    "\n",
    "    for col in colunas_limpas:\n",
    "        if col in duplicadas:\n",
    "            if col not in contador:\n",
    "                contador[col] = 0\n",
    "                colunas_finais.append(col)\n",
    "            else:\n",
    "                contador[col] += 1\n",
    "                novo_nome = f\"{col}_dup{contador[col]}\"\n",
    "                colunas_finais.append(novo_nome)\n",
    "                print(f\"   '{col}' -> '{novo_nome}'\")\n",
    "                transformacoes_detalhadas['colunas_renomeadas'][col] = novo_nome\n",
    "        else:\n",
    "            colunas_finais.append(col)\n",
    "\n",
    "    df.columns = colunas_finais\n",
    "    log_limpeza.append(f\"Renomeadas {sum(contador.values())} colunas duplicadas\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'renomear_duplicadas',\n",
    "        'criterio': 'Counter + sufixo _dupN',\n",
    "        'quantidade': sum(contador.values())\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 7. REMOVER LINHAS DE TOTAIS/RESULTADOS\n",
    "# ===================================================================\n",
    "\n",
    "padroes_remover = [\n",
    "    r'(?i)^total',\n",
    "    r'(?i)^resultado',\n",
    "    r'(?i)^soma',\n",
    "    r'(?i)^subtotal',\n",
    "    r'(?i)^grand total',\n",
    "    r'(?i)^media',\n",
    "    r'(?i)^average'\n",
    "]\n",
    "\n",
    "linhas_remover = []\n",
    "for idx, row in df.iterrows():\n",
    "    primeira_celula = str(row.iloc[0]).strip().lower()\n",
    "    if any(re.search(p, primeira_celula) for p in padroes_remover):\n",
    "        linhas_remover.append(idx)\n",
    "        transformacoes_detalhadas['linhas_totais_detectadas'].append({\n",
    "            'indice': int(idx),\n",
    "            'primeira_celula': str(row.iloc[0]).strip()\n",
    "        })\n",
    "\n",
    "if linhas_remover:\n",
    "    print(f\"\\nRemovendo {len(linhas_remover)} linhas de totais/resultados\")\n",
    "    df = df.drop(index=linhas_remover)\n",
    "    log_limpeza.append(f\"Removidas {len(linhas_remover)} linhas de totais\")\n",
    "    transformacoes_detalhadas['padroes_aplicados'].append({\n",
    "        'tipo': 'remocao_totais',\n",
    "        'criterio': '7 padroes regex',\n",
    "        'quantidade': len(linhas_remover)\n",
    "    })\n",
    "\n",
    "# ===================================================================\n",
    "# 8. RESET INDEX\n",
    "# ===================================================================\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# ===================================================================\n",
    "# 9. CRIAR COPIA LIMPA\n",
    "# ===================================================================\n",
    "\n",
    "df_limpo = df.copy()\n",
    "\n",
    "# ===================================================================\n",
    "# 10. RESUMO\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"LIMPEZA CONCLUIDA\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"\\nAntes -> Depois:\")\n",
    "print(f\"   Registros: {len(df_bruto):,} -> {len(df_limpo):,}\")\n",
    "print(f\"   Colunas: {len(df_bruto.columns)} -> {len(df_limpo.columns)}\")\n",
    "\n",
    "if log_limpeza:\n",
    "    print(f\"\\nOperacoes realizadas:\")\n",
    "    for i, op in enumerate(log_limpeza, 1):\n",
    "        print(f\"   {i}. {op}\")\n",
    "else:\n",
    "    print(f\"\\nNenhuma limpeza necessaria - dados ja estavam limpos!\")\n",
    "\n",
    "print(f\"\\nPreview dos dados limpos:\")\n",
    "print(\"-\" * 70)\n",
    "display(df_limpo.head(3))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ===================================================================\n",
    "# 11. SALVAR ESTADO NO LOG (NOVO!)\n",
    "# ===================================================================\n",
    "\n",
    "estado_bloco10 = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'bloco': 10,\n",
    "    'nome': 'LIMPEZA DE ESTRUTURA',\n",
    "    'status': 'concluido',\n",
    "    'variaveis_criadas': ['df_limpo', 'log_limpeza'],\n",
    "    'estatisticas': {\n",
    "        'registros_antes': len(df_bruto),\n",
    "        'registros_depois': len(df_limpo),\n",
    "        'colunas_antes': len(df_bruto.columns),\n",
    "        'colunas_depois': len(df_limpo.columns),\n",
    "        'colunas_removidas': len(colunas_vazias) if colunas_vazias else 0,\n",
    "        'linhas_removidas_vazias': linhas_vazias,\n",
    "        'linhas_removidas_totais': len(linhas_remover) if linhas_remover else 0,\n",
    "        'colunas_renomeadas': sum(contador.values()) if duplicadas else 0\n",
    "    },\n",
    "    'transformacoes': transformacoes_detalhadas,\n",
    "    'log_resumido': log_limpeza\n",
    "}\n",
    "\n",
    "# Salvar estado\n",
    "arquivo_estado = fm.pastas['logs'] / '.bloco_10_state.json'\n",
    "with open(arquivo_estado, 'w', encoding='utf-8') as f:\n",
    "    json.dump(estado_bloco10, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nEstado salvo:\")\n",
    "print(f\"   {arquivo_estado.name}\")\n",
    "\n",
    "# Salvar transformacoes detalhadas (para rastreabilidade)\n",
    "arquivo_transformacoes = fm.pastas['logs'] / 'LOG_Transformacoes_Limpeza.json'\n",
    "with open(arquivo_transformacoes, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transformacoes_detalhadas, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   {arquivo_transformacoes.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BLOCO 10 CONCLUIDO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDigite 'BLOCO 10 OK' para prosseguir ao BLOCO 11\")\n",
    "print(\"=\"*70)"
   ],
   "id": "a1261390787ca008",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIMPEZA DE ESTRUTURA\n",
      "======================================================================\n",
      "ERRO: DataFrame bruto (df_bruto) nao encontrado!\n",
      "   Execute os BLOCOS 1-9 primeiro!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "df_bruto nao definido",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     26\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mERRO: DataFrame bruto (df_bruto) nao encontrado!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     27\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m   Execute os BLOCOS 1-9 primeiro!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNameError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mdf_bruto nao definido\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     30\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mConectado ao container: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfm.base_path.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     31\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDataFrame bruto carregado: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(df_bruto)\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m registros\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: df_bruto nao definido"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TRATAMENTO DE FORMATO BW/BEx - FORWARD FILL\n",
    "# Baseado em: ETL - ESTOQUE E MOVIMENTAÃ‡ÃƒO (SAP BEx).ipynb - PASSO 4\n",
    "# PosiÃ§Ã£o: APÃ“S Limpeza de Estrutura, ANTES de DetecÃ§Ã£o de Campos\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”„ TRATAMENTO DE FORMATO BW/BEx (FORWARD FILL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ETAPA 1: DETECTAR SE Ã‰ FORMATO BW\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\"\"\n",
    "â„¹ï¸  CONTEXTO:\n",
    "   Arquivos do SAP Business Warehouse (BW/BEx) usam formataÃ§Ã£o hierÃ¡rquica:\n",
    "   - DimensÃµes aparecem apenas na PRIMEIRA linha de cada agrupamento\n",
    "   - Linhas seguintes ficam VAZIAS atÃ© mudar o agrupamento\n",
    "\n",
    "   Este bloco detecta automaticamente e aplica forward fill se necessÃ¡rio.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ” ETAPA 1: DETECTANDO FORMATO BW\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# Analisar primeiras colunas (geralmente dimensÃµes em BW)\n",
    "colunas_iniciais = df.columns[:min(6, len(df.columns))]\n",
    "\n",
    "print(f\"\\nğŸ“Š Analisando {len(colunas_iniciais)} primeiras colunas:\")\n",
    "\n",
    "analise_colunas = []\n",
    "\n",
    "for col in colunas_iniciais:\n",
    "    # Contar valores nÃ£o-nulos\n",
    "    valores_nao_nulos = df[col].notna()\n",
    "    count_nao_nulos = valores_nao_nulos.sum()\n",
    "\n",
    "    # Contar valores Ãºnicos (ignorando NaN)\n",
    "    valores_unicos = df[col].dropna().nunique()\n",
    "\n",
    "    # Percentual de NaN\n",
    "    pct_nulos = (len(df) - count_nao_nulos) / len(df) * 100\n",
    "\n",
    "    # Armazenar anÃ¡lise\n",
    "    analise_colunas.append({\n",
    "        'coluna': col,\n",
    "        'count_nao_nulos': count_nao_nulos,\n",
    "        'valores_unicos': valores_unicos,\n",
    "        'pct_nulos': pct_nulos,\n",
    "        'eh_dimensao_bw': pct_nulos > 30 and valores_unicos < 1000\n",
    "    })\n",
    "\n",
    "    emoji = \"ğŸ”„\" if pct_nulos > 30 and valores_unicos < 1000 else \"  \"\n",
    "    print(f\"   {emoji} {col[:35].ljust(35)} | Ãšnicos: {valores_unicos:>5} | NaN: {pct_nulos:>5.1f}%\")\n",
    "\n",
    "# Contar quantas colunas parecem ser BW\n",
    "colunas_bw = [a for a in analise_colunas if a['eh_dimensao_bw']]\n",
    "\n",
    "print(f\"\\nğŸ“Š RESULTADO DA DETECÃ‡ÃƒO:\")\n",
    "print(f\"   Colunas com padrÃ£o BW: {len(colunas_bw)}/{len(colunas_iniciais)}\")\n",
    "\n",
    "eh_formato_bw = len(colunas_bw) >= 2  # Pelo menos 2 colunas com padrÃ£o BW\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(f\"   âœ… FORMATO BW DETECTADO - Forward fill serÃ¡ aplicado\")\n",
    "else:\n",
    "    print(f\"   â„¹ï¸  Formato padrÃ£o - Forward fill NÃƒO necessÃ¡rio\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ETAPA 2: APLICAR FFILL (SE DETECTADO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if eh_formato_bw:\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"ğŸ”„ ETAPA 2: APLICANDO FORWARD FILL\")\n",
    "    print(\"â”€\"*70)\n",
    "\n",
    "    # Listar colunas que receberÃ£o ffill\n",
    "    colunas_para_ffill = [a['coluna'] for a in analise_colunas if a['eh_dimensao_bw']]\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Colunas que receberÃ£o forward fill ({len(colunas_para_ffill)}):\")\n",
    "    for i, col in enumerate(colunas_para_ffill, 1):\n",
    "        print(f\"   {i}. {col}\")\n",
    "\n",
    "    # Contar NULLs ANTES do ffill\n",
    "    print(f\"\\nğŸ“Š Contagem de NULLs ANTES do ffill:\")\n",
    "    nulls_antes = {}\n",
    "    total_nulls_antes = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        count = int(df[col].isnull().sum())\n",
    "        nulls_antes[col] = count\n",
    "        total_nulls_antes += count\n",
    "        print(f\"   {col[:40].ljust(40)}: {count:>8,} NULLs\")\n",
    "\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: {total_nulls_antes:>8,} NULLs\")\n",
    "\n",
    "    # APLICAR FFILL\n",
    "    print(f\"\\nğŸ”„ Aplicando forward fill...\")\n",
    "    df[colunas_para_ffill] = df[colunas_para_ffill].ffill()\n",
    "\n",
    "    # Contar NULLs DEPOIS do ffill\n",
    "    print(f\"\\nâœ… Contagem de NULLs DEPOIS do ffill:\")\n",
    "    total_nulls_depois = 0\n",
    "\n",
    "    for col in colunas_para_ffill:\n",
    "        nulls_depois = int(df[col].isnull().sum())\n",
    "        total_nulls_depois += nulls_depois\n",
    "\n",
    "        # Calcular preenchidas\n",
    "        preenchidas = nulls_antes[col] - nulls_depois\n",
    "\n",
    "        print(f\"   {col[:40].ljust(40)}: {nulls_antes[col]:>8,} â†’ {nulls_depois:>8,} (Î” {preenchidas:>7,})\")\n",
    "\n",
    "    total_preenchidas = total_nulls_antes - total_nulls_depois\n",
    "    print(f\"   {'TOTAL'.ljust(40)}: {total_nulls_antes:>8,} â†’ {total_nulls_depois:>8,} (Î” {total_preenchidas:>7,})\")\n",
    "\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # ETAPA 3: VALIDAR RESULTADO\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "    print(\"\\n\" + \"â”€\"*70)\n",
    "    print(\"âœ… ETAPA 3: VALIDAÃ‡ÃƒO DO RESULTADO\")\n",
    "    print(\"â”€\"*70)\n",
    "\n",
    "    print(f\"\\nğŸ‘ï¸  COMPARAÃ‡ÃƒO (primeiras 10 linhas):\")\n",
    "\n",
    "    # Criar DataFrame comparativo\n",
    "    print(f\"\\n   ANTES do ffill:\")\n",
    "    # Recarregar apenas para mostrar (nÃ£o aplicar)\n",
    "    if metodo_carga == 'csv':\n",
    "        df_antes = pd.read_csv(\n",
    "            arquivo_selecionado,\n",
    "            sep=separador_detectado,\n",
    "            encoding='cp1252',\n",
    "            skiprows=skiprows_csv if 'skiprows_csv' in locals() else None,\n",
    "            header=idx_cab_inicio,\n",
    "            usecols=range(idx_col_inicio, idx_col_fim)\n",
    "        )\n",
    "        if idx_dados_inicio > idx_cab_inicio + 1:\n",
    "            df_antes = df_antes.iloc[idx_dados_inicio - idx_cab_inicio - 1:]\n",
    "    else:\n",
    "        df_antes = pd.read_excel(\n",
    "            arquivo_selecionado,\n",
    "            sheet_name=sheet_nome if 'sheet_nome' in locals() else 0,\n",
    "            header=idx_cab_inicio,\n",
    "            usecols=range(idx_col_inicio, idx_col_fim)\n",
    "        )\n",
    "        if idx_dados_inicio > idx_cab_inicio + 1:\n",
    "            df_antes = df_antes.iloc[idx_dados_inicio - idx_cab_inicio - 1:]\n",
    "\n",
    "    print(df_antes[colunas_para_ffill].head(10).to_string())\n",
    "\n",
    "    print(f\"\\n   DEPOIS do ffill:\")\n",
    "    print(df[colunas_para_ffill].head(10).to_string())\n",
    "\n",
    "    # Verificar se primeira linha tem valores\n",
    "    primeira_linha_nulos = df.iloc[0][colunas_para_ffill].isnull().sum()\n",
    "\n",
    "    if primeira_linha_nulos > 0:\n",
    "        print(f\"\\nâš ï¸  ATENÃ‡ÃƒO: Primeira linha ainda tem {primeira_linha_nulos} NaN(s)!\")\n",
    "        print(f\"   Isso pode indicar problema no cabeÃ§alho ou dados\")\n",
    "        print(f\"   Recomenda-se revisar a extraÃ§Ã£o de dados\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… Primeira linha OK - Todos os valores preenchidos\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… FORWARD FILL APLICADO COM SUCESSO\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(f\"\\nğŸ“Š RESUMO:\")\n",
    "    print(f\"   Colunas processadas: {len(colunas_para_ffill)}\")\n",
    "    print(f\"   CÃ©lulas preenchidas: {total_preenchidas:,}\")\n",
    "    print(f\"   ReduÃ§Ã£o de NaN: {(total_preenchidas / total_nulls_antes * 100):.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"â„¹ï¸  FORWARD FILL NÃƒO NECESSÃRIO\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n   Arquivo nÃ£o possui formataÃ§Ã£o BW/BEx hierÃ¡rquica\")\n",
    "    print(f\"   Prosseguindo para prÃ³xima etapa...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TRATAMENTO BW CONCLUÃDO\")\n",
    "print(\"=\"*70)"
   ],
   "id": "19009614f0364f42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# REMOÃ‡ÃƒO DE LINHAS DE TOTALIZAÃ‡ÃƒO (ARQUIVOS BW/BEx)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ—‘ï¸  REMOÃ‡ÃƒO DE LINHAS DE TOTALIZAÃ‡ÃƒO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâ„¹ï¸  CONTEXTO:\")\n",
    "print(\"   Arquivos BW/BEx frequentemente contÃªm linhas de:\")\n",
    "print(\"   - Totais gerais\")\n",
    "print(\"   - Subtotais por agrupamento\")\n",
    "print(\"   - Resultados parciais\")\n",
    "print(\"   - MÃ©dias agregadas\")\n",
    "print(\"   Estas linhas INFLAM valores e devem ser removidas.\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ETAPA 1: DETECTAR LINHAS DE TOTALIZAÃ‡ÃƒO\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"â”€\" * 80)\n",
    "print(\"ğŸ” ETAPA 1: DETECTANDO LINHAS DE TOTALIZAÃ‡ÃƒO\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "# PadrÃµes para identificar totalizaÃ§Ãµes\n",
    "padroes_totalizacao = [\n",
    "    # PortuguÃªs\n",
    "    r'(?i)^total\\b',\n",
    "    r'(?i)^resultado\\b',\n",
    "    r'(?i)^soma\\b',\n",
    "    r'(?i)^subtotal\\b',\n",
    "    r'(?i)^parcial\\b',\n",
    "    r'(?i)^grand total',\n",
    "    r'(?i)^mÃ©dia\\b',\n",
    "    r'(?i)^media\\b',\n",
    "    r'(?i)^consolidado\\b',\n",
    "    r'(?i)^geral\\b',\n",
    "    r'(?i)total geral',\n",
    "    r'(?i)resultado final',\n",
    "\n",
    "    # InglÃªs (comum em exports SAP)\n",
    "    r'(?i)^overall',\n",
    "    r'(?i)^average',\n",
    "    r'(?i)^sum\\b',\n",
    "    r'(?i)^total\\s',\n",
    "    r'(?i)^result\\b',\n",
    "\n",
    "    # PadrÃµes numÃ©ricos (ex: \"Total 5262\", \"Resultado 1234\")\n",
    "    r'(?i)^total\\s+\\d+',\n",
    "    r'(?i)^resultado\\s+\\d+',\n",
    "    r'(?i)^subtotal\\s+\\d+',\n",
    "]\n",
    "\n",
    "# Compilar regex\n",
    "padroes_compilados = [re.compile(p) for p in padroes_totalizacao]\n",
    "\n",
    "# FunÃ§Ã£o para verificar se linha Ã© totalizaÃ§Ã£o\n",
    "def eh_linha_totalizacao(row):\n",
    "    \"\"\"Verifica se linha Ã© de totalizaÃ§Ã£o.\"\"\"\n",
    "    # Verificar primeira coluna (mais comum)\n",
    "    primeira_celula = str(row.iloc[0]).strip()\n",
    "\n",
    "    if any(padrao.search(primeira_celula) for padrao in padroes_compilados):\n",
    "        return True\n",
    "\n",
    "    # Verificar segunda coluna (caso primeira esteja preenchida com cÃ³digo)\n",
    "    if len(row) > 1:\n",
    "        segunda_celula = str(row.iloc[1]).strip()\n",
    "        if any(padrao.search(segunda_celula) for padrao in padroes_compilados):\n",
    "            return True\n",
    "\n",
    "    # Verificar se TODAS as colunas categÃ³ricas estÃ£o vazias\n",
    "    # (indicativo de linha de totalizaÃ§Ã£o em hierarquia BW)\n",
    "    colunas_categoricas = df.select_dtypes(include=['object']).columns\n",
    "    if len(colunas_categoricas) > 0:\n",
    "        valores_cat = row[colunas_categoricas].dropna()\n",
    "        # Se menos de 30% preenchidos E primeira cÃ©lula sugere total\n",
    "        if len(valores_cat) < len(colunas_categoricas) * 0.3:\n",
    "            primeira_palavra = primeira_celula.lower().split()[0] if primeira_celula else ''\n",
    "            if primeira_palavra in ['total', 'resultado', 'soma', 'mÃ©dia', 'media', 'geral']:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Identificar linhas a remover\n",
    "print(f\"\\nğŸ“Š Analisando {len(df):,} linhas...\")\n",
    "\n",
    "linhas_totalizacao = []\n",
    "for idx, row in df.iterrows():\n",
    "    if eh_linha_totalizacao(row):\n",
    "        linhas_totalizacao.append(idx)\n",
    "\n",
    "print(f\"\\nğŸ” Linhas de totalizaÃ§Ã£o detectadas: {len(linhas_totalizacao)}\")\n",
    "\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    # Mostrar exemplos\n",
    "    print(f\"\\nğŸ“‹ Exemplos de linhas detectadas (primeiras 5):\")\n",
    "    for i, idx in enumerate(linhas_totalizacao[:5], 1):\n",
    "        primeira_col = df.iloc[idx, 0]\n",
    "        segunda_col = df.iloc[idx, 1] if len(df.columns) > 1 else 'N/A'\n",
    "        print(f\"   {i}. Linha {idx}: '{primeira_col}' | '{segunda_col}'\")\n",
    "\n",
    "    if len(linhas_totalizacao) > 5:\n",
    "        print(f\"   ... e mais {len(linhas_totalizacao) - 5}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ETAPA 2: REMOVER LINHAS DETECTADAS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "if len(linhas_totalizacao) > 0:\n",
    "    print(\"\\n\" + \"â”€\" * 80)\n",
    "    print(\"ğŸ—‘ï¸  ETAPA 2: REMOVENDO LINHAS DE TOTALIZAÃ‡ÃƒO\")\n",
    "    print(\"â”€\" * 80)\n",
    "\n",
    "    # Backup\n",
    "    registros_antes = len(df)\n",
    "\n",
    "    # Remover\n",
    "    df_sem_totais = df.drop(index=linhas_totalizacao)\n",
    "\n",
    "    # Reset index\n",
    "    df_sem_totais = df_sem_totais.reset_index(drop=True)\n",
    "\n",
    "    registros_depois = len(df_sem_totais)\n",
    "    removidos = registros_antes - registros_depois\n",
    "    pct_removido = (removidos / registros_antes) * 100\n",
    "\n",
    "    print(f\"\\nâœ… RemoÃ§Ã£o concluÃ­da:\")\n",
    "    print(f\"   Antes:    {registros_antes:>7,} linhas\")\n",
    "    print(f\"   Removido: {removidos:>7,} linhas ({pct_removido:.1f}%)\")\n",
    "    print(f\"   Depois:   {registros_depois:>7,} linhas\")\n",
    "\n",
    "    # ValidaÃ§Ã£o: verificar se nÃ£o removemos demais\n",
    "    if pct_removido > 50:\n",
    "        print(f\"\\nâš ï¸  ALERTA: Mais de 50% das linhas foram removidas!\")\n",
    "        print(f\"   Isso pode indicar falso positivo na detecÃ§Ã£o.\")\n",
    "        print(f\"   Recomenda-se revisar os padrÃµes ou validar manualmente.\")\n",
    "\n",
    "        resposta = input(\"\\n   Deseja MANTER a remoÃ§Ã£o? (S/N): \").strip().upper()\n",
    "        if resposta != 'S':\n",
    "            print(f\"\\n   â„¹ï¸  RemoÃ§Ã£o CANCELADA - mantendo dados originais\")\n",
    "            df_sem_totais = df.copy()\n",
    "\n",
    "    # Atualizar DataFrame principal\n",
    "    df = df_sem_totais\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâœ… Nenhuma linha de totalizaÃ§Ã£o detectada - dados jÃ¡ estÃ£o limpos!\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ETAPA 3: VALIDAÃ‡ÃƒO FINAL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\n\" + \"â”€\" * 80)\n",
    "print(\"âœ… ETAPA 3: VALIDAÃ‡ÃƒO FINAL\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset final:\")\n",
    "print(f\"   Registros: {len(df):,}\")\n",
    "print(f\"   Colunas: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\nğŸ‘ï¸  Preview (primeiras 3 linhas):\")\n",
    "print(\"â”€\" * 80)\n",
    "print(df.head(3).to_string())\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… REMOÃ‡ÃƒO DE TOTALIZAÃ‡Ã•ES CONCLUÃDA\")\n",
    "print(\"=\"*70)"
   ],
   "id": "daae06299d6ea974",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECÃ‡ÃƒO AUTOMÃTICA DE CAMPOS (COM DICIONÃRIO PERSISTENTE) -> pedir para detectar nomes de campos unnamed com base no conteudo dos registros, exemplo unnamed com siglas , unnamed com codigos de material, unnamed com siglas, etc e tb remover linhas de totalizacoes, resultados, totais, parciais, em qualquer nivel hierarquivco de agregacao ou granularidade, pois costumam aumentar valores em colunas que tem registros linha a linha (apenas para arquivos tipo bw com hierarquias nao repetidas conforme acima)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” DETECÃ‡ÃƒO AUTOMÃTICA DE CAMPOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CLASSE DETECTOR DE CAMPOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class DetectorCampos:\n",
    "    \"\"\"Detecta e mapeia campos automaticamente.\"\"\"\n",
    "\n",
    "    def __init__(self, df, dicionario_persistente):\n",
    "        self.df = df\n",
    "        self.dicionario = dicionario_persistente\n",
    "        self.mapeamento = {}\n",
    "        self.relatorio = {\n",
    "            'total_campos': len(df.columns),\n",
    "            'mapeados_dicionario': 0,\n",
    "            'mapeados_heuristica': 0,\n",
    "            'desconhecidos': 0,\n",
    "            'ambiguos': 0,\n",
    "            'detalhes': []\n",
    "        }\n",
    "\n",
    "    def detectar_todos(self):\n",
    "        \"\"\"Detecta todos os campos do DataFrame.\"\"\"\n",
    "        print(f\"\\nğŸ“Š Analisando {len(self.df.columns)} campos...\")\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            print(f\"\\n   ğŸ” Analisando: '{col}'\")\n",
    "\n",
    "            # Extrair amostra de valores\n",
    "            valores_amostra = self.df[col].dropna().head(100).astype(str).tolist()\n",
    "\n",
    "            # Tentar detecÃ§Ã£o\n",
    "            resultado = self._detectar_campo(col, valores_amostra)\n",
    "\n",
    "            # Armazenar\n",
    "            self.mapeamento[col] = resultado\n",
    "\n",
    "            # Atualizar relatÃ³rio\n",
    "            if resultado['metodo'] == 'DICIONARIO':\n",
    "                self.relatorio['mapeados_dicionario'] += 1\n",
    "                emoji = \"âœ…\"\n",
    "            elif resultado['metodo'] == 'HEURISTICA':\n",
    "                self.relatorio['mapeados_heuristica'] += 1\n",
    "                emoji = \"ğŸ¤–\"\n",
    "            elif resultado['campo_detectado'] == 'DESCONHECIDO':\n",
    "                self.relatorio['desconhecidos'] += 1\n",
    "                emoji = \"â“\"\n",
    "            else:\n",
    "                emoji = \"âš ï¸\"\n",
    "\n",
    "            if resultado.get('ambiguidade', False):\n",
    "                self.relatorio['ambiguos'] += 1\n",
    "                emoji += \"âš ï¸\"\n",
    "\n",
    "            # Exibir resultado\n",
    "            print(f\"      {emoji} {resultado['campo_detectado']}\")\n",
    "            print(f\"      ConfianÃ§a: {resultado['confianca']:.0%} | MÃ©todo: {resultado['metodo']}\")\n",
    "\n",
    "            # Adicionar ao relatÃ³rio\n",
    "            self.relatorio['detalhes'].append({\n",
    "                'coluna_original': col,\n",
    "                'campo_detectado': resultado['campo_detectado'],\n",
    "                'confianca': resultado['confianca'],\n",
    "                'metodo': resultado['metodo'],\n",
    "                'ambiguidade': resultado.get('ambiguidade', False)\n",
    "            })\n",
    "\n",
    "        return self.mapeamento, self.relatorio\n",
    "\n",
    "    def _detectar_campo(self, nome_coluna, valores):\n",
    "        \"\"\"Detecta um Ãºnico campo.\"\"\"\n",
    "\n",
    "        # ESTRATÃ‰GIA 1: Buscar no dicionÃ¡rio persistente (MÃXIMA PRIORIDADE)\n",
    "        if self.dicionario and 'arquivos' in self.dicionario:\n",
    "            for arquivo_info in self.dicionario.get('arquivos', {}).values():\n",
    "                if 'campos_mapeados' in arquivo_info:\n",
    "                    for campo_orig, campo_info in arquivo_info['campos_mapeados'].items():\n",
    "                        # Match exato no nome\n",
    "                        if nome_coluna.lower() == campo_orig.lower():\n",
    "                            return {\n",
    "                                'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                                'confianca': 1.0,\n",
    "                                'metodo': 'DICIONARIO',\n",
    "                                'ambiguidade': False\n",
    "                            }\n",
    "\n",
    "                        # Match parcial\n",
    "                        if nome_coluna.lower() in campo_orig.lower() or campo_orig.lower() in nome_coluna.lower():\n",
    "                            return {\n",
    "                                'campo_detectado': campo_info.get('nome_padrao', campo_orig),\n",
    "                                'confianca': 0.85,\n",
    "                                'metodo': 'DICIONARIO',\n",
    "                                'ambiguidade': False\n",
    "                            }\n",
    "\n",
    "        # ESTRATÃ‰GIA 2: HeurÃ­sticas (se nÃ£o achou no dicionÃ¡rio)\n",
    "        resultado_heuristica = self._heuristica_simples(nome_coluna, valores)\n",
    "\n",
    "        if resultado_heuristica:\n",
    "            return resultado_heuristica\n",
    "\n",
    "        # ESTRATÃ‰GIA 3: Desconhecido\n",
    "        return {\n",
    "            'campo_detectado': 'DESCONHECIDO',\n",
    "            'confianca': 0.0,\n",
    "            'metodo': 'NENHUM',\n",
    "            'ambiguidade': False\n",
    "        }\n",
    "\n",
    "    def _heuristica_simples(self, nome, valores):\n",
    "        \"\"\"HeurÃ­sticas avanÃ§adas por padrÃµes de conteÃºdo.\"\"\"\n",
    "\n",
    "        if not valores:\n",
    "            return None\n",
    "\n",
    "        # Remover valores vazios\n",
    "        valores = [v for v in valores if v and str(v).strip().lower() not in ['nan', 'none', '']]\n",
    "\n",
    "        if not valores:\n",
    "            return None\n",
    "\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # HEURÃSTICAS PARA CAMPOS UNNAMED (PRIORIDADE MÃXIMA)\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "        if 'unnamed' in nome.lower():\n",
    "            print(f\"      ğŸ” Analisando conteÃºdo de '{nome}'...\")\n",
    "\n",
    "            # Amostra de valores para anÃ¡lise\n",
    "            amostra = valores[:20]\n",
    "\n",
    "            # U1: CÃ³digos de Centro (4-5 dÃ­gitos numÃ©ricos)\n",
    "            if all(str(v).isdigit() and 3 <= len(str(v)) <= 5 for v in amostra):\n",
    "                return {\n",
    "                    'campo_detectado': 'CÃ³digo Centro',\n",
    "                    'confianca': 0.90,\n",
    "                    'metodo': 'HEURISTICA_UNNAMED',\n",
    "                    'ambiguidade': False,\n",
    "                    'justificativa': 'CÃ³digos numÃ©ricos de 3-5 dÃ­gitos'\n",
    "                }\n",
    "\n",
    "            # U2: Siglas de Base (2-6 letras maiÃºsculas)\n",
    "            if all(str(v).isalpha() and str(v).isupper() and 2 <= len(str(v)) <= 6 for v in amostra):\n",
    "                return {\n",
    "                    'campo_detectado': 'Sigla Base',\n",
    "                    'confianca': 0.90,\n",
    "                    'metodo': 'HEURISTICA_UNNAMED',\n",
    "                    'ambiguidade': False,\n",
    "                    'justificativa': 'Siglas em letras maiÃºsculas'\n",
    "                }\n",
    "\n",
    "            # U3: CÃ³digos de Produto (formato: NN.NNN.NNN)\n",
    "            padrao_produto = r'^\\d{2}\\.\\d{3}\\.\\d{3}$'\n",
    "            if all(re.match(padrao_produto, str(v)) for v in amostra):\n",
    "                return {\n",
    "                    'campo_detectado': 'CÃ³digo Produto',\n",
    "                    'confianca': 0.95,\n",
    "                    'metodo': 'HEURISTICA_UNNAMED',\n",
    "                    'ambiguidade': False,\n",
    "                    'justificativa': 'Formato de cÃ³digo de produto (XX.XXX.XXX)'\n",
    "                }\n",
    "\n",
    "            # U4: CÃ³digos AlfanumÃ©ricos (possÃ­vel cÃ³digo de emissor)\n",
    "            if all(bool(re.search(r'\\d', str(v))) and len(str(v)) >= 4 for v in amostra):\n",
    "                # Verificar se tem letras tambÃ©m\n",
    "                tem_letras = any(c.isalpha() for v in amostra for c in str(v))\n",
    "                if tem_letras:\n",
    "                    return {\n",
    "                        'campo_detectado': 'CÃ³digo Emissor',\n",
    "                        'confianca': 0.80,\n",
    "                        'metodo': 'HEURISTICA_UNNAMED',\n",
    "                        'ambiguidade': False,\n",
    "                        'justificativa': 'CÃ³digos alfanumÃ©ricos'\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'campo_detectado': 'CÃ³digo Identificador',\n",
    "                        'confianca': 0.75,\n",
    "                        'metodo': 'HEURISTICA_UNNAMED',\n",
    "                        'ambiguidade': False,\n",
    "                        'justificativa': 'CÃ³digos numÃ©ricos longos'\n",
    "                    }\n",
    "\n",
    "            # U5: Nomes/DescriÃ§Ãµes (strings longas com espaÃ§os)\n",
    "            tem_espacos = any(' ' in str(v) for v in amostra)\n",
    "            tamanho_medio = sum(len(str(v)) for v in amostra) / len(amostra)\n",
    "\n",
    "            if tem_espacos and tamanho_medio > 10:\n",
    "                # Verificar se Ã© nome de empresa\n",
    "                palavras_empresa = ['ltda', 'sa', 's.a', 's/a', 'cia', 'company', 'corporation', 'industria', 'comercio']\n",
    "                eh_empresa = any(any(palavra in str(v).lower() for palavra in palavras_empresa) for v in amostra[:5])\n",
    "\n",
    "                if eh_empresa:\n",
    "                    return {\n",
    "                        'campo_detectado': 'RazÃ£o Social',\n",
    "                        'confianca': 0.85,\n",
    "                        'metodo': 'HEURISTICA_UNNAMED',\n",
    "                        'ambiguidade': False,\n",
    "                        'justificativa': 'Nomes de empresas detectados'\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'campo_detectado': 'DescriÃ§Ã£o',\n",
    "                        'confianca': 0.75,\n",
    "                        'metodo': 'HEURISTICA_UNNAMED',\n",
    "                        'ambiguidade': False,\n",
    "                        'justificativa': 'Textos descritivos longos'\n",
    "                    }\n",
    "\n",
    "            # U6: CÃ³digos curtos (2-3 caracteres)\n",
    "            if all(2 <= len(str(v)) <= 3 for v in amostra):\n",
    "                if all(str(v).isalpha() for v in amostra):\n",
    "                    return {\n",
    "                        'campo_detectado': 'CÃ³digo Curto (Categoria)',\n",
    "                        'confianca': 0.70,\n",
    "                        'metodo': 'HEURISTICA_UNNAMED',\n",
    "                        'ambiguidade': True,\n",
    "                        'justificativa': 'CÃ³digos alfabÃ©ticos curtos'\n",
    "                    }\n",
    "\n",
    "            # U7: Estados (2 letras maiÃºsculas) - comum em BW Brasil\n",
    "            estados_br = ['AC','AL','AP','AM','BA','CE','DF','ES','GO','MA','MT','MS','MG',\n",
    "                         'PA','PB','PR','PE','PI','RJ','RN','RS','RO','RR','SC','SP','SE','TO']\n",
    "            if all(str(v).upper() in estados_br for v in amostra[:10]):\n",
    "                return {\n",
    "                    'campo_detectado': 'Estado (UF)',\n",
    "                    'confianca': 0.95,\n",
    "                    'metodo': 'HEURISTICA_UNNAMED',\n",
    "                    'ambiguidade': False,\n",
    "                    'justificativa': 'Siglas de estados brasileiros'\n",
    "                }\n",
    "\n",
    "            # Se chegou aqui e Ã© Unnamed, marcar como desconhecido mas com contexto\n",
    "            print(f\"      âš ï¸  PadrÃ£o nÃ£o reconhecido em '{nome}'\")\n",
    "            print(f\"      Exemplos: {amostra[:3]}\")\n",
    "\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # HEURÃSTICAS GERAIS (PARA CAMPOS NÃƒO-UNNAMED)\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "        # H1: Data no formato YYYY-MM-DD ou DD/MM/YYYY\n",
    "        padrao_data1 = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "        padrao_data2 = r'^\\d{2}/\\d{2}/\\d{4}$'\n",
    "        padrao_data3 = r'^\\d{1,2}\\.\\d{4}$'  # M.YYYY ou MM.YYYY\n",
    "\n",
    "        if all(re.match(padrao_data1, str(v)) or re.match(padrao_data2, str(v)) for v in valores[:10]):\n",
    "            return {\n",
    "                'campo_detectado': 'Data',\n",
    "                'confianca': 0.95,\n",
    "                'metodo': 'HEURISTICA',\n",
    "                'ambiguidade': False\n",
    "            }\n",
    "\n",
    "        # Formato \"M.YYYY\" comum em exports BW\n",
    "        if all(re.match(padrao_data3, str(v)) for v in valores[:10]):\n",
    "            return {\n",
    "                'campo_detectado': 'MÃªs de CalendÃ¡rio',\n",
    "                'confianca': 0.90,\n",
    "                'metodo': 'HEURISTICA',\n",
    "                'ambiguidade': False\n",
    "            }\n",
    "\n",
    "        # H2: NÃºmeros de 4 dÃ­gitos (provÃ¡vel cÃ³digo de centro)\n",
    "        if all(re.match(r'^\\d{4}$', str(v)) for v in valores[:10]):\n",
    "            if 'centro' in nome.lower() or 'cod' in nome.lower() or 'base' in nome.lower():\n",
    "                return {\n",
    "                    'campo_detectado': 'CÃ³digo Centro',\n",
    "                    'confianca': 0.85,\n",
    "                    'metodo': 'HEURISTICA',\n",
    "                    'ambiguidade': False\n",
    "                }\n",
    "\n",
    "        # H3: Siglas de 5 letras (formato clÃ¡ssico de bases BR)\n",
    "        if all(len(str(v)) == 5 and str(v).isalpha() and str(v).isupper() for v in valores[:10]):\n",
    "            return {\n",
    "                'campo_detectado': 'Sigla Base',\n",
    "                'confianca': 0.85,\n",
    "                'metodo': 'HEURISTICA',\n",
    "                'ambiguidade': False\n",
    "            }\n",
    "\n",
    "        # H4: Percentuais\n",
    "        if 'porcent' in nome.lower() or '%' in nome or 'perc' in nome.lower():\n",
    "            return {\n",
    "                'campo_detectado': 'Percentual',\n",
    "                'confianca': 0.80,\n",
    "                'metodo': 'HEURISTICA',\n",
    "                'ambiguidade': False\n",
    "            }\n",
    "\n",
    "        # H5: Valores numÃ©ricos grandes (volume/estoque)\n",
    "        try:\n",
    "            valores_num = []\n",
    "            for v in valores[:10]:\n",
    "                v_str = str(v).replace(',', '.').replace(' ', '')\n",
    "                valores_num.append(float(v_str))\n",
    "\n",
    "            if all(v > 1000 for v in valores_num):\n",
    "                # Identificar tipo por nome ou contexto\n",
    "                if 'volume' in nome.lower() or 'expedicao' in nome.lower() or 'expediÃ§Ã£o' in nome.lower():\n",
    "                    return {\n",
    "                        'campo_detectado': 'Volume ExpediÃ§Ã£o',\n",
    "                        'confianca': 0.85,\n",
    "                        'metodo': 'HEURISTICA',\n",
    "                        'ambiguidade': False\n",
    "                    }\n",
    "                elif 'estoque' in nome.lower() or 'saldo' in nome.lower():\n",
    "                    return {\n",
    "                        'campo_detectado': 'Estoque',\n",
    "                        'confianca': 0.85,\n",
    "                        'metodo': 'HEURISTICA',\n",
    "                        'ambiguidade': False\n",
    "                    }\n",
    "                elif 'consigna' in nome.lower():\n",
    "                    return {\n",
    "                        'campo_detectado': 'Estoque Consignado',\n",
    "                        'confianca': 0.90,\n",
    "                        'metodo': 'HEURISTICA',\n",
    "                        'ambiguidade': False\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'campo_detectado': 'Quantidade',\n",
    "                        'confianca': 0.70,\n",
    "                        'metodo': 'HEURISTICA',\n",
    "                        'ambiguidade': True\n",
    "                    }\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # H6: CÃ³digos de Produto (por nome + formato)\n",
    "        if 'produto' in nome.lower() or 'material' in nome.lower():\n",
    "            # Verificar se tem formato de cÃ³digo\n",
    "            if all(any(c.isdigit() for c in str(v)) for v in valores[:10]):\n",
    "                return {\n",
    "                    'campo_detectado': 'CÃ³digo Produto',\n",
    "                    'confianca': 0.80,\n",
    "                    'metodo': 'HEURISTICA',\n",
    "                    'ambiguidade': False\n",
    "                }\n",
    "\n",
    "        # H7: Nomes de Produtos/Materiais (por nome + conteÃºdo textual)\n",
    "        if 'produto' in nome.lower() or 'material' in nome.lower() or 'descri' in nome.lower():\n",
    "            tem_texto = any(len(str(v)) > 10 and any(c.isalpha() for c in str(v)) for v in valores[:5])\n",
    "            if tem_texto:\n",
    "                return {\n",
    "                    'campo_detectado': 'DescriÃ§Ã£o Produto',\n",
    "                    'confianca': 0.80,\n",
    "                    'metodo': 'HEURISTICA',\n",
    "                    'ambiguidade': False\n",
    "                }\n",
    "\n",
    "        return None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXECUTAR DETECÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "detector = DetectorCampos(df, DICIONARIO_PERSISTENTE)\n",
    "mapeamento_campos, relatorio_deteccao = detector.detectar_todos()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RELATÃ“RIO DE DETECÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ RELATÃ“RIO DE DETECÃ‡ÃƒO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š RESUMO:\")\n",
    "print(f\"   Total de campos: {relatorio_deteccao['total_campos']}\")\n",
    "print(f\"   âœ… DicionÃ¡rio: {relatorio_deteccao['mapeados_dicionario']}\")\n",
    "print(f\"   ğŸ¤– HeurÃ­stica: {relatorio_deteccao['mapeados_heuristica']}\")\n",
    "print(f\"   â“ Desconhecidos: {relatorio_deteccao['desconhecidos']}\")\n",
    "print(f\"   âš ï¸  AmbÃ­guos: {relatorio_deteccao['ambiguos']}\")\n",
    "\n",
    "# Taxa de sucesso\n",
    "taxa_sucesso = ((relatorio_deteccao['mapeados_dicionario'] + relatorio_deteccao['mapeados_heuristica']) /\n",
    "                relatorio_deteccao['total_campos']) * 100\n",
    "\n",
    "print(f\"\\nğŸ¯ Taxa de detecÃ§Ã£o: {taxa_sucesso:.1f}%\")\n",
    "\n",
    "# Detalhes por confianÃ§a\n",
    "print(f\"\\nğŸ“Š DISTRIBUIÃ‡ÃƒO POR CONFIANÃ‡A:\")\n",
    "\n",
    "alta = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] >= 0.85)\n",
    "media = sum(1 for d in relatorio_deteccao['detalhes'] if 0.70 <= d['confianca'] < 0.85)\n",
    "baixa = sum(1 for d in relatorio_deteccao['detalhes'] if 0 < d['confianca'] < 0.70)\n",
    "zero = sum(1 for d in relatorio_deteccao['detalhes'] if d['confianca'] == 0)\n",
    "\n",
    "print(f\"   ğŸŸ¢ Alta (â‰¥85%): {alta}\")\n",
    "print(f\"   ğŸŸ¡ MÃ©dia (70-85%): {media}\")\n",
    "print(f\"   ğŸŸ  Baixa (<70%): {baixa}\")\n",
    "print(f\"   âš« Desconhecidos: {zero}\")\n",
    "\n",
    "# Lista de desconhecidos\n",
    "desconhecidos = [d for d in relatorio_deteccao['detalhes'] if d['campo_detectado'] == 'DESCONHECIDO']\n",
    "\n",
    "if desconhecidos:\n",
    "    print(f\"\\nâ“ CAMPOS DESCONHECIDOS:\")\n",
    "    for item in desconhecidos:\n",
    "        print(f\"   â€¢ {item['coluna_original']}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# APLICAR MAPEAMENTO (CRIAR COLUNAS PADRONIZADAS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ”„ APLICANDO MAPEAMENTO\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# Criar dicionÃ¡rio de rename (apenas campos com confianÃ§a â‰¥70%)\n",
    "rename_dict = {}\n",
    "for col_orig, info in mapeamento_campos.items():\n",
    "    if info['confianca'] >= 0.70 and info['campo_detectado'] != 'DESCONHECIDO':\n",
    "        # Se nome diferente, mapear\n",
    "        if col_orig != info['campo_detectado']:\n",
    "            rename_dict[col_orig] = info['campo_detectado']\n",
    "\n",
    "print(f\"\\nğŸ“ Mapeamentos a aplicar: {len(rename_dict)}\")\n",
    "\n",
    "if rename_dict:\n",
    "    # Exibir primeiros 10\n",
    "    print(f\"\\n   Primeiros 10 mapeamentos:\")\n",
    "    for i, (orig, novo) in enumerate(list(rename_dict.items())[:10], 1):\n",
    "        print(f\"   {i:2d}. '{orig}' â†’ '{novo}'\")\n",
    "\n",
    "    if len(rename_dict) > 10:\n",
    "        print(f\"   ... e mais {len(rename_dict) - 10}\")\n",
    "\n",
    "    # Aplicar rename\n",
    "    df_mapeado = df.rename(columns=rename_dict)\n",
    "\n",
    "    print(f\"\\nâœ… Mapeamento aplicado!\")\n",
    "else:\n",
    "    df_mapeado = df.copy()\n",
    "    print(f\"\\n   â„¹ï¸  Nenhum mapeamento necessÃ¡rio (nomes jÃ¡ padronizados)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SALVAR MAPEAMENTO NO DICIONÃRIO PERSISTENTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"ğŸ’¾ ATUALIZANDO DICIONÃRIO PERSISTENTE\")\n",
    "print(\"â”€\"*70)\n",
    "\n",
    "# Identificar fonte\n",
    "nome_fonte = f\"CSV_{arquivo_selecionado.stem}\"\n",
    "\n",
    "# Criar entrada no dicionÃ¡rio\n",
    "if 'arquivos' not in DICIONARIO_PERSISTENTE:\n",
    "    DICIONARIO_PERSISTENTE['arquivos'] = {}\n",
    "\n",
    "DICIONARIO_PERSISTENTE['arquivos'][nome_fonte] = {\n",
    "    'arquivo_origem': arquivo_selecionado.name,\n",
    "    'data_processamento': datetime.now().isoformat(),\n",
    "    'total_campos': len(df.columns),\n",
    "    'campos_mapeados': {}\n",
    "}\n",
    "\n",
    "# Adicionar campos com confianÃ§a â‰¥ 85%\n",
    "for col_orig, info in mapeamento_campos.items():\n",
    "    if info['confianca'] >= 0.85:\n",
    "        DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['campos_mapeados'][col_orig] = {\n",
    "            'nome_padrao': info['campo_detectado'],\n",
    "            'confianca': info['confianca'],\n",
    "            'metodo': info['metodo']\n",
    "        }\n",
    "\n",
    "# Salvar dicionÃ¡rio\n",
    "dict_path = fm.pastas['logs'] / 'DICT_Dicionario_Persistente.json'\n",
    "with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(DICIONARIO_PERSISTENTE, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… DicionÃ¡rio atualizado: {dict_path.name}\")\n",
    "print(f\"   Novos campos: {len(DICIONARIO_PERSISTENTE['arquivos'][nome_fonte]['campos_mapeados'])}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PREVIEW DOS DADOS MAPEADOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‘€ PREVIEW DOS DADOS MAPEADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š Shape: {df_mapeado.shape[0]:,} registros Ã— {df_mapeado.shape[1]} colunas\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Primeiras 10 colunas:\")\n",
    "for i, col in enumerate(df_mapeado.columns[:10], 1):\n",
    "    original = [k for k, v in rename_dict.items() if v == col]\n",
    "    if original:\n",
    "        print(f\"   {i:2d}. {col} (era: {original[0]})\")\n",
    "    else:\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Primeiras 3 linhas:\")\n",
    "print(df_mapeado.head(3).to_string())\n",
    "\n",
    "# Substituir df original\n",
    "df = df_mapeado\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DETECÃ‡ÃƒO DE CAMPOS CONCLUÃDA\")\n",
    "print(\"=\"*70)"
   ],
   "id": "7248ad79f5d29e2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# GUI VISUAL PARA CONFIRMAR TIPOS - INTERFACE INTUITIVA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ CONFIRMAÃ‡ÃƒO VISUAL DE TIPOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not requer_confirmacao:\n",
    "    print(\"\\nâœ… Nenhuma confirmaÃ§Ã£o necessÃ¡ria - todas com confianÃ§a â‰¥ 90%\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“‹ {len(requer_confirmacao)} campos requerem confirmaÃ§Ã£o\")\n",
    "    print(f\"   Abrindo interface visual...\")\n",
    "\n",
    "    def confirmar_tipos_visual(campos_confirmar, tipos_detectados, df):\n",
    "        \"\"\"\n",
    "        GUI VISUAL com lista numerada de tipos\n",
    "        \"\"\"\n",
    "        # Preparar lista de tipos disponÃ­veis\n",
    "        tipos_dict = dicionario.dados['campos_conhecidos']\n",
    "        tipos_lista = []\n",
    "\n",
    "        for i, (nome_tipo, info) in enumerate(sorted(tipos_dict.items()), 1):\n",
    "            tipos_lista.append({\n",
    "                'numero': i,\n",
    "                'nome': nome_tipo,\n",
    "                'descricao': info.get('descricao', ''),\n",
    "                'exemplos': info.get('exemplos', [])\n",
    "            })\n",
    "\n",
    "        # Adicionar opÃ§Ãµes especiais\n",
    "        tipos_lista.append({\n",
    "            'numero': 0,\n",
    "            'nome': 'DESCONHECIDO',\n",
    "            'descricao': 'Tipo nÃ£o identificado',\n",
    "            'exemplos': []\n",
    "        })\n",
    "\n",
    "        confirmacoes = {}\n",
    "        idx_atual = [0]\n",
    "\n",
    "        def processar_proximo():\n",
    "            if idx_atual[0] >= len(campos_confirmar):\n",
    "                return\n",
    "\n",
    "            col = campos_confirmar[idx_atual[0]]\n",
    "            info_campo = tipos_detectados[col]\n",
    "            valores_exemplo = df[col].dropna().unique()[:5].tolist()\n",
    "\n",
    "            # Criar janela\n",
    "            root = tk.Tk()\n",
    "            root.title(f\"DETECTOR - ConfirmaÃ§Ã£o ({idx_atual[0]+1}/{len(campos_confirmar)})\")\n",
    "            root.geometry(\"900x650\")\n",
    "\n",
    "            x = (root.winfo_screenwidth() // 2) - 450\n",
    "            y = (root.winfo_screenheight() // 2) - 325\n",
    "            root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "            frame_principal = tk.Frame(root, bg='white')\n",
    "            frame_principal.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)\n",
    "\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            # TOPO: Progresso\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            frame_topo = tk.Frame(frame_principal, bg='#E3F2FD', relief=tk.RAISED, borderwidth=2)\n",
    "            frame_topo.pack(fill=tk.X, pady=(0, 15))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_topo,\n",
    "                text=f\"ğŸ¯ Campo {idx_atual[0]+1} de {len(campos_confirmar)}\",\n",
    "                font=('Arial', 12, 'bold'),\n",
    "                bg='#E3F2FD',\n",
    "                fg='#1565C0'\n",
    "            ).pack(pady=8)\n",
    "\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            # ESQUERDA: Info do campo\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            frame_conteudo = tk.Frame(frame_principal, bg='white')\n",
    "            frame_conteudo.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            # Coluna esquerda\n",
    "            frame_esquerda = tk.Frame(frame_conteudo, bg='white', width=400)\n",
    "            frame_esquerda.pack(side=tk.LEFT, fill=tk.BOTH, expand=False, padx=(0, 10))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_esquerda,\n",
    "                text=\"ğŸ“‹ CAMPO DO ARQUIVO\",\n",
    "                font=('Arial', 11, 'bold'),\n",
    "                bg='white',\n",
    "                anchor='w'\n",
    "            ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            # Box campo\n",
    "            frame_campo = tk.Frame(frame_esquerda, bg='#FFF9C4', relief=tk.SUNKEN, borderwidth=2)\n",
    "            frame_campo.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_campo,\n",
    "                text=f\"ğŸ”– {col}\",\n",
    "                font=('Arial', 10, 'bold'),\n",
    "                bg='#FFF9C4',\n",
    "                anchor='w',\n",
    "                wraplength=380\n",
    "            ).pack(fill=tk.X, padx=10, pady=(8, 5))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_campo,\n",
    "                text=f\"ğŸ¤– Detectado: {info_campo['campo_detectado']}\",\n",
    "                font=('Arial', 9),\n",
    "                bg='#FFF9C4',\n",
    "                fg='#F57F17',\n",
    "                anchor='w'\n",
    "            ).pack(fill=tk.X, padx=10, pady=(0, 3))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_campo,\n",
    "                text=f\"ğŸ“Š ConfianÃ§a: {info_campo['confianca']:.0%}\",\n",
    "                font=('Arial', 9),\n",
    "                bg='#FFF9C4',\n",
    "                fg='#F57F17',\n",
    "                anchor='w'\n",
    "            ).pack(fill=tk.X, padx=10, pady=(0, 8))\n",
    "\n",
    "            # Exemplos\n",
    "            tk.Label(\n",
    "                frame_esquerda,\n",
    "                text=\"ğŸ“Š EXEMPLOS DE VALORES\",\n",
    "                font=('Arial', 10, 'bold'),\n",
    "                bg='white',\n",
    "                anchor='w'\n",
    "            ).pack(fill=tk.X, pady=(5, 5))\n",
    "\n",
    "            frame_exemplos = tk.Frame(frame_esquerda, bg='#F5F5F5', relief=tk.SUNKEN, borderwidth=1)\n",
    "            frame_exemplos.pack(fill=tk.X)\n",
    "\n",
    "            for i, val in enumerate(valores_exemplo, 1):\n",
    "                val_str = str(val)[:50]\n",
    "                tk.Label(\n",
    "                    frame_exemplos,\n",
    "                    text=f\"{i}. {val_str}\",\n",
    "                    font=('Arial', 9),\n",
    "                    bg='#F5F5F5',\n",
    "                    anchor='w'\n",
    "                ).pack(fill=tk.X, padx=10, pady=2)\n",
    "\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            # DIREITA: Lista de tipos\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            frame_direita = tk.Frame(frame_conteudo, bg='white')\n",
    "            frame_direita.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            tk.Label(\n",
    "                frame_direita,\n",
    "                text=\"ğŸ”¢ TIPOS DISPONÃVEIS - Digite o nÃºmero\",\n",
    "                font=('Arial', 11, 'bold'),\n",
    "                bg='white',\n",
    "                anchor='w'\n",
    "            ).pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            # Canvas + Scrollbar para lista\n",
    "            frame_lista_outer = tk.Frame(frame_direita, bg='white')\n",
    "            frame_lista_outer.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "            canvas = tk.Canvas(frame_lista_outer, bg='white', highlightthickness=0)\n",
    "            scrollbar = tk.Scrollbar(frame_lista_outer, orient=\"vertical\", command=canvas.yview)\n",
    "            frame_lista = tk.Frame(canvas, bg='white')\n",
    "\n",
    "            frame_lista.bind(\n",
    "                \"<Configure>\",\n",
    "                lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "            )\n",
    "\n",
    "            canvas.create_window((0, 0), window=frame_lista, anchor=\"nw\")\n",
    "            canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "            canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "            scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "            # Popular lista\n",
    "            for tipo_info in tipos_lista:\n",
    "                num = tipo_info['numero']\n",
    "                nome = tipo_info['nome']\n",
    "                desc = tipo_info['descricao']\n",
    "\n",
    "                # Destacar tipo detectado\n",
    "                bg_cor = '#E8F5E9' if nome == info_campo['campo_detectado'] else 'white'\n",
    "                fg_cor = '#2E7D32' if nome == info_campo['campo_detectado'] else 'black'\n",
    "\n",
    "                frame_item = tk.Frame(frame_lista, bg=bg_cor, relief=tk.GROOVE, borderwidth=1)\n",
    "                frame_item.pack(fill=tk.X, pady=2, padx=5)\n",
    "\n",
    "                tk.Label(\n",
    "                    frame_item,\n",
    "                    text=f\"[{num:2d}]  {nome}\",\n",
    "                    font=('Courier', 9, 'bold'),\n",
    "                    bg=bg_cor,\n",
    "                    fg=fg_cor,\n",
    "                    anchor='w'\n",
    "                ).pack(fill=tk.X, padx=8, pady=(3, 0))\n",
    "\n",
    "                if desc:\n",
    "                    tk.Label(\n",
    "                        frame_item,\n",
    "                        text=f\"      {desc}\",\n",
    "                        font=('Arial', 8),\n",
    "                        bg=bg_cor,\n",
    "                        fg='#666666',\n",
    "                        anchor='w'\n",
    "                    ).pack(fill=tk.X, padx=8, pady=(0, 3))\n",
    "\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            # RODAPÃ‰: Campo de entrada + botÃµes\n",
    "            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "            frame_rodape = tk.Frame(frame_principal, bg='white')\n",
    "            frame_rodape.pack(fill=tk.X, pady=(15, 0))\n",
    "\n",
    "            tk.Frame(frame_rodape, height=2, bg='#CCCCCC').pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "            # Campo de entrada\n",
    "            frame_entrada = tk.Frame(frame_rodape, bg='white')\n",
    "            frame_entrada.pack(pady=(0, 10))\n",
    "\n",
    "            tk.Label(\n",
    "                frame_entrada,\n",
    "                text=\"Digite o nÃºmero do tipo correto:\",\n",
    "                font=('Arial', 10, 'bold'),\n",
    "                bg='white'\n",
    "            ).pack(side=tk.LEFT, padx=(0, 10))\n",
    "\n",
    "            var_numero = tk.StringVar()\n",
    "            entry = tk.Entry(\n",
    "                frame_entrada,\n",
    "                textvariable=var_numero,\n",
    "                font=('Arial', 12, 'bold'),\n",
    "                width=8,\n",
    "                justify='center'\n",
    "            )\n",
    "            entry.pack(side=tk.LEFT)\n",
    "            entry.focus()\n",
    "\n",
    "            label_erro = tk.Label(\n",
    "                frame_entrada,\n",
    "                text=\"\",\n",
    "                font=('Arial', 9),\n",
    "                fg='#FF0000',\n",
    "                bg='white'\n",
    "            )\n",
    "            label_erro.pack(side=tk.LEFT, padx=(10, 0))\n",
    "\n",
    "            # BotÃµes\n",
    "            frame_btns = tk.Frame(frame_rodape, bg='white')\n",
    "            frame_btns.pack()\n",
    "\n",
    "            def validar_e_confirmar():\n",
    "                try:\n",
    "                    num_digitado = int(var_numero.get().strip())\n",
    "\n",
    "                    # Buscar tipo pelo nÃºmero\n",
    "                    tipo_escolhido = None\n",
    "                    for t in tipos_lista:\n",
    "                        if t['numero'] == num_digitado:\n",
    "                            tipo_escolhido = t['nome']\n",
    "                            break\n",
    "\n",
    "                    if tipo_escolhido:\n",
    "                        confirmacoes[col] = tipo_escolhido\n",
    "                        idx_atual[0] += 1\n",
    "                        root.destroy()\n",
    "                        processar_proximo()\n",
    "                    else:\n",
    "                        label_erro.config(text=f\"âŒ NÃºmero {num_digitado} invÃ¡lido!\")\n",
    "\n",
    "                except ValueError:\n",
    "                    label_erro.config(text=\"âŒ Digite um nÃºmero!\")\n",
    "\n",
    "            def manter_detectado():\n",
    "                confirmacoes[col] = info_campo['campo_detectado']\n",
    "                idx_atual[0] += 1\n",
    "                root.destroy()\n",
    "                processar_proximo()\n",
    "\n",
    "            def pular_todos():\n",
    "                for campo_restante in campos_confirmar[idx_atual[0]:]:\n",
    "                    confirmacoes[campo_restante] = tipos_detectados[campo_restante]['campo_detectado']\n",
    "                root.destroy()\n",
    "\n",
    "            # Enter = confirmar\n",
    "            entry.bind('<Return>', lambda e: validar_e_confirmar())\n",
    "\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"âœ… Confirmar\",\n",
    "                command=validar_e_confirmar,\n",
    "                width=15,\n",
    "                height=2,\n",
    "                bg='#4CAF50',\n",
    "                fg='white',\n",
    "                font=('Arial', 10, 'bold'),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"â¡ï¸  Manter Detectado\",\n",
    "                command=manter_detectado,\n",
    "                width=18,\n",
    "                height=2,\n",
    "                bg='#FF9800',\n",
    "                fg='white',\n",
    "                font=('Arial', 10),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "            tk.Button(\n",
    "                frame_btns,\n",
    "                text=\"â­ï¸  Pular Todos\",\n",
    "                command=pular_todos,\n",
    "                width=15,\n",
    "                height=2,\n",
    "                bg='#757575',\n",
    "                fg='white',\n",
    "                font=('Arial', 10),\n",
    "                cursor='hand2'\n",
    "            ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "            root.mainloop()\n",
    "\n",
    "        # Iniciar processamento\n",
    "        processar_proximo()\n",
    "        return confirmacoes\n",
    "\n",
    "    # Executar GUI\n",
    "    confirmacoes = confirmar_tipos_visual(requer_confirmacao, tipos_detectados, df_limpo)\n",
    "\n",
    "    # Aplicar confirmaÃ§Ãµes\n",
    "    if confirmacoes:\n",
    "        print(f\"\\nâœ… ConfirmaÃ§Ãµes aplicadas:\")\n",
    "        for col, tipo_confirmado in confirmacoes.items():\n",
    "            if tipo_confirmado != tipos_detectados[col]['campo_detectado']:\n",
    "                print(f\"   âœï¸  {col}\")\n",
    "                print(f\"       {tipos_detectados[col]['campo_detectado']} â†’ {tipo_confirmado}\")\n",
    "                tipos_detectados[col]['campo_detectado'] = tipo_confirmado\n",
    "                tipos_detectados[col]['confianca'] = 1.0\n",
    "                tipos_detectados[col]['metodo'] = 'CONFIRMACAO_USUARIO'\n",
    "\n",
    "        print(f\"\\nâœ… Total: {len(confirmacoes)} campos confirmados\")\n",
    "    else:\n",
    "        print(f\"\\nâ­ï¸  Nenhuma confirmaÃ§Ã£o realizada\")"
   ],
   "id": "302fbbdf08b6cd1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VALIDAÃ‡Ã•ES E ESTATÃSTICAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š VALIDAÃ‡Ã•ES E ESTATÃSTICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Resumo Geral\n",
    "print(\"\\nğŸ“‹ RESUMO GERAL:\")\n",
    "print(\"â”€\" * 80)\n",
    "print(f\"   Registros finais: {len(df_limpo):,}\")\n",
    "print(f\"   Colunas finais: {len(df_limpo.columns)}\")\n",
    "print(f\"   MemÃ³ria em uso: {df_limpo.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"   Linhas duplicadas: {df_limpo.duplicated().sum():,}\")\n",
    "\n",
    "# 2. Valores Nulos\n",
    "print(\"\\nğŸ” ANÃLISE DE VALORES NULOS:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "nulos_por_col = df_limpo.isnull().sum()\n",
    "colunas_com_nulos = nulos_por_col[nulos_por_col > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"   âš ï¸  {len(colunas_com_nulos)} colunas com valores nulos:\")\n",
    "    for col, qtd in colunas_com_nulos.items():\n",
    "        pct = (qtd / len(df_limpo)) * 100\n",
    "        barra = \"â–ˆ\" * int(pct / 5)\n",
    "        print(f\"      {col:30s} | {qtd:6,} ({pct:5.1f}%) {barra}\")\n",
    "else:\n",
    "    print(f\"   âœ… Nenhum valor nulo!\")\n",
    "\n",
    "# 3. DistribuiÃ§Ã£o de Tipos Detectados\n",
    "print(\"\\nğŸ”¬ DISTRIBUIÃ‡ÃƒO DE TIPOS DETECTADOS:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "tipos_resumo = {}\n",
    "for info in tipos_detectados.values():\n",
    "    tipo = info['campo_detectado']  # âœ… CHAVE CORRETA\n",
    "    tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "for tipo, count in sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True):\n",
    "    barra = \"â–ˆ\" * (count * 2)\n",
    "    print(f\"   â€¢ {tipo:25s}: {count:2d} colunas {barra}\")\n",
    "\n",
    "# 4. Campos com Alta/MÃ©dia/Baixa ConfianÃ§a\n",
    "print(\"\\nğŸ“ˆ CONFIANÃ‡A NA DETECÃ‡ÃƒO:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "alta = sum(1 for info in tipos_detectados.values() if info['confianca'] >= 0.90)\n",
    "media = sum(1 for info in tipos_detectados.values() if 0.70 <= info['confianca'] < 0.90)\n",
    "baixa = sum(1 for info in tipos_detectados.values() if info['confianca'] < 0.70)\n",
    "\n",
    "print(f\"   âœ… Alta (â‰¥90%):   {alta:2d} colunas\")\n",
    "print(f\"   âš ï¸  MÃ©dia (70-90%): {media:2d} colunas\")\n",
    "print(f\"   â“ Baixa (<70%):   {baixa:2d} colunas\")\n",
    "\n",
    "# 5. Campos AmbÃ­guos\n",
    "print(\"\\nâš ï¸  CAMPOS AMBÃGUOS:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "ambiguos = {col: info for col, info in tipos_detectados.items() if info.get('ambiguidade', False)}\n",
    "\n",
    "if ambiguos:\n",
    "    print(f\"   {len(ambiguos)} campos com ambiguidade:\")\n",
    "    for col, info in list(ambiguos.items())[:5]:\n",
    "        print(f\"\\n   ğŸ“Œ {col}\")\n",
    "        print(f\"      Detectado: {info['campo_detectado']}\")\n",
    "        print(f\"      Similar a: {', '.join(info.get('candidatos', []))}\")\n",
    "\n",
    "    if len(ambiguos) > 5:\n",
    "        print(f\"\\n   ... e mais {len(ambiguos) - 5} campos\")\n",
    "else:\n",
    "    print(f\"   âœ… Nenhum campo ambÃ­guo!\")\n",
    "\n",
    "# 6. Campos Ãšnicos (potenciais IDs)\n",
    "print(\"\\nğŸ”‘ ANÃLISE DE UNICIDADE:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "for col in df_limpo.columns:\n",
    "    unicos = df_limpo[col].nunique()\n",
    "    total = len(df_limpo)\n",
    "    pct_unico = (unicos / total) * 100\n",
    "\n",
    "    if pct_unico == 100:\n",
    "        print(f\"   ğŸ”‘ {col:30s} | 100% Ãºnico (potencial ID)\")\n",
    "    elif pct_unico >= 95:\n",
    "        print(f\"   âš ï¸  {col:30s} | {pct_unico:5.1f}% Ãºnico\")\n",
    "\n",
    "# 7. Cardinalidade (valores Ãºnicos)\n",
    "print(\"\\nğŸ“Š CARDINALIDADE:\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "for col in df_limpo.columns[:10]:  # Primeiras 10\n",
    "    unicos = df_limpo[col].nunique()\n",
    "    total = len(df_limpo)\n",
    "    pct = (unicos / total) * 100\n",
    "\n",
    "    if pct <= 10:\n",
    "        categoria = \"Categoria (baixa)\"\n",
    "    elif pct <= 50:\n",
    "        categoria = \"Mista (mÃ©dia)\"\n",
    "    else:\n",
    "        categoria = \"ContÃ­nua (alta)\"\n",
    "\n",
    "    print(f\"   {col:30s} | {unicos:4d} Ãºnicos ({pct:5.1f}%) - {categoria}\")\n",
    "\n",
    "if len(df_limpo.columns) > 10:\n",
    "    print(f\"\\n   ... e mais {len(df_limpo.columns) - 10} colunas\")\n",
    "\n",
    "# 8. Tipos de Dados Pandas\n",
    "print(\"\\nğŸ’¾ TIPOS DE DADOS (PANDAS):\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "dtype_counts = df_limpo.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"   â€¢ {str(dtype):15s}: {count:2d} colunas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… VALIDAÃ‡Ã•ES CONCLUÃDAS\")\n",
    "print(\"=\"*70)"
   ],
   "id": "74512ff8a1905539",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXPORTAÃ‡ÃƒO DE RESULTADOS - VERSÃƒO DEFENSIVA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¾ EXPORTAÃ‡ÃƒO DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "nome_base = arquivo_selecionado.stem\n",
    "\n",
    "# 1ï¸âƒ£  DADOS LIMPOS\n",
    "print(\"\\n1ï¸âƒ£  Dados limpos...\")\n",
    "arquivo_limpo = fm.salvar(df_limpo, f\"{nome_base}_Limpo\", tipo='xlsx', pasta='processados')\n",
    "print(f\"   âœ… {arquivo_limpo.name}\")\n",
    "\n",
    "# 2ï¸âƒ£  DICIONÃRIO DE CAMPOS\n",
    "print(\"\\n2ï¸âƒ£  DicionÃ¡rio de campos...\")\n",
    "registros_dict = []\n",
    "\n",
    "for col in df_limpo.columns:\n",
    "    tipo_info = tipos_detectados.get(col, {})\n",
    "    valores_exemplo = df_limpo[col].dropna().unique()[:3].tolist()\n",
    "\n",
    "    registros_dict.append({\n",
    "        'Coluna': col,\n",
    "        'Tipo_Detectado': tipo_info.get('campo_detectado', 'DESCONHECIDO'),\n",
    "        'Confianca_%': tipo_info.get('confianca', 0.0) * 100,\n",
    "        'Score_Conteudo_%': tipo_info.get('score_conteudo', 0.0) * 100,\n",
    "        'Score_Nome_%': tipo_info.get('score_nome', 0.0) * 100,\n",
    "        'Metodo': tipo_info.get('metodo', 'N/A'),\n",
    "        'Ambiguidade': 'Sim' if tipo_info.get('ambiguidade') else 'NÃ£o',\n",
    "        'Dtype_Pandas': str(df_limpo[col].dtype),\n",
    "        'Valores_Unicos': df_limpo[col].nunique(),\n",
    "        'Nulos_Qtd': df_limpo[col].isna().sum(),\n",
    "        'Nulos_%': (df_limpo[col].isna().sum() / len(df_limpo)) * 100,\n",
    "        'Exemplo_1': str(valores_exemplo[0]) if len(valores_exemplo) > 0 else None,\n",
    "        'Exemplo_2': str(valores_exemplo[1]) if len(valores_exemplo) > 1 else None,\n",
    "        'Exemplo_3': str(valores_exemplo[2]) if len(valores_exemplo) > 2 else None\n",
    "    })\n",
    "\n",
    "df_dict = pd.DataFrame(registros_dict)\n",
    "arquivo_dict = fm.salvar(df_dict, f\"DICT_{nome_base}\", tipo='xlsx', pasta='outputs')\n",
    "print(f\"   âœ… {arquivo_dict.name}\")\n",
    "\n",
    "# 3ï¸âƒ£  LOG DE PROCESSAMENTO (COM VERIFICAÃ‡ÃƒO DEFENSIVA)\n",
    "print(\"\\n3ï¸âƒ£  Log de processamento...\")\n",
    "\n",
    "# âœ… VERIFICAÃ‡ÃƒO DEFENSIVA - garantir que variÃ¡veis existam\n",
    "try:\n",
    "    # Tentar usar as variÃ¡veis da CÃ©lula 8\n",
    "    _linha_cab_ini = linha_cabecalho_inicio\n",
    "    _linha_cab_fim = linha_cabecalho_fim\n",
    "    _idx_cab_ini = idx_cab_inicio\n",
    "    _idx_cab_fim = idx_cab_fim\n",
    "    _col_ini = col_inicio\n",
    "    _col_fim = col_fim\n",
    "    _idx_col_ini = idx_col_inicio\n",
    "    _idx_col_fim = idx_col_fim\n",
    "    _linha_dados_ini_excel = config.get('linha_dados_inicio', linha_cabecalho_inicio + 1)\n",
    "    _idx_dados_ini = idx_dados_inicio\n",
    "except NameError:\n",
    "    # Se nÃ£o existirem, usar valores padrÃ£o/detectados\n",
    "    print(\"   âš ï¸  Algumas variÃ¡veis nÃ£o encontradas - usando valores padrÃ£o\")\n",
    "    _linha_cab_ini = 1\n",
    "    _linha_cab_fim = 1\n",
    "    _idx_cab_ini = 0\n",
    "    _idx_cab_fim = 0\n",
    "    _col_ini = 1\n",
    "    _col_fim = len(df_bruto.columns)\n",
    "    _idx_col_ini = 0\n",
    "    _idx_col_fim = len(df_bruto.columns)\n",
    "    _linha_dados_ini_excel = 2\n",
    "    _idx_dados_ini = 1\n",
    "\n",
    "log_processamento = {\n",
    "    'Arquivo_Original': arquivo_selecionado.name,\n",
    "    'Caminho_Original': str(arquivo_selecionado),\n",
    "    'Sheet_Processada': sheet_nome,\n",
    "    'Metodo_Carga': metodo_carga,\n",
    "\n",
    "    # CabeÃ§alho\n",
    "    'Linha_Cabecalho_Inicio_Excel': _linha_cab_ini,\n",
    "    'Linha_Cabecalho_Fim_Excel': _linha_cab_fim,\n",
    "    'Indice_Cabecalho_Inicio_Python': _idx_cab_ini,\n",
    "    'Indice_Cabecalho_Fim_Python': _idx_cab_fim,\n",
    "\n",
    "    # Colunas\n",
    "    'Coluna_Inicio_Excel': _col_ini,\n",
    "    'Coluna_Fim_Excel': _col_fim,\n",
    "    'Indice_Coluna_Inicio_Python': _idx_col_ini,\n",
    "    'Indice_Coluna_Fim_Python': _idx_col_fim,\n",
    "\n",
    "    # Dados\n",
    "    'Linha_Dados_Inicio_Excel': _linha_dados_ini_excel,\n",
    "    'Indice_Dados_Inicio_Python': _idx_dados_ini,\n",
    "\n",
    "    # Contadores\n",
    "    'Registros_Bruto': len(df_bruto),\n",
    "    'Colunas_Bruto': len(df_bruto.columns),\n",
    "    'Registros_Limpo': len(df_limpo),\n",
    "    'Colunas_Limpo': len(df_limpo.columns),\n",
    "    'Operacoes_Limpeza': ', '.join(log_limpeza) if 'log_limpeza' in locals() and log_limpeza else 'Nenhuma',\n",
    "\n",
    "    # Timestamp\n",
    "    'Timestamp': fm.timestamp,\n",
    "    'Data_Processamento': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "df_log = pd.DataFrame([log_processamento])\n",
    "arquivo_log = fm.salvar(df_log, f\"LOG_{nome_base}\", tipo='xlsx', pasta='logs')\n",
    "print(f\"   âœ… {arquivo_log.name}\")\n",
    "\n",
    "# 4ï¸âƒ£  CÃ“DIGO PYTHON PARA REPRODUÃ‡ÃƒO\n",
    "print(\"\\n4ï¸âƒ£  CÃ³digo de reproduÃ§Ã£o...\")\n",
    "codigo_reprod = f'''# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CÃ“DIGO DE REPRODUÃ‡ÃƒO - Gerado automaticamente\n",
    "# Arquivo: {arquivo_selecionado.name}\n",
    "# Sheet: {sheet_nome}\n",
    "# Data: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "arquivo = Path(r\"{arquivo_selecionado}\")\n",
    "sheet = \"{sheet_nome}\"\n",
    "\n",
    "# Range de extraÃ§Ã£o (Ã­ndices Python - comeÃ§a em 0)\n",
    "linha_cabecalho_inicio = {_idx_cab_ini}\n",
    "linha_cabecalho_fim = {_idx_cab_fim}\n",
    "col_inicio = {_idx_col_ini}\n",
    "col_fim = {_idx_col_fim}\n",
    "linha_dados_inicio = {_idx_dados_ini}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CARREGAMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"ğŸ“‚ Carregando: {{arquivo.name}}\")\n",
    "print(f\"ğŸ“„ Sheet: {{sheet}}\")\n",
    "\n",
    "if linha_cabecalho_inicio == linha_cabecalho_fim:\n",
    "    # CASO 1: CabeÃ§alho em 1 linha\n",
    "    print(f\"ğŸ“‹ CabeÃ§alho: Linha {{linha_cabecalho_inicio + 1}} (Excel)\")\n",
    "\n",
    "    df = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=linha_cabecalho_inicio,\n",
    "        usecols=range(col_inicio, col_fim)\n",
    "    )\n",
    "\n",
    "    # Pular linhas entre cabeÃ§alho e dados\n",
    "    linhas_pular = linha_dados_inicio - linha_cabecalho_inicio - 1\n",
    "    if linhas_pular > 0:\n",
    "        print(f\"â­ï¸  Pulando {{linhas_pular}} linhas\")\n",
    "        df = df.iloc[linhas_pular:].copy()\n",
    "else:\n",
    "    # CASO 2: CabeÃ§alho em mÃºltiplas linhas\n",
    "    print(f\"ğŸ“‹ CabeÃ§alho: Linhas {{linha_cabecalho_inicio + 1}} a {{linha_cabecalho_fim + 1}} (Excel)\")\n",
    "\n",
    "    df_temp = pd.read_excel(\n",
    "        arquivo,\n",
    "        sheet_name=sheet,\n",
    "        header=None,\n",
    "        usecols=range(col_inicio, col_fim)\n",
    "    )\n",
    "\n",
    "    # Combinar linhas do cabeÃ§alho\n",
    "    cabecalho = df_temp.iloc[linha_cabecalho_inicio:linha_cabecalho_fim+1].values\n",
    "    cab_final = []\n",
    "\n",
    "    for col_idx in range(cabecalho.shape[1]):\n",
    "        partes = [\n",
    "            str(linha[col_idx]).strip()\n",
    "            for linha in cabecalho\n",
    "            if str(linha[col_idx]).strip() not in ['', 'nan', 'None']\n",
    "        ]\n",
    "        cab_final.append(' - '.join(partes) if partes else f'Col_{{col_idx}}')\n",
    "\n",
    "    # Extrair dados\n",
    "    df = df_temp.iloc[linha_dados_inicio:].copy()\n",
    "    df.columns = cab_final\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Carregado: {{len(df):,}} registros Ã— {{len(df.columns)}} colunas\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VALIDAÃ‡ÃƒO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "colunas_esperadas = {df_limpo.columns.tolist()}\n",
    "\n",
    "if df.columns.tolist() == colunas_esperadas:\n",
    "    print(\"âœ… Estrutura validada - colunas correspondem!\")\n",
    "else:\n",
    "    print(\"âš ï¸  DiferenÃ§a na estrutura:\")\n",
    "\n",
    "    extras = set(df.columns) - set(colunas_esperadas)\n",
    "    if extras:\n",
    "        print(f\"   Colunas extras: {{extras}}\")\n",
    "\n",
    "    faltando = set(colunas_esperadas) - set(df.columns)\n",
    "    if faltando:\n",
    "        print(f\"   Colunas faltando: {{faltando}}\")\n",
    "\n",
    "print(f\"\\\\nğŸ“Š Shape: {{df.shape}}\")\n",
    "print(f\"ğŸ’¾ MemÃ³ria: {{df.memory_usage(deep=True).sum() / 1024**2:.2f}} MB\")\n",
    "'''\n",
    "\n",
    "arquivo_codigo = fm.pastas['codigos_integracao'] / f\"REPROD_{nome_base}_{fm.timestamp}.py\"\n",
    "with open(arquivo_codigo, 'w', encoding='utf-8') as f:\n",
    "    f.write(codigo_reprod)\n",
    "\n",
    "print(f\"   âœ… {arquivo_codigo.name}\")\n",
    "\n",
    "# 5ï¸âƒ£  ATUALIZAR DICIONÃRIO MASTER\n",
    "print(\"\\n5ï¸âƒ£  Atualizando dicionÃ¡rio master...\")\n",
    "dicionario.atualizar_historico({\n",
    "    'arquivo': arquivo_selecionado.name,\n",
    "    'sheet': sheet_nome,\n",
    "    'timestamp': fm.timestamp,\n",
    "    'colunas': df_limpo.columns.tolist(),\n",
    "    'registros': len(df_limpo),\n",
    "    'tipos': {col: info['campo_detectado'] for col, info in tipos_detectados.items()}\n",
    "})\n",
    "print(f\"   âœ… HistÃ³rico atualizado\")\n",
    "\n",
    "# 6ï¸âƒ£  RESUMO DE ARQUIVOS GERADOS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‚ ARQUIVOS GERADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "arquivos_gerados = [\n",
    "    ('ğŸ“Š Dados Limpos', arquivo_limpo),\n",
    "    ('ğŸ“– DicionÃ¡rio de Campos', arquivo_dict),\n",
    "    ('ğŸ“‹ Log de Processamento', arquivo_log),\n",
    "    ('ğŸ CÃ³digo de ReproduÃ§Ã£o', arquivo_codigo)\n",
    "]\n",
    "\n",
    "for emoji_desc, path in arquivos_gerados:\n",
    "    print(f\"\\n{emoji_desc}\")\n",
    "    print(f\"   ğŸ“ {path.name}\")\n",
    "    print(f\"   ğŸ“‚ {path.parent}\")\n",
    "    print(f\"   ğŸ“ {path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… EXPORTAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# VariÃ¡vel global para uso posterior\n",
    "df_resultado = df_limpo.copy()\n",
    "\n",
    "print(f\"\\nğŸ’¡ Dataset disponÃ­vel em: df_resultado\")\n",
    "print(f\"   Shape: {df_resultado.shape}\")\n",
    "print(f\"   MemÃ³ria: {df_resultado.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ],
   "id": "a7de448725d158e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RELATÃ“RIO FINAL - RESUMO VISUAL COMPLETO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"â•”\" + \"=\"*68 + \"â•—\")\n",
    "print(\"â•‘\" + \" ğŸ“‹ RELATÃ“RIO FINAL - PROCESSAMENTO CONCLUÃDO\".center(78) + \"â•‘\")\n",
    "print(\"â•š\" + \"=\"*68 + \"â•\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INFORMAÃ‡Ã•ES DO ARQUIVO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ“ INFORMAÃ‡Ã•ES DO ARQUIVO\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "print(f\"â”ƒ  Nome: {arquivo_selecionado.name:<68}â”ƒ\")\n",
    "print(f\"â”ƒ  Sheet: {sheet_nome:<67}â”ƒ\")\n",
    "\n",
    "# âœ… CÃ“DIGO DEFENSIVO - verificar se variÃ¡veis existem\n",
    "try:\n",
    "    _linha_cab_ini = linha_cabecalho_inicio\n",
    "    _idx_cab_ini = idx_cab_inicio\n",
    "    _linha_dados = config.get('linha_dados_inicio', linha_cabecalho_inicio + 1)\n",
    "    print(f\"â”ƒ  CabeÃ§alho: Linha {_linha_cab_ini} (Excel) / Ãndice {_idx_cab_ini} (Python){' '*20}â”ƒ\")\n",
    "    print(f\"â”ƒ  Dados: A partir da linha {_linha_dados} (Excel){' '*37}â”ƒ\")\n",
    "except NameError:\n",
    "    print(f\"â”ƒ  CabeÃ§alho: [informaÃ§Ã£o nÃ£o disponÃ­vel]{' '*36}â”ƒ\")\n",
    "\n",
    "print(f\"â”ƒ  MÃ©todo: {metodo_carga:<66}â”ƒ\")\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ESTATÃSTICAS DE PROCESSAMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ“Š ESTATÃSTICAS DE PROCESSAMENTO\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "print(f\"â”ƒ  Registros originais: {len(df_bruto):>6,}{' '*47}â”ƒ\")\n",
    "print(f\"â”ƒ  Registros finais:    {len(df_limpo):>6,}{' '*47}â”ƒ\")\n",
    "print(f\"â”ƒ  DiferenÃ§a:           {len(df_bruto) - len(df_limpo):>6,} removidos{' '*39}â”ƒ\")\n",
    "print(\"â”ƒ\" + \"â”€\"*68 + \"â”ƒ\")\n",
    "print(f\"â”ƒ  Colunas originais:   {len(df_bruto.columns):>6,}{' '*47}â”ƒ\")\n",
    "print(f\"â”ƒ  Colunas finais:      {len(df_limpo.columns):>6,}{' '*47}â”ƒ\")\n",
    "print(f\"â”ƒ  DiferenÃ§a:           {len(df_bruto.columns) - len(df_limpo.columns):>6,} removidas{' '*38}â”ƒ\")\n",
    "print(\"â”ƒ\" + \"â”€\"*68 + \"â”ƒ\")\n",
    "\n",
    "memoria_mb = df_limpo.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"â”ƒ  MemÃ³ria em uso:      {memoria_mb:>6.2f} MB{' '*43}â”ƒ\")\n",
    "\n",
    "duplicatas = df_limpo.duplicated().sum()\n",
    "print(f\"â”ƒ  Linhas duplicadas:   {duplicatas:>6,}{' '*47}â”ƒ\")\n",
    "\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# QUALIDADE DOS DADOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ” QUALIDADE DOS DADOS\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "total_nulos = df_limpo.isnull().sum().sum()\n",
    "total_celulas = len(df_limpo) * len(df_limpo.columns)\n",
    "pct_nulos = (total_nulos / total_celulas) * 100\n",
    "\n",
    "print(f\"â”ƒ  Total de valores nulos: {total_nulos:>6,} ({pct_nulos:>5.2f}%){' '*35}â”ƒ\")\n",
    "\n",
    "colunas_com_nulos = df_limpo.isnull().sum()\n",
    "colunas_com_nulos = colunas_com_nulos[colunas_com_nulos > 0]\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"â”ƒ  Colunas com nulos:      {len(colunas_com_nulos):>6,}{' '*47}â”ƒ\")\n",
    "else:\n",
    "    print(f\"â”ƒ  âœ… Nenhuma coluna com valores nulos!{' '*39}â”ƒ\")\n",
    "\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# DETECÃ‡ÃƒO DE TIPOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ”¬ DETECÃ‡ÃƒO DE TIPOS\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "alta = sum(1 for info in tipos_detectados.values() if info['confianca'] >= 0.90)\n",
    "media = sum(1 for info in tipos_detectados.values() if 0.70 <= info['confianca'] < 0.90)\n",
    "baixa = sum(1 for info in tipos_detectados.values() if info['confianca'] < 0.70)\n",
    "\n",
    "print(f\"â”ƒ  âœ… Alta confianÃ§a (â‰¥90%):   {alta:>3} colunas{' '*41}â”ƒ\")\n",
    "print(f\"â”ƒ  âš ï¸  MÃ©dia confianÃ§a (70-90%): {media:>3} colunas{' '*41}â”ƒ\")\n",
    "print(f\"â”ƒ  â“ Baixa confianÃ§a (<70%):   {baixa:>3} colunas{' '*41}â”ƒ\")\n",
    "\n",
    "print(\"â”ƒ\" + \"â”€\"*68 + \"â”ƒ\")\n",
    "\n",
    "# Top 5 tipos detectados\n",
    "tipos_resumo = {}\n",
    "for info in tipos_detectados.values():\n",
    "    tipo = info['campo_detectado']\n",
    "    tipos_resumo[tipo] = tipos_resumo.get(tipo, 0) + 1\n",
    "\n",
    "print(\"â”ƒ  Top 5 tipos mais comuns:{' '*53}â”ƒ\")\n",
    "for i, (tipo, count) in enumerate(sorted(tipos_resumo.items(), key=lambda x: x[1], reverse=True)[:5], 1):\n",
    "    print(f\"â”ƒ     {i}. {tipo:<25} ({count:>2} colunas){' '*24}â”ƒ\")\n",
    "\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPERAÃ‡Ã•ES DE LIMPEZA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ§¹ OPERAÃ‡Ã•ES DE LIMPEZA REALIZADAS\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "if 'log_limpeza' in locals() and log_limpeza:\n",
    "    for i, operacao in enumerate(log_limpeza, 1):\n",
    "        # Quebrar linhas longas\n",
    "        if len(operacao) > 70:\n",
    "            print(f\"â”ƒ  {i}. {operacao[:67]}...â”ƒ\")\n",
    "        else:\n",
    "            print(f\"â”ƒ  {i}. {operacao:<73}â”ƒ\")\n",
    "else:\n",
    "    print(f\"â”ƒ  âœ… Nenhuma limpeza necessÃ¡ria - dados jÃ¡ estavam limpos!{' '*18}â”ƒ\")\n",
    "\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ARQUIVOS GERADOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ“‚ ARQUIVOS GERADOS\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "arquivos_info = [\n",
    "    (\"Dados Limpos\", arquivo_limpo),\n",
    "    (\"DicionÃ¡rio de Campos\", arquivo_dict),\n",
    "    (\"Log de Processamento\", arquivo_log),\n",
    "    (\"CÃ³digo de ReproduÃ§Ã£o\", arquivo_codigo)\n",
    "]\n",
    "\n",
    "for descricao, path in arquivos_info:\n",
    "    tamanho_kb = path.stat().st_size / 1024\n",
    "    nome_arquivo = path.name\n",
    "\n",
    "    # Truncar nome se muito longo\n",
    "    if len(nome_arquivo) > 50:\n",
    "        nome_arquivo = nome_arquivo[:47] + \"...\"\n",
    "\n",
    "    print(f\"â”ƒ  {descricao}:{' '*(30 - len(descricao))}â”ƒ\")\n",
    "    print(f\"â”ƒ     ğŸ“„ {nome_arquivo:<68}â”ƒ\")\n",
    "    print(f\"â”ƒ     ğŸ“ {tamanho_kb:>6.1f} KB{' '*61}â”ƒ\")\n",
    "    print(\"â”ƒ\" + \"â”€\"*68 + \"â”ƒ\")\n",
    "\n",
    "# Remover Ãºltima linha divisÃ³ria\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PRÃ“XIMOS PASSOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ”\" + \"â”\"*68 + \"â”“\")\n",
    "print(\"â”ƒ\" + \" ğŸ’¡ PRÃ“XIMOS PASSOS RECOMENDADOS\".center(78) + \"â”ƒ\")\n",
    "print(\"â”£\" + \"â”\"*68 + \"â”«\")\n",
    "\n",
    "sugestoes = []\n",
    "\n",
    "# SugestÃµes baseadas em qualidade\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    sugestoes.append(\"Tratar valores nulos nas colunas identificadas\")\n",
    "\n",
    "if baixa > 0:\n",
    "    sugestoes.append(f\"Revisar {baixa} campos com baixa confianÃ§a na detecÃ§Ã£o\")\n",
    "\n",
    "if duplicatas > 0:\n",
    "    sugestoes.append(\"Investigar e remover linhas duplicadas\")\n",
    "\n",
    "# SugestÃµes padrÃ£o\n",
    "sugestoes.extend([\n",
    "    \"Revisar o dicionÃ¡rio de campos gerado\",\n",
    "    \"Validar tipos detectados conforme necessidade\",\n",
    "    \"Utilizar cÃ³digo de reproduÃ§Ã£o para reprocessar\"\n",
    "])\n",
    "\n",
    "for i, sugestao in enumerate(sugestoes[:6], 1):  # MÃ¡ximo 6 sugestÃµes\n",
    "    print(f\"â”ƒ  {i}. {sugestao:<73}â”ƒ\")\n",
    "\n",
    "print(\"â”—\" + \"â”\"*68 + \"â”›\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# RODAPÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ•”\" + \"=\"*68 + \"â•—\")\n",
    "print(\"â•‘\" + \" âœ… PROCESSAMENTO CONCLUÃDO COM SUCESSO!\".center(78) + \"â•‘\")\n",
    "print(\"â• \" + \"=\"*68 + \"â•£\")\n",
    "print(\"â•‘\" + f\" Timestamp: {fm.timestamp}\".ljust(78) + \"â•‘\")\n",
    "print(\"â•‘\" + f\" Dataset disponÃ­vel em: df_resultado\".ljust(78) + \"â•‘\")\n",
    "print(\"â•‘\" + f\" Shape: {df_resultado.shape}\".ljust(78) + \"â•‘\")\n",
    "print(\"â•š\" + \"=\"*68 + \"â•\")\n",
    "\n",
    "print(\"\\n\")"
   ],
   "id": "57bb5f7ac9d4eca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ABERTURA AUTOMÃTICA DA PASTA DESTINO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Abrir pasta de outputs automaticamente\n",
    "fm.abrir_pasta('outputs')\n",
    "\n",
    "print(\"\\nğŸ’¡ TIP: Se a pasta nÃ£o abriu, o caminho estÃ¡ exibido no relatÃ³rio acima!\")"
   ],
   "id": "80605530285065dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_resultado",
   "id": "4c205ea0a09c0231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7608733d363b944b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
